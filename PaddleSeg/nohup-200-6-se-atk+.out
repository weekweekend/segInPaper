2023-02-04 23:56:45 [INFO]	
------------Environment Information-------------
platform: Linux-5.4.0-113-generic-x86_64-with-glibc2.17
Python: 3.8.16 (default, Jan 17 2023, 23:13:24) [GCC 11.2.0]
Paddle compiled with cuda: True
NVCC: Build cuda_11.3.r11.3/compiler.29745058_0
cudnn: 8.4
GPUs used: 1
CUDA_VISIBLE_DEVICES: 1
GPU: ['GPU 0: NVIDIA GeForce', 'GPU 1: NVIDIA GeForce']
GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
PaddleSeg: 2.5.0
PaddlePaddle: 2.4.1
OpenCV: 4.7.0
------------------------------------------------
2023-02-04 23:56:45 [INFO]	
---------------Config Information---------------
batch_size: 6
iters: 250000
loss:
  coef:
  - 1
  - 1
  types:
  - ignore_index: 255
    type: CrossEntropyLoss
  - ignore_index: 255
    type: PointCrossEntropyLoss
lr_scheduler:
  end_lr: 0
  learning_rate: 0.01
  power: 0.9
  type: PolynomialDecay
model:
  backbone:
    output_stride: 8
    pretrained: https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz
    type: ResNet50_vd
  backbone_indices:
  - 0
  - 1
  - 2
  - 3
  type: PointRend
optimizer:
  momentum: 0.9
  type: sgd
  weight_decay: 0.0005
train_dataset:
  dataset_root: data/cocostuff/
  mode: train
  transforms:
  - max_scale_factor: 2.0
    min_scale_factor: 0.5
    scale_step_size: 0.25
    type: ResizeStepScaling
  - crop_size:
    - 520
    - 520
    type: RandomPaddingCrop
  - type: RandomHorizontalFlip
  - brightness_range: 0.5
    contrast_range: 0.5
    saturation_range: 0.5
    type: RandomDistort
  - type: RandomAttack
  - type: Normalize
  type: CocoStuff
val_dataset:
  dataset_root: data/cocostuff/
  mode: val
  transforms:
  - type: Normalize
  type: CocoStuff
------------------------------------------------
W0204 23:56:45.057595 378375 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.3
W0204 23:56:45.057627 378375 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.
2023-02-04 23:56:45 [INFO]	Loading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz
2023-02-04 23:56:46 [WARNING]	bb_0_0.se.fc1.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_0_0.se.fc1.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_0_0.se.fc2.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_0_0.se.fc2.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_0_1.se.fc1.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_0_1.se.fc1.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_0_1.se.fc2.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_0_1.se.fc2.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_0_2.se.fc1.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_0_2.se.fc1.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_0_2.se.fc2.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_0_2.se.fc2.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_1_0.se.fc1.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_1_0.se.fc1.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_1_0.se.fc2.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_1_0.se.fc2.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_1_1.se.fc1.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_1_1.se.fc1.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_1_1.se.fc2.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_1_1.se.fc2.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_1_2.se.fc1.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_1_2.se.fc1.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_1_2.se.fc2.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_1_2.se.fc2.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_1_3.se.fc1.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_1_3.se.fc1.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_1_3.se.fc2.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_1_3.se.fc2.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_0.se.fc1.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_0.se.fc1.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_0.se.fc2.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_0.se.fc2.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_1.se.fc1.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_1.se.fc1.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_1.se.fc2.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_1.se.fc2.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_2.se.fc1.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_2.se.fc1.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_2.se.fc2.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_2.se.fc2.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_3.se.fc1.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_3.se.fc1.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_3.se.fc2.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_3.se.fc2.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_4.se.fc1.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_4.se.fc1.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_4.se.fc2.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_4.se.fc2.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_5.se.fc1.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_5.se.fc1.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_5.se.fc2.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_2_5.se.fc2.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_3_0.se.fc1.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_3_0.se.fc1.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_3_0.se.fc2.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_3_0.se.fc2.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_3_1.se.fc1.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_3_1.se.fc1.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_3_1.se.fc2.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_3_1.se.fc2.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_3_2.se.fc1.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_3_2.se.fc1.bias is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_3_2.se.fc2.weight is not in pretrained model
2023-02-04 23:56:46 [WARNING]	bb_3_2.se.fc2.bias is not in pretrained model
2023-02-04 23:56:46 [INFO]	There are 275/339 variables loaded into ResNet_vd.
PointRend(
  (backbone): ResNet_vd(
    (conv1_1): ConvBNLayer(
      (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
      (_conv): Conv2D(3, 32, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
      (_batch_norm): SyncBatchNorm(num_features=32, momentum=0.9, epsilon=1e-05)
      (_act_op): Activation(
        (act_func): ReLU()
      )
    )
    (conv1_2): ConvBNLayer(
      (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
      (_conv): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (_batch_norm): SyncBatchNorm(num_features=32, momentum=0.9, epsilon=1e-05)
      (_act_op): Activation(
        (act_func): ReLU()
      )
    )
    (conv1_3): ConvBNLayer(
      (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
      (_conv): Conv2D(32, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (_batch_norm): SyncBatchNorm(num_features=64, momentum=0.9, epsilon=1e-05)
      (_act_op): Activation(
        (act_func): ReLU()
      )
    )
    (pool2d_max): MaxPool2D(kernel_size=3, stride=2, padding=1)
    (bb_0_0): BottleneckBlock(
      (conv0): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(64, 64, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=64, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv1): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=64, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv2): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (short): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (add): Add()
      (relu): Activation(
        (act_func): ReLU()
      )
      (se): SEModule(
        (avg_pool): AdaptiveAvgPool2D(output_size=1)
        (fc1): Conv2D(256, 32, kernel_size=[1, 1], data_format=NCHW)
        (relu): ReLU()
        (fc2): Conv2D(32, 256, kernel_size=[1, 1], data_format=NCHW)
        (sigmoid): Sigmoid()
      )
    )
    (bb_0_1): BottleneckBlock(
      (conv0): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=64, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv1): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=64, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv2): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (add): Add()
      (relu): Activation(
        (act_func): ReLU()
      )
      (se): SEModule(
        (avg_pool): AdaptiveAvgPool2D(output_size=1)
        (fc1): Conv2D(256, 32, kernel_size=[1, 1], data_format=NCHW)
        (relu): ReLU()
        (fc2): Conv2D(32, 256, kernel_size=[1, 1], data_format=NCHW)
        (sigmoid): Sigmoid()
      )
    )
    (bb_0_2): BottleneckBlock(
      (conv0): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=64, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv1): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=64, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv2): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (add): Add()
      (relu): Activation(
        (act_func): ReLU()
      )
      (se): SEModule(
        (avg_pool): AdaptiveAvgPool2D(output_size=1)
        (fc1): Conv2D(256, 32, kernel_size=[1, 1], data_format=NCHW)
        (relu): ReLU()
        (fc2): Conv2D(32, 256, kernel_size=[1, 1], data_format=NCHW)
        (sigmoid): Sigmoid()
      )
    )
    (bb_1_0): BottleneckBlock(
      (conv0): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(256, 128, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=128, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv1): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(128, 128, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=128, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv2): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=512, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (short): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(256, 512, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=512, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (add): Add()
      (relu): Activation(
        (act_func): ReLU()
      )
      (se): SEModule(
        (avg_pool): AdaptiveAvgPool2D(output_size=1)
        (fc1): Conv2D(512, 64, kernel_size=[1, 1], data_format=NCHW)
        (relu): ReLU()
        (fc2): Conv2D(64, 512, kernel_size=[1, 1], data_format=NCHW)
        (sigmoid): Sigmoid()
      )
    )
    (bb_1_1): BottleneckBlock(
      (conv0): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=128, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv1): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=128, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv2): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=512, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (add): Add()
      (relu): Activation(
        (act_func): ReLU()
      )
      (se): SEModule(
        (avg_pool): AdaptiveAvgPool2D(output_size=1)
        (fc1): Conv2D(512, 64, kernel_size=[1, 1], data_format=NCHW)
        (relu): ReLU()
        (fc2): Conv2D(64, 512, kernel_size=[1, 1], data_format=NCHW)
        (sigmoid): Sigmoid()
      )
    )
    (bb_1_2): BottleneckBlock(
      (conv0): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=128, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv1): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=128, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv2): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=512, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (add): Add()
      (relu): Activation(
        (act_func): ReLU()
      )
      (se): SEModule(
        (avg_pool): AdaptiveAvgPool2D(output_size=1)
        (fc1): Conv2D(512, 64, kernel_size=[1, 1], data_format=NCHW)
        (relu): ReLU()
        (fc2): Conv2D(64, 512, kernel_size=[1, 1], data_format=NCHW)
        (sigmoid): Sigmoid()
      )
    )
    (bb_1_3): BottleneckBlock(
      (conv0): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=128, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv1): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=128, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv2): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=512, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (add): Add()
      (relu): Activation(
        (act_func): ReLU()
      )
      (se): SEModule(
        (avg_pool): AdaptiveAvgPool2D(output_size=1)
        (fc1): Conv2D(512, 64, kernel_size=[1, 1], data_format=NCHW)
        (relu): ReLU()
        (fc2): Conv2D(64, 512, kernel_size=[1, 1], data_format=NCHW)
        (sigmoid): Sigmoid()
      )
    )
    (bb_2_0): BottleneckBlock(
      (conv0): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(512, 256, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv1): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(256, 256, kernel_size=[3, 3], padding=2, dilation=[2, 2], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv2): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=1024, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (short): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(512, 1024, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=1024, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (add): Add()
      (relu): Activation(
        (act_func): ReLU()
      )
      (se): SEModule(
        (avg_pool): AdaptiveAvgPool2D(output_size=1)
        (fc1): Conv2D(1024, 128, kernel_size=[1, 1], data_format=NCHW)
        (relu): ReLU()
        (fc2): Conv2D(128, 1024, kernel_size=[1, 1], data_format=NCHW)
        (sigmoid): Sigmoid()
      )
    )
    (bb_2_1): BottleneckBlock(
      (conv0): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv1): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(256, 256, kernel_size=[3, 3], padding=2, dilation=[2, 2], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv2): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=1024, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (add): Add()
      (relu): Activation(
        (act_func): ReLU()
      )
      (se): SEModule(
        (avg_pool): AdaptiveAvgPool2D(output_size=1)
        (fc1): Conv2D(1024, 128, kernel_size=[1, 1], data_format=NCHW)
        (relu): ReLU()
        (fc2): Conv2D(128, 1024, kernel_size=[1, 1], data_format=NCHW)
        (sigmoid): Sigmoid()
      )
    )
    (bb_2_2): BottleneckBlock(
      (conv0): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv1): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(256, 256, kernel_size=[3, 3], padding=2, dilation=[2, 2], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv2): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=1024, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (add): Add()
      (relu): Activation(
        (act_func): ReLU()
      )
      (se): SEModule(
        (avg_pool): AdaptiveAvgPool2D(output_size=1)
        (fc1): Conv2D(1024, 128, kernel_size=[1, 1], data_format=NCHW)
        (relu): ReLU()
        (fc2): Conv2D(128, 1024, kernel_size=[1, 1], data_format=NCHW)
        (sigmoid): Sigmoid()
      )
    )
    (bb_2_3): BottleneckBlock(
      (conv0): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv1): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(256, 256, kernel_size=[3, 3], padding=2, dilation=[2, 2], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv2): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=1024, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (add): Add()
      (relu): Activation(
        (act_func): ReLU()
      )
      (se): SEModule(
        (avg_pool): AdaptiveAvgPool2D(output_size=1)
        (fc1): Conv2D(1024, 128, kernel_size=[1, 1], data_format=NCHW)
        (relu): ReLU()
        (fc2): Conv2D(128, 1024, kernel_size=[1, 1], data_format=NCHW)
        (sigmoid): Sigmoid()
      )
    )
    (bb_2_4): BottleneckBlock(
      (conv0): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv1): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(256, 256, kernel_size=[3, 3], padding=2, dilation=[2, 2], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv2): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=1024, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (add): Add()
      (relu): Activation(
        (act_func): ReLU()
      )
      (se): SEModule(
        (avg_pool): AdaptiveAvgPool2D(output_size=1)
        (fc1): Conv2D(1024, 128, kernel_size=[1, 1], data_format=NCHW)
        (relu): ReLU()
        (fc2): Conv2D(128, 1024, kernel_size=[1, 1], data_format=NCHW)
        (sigmoid): Sigmoid()
      )
    )
    (bb_2_5): BottleneckBlock(
      (conv0): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv1): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(256, 256, kernel_size=[3, 3], padding=2, dilation=[2, 2], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv2): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=1024, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (add): Add()
      (relu): Activation(
        (act_func): ReLU()
      )
      (se): SEModule(
        (avg_pool): AdaptiveAvgPool2D(output_size=1)
        (fc1): Conv2D(1024, 128, kernel_size=[1, 1], data_format=NCHW)
        (relu): ReLU()
        (fc2): Conv2D(128, 1024, kernel_size=[1, 1], data_format=NCHW)
        (sigmoid): Sigmoid()
      )
    )
    (bb_3_0): BottleneckBlock(
      (conv0): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(1024, 512, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=512, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv1): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(512, 512, kernel_size=[3, 3], padding=4, dilation=[4, 4], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=512, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv2): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=2048, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (short): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(1024, 2048, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=2048, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (add): Add()
      (relu): Activation(
        (act_func): ReLU()
      )
      (se): SEModule(
        (avg_pool): AdaptiveAvgPool2D(output_size=1)
        (fc1): Conv2D(2048, 256, kernel_size=[1, 1], data_format=NCHW)
        (relu): ReLU()
        (fc2): Conv2D(256, 2048, kernel_size=[1, 1], data_format=NCHW)
        (sigmoid): Sigmoid()
      )
    )
    (bb_3_1): BottleneckBlock(
      (conv0): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=512, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv1): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(512, 512, kernel_size=[3, 3], padding=4, dilation=[4, 4], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=512, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv2): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=2048, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (add): Add()
      (relu): Activation(
        (act_func): ReLU()
      )
      (se): SEModule(
        (avg_pool): AdaptiveAvgPool2D(output_size=1)
        (fc1): Conv2D(2048, 256, kernel_size=[1, 1], data_format=NCHW)
        (relu): ReLU()
        (fc2): Conv2D(256, 2048, kernel_size=[1, 1], data_format=NCHW)
        (sigmoid): Sigmoid()
      )
    )
    (bb_3_2): BottleneckBlock(
      (conv0): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=512, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv1): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(512, 512, kernel_size=[3, 3], padding=4, dilation=[4, 4], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=512, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation(
          (act_func): ReLU()
        )
      )
      (conv2): ConvBNLayer(
        (_pool2d_avg): AvgPool2D(kernel_size=2, stride=2, padding=0)
        (_conv): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
        (_batch_norm): SyncBatchNorm(num_features=2048, momentum=0.9, epsilon=1e-05)
        (_act_op): Activation()
      )
      (add): Add()
      (relu): Activation(
        (act_func): ReLU()
      )
      (se): SEModule(
        (avg_pool): AdaptiveAvgPool2D(output_size=1)
        (fc1): Conv2D(2048, 256, kernel_size=[1, 1], data_format=NCHW)
        (relu): ReLU()
        (fc2): Conv2D(256, 2048, kernel_size=[1, 1], data_format=NCHW)
        (sigmoid): Sigmoid()
      )
    )
  )
  (neck): FPNNeck(
    (lateral_convs): LayerList(
      (0): Sequential(
        (0): Conv2D(256, 256, kernel_size=[1, 1], data_format=NCHW)
        (1): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (2): ReLU()
      )
      (1): Sequential(
        (0): Conv2D(512, 256, kernel_size=[1, 1], data_format=NCHW)
        (1): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (2): ReLU()
      )
      (2): Sequential(
        (0): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
        (1): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (2): ReLU()
      )
      (3): Sequential(
        (0): Conv2D(2048, 256, kernel_size=[1, 1], data_format=NCHW)
        (1): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
        (2): ReLU()
      )
    )
    (fpn_out): LayerList(
      (0): Sequential(
        (0): ConvBNReLU(
          (_conv): Conv2D(256, 256, kernel_size=[3, 3], padding=same, data_format=NCHW)
          (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
          (_relu): Activation(
            (act_func): ReLU()
          )
        )
      )
      (1): Sequential(
        (0): ConvBNReLU(
          (_conv): Conv2D(256, 256, kernel_size=[3, 3], padding=same, data_format=NCHW)
          (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
          (_relu): Activation(
            (act_func): ReLU()
          )
        )
      )
      (2): Sequential(
        (0): ConvBNReLU(
          (_conv): Conv2D(256, 256, kernel_size=[3, 3], padding=same, data_format=NCHW)
          (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
          (_relu): Activation(
            (act_func): ReLU()
          )
        )
      )
      (3): Sequential(
        (0): ConvBNReLU(
          (_conv): Conv2D(256, 256, kernel_size=[3, 3], padding=same, data_format=NCHW)
          (_batch_norm): SyncBatchNorm(num_features=256, momentum=0.9, epsilon=1e-05)
          (_relu): Activation(
            (act_func): ReLU()
          )
        )
      )
    )
  )
  (pointhead): PointHead(
    (fcs): LayerList(
      (0): ConvModule(
        (_conv): Conv1D(263, 256, kernel_size=[1], data_format=NCL)
      )
      (1): ConvModule(
        (_conv): Conv1D(263, 256, kernel_size=[1], data_format=NCL)
      )
      (2): ConvModule(
        (_conv): Conv1D(263, 256, kernel_size=[1], data_format=NCL)
      )
    )
    (fc_seg): Conv1D(263, 7, kernel_size=[1], data_format=NCL)
  )
  (fpnhead): FPNHead(
    (scale_heads): LayerList(
      (0): Sequential(
        (0): ConvModule(
          (_conv): Conv2D(256, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        )
      )
      (1): Sequential(
        (0): ConvModule(
          (_conv): Conv2D(256, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        )
        (1): Upsample()
      )
      (2): Sequential(
        (0): ConvModule(
          (_conv): Conv2D(256, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        )
        (1): Upsample()
        (2): ConvModule(
          (_conv): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        )
        (3): Upsample()
      )
      (3): Sequential(
        (0): ConvModule(
          (_conv): Conv2D(256, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        )
        (1): Upsample()
        (2): ConvModule(
          (_conv): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        )
        (3): Upsample()
        (4): ConvModule(
          (_conv): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        )
        (5): Upsample()
      )
    )
    (conv_seg): Conv2D(128, 7, kernel_size=[1, 1], data_format=NCHW)
    (dropout): Dropout2D(p=0, data_format=NCHW)
  )
)
2023-02-04 23:56:46 [INFO]	Resume model from output-200-6-se-atk/iter_200000
2023-02-04 23:56:54 [INFO]	[TRAIN] epoch: 2532, iter: 200010/250000, loss: 0.1092, lr: 0.002349, batch_cost: 0.7819, reader_cost: 0.03346, ips: 7.6734 samples/sec | ETA 10:51:28
2023-02-04 23:57:00 [INFO]	[TRAIN] epoch: 2532, iter: 200020/250000, loss: 0.1038, lr: 0.002348, batch_cost: 0.5582, reader_cost: 0.00009, ips: 10.7484 samples/sec | ETA 07:44:59
2023-02-04 23:57:05 [INFO]	[TRAIN] epoch: 2533, iter: 200030/250000, loss: 0.1451, lr: 0.002348, batch_cost: 0.5592, reader_cost: 0.00010, ips: 10.7298 samples/sec | ETA 07:45:42
2023-02-04 23:57:11 [INFO]	[TRAIN] epoch: 2533, iter: 200040/250000, loss: 0.1551, lr: 0.002348, batch_cost: 0.5600, reader_cost: 0.00010, ips: 10.7151 samples/sec | ETA 07:46:15
2023-02-04 23:57:16 [INFO]	[TRAIN] epoch: 2533, iter: 200050/250000, loss: 0.1204, lr: 0.002347, batch_cost: 0.5609, reader_cost: 0.00010, ips: 10.6977 samples/sec | ETA 07:46:55
2023-02-04 23:57:22 [INFO]	[TRAIN] epoch: 2533, iter: 200060/250000, loss: 0.1693, lr: 0.002347, batch_cost: 0.5610, reader_cost: 0.00010, ips: 10.6960 samples/sec | ETA 07:46:54
2023-02-04 23:57:28 [INFO]	[TRAIN] epoch: 2533, iter: 200070/250000, loss: 0.1503, lr: 0.002346, batch_cost: 0.5613, reader_cost: 0.00010, ips: 10.6896 samples/sec | ETA 07:47:05
2023-02-04 23:57:34 [INFO]	[TRAIN] epoch: 2533, iter: 200080/250000, loss: 0.1420, lr: 0.002346, batch_cost: 0.5904, reader_cost: 0.02937, ips: 10.1618 samples/sec | ETA 08:11:15
2023-02-04 23:57:39 [INFO]	[TRAIN] epoch: 2533, iter: 200090/250000, loss: 0.1286, lr: 0.002345, batch_cost: 0.5635, reader_cost: 0.00016, ips: 10.6480 samples/sec | ETA 07:48:43
2023-02-04 23:57:45 [INFO]	[TRAIN] epoch: 2533, iter: 200100/250000, loss: 0.1249, lr: 0.002345, batch_cost: 0.5628, reader_cost: 0.00010, ips: 10.6607 samples/sec | ETA 07:48:04
2023-02-04 23:57:51 [INFO]	[TRAIN] epoch: 2534, iter: 200110/250000, loss: 0.1341, lr: 0.002345, batch_cost: 0.5634, reader_cost: 0.00010, ips: 10.6487 samples/sec | ETA 07:48:30
2023-02-04 23:57:56 [INFO]	[TRAIN] epoch: 2534, iter: 200120/250000, loss: 0.1190, lr: 0.002344, batch_cost: 0.5634, reader_cost: 0.00010, ips: 10.6487 samples/sec | ETA 07:48:24
2023-02-04 23:58:02 [INFO]	[TRAIN] epoch: 2534, iter: 200130/250000, loss: 0.1307, lr: 0.002344, batch_cost: 0.5637, reader_cost: 0.00010, ips: 10.6437 samples/sec | ETA 07:48:32
2023-02-04 23:58:07 [INFO]	[TRAIN] epoch: 2534, iter: 200140/250000, loss: 0.1480, lr: 0.002343, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6404 samples/sec | ETA 07:48:35
2023-02-04 23:58:13 [INFO]	[TRAIN] epoch: 2534, iter: 200150/250000, loss: 0.1489, lr: 0.002343, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6404 samples/sec | ETA 07:48:29
2023-02-04 23:58:19 [INFO]	[TRAIN] epoch: 2534, iter: 200160/250000, loss: 0.1250, lr: 0.002343, batch_cost: 0.5924, reader_cost: 0.02870, ips: 10.1283 samples/sec | ETA 08:12:05
2023-02-04 23:58:25 [INFO]	[TRAIN] epoch: 2534, iter: 200170/250000, loss: 0.1415, lr: 0.002342, batch_cost: 0.5643, reader_cost: 0.00024, ips: 10.6330 samples/sec | ETA 07:48:38
2023-02-04 23:58:30 [INFO]	[TRAIN] epoch: 2534, iter: 200180/250000, loss: 0.1671, lr: 0.002342, batch_cost: 0.5638, reader_cost: 0.00010, ips: 10.6427 samples/sec | ETA 07:48:06
2023-02-04 23:58:36 [INFO]	[TRAIN] epoch: 2535, iter: 200190/250000, loss: 0.1448, lr: 0.002341, batch_cost: 0.5637, reader_cost: 0.00011, ips: 10.6431 samples/sec | ETA 07:48:00
2023-02-04 23:58:42 [INFO]	[TRAIN] epoch: 2535, iter: 200200/250000, loss: 0.1777, lr: 0.002341, batch_cost: 0.5635, reader_cost: 0.00010, ips: 10.6472 samples/sec | ETA 07:47:43
2023-02-04 23:58:47 [INFO]	[TRAIN] epoch: 2535, iter: 200210/250000, loss: 0.1919, lr: 0.002340, batch_cost: 0.5630, reader_cost: 0.00009, ips: 10.6565 samples/sec | ETA 07:47:13
2023-02-04 23:58:53 [INFO]	[TRAIN] epoch: 2535, iter: 200220/250000, loss: 0.1742, lr: 0.002340, batch_cost: 0.5635, reader_cost: 0.00010, ips: 10.6477 samples/sec | ETA 07:47:31
2023-02-04 23:58:58 [INFO]	[TRAIN] epoch: 2535, iter: 200230/250000, loss: 0.1766, lr: 0.002340, batch_cost: 0.5638, reader_cost: 0.00011, ips: 10.6426 samples/sec | ETA 07:47:38
2023-02-04 23:59:04 [INFO]	[TRAIN] epoch: 2535, iter: 200240/250000, loss: 0.1948, lr: 0.002339, batch_cost: 0.6014, reader_cost: 0.03718, ips: 9.9774 samples/sec | ETA 08:18:43
2023-02-04 23:59:10 [INFO]	[TRAIN] epoch: 2535, iter: 200250/250000, loss: 0.1836, lr: 0.002339, batch_cost: 0.5636, reader_cost: 0.00011, ips: 10.6454 samples/sec | ETA 07:47:20
2023-02-04 23:59:16 [INFO]	[TRAIN] epoch: 2535, iter: 200260/250000, loss: 0.2294, lr: 0.002338, batch_cost: 0.5636, reader_cost: 0.00010, ips: 10.6466 samples/sec | ETA 07:47:11
2023-02-04 23:59:21 [INFO]	[TRAIN] epoch: 2536, iter: 200270/250000, loss: 0.1847, lr: 0.002338, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6393 samples/sec | ETA 07:47:25
2023-02-04 23:59:27 [INFO]	[TRAIN] epoch: 2536, iter: 200280/250000, loss: 0.2277, lr: 0.002337, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6351 samples/sec | ETA 07:47:30
2023-02-04 23:59:33 [INFO]	[TRAIN] epoch: 2536, iter: 200290/250000, loss: 0.2706, lr: 0.002337, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6324 samples/sec | ETA 07:47:31
2023-02-04 23:59:38 [INFO]	[TRAIN] epoch: 2536, iter: 200300/250000, loss: 0.2107, lr: 0.002337, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6279 samples/sec | ETA 07:47:38
2023-02-04 23:59:44 [INFO]	[TRAIN] epoch: 2536, iter: 200310/250000, loss: 0.3164, lr: 0.002336, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6356 samples/sec | ETA 07:47:12
2023-02-04 23:59:50 [INFO]	[TRAIN] epoch: 2536, iter: 200320/250000, loss: 0.2822, lr: 0.002336, batch_cost: 0.5955, reader_cost: 0.03101, ips: 10.0762 samples/sec | ETA 08:13:02
2023-02-04 23:59:56 [INFO]	[TRAIN] epoch: 2536, iter: 200330/250000, loss: 0.2266, lr: 0.002335, batch_cost: 0.5642, reader_cost: 0.00014, ips: 10.6351 samples/sec | ETA 07:47:02
2023-02-05 00:00:01 [INFO]	[TRAIN] epoch: 2536, iter: 200340/250000, loss: 0.2445, lr: 0.002335, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6373 samples/sec | ETA 07:46:50
2023-02-05 00:00:07 [INFO]	[TRAIN] epoch: 2537, iter: 200350/250000, loss: 0.2648, lr: 0.002334, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6316 samples/sec | ETA 07:47:00
2023-02-05 00:00:12 [INFO]	[TRAIN] epoch: 2537, iter: 200360/250000, loss: 0.2730, lr: 0.002334, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6209 samples/sec | ETA 07:47:22
2023-02-05 00:00:18 [INFO]	[TRAIN] epoch: 2537, iter: 200370/250000, loss: 0.3097, lr: 0.002334, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6364 samples/sec | ETA 07:46:36
2023-02-05 00:00:24 [INFO]	[TRAIN] epoch: 2537, iter: 200380/250000, loss: 0.2597, lr: 0.002333, batch_cost: 0.5645, reader_cost: 0.00011, ips: 10.6297 samples/sec | ETA 07:46:48
2023-02-05 00:00:29 [INFO]	[TRAIN] epoch: 2537, iter: 200390/250000, loss: 0.3085, lr: 0.002333, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6272 samples/sec | ETA 07:46:49
2023-02-05 00:00:35 [INFO]	[TRAIN] epoch: 2537, iter: 200400/250000, loss: 0.2135, lr: 0.002332, batch_cost: 0.5914, reader_cost: 0.02696, ips: 10.1447 samples/sec | ETA 08:08:55
2023-02-05 00:00:41 [INFO]	[TRAIN] epoch: 2537, iter: 200410/250000, loss: 0.4259, lr: 0.002332, batch_cost: 0.5637, reader_cost: 0.00010, ips: 10.6433 samples/sec | ETA 07:45:55
2023-02-05 00:00:47 [INFO]	[TRAIN] epoch: 2537, iter: 200420/250000, loss: 0.4449, lr: 0.002332, batch_cost: 0.5645, reader_cost: 0.00011, ips: 10.6293 samples/sec | ETA 07:46:26
2023-02-05 00:00:52 [INFO]	[TRAIN] epoch: 2538, iter: 200430/250000, loss: 0.3918, lr: 0.002331, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6326 samples/sec | ETA 07:46:12
2023-02-05 00:00:58 [INFO]	[TRAIN] epoch: 2538, iter: 200440/250000, loss: 0.3677, lr: 0.002331, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6338 samples/sec | ETA 07:46:03
2023-02-05 00:01:04 [INFO]	[TRAIN] epoch: 2538, iter: 200450/250000, loss: 0.4831, lr: 0.002330, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6199 samples/sec | ETA 07:46:34
2023-02-05 00:01:09 [INFO]	[TRAIN] epoch: 2538, iter: 200460/250000, loss: 0.3474, lr: 0.002330, batch_cost: 0.5656, reader_cost: 0.00011, ips: 10.6085 samples/sec | ETA 07:46:59
2023-02-05 00:01:15 [INFO]	[TRAIN] epoch: 2538, iter: 200470/250000, loss: 0.4266, lr: 0.002329, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6081 samples/sec | ETA 07:46:54
2023-02-05 00:01:21 [INFO]	[TRAIN] epoch: 2538, iter: 200480/250000, loss: 0.3007, lr: 0.002329, batch_cost: 0.5961, reader_cost: 0.03128, ips: 10.0657 samples/sec | ETA 08:11:58
2023-02-05 00:01:26 [INFO]	[TRAIN] epoch: 2538, iter: 200490/250000, loss: 0.2522, lr: 0.002329, batch_cost: 0.5646, reader_cost: 0.00011, ips: 10.6265 samples/sec | ETA 07:45:54
2023-02-05 00:01:32 [INFO]	[TRAIN] epoch: 2538, iter: 200500/250000, loss: 0.3178, lr: 0.002328, batch_cost: 0.5637, reader_cost: 0.00010, ips: 10.6430 samples/sec | ETA 07:45:05
2023-02-05 00:01:38 [INFO]	[TRAIN] epoch: 2539, iter: 200510/250000, loss: 0.2927, lr: 0.002328, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5976 samples/sec | ETA 07:46:59
2023-02-05 00:01:43 [INFO]	[TRAIN] epoch: 2539, iter: 200520/250000, loss: 0.2563, lr: 0.002327, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5963 samples/sec | ETA 07:46:57
2023-02-05 00:01:49 [INFO]	[TRAIN] epoch: 2539, iter: 200530/250000, loss: 0.2897, lr: 0.002327, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6039 samples/sec | ETA 07:46:31
2023-02-05 00:01:55 [INFO]	[TRAIN] epoch: 2539, iter: 200540/250000, loss: 0.2573, lr: 0.002326, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6112 samples/sec | ETA 07:46:06
2023-02-05 00:02:00 [INFO]	[TRAIN] epoch: 2539, iter: 200550/250000, loss: 0.2234, lr: 0.002326, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6047 samples/sec | ETA 07:46:18
2023-02-05 00:02:06 [INFO]	[TRAIN] epoch: 2539, iter: 200560/250000, loss: 0.2049, lr: 0.002326, batch_cost: 0.5927, reader_cost: 0.02739, ips: 10.1228 samples/sec | ETA 08:08:24
2023-02-05 00:02:12 [INFO]	[TRAIN] epoch: 2539, iter: 200570/250000, loss: 0.2195, lr: 0.002325, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6232 samples/sec | ETA 07:45:18
2023-02-05 00:02:18 [INFO]	[TRAIN] epoch: 2539, iter: 200580/250000, loss: 0.2435, lr: 0.002325, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6214 samples/sec | ETA 07:45:17
2023-02-05 00:02:23 [INFO]	[TRAIN] epoch: 2540, iter: 200590/250000, loss: 0.2434, lr: 0.002324, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6277 samples/sec | ETA 07:44:55
2023-02-05 00:02:29 [INFO]	[TRAIN] epoch: 2540, iter: 200600/250000, loss: 0.2386, lr: 0.002324, batch_cost: 0.5644, reader_cost: 0.00012, ips: 10.6299 samples/sec | ETA 07:44:43
2023-02-05 00:02:35 [INFO]	[TRAIN] epoch: 2540, iter: 200610/250000, loss: 0.2571, lr: 0.002323, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6157 samples/sec | ETA 07:45:15
2023-02-05 00:02:40 [INFO]	[TRAIN] epoch: 2540, iter: 200620/250000, loss: 0.2881, lr: 0.002323, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6141 samples/sec | ETA 07:45:13
2023-02-05 00:02:46 [INFO]	[TRAIN] epoch: 2540, iter: 200630/250000, loss: 0.2620, lr: 0.002323, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6150 samples/sec | ETA 07:45:05
2023-02-05 00:02:52 [INFO]	[TRAIN] epoch: 2540, iter: 200640/250000, loss: 0.2013, lr: 0.002322, batch_cost: 0.5932, reader_cost: 0.02874, ips: 10.1149 samples/sec | ETA 08:07:59
2023-02-05 00:02:57 [INFO]	[TRAIN] epoch: 2540, iter: 200650/250000, loss: 0.2563, lr: 0.002322, batch_cost: 0.5641, reader_cost: 0.00011, ips: 10.6363 samples/sec | ETA 07:43:58
2023-02-05 00:03:03 [INFO]	[TRAIN] epoch: 2540, iter: 200660/250000, loss: 0.3618, lr: 0.002321, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6366 samples/sec | ETA 07:43:52
2023-02-05 00:03:09 [INFO]	[TRAIN] epoch: 2541, iter: 200670/250000, loss: 0.2205, lr: 0.002321, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6125 samples/sec | ETA 07:44:49
2023-02-05 00:03:14 [INFO]	[TRAIN] epoch: 2541, iter: 200680/250000, loss: 0.2521, lr: 0.002321, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6009 samples/sec | ETA 07:45:14
2023-02-05 00:03:20 [INFO]	[TRAIN] epoch: 2541, iter: 200690/250000, loss: 0.1786, lr: 0.002320, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5988 samples/sec | ETA 07:45:14
2023-02-05 00:03:26 [INFO]	[TRAIN] epoch: 2541, iter: 200700/250000, loss: 0.2246, lr: 0.002320, batch_cost: 0.5664, reader_cost: 0.00010, ips: 10.5938 samples/sec | ETA 07:45:21
2023-02-05 00:03:31 [INFO]	[TRAIN] epoch: 2541, iter: 200710/250000, loss: 0.2602, lr: 0.002319, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5971 samples/sec | ETA 07:45:07
2023-02-05 00:03:37 [INFO]	[TRAIN] epoch: 2541, iter: 200720/250000, loss: 0.2766, lr: 0.002319, batch_cost: 0.5929, reader_cost: 0.02726, ips: 10.1189 samples/sec | ETA 08:07:00
2023-02-05 00:03:43 [INFO]	[TRAIN] epoch: 2541, iter: 200730/250000, loss: 0.2342, lr: 0.002318, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6036 samples/sec | ETA 07:44:39
2023-02-05 00:03:49 [INFO]	[TRAIN] epoch: 2542, iter: 200740/250000, loss: 0.1995, lr: 0.002318, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.5999 samples/sec | ETA 07:44:43
2023-02-05 00:03:54 [INFO]	[TRAIN] epoch: 2542, iter: 200750/250000, loss: 0.1956, lr: 0.002318, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6038 samples/sec | ETA 07:44:27
2023-02-05 00:04:00 [INFO]	[TRAIN] epoch: 2542, iter: 200760/250000, loss: 0.2318, lr: 0.002317, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6216 samples/sec | ETA 07:43:35
2023-02-05 00:04:06 [INFO]	[TRAIN] epoch: 2542, iter: 200770/250000, loss: 0.1820, lr: 0.002317, batch_cost: 0.5664, reader_cost: 0.00010, ips: 10.5933 samples/sec | ETA 07:44:43
2023-02-05 00:04:11 [INFO]	[TRAIN] epoch: 2542, iter: 200780/250000, loss: 0.2057, lr: 0.002316, batch_cost: 0.5662, reader_cost: 0.00011, ips: 10.5973 samples/sec | ETA 07:44:27
2023-02-05 00:04:17 [INFO]	[TRAIN] epoch: 2542, iter: 200790/250000, loss: 0.2254, lr: 0.002316, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6070 samples/sec | ETA 07:43:56
2023-02-05 00:04:23 [INFO]	[TRAIN] epoch: 2542, iter: 200800/250000, loss: 0.2629, lr: 0.002315, batch_cost: 0.5949, reader_cost: 0.02987, ips: 10.0863 samples/sec | ETA 08:07:47
2023-02-05 00:04:29 [INFO]	[TRAIN] epoch: 2542, iter: 200810/250000, loss: 0.1957, lr: 0.002315, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6310 samples/sec | ETA 07:42:42
2023-02-05 00:04:34 [INFO]	[TRAIN] epoch: 2543, iter: 200820/250000, loss: 0.2341, lr: 0.002315, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6304 samples/sec | ETA 07:42:38
2023-02-05 00:04:40 [INFO]	[TRAIN] epoch: 2543, iter: 200830/250000, loss: 0.2234, lr: 0.002314, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6272 samples/sec | ETA 07:42:40
2023-02-05 00:04:45 [INFO]	[TRAIN] epoch: 2543, iter: 200840/250000, loss: 0.1876, lr: 0.002314, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6052 samples/sec | ETA 07:43:32
2023-02-05 00:04:51 [INFO]	[TRAIN] epoch: 2543, iter: 200850/250000, loss: 0.2895, lr: 0.002313, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6034 samples/sec | ETA 07:43:31
2023-02-05 00:04:57 [INFO]	[TRAIN] epoch: 2543, iter: 200860/250000, loss: 0.2439, lr: 0.002313, batch_cost: 0.5663, reader_cost: 0.00010, ips: 10.5952 samples/sec | ETA 07:43:47
2023-02-05 00:05:03 [INFO]	[TRAIN] epoch: 2543, iter: 200870/250000, loss: 0.2176, lr: 0.002312, batch_cost: 0.5898, reader_cost: 0.02376, ips: 10.1737 samples/sec | ETA 08:02:54
2023-02-05 00:05:08 [INFO]	[TRAIN] epoch: 2543, iter: 200880/250000, loss: 0.2285, lr: 0.002312, batch_cost: 0.5651, reader_cost: 0.00016, ips: 10.6182 samples/sec | ETA 07:42:36
2023-02-05 00:05:14 [INFO]	[TRAIN] epoch: 2543, iter: 200890/250000, loss: 0.2248, lr: 0.002312, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6221 samples/sec | ETA 07:42:20
2023-02-05 00:05:20 [INFO]	[TRAIN] epoch: 2544, iter: 200900/250000, loss: 0.2407, lr: 0.002311, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6293 samples/sec | ETA 07:41:55
2023-02-05 00:05:25 [INFO]	[TRAIN] epoch: 2544, iter: 200910/250000, loss: 0.2804, lr: 0.002311, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6320 samples/sec | ETA 07:41:43
2023-02-05 00:05:31 [INFO]	[TRAIN] epoch: 2544, iter: 200920/250000, loss: 0.2292, lr: 0.002310, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6237 samples/sec | ETA 07:41:59
2023-02-05 00:05:37 [INFO]	[TRAIN] epoch: 2544, iter: 200930/250000, loss: 0.2988, lr: 0.002310, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6081 samples/sec | ETA 07:42:34
2023-02-05 00:05:42 [INFO]	[TRAIN] epoch: 2544, iter: 200940/250000, loss: 0.1936, lr: 0.002309, batch_cost: 0.5662, reader_cost: 0.00011, ips: 10.5975 samples/sec | ETA 07:42:56
2023-02-05 00:05:48 [INFO]	[TRAIN] epoch: 2544, iter: 200950/250000, loss: 0.2410, lr: 0.002309, batch_cost: 0.6015, reader_cost: 0.03577, ips: 9.9744 samples/sec | ETA 08:11:45
2023-02-05 00:05:54 [INFO]	[TRAIN] epoch: 2544, iter: 200960/250000, loss: 0.2269, lr: 0.002309, batch_cost: 0.5654, reader_cost: 0.00019, ips: 10.6120 samples/sec | ETA 07:42:07
2023-02-05 00:06:00 [INFO]	[TRAIN] epoch: 2544, iter: 200970/250000, loss: 0.2967, lr: 0.002308, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6334 samples/sec | ETA 07:41:05
2023-02-05 00:06:05 [INFO]	[TRAIN] epoch: 2545, iter: 200980/250000, loss: 0.2817, lr: 0.002308, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6239 samples/sec | ETA 07:41:24
2023-02-05 00:06:11 [INFO]	[TRAIN] epoch: 2545, iter: 200990/250000, loss: 0.2038, lr: 0.002307, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6216 samples/sec | ETA 07:41:25
2023-02-05 00:06:17 [INFO]	[TRAIN] epoch: 2545, iter: 201000/250000, loss: 0.1877, lr: 0.002307, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6338 samples/sec | ETA 07:40:47
2023-02-05 00:06:22 [INFO]	[TRAIN] epoch: 2545, iter: 201010/250000, loss: 0.2353, lr: 0.002307, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6240 samples/sec | ETA 07:41:07
2023-02-05 00:06:28 [INFO]	[TRAIN] epoch: 2545, iter: 201020/250000, loss: 0.2992, lr: 0.002306, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6336 samples/sec | ETA 07:40:37
2023-02-05 00:06:34 [INFO]	[TRAIN] epoch: 2545, iter: 201030/250000, loss: 0.2450, lr: 0.002306, batch_cost: 0.5911, reader_cost: 0.02633, ips: 10.1502 samples/sec | ETA 08:02:27
2023-02-05 00:06:39 [INFO]	[TRAIN] epoch: 2545, iter: 201040/250000, loss: 0.2794, lr: 0.002305, batch_cost: 0.5661, reader_cost: 0.00015, ips: 10.5994 samples/sec | ETA 07:41:54
2023-02-05 00:06:45 [INFO]	[TRAIN] epoch: 2545, iter: 201050/250000, loss: 0.2501, lr: 0.002305, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6038 samples/sec | ETA 07:41:37
2023-02-05 00:06:51 [INFO]	[TRAIN] epoch: 2546, iter: 201060/250000, loss: 0.2263, lr: 0.002304, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5992 samples/sec | ETA 07:41:44
2023-02-05 00:06:56 [INFO]	[TRAIN] epoch: 2546, iter: 201070/250000, loss: 0.2919, lr: 0.002304, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6062 samples/sec | ETA 07:41:20
2023-02-05 00:07:02 [INFO]	[TRAIN] epoch: 2546, iter: 201080/250000, loss: 0.2111, lr: 0.002304, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6114 samples/sec | ETA 07:41:00
2023-02-05 00:07:08 [INFO]	[TRAIN] epoch: 2546, iter: 201090/250000, loss: 0.2227, lr: 0.002303, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6028 samples/sec | ETA 07:41:17
2023-02-05 00:07:13 [INFO]	[TRAIN] epoch: 2546, iter: 201100/250000, loss: 0.2246, lr: 0.002303, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6013 samples/sec | ETA 07:41:15
2023-02-05 00:07:19 [INFO]	[TRAIN] epoch: 2546, iter: 201110/250000, loss: 0.2443, lr: 0.002302, batch_cost: 0.5917, reader_cost: 0.02681, ips: 10.1398 samples/sec | ETA 08:02:09
2023-02-05 00:07:25 [INFO]	[TRAIN] epoch: 2546, iter: 201120/250000, loss: 0.2165, lr: 0.002302, batch_cost: 0.5650, reader_cost: 0.00011, ips: 10.6191 samples/sec | ETA 07:40:18
2023-02-05 00:07:31 [INFO]	[TRAIN] epoch: 2546, iter: 201130/250000, loss: 0.2356, lr: 0.002301, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6023 samples/sec | ETA 07:40:56
2023-02-05 00:07:36 [INFO]	[TRAIN] epoch: 2547, iter: 201140/250000, loss: 0.2652, lr: 0.002301, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6119 samples/sec | ETA 07:40:25
2023-02-05 00:07:42 [INFO]	[TRAIN] epoch: 2547, iter: 201150/250000, loss: 0.2592, lr: 0.002301, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6048 samples/sec | ETA 07:40:38
2023-02-05 00:07:48 [INFO]	[TRAIN] epoch: 2547, iter: 201160/250000, loss: 0.1952, lr: 0.002300, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6145 samples/sec | ETA 07:40:07
2023-02-05 00:07:53 [INFO]	[TRAIN] epoch: 2547, iter: 201170/250000, loss: 0.1634, lr: 0.002300, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6112 samples/sec | ETA 07:40:10
2023-02-05 00:07:59 [INFO]	[TRAIN] epoch: 2547, iter: 201180/250000, loss: 0.2261, lr: 0.002299, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6005 samples/sec | ETA 07:40:32
2023-02-05 00:08:05 [INFO]	[TRAIN] epoch: 2547, iter: 201190/250000, loss: 0.1721, lr: 0.002299, batch_cost: 0.5873, reader_cost: 0.02140, ips: 10.2156 samples/sec | ETA 07:57:48
2023-02-05 00:08:10 [INFO]	[TRAIN] epoch: 2547, iter: 201200/250000, loss: 0.2393, lr: 0.002298, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6266 samples/sec | ETA 07:39:13
2023-02-05 00:08:16 [INFO]	[TRAIN] epoch: 2547, iter: 201210/250000, loss: 0.2280, lr: 0.002298, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6107 samples/sec | ETA 07:39:49
2023-02-05 00:08:22 [INFO]	[TRAIN] epoch: 2548, iter: 201220/250000, loss: 0.2792, lr: 0.002298, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5994 samples/sec | ETA 07:40:12
2023-02-05 00:08:27 [INFO]	[TRAIN] epoch: 2548, iter: 201230/250000, loss: 0.2470, lr: 0.002297, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6121 samples/sec | ETA 07:39:34
2023-02-05 00:08:33 [INFO]	[TRAIN] epoch: 2548, iter: 201240/250000, loss: 0.3057, lr: 0.002297, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6095 samples/sec | ETA 07:39:35
2023-02-05 00:08:39 [INFO]	[TRAIN] epoch: 2548, iter: 201250/250000, loss: 0.2427, lr: 0.002296, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6064 samples/sec | ETA 07:39:37
2023-02-05 00:08:44 [INFO]	[TRAIN] epoch: 2548, iter: 201260/250000, loss: 0.2235, lr: 0.002296, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6153 samples/sec | ETA 07:39:08
2023-02-05 00:08:50 [INFO]	[TRAIN] epoch: 2548, iter: 201270/250000, loss: 0.2001, lr: 0.002296, batch_cost: 0.6049, reader_cost: 0.04030, ips: 9.9183 samples/sec | ETA 08:11:18
2023-02-05 00:08:56 [INFO]	[TRAIN] epoch: 2548, iter: 201280/250000, loss: 0.2778, lr: 0.002295, batch_cost: 0.5650, reader_cost: 0.00012, ips: 10.6198 samples/sec | ETA 07:38:45
2023-02-05 00:09:02 [INFO]	[TRAIN] epoch: 2548, iter: 201290/250000, loss: 0.2202, lr: 0.002295, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6048 samples/sec | ETA 07:39:19
2023-02-05 00:09:07 [INFO]	[TRAIN] epoch: 2549, iter: 201300/250000, loss: 0.2823, lr: 0.002294, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6014 samples/sec | ETA 07:39:22
2023-02-05 00:09:13 [INFO]	[TRAIN] epoch: 2549, iter: 201310/250000, loss: 0.2271, lr: 0.002294, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6117 samples/sec | ETA 07:38:49
2023-02-05 00:09:19 [INFO]	[TRAIN] epoch: 2549, iter: 201320/250000, loss: 0.2536, lr: 0.002293, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6102 samples/sec | ETA 07:38:48
2023-02-05 00:09:24 [INFO]	[TRAIN] epoch: 2549, iter: 201330/250000, loss: 0.3198, lr: 0.002293, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5976 samples/sec | ETA 07:39:15
2023-02-05 00:09:30 [INFO]	[TRAIN] epoch: 2549, iter: 201340/250000, loss: 0.2761, lr: 0.002293, batch_cost: 0.5658, reader_cost: 0.00011, ips: 10.6037 samples/sec | ETA 07:38:53
2023-02-05 00:09:36 [INFO]	[TRAIN] epoch: 2549, iter: 201350/250000, loss: 0.2784, lr: 0.002292, batch_cost: 0.5896, reader_cost: 0.02487, ips: 10.1769 samples/sec | ETA 07:58:02
2023-02-05 00:09:41 [INFO]	[TRAIN] epoch: 2549, iter: 201360/250000, loss: 0.2648, lr: 0.002292, batch_cost: 0.5652, reader_cost: 0.00011, ips: 10.6155 samples/sec | ETA 07:38:11
2023-02-05 00:09:47 [INFO]	[TRAIN] epoch: 2549, iter: 201370/250000, loss: 0.2510, lr: 0.002291, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6092 samples/sec | ETA 07:38:22
2023-02-05 00:09:53 [INFO]	[TRAIN] epoch: 2550, iter: 201380/250000, loss: 0.3758, lr: 0.002291, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6126 samples/sec | ETA 07:38:08
2023-02-05 00:09:58 [INFO]	[TRAIN] epoch: 2550, iter: 201390/250000, loss: 0.6200, lr: 0.002290, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5969 samples/sec | ETA 07:38:43
2023-02-05 00:10:04 [INFO]	[TRAIN] epoch: 2550, iter: 201400/250000, loss: 0.7928, lr: 0.002290, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6075 samples/sec | ETA 07:38:10
2023-02-05 00:10:10 [INFO]	[TRAIN] epoch: 2550, iter: 201410/250000, loss: 0.3361, lr: 0.002290, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6174 samples/sec | ETA 07:37:38
2023-02-05 00:10:15 [INFO]	[TRAIN] epoch: 2550, iter: 201420/250000, loss: 0.3249, lr: 0.002289, batch_cost: 0.5658, reader_cost: 0.00011, ips: 10.6046 samples/sec | ETA 07:38:06
2023-02-05 00:10:21 [INFO]	[TRAIN] epoch: 2550, iter: 201430/250000, loss: 0.4442, lr: 0.002289, batch_cost: 0.5944, reader_cost: 0.02933, ips: 10.0947 samples/sec | ETA 08:01:08
2023-02-05 00:10:27 [INFO]	[TRAIN] epoch: 2550, iter: 201440/250000, loss: 0.3765, lr: 0.002288, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6315 samples/sec | ETA 07:36:45
2023-02-05 00:10:33 [INFO]	[TRAIN] epoch: 2550, iter: 201450/250000, loss: 0.3839, lr: 0.002288, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6262 samples/sec | ETA 07:36:53
2023-02-05 00:10:38 [INFO]	[TRAIN] epoch: 2551, iter: 201460/250000, loss: 0.3390, lr: 0.002287, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6346 samples/sec | ETA 07:36:26
2023-02-05 00:10:44 [INFO]	[TRAIN] epoch: 2551, iter: 201470/250000, loss: 0.2384, lr: 0.002287, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6326 samples/sec | ETA 07:36:25
2023-02-05 00:10:50 [INFO]	[TRAIN] epoch: 2551, iter: 201480/250000, loss: 0.2896, lr: 0.002287, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6297 samples/sec | ETA 07:36:27
2023-02-05 00:10:55 [INFO]	[TRAIN] epoch: 2551, iter: 201490/250000, loss: 0.2964, lr: 0.002286, batch_cost: 0.5644, reader_cost: 0.00011, ips: 10.6317 samples/sec | ETA 07:36:16
2023-02-05 00:11:01 [INFO]	[TRAIN] epoch: 2551, iter: 201500/250000, loss: 0.2770, lr: 0.002286, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6278 samples/sec | ETA 07:36:21
2023-02-05 00:11:07 [INFO]	[TRAIN] epoch: 2551, iter: 201510/250000, loss: 0.4372, lr: 0.002285, batch_cost: 0.5981, reader_cost: 0.03288, ips: 10.0315 samples/sec | ETA 08:03:22
2023-02-05 00:11:13 [INFO]	[TRAIN] epoch: 2551, iter: 201520/250000, loss: 0.2917, lr: 0.002285, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6327 samples/sec | ETA 07:35:57
2023-02-05 00:11:18 [INFO]	[TRAIN] epoch: 2552, iter: 201530/250000, loss: 0.4796, lr: 0.002284, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6335 samples/sec | ETA 07:35:49
2023-02-05 00:11:24 [INFO]	[TRAIN] epoch: 2552, iter: 201540/250000, loss: 0.2965, lr: 0.002284, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6259 samples/sec | ETA 07:36:03
2023-02-05 00:11:29 [INFO]	[TRAIN] epoch: 2552, iter: 201550/250000, loss: 0.3298, lr: 0.002284, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6310 samples/sec | ETA 07:35:44
2023-02-05 00:11:35 [INFO]	[TRAIN] epoch: 2552, iter: 201560/250000, loss: 0.2889, lr: 0.002283, batch_cost: 0.5637, reader_cost: 0.00010, ips: 10.6435 samples/sec | ETA 07:35:06
2023-02-05 00:11:41 [INFO]	[TRAIN] epoch: 2552, iter: 201570/250000, loss: 0.2565, lr: 0.002283, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6364 samples/sec | ETA 07:35:19
2023-02-05 00:11:46 [INFO]	[TRAIN] epoch: 2552, iter: 201580/250000, loss: 0.2668, lr: 0.002282, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6268 samples/sec | ETA 07:35:38
2023-02-05 00:11:52 [INFO]	[TRAIN] epoch: 2552, iter: 201590/250000, loss: 0.3466, lr: 0.002282, batch_cost: 0.5894, reader_cost: 0.02388, ips: 10.1803 samples/sec | ETA 07:55:31
2023-02-05 00:11:58 [INFO]	[TRAIN] epoch: 2552, iter: 201600/250000, loss: 0.3274, lr: 0.002282, batch_cost: 0.5640, reader_cost: 0.00011, ips: 10.6388 samples/sec | ETA 07:34:56
2023-02-05 00:12:04 [INFO]	[TRAIN] epoch: 2553, iter: 201610/250000, loss: 0.3155, lr: 0.002281, batch_cost: 0.5640, reader_cost: 0.00011, ips: 10.6390 samples/sec | ETA 07:34:50
2023-02-05 00:12:09 [INFO]	[TRAIN] epoch: 2553, iter: 201620/250000, loss: 0.3173, lr: 0.002281, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6323 samples/sec | ETA 07:35:01
2023-02-05 00:12:15 [INFO]	[TRAIN] epoch: 2553, iter: 201630/250000, loss: 0.2822, lr: 0.002280, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6210 samples/sec | ETA 07:35:25
2023-02-05 00:12:20 [INFO]	[TRAIN] epoch: 2553, iter: 201640/250000, loss: 0.3785, lr: 0.002280, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6116 samples/sec | ETA 07:35:43
2023-02-05 00:12:26 [INFO]	[TRAIN] epoch: 2553, iter: 201650/250000, loss: 0.2874, lr: 0.002279, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5960 samples/sec | ETA 07:36:18
2023-02-05 00:12:32 [INFO]	[TRAIN] epoch: 2553, iter: 201660/250000, loss: 0.3225, lr: 0.002279, batch_cost: 0.5957, reader_cost: 0.03005, ips: 10.0718 samples/sec | ETA 07:59:57
2023-02-05 00:12:38 [INFO]	[TRAIN] epoch: 2553, iter: 201670/250000, loss: 0.2962, lr: 0.002279, batch_cost: 0.5645, reader_cost: 0.00024, ips: 10.6282 samples/sec | ETA 07:34:44
2023-02-05 00:12:43 [INFO]	[TRAIN] epoch: 2553, iter: 201680/250000, loss: 0.2968, lr: 0.002278, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6344 samples/sec | ETA 07:34:22
2023-02-05 00:12:49 [INFO]	[TRAIN] epoch: 2554, iter: 201690/250000, loss: 0.3014, lr: 0.002278, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6350 samples/sec | ETA 07:34:15
2023-02-05 00:12:55 [INFO]	[TRAIN] epoch: 2554, iter: 201700/250000, loss: 0.3663, lr: 0.002277, batch_cost: 0.5638, reader_cost: 0.00010, ips: 10.6428 samples/sec | ETA 07:33:49
2023-02-05 00:13:00 [INFO]	[TRAIN] epoch: 2554, iter: 201710/250000, loss: 0.3517, lr: 0.002277, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6344 samples/sec | ETA 07:34:05
2023-02-05 00:13:06 [INFO]	[TRAIN] epoch: 2554, iter: 201720/250000, loss: 0.3775, lr: 0.002276, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6235 samples/sec | ETA 07:34:27
2023-02-05 00:13:12 [INFO]	[TRAIN] epoch: 2554, iter: 201730/250000, loss: 0.2940, lr: 0.002276, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6265 samples/sec | ETA 07:34:14
2023-02-05 00:13:17 [INFO]	[TRAIN] epoch: 2554, iter: 201740/250000, loss: 0.2915, lr: 0.002276, batch_cost: 0.5859, reader_cost: 0.02113, ips: 10.2411 samples/sec | ETA 07:51:14
2023-02-05 00:13:23 [INFO]	[TRAIN] epoch: 2554, iter: 201750/250000, loss: 0.2423, lr: 0.002275, batch_cost: 0.5642, reader_cost: 0.00012, ips: 10.6339 samples/sec | ETA 07:33:44
2023-02-05 00:13:29 [INFO]	[TRAIN] epoch: 2554, iter: 201760/250000, loss: 0.2861, lr: 0.002275, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6383 samples/sec | ETA 07:33:27
2023-02-05 00:13:34 [INFO]	[TRAIN] epoch: 2555, iter: 201770/250000, loss: 0.2666, lr: 0.002274, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6316 samples/sec | ETA 07:33:38
2023-02-05 00:13:40 [INFO]	[TRAIN] epoch: 2555, iter: 201780/250000, loss: 0.2731, lr: 0.002274, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6298 samples/sec | ETA 07:33:37
2023-02-05 00:13:46 [INFO]	[TRAIN] epoch: 2555, iter: 201790/250000, loss: 0.2121, lr: 0.002273, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6314 samples/sec | ETA 07:33:28
2023-02-05 00:13:51 [INFO]	[TRAIN] epoch: 2555, iter: 201800/250000, loss: 0.1971, lr: 0.002273, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6354 samples/sec | ETA 07:33:12
2023-02-05 00:13:57 [INFO]	[TRAIN] epoch: 2555, iter: 201810/250000, loss: 0.3351, lr: 0.002273, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6377 samples/sec | ETA 07:33:00
2023-02-05 00:14:03 [INFO]	[TRAIN] epoch: 2555, iter: 201820/250000, loss: 0.2917, lr: 0.002272, batch_cost: 0.5898, reader_cost: 0.02595, ips: 10.1728 samples/sec | ETA 07:53:36
2023-02-05 00:14:09 [INFO]	[TRAIN] epoch: 2555, iter: 201830/250000, loss: 0.2613, lr: 0.002272, batch_cost: 0.5644, reader_cost: 0.00019, ips: 10.6315 samples/sec | ETA 07:33:05
2023-02-05 00:14:14 [INFO]	[TRAIN] epoch: 2555, iter: 201840/250000, loss: 0.2803, lr: 0.002271, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6336 samples/sec | ETA 07:32:54
2023-02-05 00:14:20 [INFO]	[TRAIN] epoch: 2556, iter: 201850/250000, loss: 0.2709, lr: 0.002271, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6253 samples/sec | ETA 07:33:09
2023-02-05 00:14:25 [INFO]	[TRAIN] epoch: 2556, iter: 201860/250000, loss: 0.2281, lr: 0.002270, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6321 samples/sec | ETA 07:32:46
2023-02-05 00:14:31 [INFO]	[TRAIN] epoch: 2556, iter: 201870/250000, loss: 0.2261, lr: 0.002270, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6226 samples/sec | ETA 07:33:05
2023-02-05 00:14:37 [INFO]	[TRAIN] epoch: 2556, iter: 201880/250000, loss: 0.2779, lr: 0.002270, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6351 samples/sec | ETA 07:32:27
2023-02-05 00:14:42 [INFO]	[TRAIN] epoch: 2556, iter: 201890/250000, loss: 0.2433, lr: 0.002269, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6340 samples/sec | ETA 07:32:24
2023-02-05 00:14:48 [INFO]	[TRAIN] epoch: 2556, iter: 201900/250000, loss: 0.2228, lr: 0.002269, batch_cost: 0.5899, reader_cost: 0.02581, ips: 10.1715 samples/sec | ETA 07:52:53
2023-02-05 00:14:54 [INFO]	[TRAIN] epoch: 2556, iter: 201910/250000, loss: 0.2706, lr: 0.002268, batch_cost: 0.5648, reader_cost: 0.00048, ips: 10.6230 samples/sec | ETA 07:32:41
2023-02-05 00:15:00 [INFO]	[TRAIN] epoch: 2556, iter: 201920/250000, loss: 0.3300, lr: 0.002268, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6358 samples/sec | ETA 07:32:03
2023-02-05 00:15:05 [INFO]	[TRAIN] epoch: 2557, iter: 201930/250000, loss: 0.3683, lr: 0.002268, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6360 samples/sec | ETA 07:31:57
2023-02-05 00:15:11 [INFO]	[TRAIN] epoch: 2557, iter: 201940/250000, loss: 0.2708, lr: 0.002267, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6325 samples/sec | ETA 07:32:00
2023-02-05 00:15:17 [INFO]	[TRAIN] epoch: 2557, iter: 201950/250000, loss: 0.3526, lr: 0.002267, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6225 samples/sec | ETA 07:32:20
2023-02-05 00:15:22 [INFO]	[TRAIN] epoch: 2557, iter: 201960/250000, loss: 0.3414, lr: 0.002266, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6332 samples/sec | ETA 07:31:47
2023-02-05 00:15:28 [INFO]	[TRAIN] epoch: 2557, iter: 201970/250000, loss: 0.2599, lr: 0.002266, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6408 samples/sec | ETA 07:31:22
2023-02-05 00:15:34 [INFO]	[TRAIN] epoch: 2557, iter: 201980/250000, loss: 0.3070, lr: 0.002265, batch_cost: 0.5940, reader_cost: 0.02949, ips: 10.1017 samples/sec | ETA 07:55:21
2023-02-05 00:15:39 [INFO]	[TRAIN] epoch: 2557, iter: 201990/250000, loss: 0.3014, lr: 0.002265, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6351 samples/sec | ETA 07:31:25
2023-02-05 00:15:45 [INFO]	[TRAIN] epoch: 2557, iter: 202000/250000, loss: 0.3857, lr: 0.002265, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6390 samples/sec | ETA 07:31:10
2023-02-05 00:15:45 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
/data/zcq/PaddleSeg/paddleseg/models/losses/decoupledsegnet_relax_boundary_loss.py:19: DeprecationWarning: Please use `shift` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.
  from scipy.ndimage.interpolation import shift
/home/zcq/.conda/envs/detectron/lib/python3.8/site-packages/skimage/util/dtype.py:27: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  np.bool8: (False, True),
/data/zcq/PaddleSeg/paddleseg/transforms/functional.py:18: DeprecationWarning: Please use `distance_transform_edt` from the `scipy.ndimage` namespace, the `scipy.ndimage.morphology` namespace is deprecated.
  from scipy.ndimage.morphology import distance_transform_edt
/home/zcq/.conda/envs/detectron/lib/python3.8/site-packages/paddle/fluid/dygraph/math_op_patch.py:275: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.float32, but right dtype is paddle.int64, the right dtype will convert to paddle.float32
  warnings.warn(
/home/zcq/.conda/envs/detectron/lib/python3.8/site-packages/paddle/fluid/dygraph/math_op_patch.py:275: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.int64, but right dtype is paddle.int32, the right dtype will convert to paddle.int64
  warnings.warn(
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1332 - reader cost: 0.0250 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1530 - reader cost: 0.0125 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1593 - reader cost: 0.0084 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1595 - reader cost: 0.0063 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1600 - reader cost: 0.0051 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1614 - reader cost: 0.0042 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1605 - reader cost: 0.0036 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1610 - reader cost: 0.0032 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1621 - reader cost: 0.002810/36 [=======>......................] - ETA: 4s - batch_cost: 0.1619 - reader cost: 0.002611/36 [========>.....................] - ETA: 4s - batch_cost: 0.1629 - reader cost: 0.002312/36 [=========>....................] - ETA: 3s - batch_cost: 0.1631 - reader cost: 0.002213/36 [=========>....................] - ETA: 3s - batch_cost: 0.1642 - reader cost: 0.002014/36 [==========>...................] - ETA: 3s - batch_cost: 0.1649 - reader cost: 0.001915/36 [===========>..................] - ETA: 3s - batch_cost: 0.1652 - reader cost: 0.001716/36 [============>.................] - ETA: 3s - batch_cost: 0.1657 - reader cost: 0.001617/36 [=============>................] - ETA: 3s - batch_cost: 0.1657 - reader cost: 0.001518/36 [==============>...............] - ETA: 2s - batch_cost: 0.1659 - reader cost: 0.001519/36 [==============>...............] - ETA: 2s - batch_cost: 0.1659 - reader cost: 0.001420/36 [===============>..............] - ETA: 2s - batch_cost: 0.1659 - reader cost: 0.001321/36 [================>.............] - ETA: 2s - batch_cost: 0.1660 - reader cost: 0.001322/36 [=================>............] - ETA: 2s - batch_cost: 0.1660 - reader cost: 0.001223/36 [==================>...........] - ETA: 2s - batch_cost: 0.1663 - reader cost: 0.001224/36 [===================>..........] - ETA: 1s - batch_cost: 0.1665 - reader cost: 0.001125/36 [===================>..........] - ETA: 1s - batch_cost: 0.1665 - reader cost: 0.001126/36 [====================>.........] - ETA: 1s - batch_cost: 0.1665 - reader cost: 0.001027/36 [=====================>........] - ETA: 1s - batch_cost: 0.1666 - reader cost: 9.9694e-0428/36 [======================>.......] - ETA: 1s - batch_cost: 0.1669 - reader cost: 9.6434e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1669 - reader cost: 9.3371e-0430/36 [========================>.....] - ETA: 1s - batch_cost: 0.1668 - reader cost: 9.0487e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1666 - reader cost: 8.7846e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1668 - reader cost: 8.5326e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1665 - reader cost: 8.2938e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1665 - reader cost: 8.0699e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1668 - reader cost: 7.8623e-0436/36 [==============================] - 6s 167ms/step - batch_cost: 0.1670 - reader cost: 7.6612e-04
2023-02-05 00:15:51 [INFO]	[EVAL] #Images: 36 mIoU: 0.8398 Acc: 0.9827 Kappa: 0.9369 Dice: 0.9086
2023-02-05 00:15:51 [INFO]	[EVAL] Class IoU: 
[0.982  0.897  0.8664 0.7208 0.6464 0.9602 0.8062]
2023-02-05 00:15:51 [INFO]	[EVAL] Class Precision: 
[0.9898 0.9506 0.9227 0.8395 0.8392 0.9671 0.9664]
2023-02-05 00:15:51 [INFO]	[EVAL] Class Recall: 
[0.992  0.9409 0.9342 0.836  0.7377 0.9926 0.8294]
2023-02-05 00:15:52 [INFO]	[EVAL] The model with the best validation mIoU (0.8398) was saved at iter 202000.
2023-02-05 00:15:58 [INFO]	[TRAIN] epoch: 2558, iter: 202010/250000, loss: 0.2754, lr: 0.002264, batch_cost: 0.5641, reader_cost: 0.00011, ips: 10.6371 samples/sec | ETA 07:31:09
2023-02-05 00:16:03 [INFO]	[TRAIN] epoch: 2558, iter: 202020/250000, loss: 0.2387, lr: 0.002264, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6366 samples/sec | ETA 07:31:04
2023-02-05 00:16:09 [INFO]	[TRAIN] epoch: 2558, iter: 202030/250000, loss: 0.2268, lr: 0.002263, batch_cost: 0.5635, reader_cost: 0.00009, ips: 10.6474 samples/sec | ETA 07:30:31
2023-02-05 00:16:15 [INFO]	[TRAIN] epoch: 2558, iter: 202040/250000, loss: 0.2508, lr: 0.002263, batch_cost: 0.5637, reader_cost: 0.00010, ips: 10.6442 samples/sec | ETA 07:30:34
2023-02-05 00:16:20 [INFO]	[TRAIN] epoch: 2558, iter: 202050/250000, loss: 0.2721, lr: 0.002262, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6384 samples/sec | ETA 07:30:43
2023-02-05 00:16:26 [INFO]	[TRAIN] epoch: 2558, iter: 202060/250000, loss: 0.2411, lr: 0.002262, batch_cost: 0.5975, reader_cost: 0.03228, ips: 10.0426 samples/sec | ETA 07:57:22
2023-02-05 00:16:32 [INFO]	[TRAIN] epoch: 2558, iter: 202070/250000, loss: 0.2847, lr: 0.002262, batch_cost: 0.5643, reader_cost: 0.00014, ips: 10.6321 samples/sec | ETA 07:30:48
2023-02-05 00:16:38 [INFO]	[TRAIN] epoch: 2558, iter: 202080/250000, loss: 0.2628, lr: 0.002261, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6360 samples/sec | ETA 07:30:32
2023-02-05 00:16:43 [INFO]	[TRAIN] epoch: 2559, iter: 202090/250000, loss: 0.3454, lr: 0.002261, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6385 samples/sec | ETA 07:30:20
2023-02-05 00:16:49 [INFO]	[TRAIN] epoch: 2559, iter: 202100/250000, loss: 0.2514, lr: 0.002260, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6356 samples/sec | ETA 07:30:22
2023-02-05 00:16:55 [INFO]	[TRAIN] epoch: 2559, iter: 202110/250000, loss: 0.2375, lr: 0.002260, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6313 samples/sec | ETA 07:30:27
2023-02-05 00:17:00 [INFO]	[TRAIN] epoch: 2559, iter: 202120/250000, loss: 0.2886, lr: 0.002259, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6355 samples/sec | ETA 07:30:11
2023-02-05 00:17:06 [INFO]	[TRAIN] epoch: 2559, iter: 202130/250000, loss: 0.2385, lr: 0.002259, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6243 samples/sec | ETA 07:30:34
2023-02-05 00:17:12 [INFO]	[TRAIN] epoch: 2559, iter: 202140/250000, loss: 0.2646, lr: 0.002259, batch_cost: 0.6008, reader_cost: 0.03603, ips: 9.9871 samples/sec | ETA 07:59:13
2023-02-05 00:17:17 [INFO]	[TRAIN] epoch: 2559, iter: 202150/250000, loss: 0.2228, lr: 0.002258, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6337 samples/sec | ETA 07:29:59
2023-02-05 00:17:23 [INFO]	[TRAIN] epoch: 2559, iter: 202160/250000, loss: 0.3018, lr: 0.002258, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6349 samples/sec | ETA 07:29:50
2023-02-05 00:17:29 [INFO]	[TRAIN] epoch: 2560, iter: 202170/250000, loss: 0.3546, lr: 0.002257, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6327 samples/sec | ETA 07:29:50
2023-02-05 00:17:34 [INFO]	[TRAIN] epoch: 2560, iter: 202180/250000, loss: 0.3175, lr: 0.002257, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6392 samples/sec | ETA 07:29:28
2023-02-05 00:17:40 [INFO]	[TRAIN] epoch: 2560, iter: 202190/250000, loss: 0.2976, lr: 0.002256, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6395 samples/sec | ETA 07:29:21
2023-02-05 00:17:46 [INFO]	[TRAIN] epoch: 2560, iter: 202200/250000, loss: 0.3464, lr: 0.002256, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6365 samples/sec | ETA 07:29:23
2023-02-05 00:17:51 [INFO]	[TRAIN] epoch: 2560, iter: 202210/250000, loss: 0.3444, lr: 0.002256, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6325 samples/sec | ETA 07:29:28
2023-02-05 00:17:57 [INFO]	[TRAIN] epoch: 2560, iter: 202220/250000, loss: 0.3127, lr: 0.002255, batch_cost: 0.5869, reader_cost: 0.02105, ips: 10.2235 samples/sec | ETA 07:47:21
2023-02-05 00:18:03 [INFO]	[TRAIN] epoch: 2560, iter: 202230/250000, loss: 0.4744, lr: 0.002255, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6329 samples/sec | ETA 07:29:15
2023-02-05 00:18:08 [INFO]	[TRAIN] epoch: 2560, iter: 202240/250000, loss: 0.2676, lr: 0.002254, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6382 samples/sec | ETA 07:28:56
2023-02-05 00:18:14 [INFO]	[TRAIN] epoch: 2561, iter: 202250/250000, loss: 0.3584, lr: 0.002254, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6336 samples/sec | ETA 07:29:02
2023-02-05 00:18:20 [INFO]	[TRAIN] epoch: 2561, iter: 202260/250000, loss: 0.4056, lr: 0.002253, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6294 samples/sec | ETA 07:29:07
2023-02-05 00:18:25 [INFO]	[TRAIN] epoch: 2561, iter: 202270/250000, loss: 0.4088, lr: 0.002253, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6291 samples/sec | ETA 07:29:02
2023-02-05 00:18:31 [INFO]	[TRAIN] epoch: 2561, iter: 202280/250000, loss: 0.4261, lr: 0.002253, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6333 samples/sec | ETA 07:28:46
2023-02-05 00:18:37 [INFO]	[TRAIN] epoch: 2561, iter: 202290/250000, loss: 0.4241, lr: 0.002252, batch_cost: 0.5637, reader_cost: 0.00010, ips: 10.6433 samples/sec | ETA 07:28:15
2023-02-05 00:18:43 [INFO]	[TRAIN] epoch: 2561, iter: 202300/250000, loss: 0.3517, lr: 0.002252, batch_cost: 0.5886, reader_cost: 0.02434, ips: 10.1939 samples/sec | ETA 07:47:55
2023-02-05 00:18:48 [INFO]	[TRAIN] epoch: 2561, iter: 202310/250000, loss: 0.3578, lr: 0.002251, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6345 samples/sec | ETA 07:28:26
2023-02-05 00:18:54 [INFO]	[TRAIN] epoch: 2562, iter: 202320/250000, loss: 0.2985, lr: 0.002251, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6323 samples/sec | ETA 07:28:26
2023-02-05 00:18:59 [INFO]	[TRAIN] epoch: 2562, iter: 202330/250000, loss: 0.2928, lr: 0.002251, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6339 samples/sec | ETA 07:28:16
2023-02-05 00:19:05 [INFO]	[TRAIN] epoch: 2562, iter: 202340/250000, loss: 0.3032, lr: 0.002250, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6321 samples/sec | ETA 07:28:15
2023-02-05 00:19:11 [INFO]	[TRAIN] epoch: 2562, iter: 202350/250000, loss: 0.2907, lr: 0.002250, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6396 samples/sec | ETA 07:27:51
2023-02-05 00:19:16 [INFO]	[TRAIN] epoch: 2562, iter: 202360/250000, loss: 0.3281, lr: 0.002249, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6349 samples/sec | ETA 07:27:57
2023-02-05 00:19:22 [INFO]	[TRAIN] epoch: 2562, iter: 202370/250000, loss: 0.3020, lr: 0.002249, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6265 samples/sec | ETA 07:28:13
2023-02-05 00:19:28 [INFO]	[TRAIN] epoch: 2562, iter: 202380/250000, loss: 0.2814, lr: 0.002248, batch_cost: 0.5913, reader_cost: 0.02628, ips: 10.1477 samples/sec | ETA 07:49:16
2023-02-05 00:19:34 [INFO]	[TRAIN] epoch: 2562, iter: 202390/250000, loss: 0.2803, lr: 0.002248, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6377 samples/sec | ETA 07:27:33
2023-02-05 00:19:39 [INFO]	[TRAIN] epoch: 2563, iter: 202400/250000, loss: 0.2805, lr: 0.002248, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6277 samples/sec | ETA 07:27:53
2023-02-05 00:19:45 [INFO]	[TRAIN] epoch: 2563, iter: 202410/250000, loss: 0.2518, lr: 0.002247, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6342 samples/sec | ETA 07:27:31
2023-02-05 00:19:51 [INFO]	[TRAIN] epoch: 2563, iter: 202420/250000, loss: 0.2483, lr: 0.002247, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6422 samples/sec | ETA 07:27:05
2023-02-05 00:19:56 [INFO]	[TRAIN] epoch: 2563, iter: 202430/250000, loss: 0.2326, lr: 0.002246, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6357 samples/sec | ETA 07:27:16
2023-02-05 00:20:02 [INFO]	[TRAIN] epoch: 2563, iter: 202440/250000, loss: 0.2455, lr: 0.002246, batch_cost: 0.5647, reader_cost: 0.00012, ips: 10.6249 samples/sec | ETA 07:27:37
2023-02-05 00:20:08 [INFO]	[TRAIN] epoch: 2563, iter: 202450/250000, loss: 0.2191, lr: 0.002245, batch_cost: 0.5896, reader_cost: 0.02510, ips: 10.1763 samples/sec | ETA 07:47:15
2023-02-05 00:20:13 [INFO]	[TRAIN] epoch: 2563, iter: 202460/250000, loss: 0.2766, lr: 0.002245, batch_cost: 0.5652, reader_cost: 0.00023, ips: 10.6149 samples/sec | ETA 07:27:51
2023-02-05 00:20:19 [INFO]	[TRAIN] epoch: 2563, iter: 202470/250000, loss: 0.2120, lr: 0.002245, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6325 samples/sec | ETA 07:27:01
2023-02-05 00:20:25 [INFO]	[TRAIN] epoch: 2564, iter: 202480/250000, loss: 0.2917, lr: 0.002244, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6314 samples/sec | ETA 07:26:58
2023-02-05 00:20:30 [INFO]	[TRAIN] epoch: 2564, iter: 202490/250000, loss: 0.2607, lr: 0.002244, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6360 samples/sec | ETA 07:26:41
2023-02-05 00:20:36 [INFO]	[TRAIN] epoch: 2564, iter: 202500/250000, loss: 0.2193, lr: 0.002243, batch_cost: 0.5643, reader_cost: 0.00011, ips: 10.6323 samples/sec | ETA 07:26:45
2023-02-05 00:20:42 [INFO]	[TRAIN] epoch: 2564, iter: 202510/250000, loss: 0.2310, lr: 0.002243, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6325 samples/sec | ETA 07:26:38
2023-02-05 00:20:47 [INFO]	[TRAIN] epoch: 2564, iter: 202520/250000, loss: 0.2659, lr: 0.002242, batch_cost: 0.5645, reader_cost: 0.00011, ips: 10.6292 samples/sec | ETA 07:26:41
2023-02-05 00:20:53 [INFO]	[TRAIN] epoch: 2564, iter: 202530/250000, loss: 0.4305, lr: 0.002242, batch_cost: 0.5928, reader_cost: 0.02840, ips: 10.1211 samples/sec | ETA 07:49:01
2023-02-05 00:20:59 [INFO]	[TRAIN] epoch: 2564, iter: 202540/250000, loss: 0.2091, lr: 0.002242, batch_cost: 0.5646, reader_cost: 0.00020, ips: 10.6276 samples/sec | ETA 07:26:34
2023-02-05 00:21:04 [INFO]	[TRAIN] epoch: 2564, iter: 202550/250000, loss: 0.2215, lr: 0.002241, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6261 samples/sec | ETA 07:26:32
2023-02-05 00:21:10 [INFO]	[TRAIN] epoch: 2565, iter: 202560/250000, loss: 0.2352, lr: 0.002241, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6294 samples/sec | ETA 07:26:18
2023-02-05 00:21:16 [INFO]	[TRAIN] epoch: 2565, iter: 202570/250000, loss: 0.2773, lr: 0.002240, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6392 samples/sec | ETA 07:25:48
2023-02-05 00:21:21 [INFO]	[TRAIN] epoch: 2565, iter: 202580/250000, loss: 0.2421, lr: 0.002240, batch_cost: 0.5640, reader_cost: 0.00011, ips: 10.6383 samples/sec | ETA 07:25:44
2023-02-05 00:21:27 [INFO]	[TRAIN] epoch: 2565, iter: 202590/250000, loss: 0.2317, lr: 0.002239, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6340 samples/sec | ETA 07:25:50
2023-02-05 00:21:33 [INFO]	[TRAIN] epoch: 2565, iter: 202600/250000, loss: 0.2762, lr: 0.002239, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6305 samples/sec | ETA 07:25:53
2023-02-05 00:21:39 [INFO]	[TRAIN] epoch: 2565, iter: 202610/250000, loss: 0.2558, lr: 0.002239, batch_cost: 0.5845, reader_cost: 0.01963, ips: 10.2649 samples/sec | ETA 07:41:40
2023-02-05 00:21:44 [INFO]	[TRAIN] epoch: 2565, iter: 202620/250000, loss: 0.2269, lr: 0.002238, batch_cost: 0.5646, reader_cost: 0.00014, ips: 10.6269 samples/sec | ETA 07:25:50
2023-02-05 00:21:50 [INFO]	[TRAIN] epoch: 2565, iter: 202630/250000, loss: 0.2072, lr: 0.002238, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6304 samples/sec | ETA 07:25:36
2023-02-05 00:21:55 [INFO]	[TRAIN] epoch: 2566, iter: 202640/250000, loss: 0.2705, lr: 0.002237, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6382 samples/sec | ETA 07:25:11
2023-02-05 00:22:01 [INFO]	[TRAIN] epoch: 2566, iter: 202650/250000, loss: 0.2897, lr: 0.002237, batch_cost: 0.5641, reader_cost: 0.00011, ips: 10.6357 samples/sec | ETA 07:25:11
2023-02-05 00:22:07 [INFO]	[TRAIN] epoch: 2566, iter: 202660/250000, loss: 0.2554, lr: 0.002236, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6325 samples/sec | ETA 07:25:14
2023-02-05 00:22:12 [INFO]	[TRAIN] epoch: 2566, iter: 202670/250000, loss: 0.4218, lr: 0.002236, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6289 samples/sec | ETA 07:25:17
2023-02-05 00:22:18 [INFO]	[TRAIN] epoch: 2566, iter: 202680/250000, loss: 0.2543, lr: 0.002236, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6317 samples/sec | ETA 07:25:05
2023-02-05 00:22:24 [INFO]	[TRAIN] epoch: 2566, iter: 202690/250000, loss: 0.2932, lr: 0.002235, batch_cost: 0.5947, reader_cost: 0.03001, ips: 10.0886 samples/sec | ETA 07:48:56
2023-02-05 00:22:30 [INFO]	[TRAIN] epoch: 2566, iter: 202700/250000, loss: 0.2672, lr: 0.002235, batch_cost: 0.5640, reader_cost: 0.00015, ips: 10.6381 samples/sec | ETA 07:24:37
2023-02-05 00:22:35 [INFO]	[TRAIN] epoch: 2566, iter: 202710/250000, loss: 0.2089, lr: 0.002234, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6371 samples/sec | ETA 07:24:34
2023-02-05 00:22:41 [INFO]	[TRAIN] epoch: 2567, iter: 202720/250000, loss: 0.2330, lr: 0.002234, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6308 samples/sec | ETA 07:24:44
2023-02-05 00:22:47 [INFO]	[TRAIN] epoch: 2567, iter: 202730/250000, loss: 0.2635, lr: 0.002234, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6327 samples/sec | ETA 07:24:34
2023-02-05 00:22:52 [INFO]	[TRAIN] epoch: 2567, iter: 202740/250000, loss: 0.2716, lr: 0.002233, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6216 samples/sec | ETA 07:24:56
2023-02-05 00:22:58 [INFO]	[TRAIN] epoch: 2567, iter: 202750/250000, loss: 0.1902, lr: 0.002233, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6279 samples/sec | ETA 07:24:35
2023-02-05 00:23:03 [INFO]	[TRAIN] epoch: 2567, iter: 202760/250000, loss: 0.2869, lr: 0.002232, batch_cost: 0.5638, reader_cost: 0.00010, ips: 10.6419 samples/sec | ETA 07:23:54
2023-02-05 00:23:09 [INFO]	[TRAIN] epoch: 2567, iter: 202770/250000, loss: 0.2578, lr: 0.002232, batch_cost: 0.5921, reader_cost: 0.02765, ips: 10.1338 samples/sec | ETA 07:46:03
2023-02-05 00:23:15 [INFO]	[TRAIN] epoch: 2567, iter: 202780/250000, loss: 0.2431, lr: 0.002231, batch_cost: 0.5640, reader_cost: 0.00014, ips: 10.6388 samples/sec | ETA 07:23:50
2023-02-05 00:23:21 [INFO]	[TRAIN] epoch: 2567, iter: 202790/250000, loss: 0.2660, lr: 0.002231, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6342 samples/sec | ETA 07:23:56
2023-02-05 00:23:26 [INFO]	[TRAIN] epoch: 2568, iter: 202800/250000, loss: 0.3302, lr: 0.002231, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6306 samples/sec | ETA 07:24:00
2023-02-05 00:23:32 [INFO]	[TRAIN] epoch: 2568, iter: 202810/250000, loss: 0.2431, lr: 0.002230, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6319 samples/sec | ETA 07:23:51
2023-02-05 00:23:38 [INFO]	[TRAIN] epoch: 2568, iter: 202820/250000, loss: 0.2367, lr: 0.002230, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6316 samples/sec | ETA 07:23:46
2023-02-05 00:23:43 [INFO]	[TRAIN] epoch: 2568, iter: 202830/250000, loss: 0.2855, lr: 0.002229, batch_cost: 0.5645, reader_cost: 0.00011, ips: 10.6296 samples/sec | ETA 07:23:45
2023-02-05 00:23:49 [INFO]	[TRAIN] epoch: 2568, iter: 202840/250000, loss: 0.2850, lr: 0.002229, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6378 samples/sec | ETA 07:23:19
2023-02-05 00:23:55 [INFO]	[TRAIN] epoch: 2568, iter: 202850/250000, loss: 0.2570, lr: 0.002228, batch_cost: 0.5961, reader_cost: 0.03161, ips: 10.0658 samples/sec | ETA 07:48:25
2023-02-05 00:24:01 [INFO]	[TRAIN] epoch: 2568, iter: 202860/250000, loss: 0.2343, lr: 0.002228, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6310 samples/sec | ETA 07:23:25
2023-02-05 00:24:06 [INFO]	[TRAIN] epoch: 2568, iter: 202870/250000, loss: 0.2757, lr: 0.002228, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6353 samples/sec | ETA 07:23:08
2023-02-05 00:24:12 [INFO]	[TRAIN] epoch: 2569, iter: 202880/250000, loss: 0.2320, lr: 0.002227, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6356 samples/sec | ETA 07:23:02
2023-02-05 00:24:17 [INFO]	[TRAIN] epoch: 2569, iter: 202890/250000, loss: 0.1939, lr: 0.002227, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6345 samples/sec | ETA 07:22:59
2023-02-05 00:24:23 [INFO]	[TRAIN] epoch: 2569, iter: 202900/250000, loss: 0.2139, lr: 0.002226, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6372 samples/sec | ETA 07:22:47
2023-02-05 00:24:29 [INFO]	[TRAIN] epoch: 2569, iter: 202910/250000, loss: 0.2940, lr: 0.002226, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6393 samples/sec | ETA 07:22:36
2023-02-05 00:24:34 [INFO]	[TRAIN] epoch: 2569, iter: 202920/250000, loss: 0.3115, lr: 0.002225, batch_cost: 0.5650, reader_cost: 0.00011, ips: 10.6197 samples/sec | ETA 07:23:19
2023-02-05 00:24:40 [INFO]	[TRAIN] epoch: 2569, iter: 202930/250000, loss: 0.3388, lr: 0.002225, batch_cost: 0.5921, reader_cost: 0.02711, ips: 10.1328 samples/sec | ETA 07:44:31
2023-02-05 00:24:46 [INFO]	[TRAIN] epoch: 2569, iter: 202940/250000, loss: 0.2641, lr: 0.002225, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6013 samples/sec | ETA 07:23:54
2023-02-05 00:24:52 [INFO]	[TRAIN] epoch: 2569, iter: 202950/250000, loss: 0.2940, lr: 0.002224, batch_cost: 0.5663, reader_cost: 0.00011, ips: 10.5950 samples/sec | ETA 07:24:04
2023-02-05 00:24:57 [INFO]	[TRAIN] epoch: 2570, iter: 202960/250000, loss: 0.2656, lr: 0.002224, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6000 samples/sec | ETA 07:23:46
2023-02-05 00:25:03 [INFO]	[TRAIN] epoch: 2570, iter: 202970/250000, loss: 0.2816, lr: 0.002223, batch_cost: 0.5661, reader_cost: 0.00012, ips: 10.5981 samples/sec | ETA 07:23:45
2023-02-05 00:25:09 [INFO]	[TRAIN] epoch: 2570, iter: 202980/250000, loss: 0.2507, lr: 0.002223, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5970 samples/sec | ETA 07:23:42
2023-02-05 00:25:14 [INFO]	[TRAIN] epoch: 2570, iter: 202990/250000, loss: 0.2672, lr: 0.002222, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6076 samples/sec | ETA 07:23:10
2023-02-05 00:25:20 [INFO]	[TRAIN] epoch: 2570, iter: 203000/250000, loss: 0.3124, lr: 0.002222, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6068 samples/sec | ETA 07:23:06
2023-02-05 00:25:26 [INFO]	[TRAIN] epoch: 2570, iter: 203010/250000, loss: 0.2520, lr: 0.002222, batch_cost: 0.5937, reader_cost: 0.02914, ips: 10.1063 samples/sec | ETA 07:44:57
2023-02-05 00:25:31 [INFO]	[TRAIN] epoch: 2570, iter: 203020/250000, loss: 0.2550, lr: 0.002221, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6322 samples/sec | ETA 07:21:51
2023-02-05 00:25:37 [INFO]	[TRAIN] epoch: 2570, iter: 203030/250000, loss: 0.2417, lr: 0.002221, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6245 samples/sec | ETA 07:22:05
2023-02-05 00:25:43 [INFO]	[TRAIN] epoch: 2571, iter: 203040/250000, loss: 0.2796, lr: 0.002220, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6383 samples/sec | ETA 07:21:25
2023-02-05 00:25:48 [INFO]	[TRAIN] epoch: 2571, iter: 203050/250000, loss: 0.2964, lr: 0.002220, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6335 samples/sec | ETA 07:21:31
2023-02-05 00:25:54 [INFO]	[TRAIN] epoch: 2571, iter: 203060/250000, loss: 0.3083, lr: 0.002219, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6317 samples/sec | ETA 07:21:30
2023-02-05 00:26:00 [INFO]	[TRAIN] epoch: 2571, iter: 203070/250000, loss: 0.2543, lr: 0.002219, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6274 samples/sec | ETA 07:21:35
2023-02-05 00:26:05 [INFO]	[TRAIN] epoch: 2571, iter: 203080/250000, loss: 0.2461, lr: 0.002219, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6270 samples/sec | ETA 07:21:31
2023-02-05 00:26:11 [INFO]	[TRAIN] epoch: 2571, iter: 203090/250000, loss: 0.2423, lr: 0.002218, batch_cost: 0.5879, reader_cost: 0.02376, ips: 10.2065 samples/sec | ETA 07:39:36
2023-02-05 00:26:17 [INFO]	[TRAIN] epoch: 2571, iter: 203100/250000, loss: 0.2903, lr: 0.002218, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6358 samples/sec | ETA 07:20:57
2023-02-05 00:26:23 [INFO]	[TRAIN] epoch: 2572, iter: 203110/250000, loss: 0.2675, lr: 0.002217, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6324 samples/sec | ETA 07:21:00
2023-02-05 00:26:28 [INFO]	[TRAIN] epoch: 2572, iter: 203120/250000, loss: 0.2782, lr: 0.002217, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6315 samples/sec | ETA 07:20:57
2023-02-05 00:26:34 [INFO]	[TRAIN] epoch: 2572, iter: 203130/250000, loss: 0.3374, lr: 0.002217, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6357 samples/sec | ETA 07:20:41
2023-02-05 00:26:39 [INFO]	[TRAIN] epoch: 2572, iter: 203140/250000, loss: 0.3554, lr: 0.002216, batch_cost: 0.5638, reader_cost: 0.00010, ips: 10.6422 samples/sec | ETA 07:20:19
2023-02-05 00:26:45 [INFO]	[TRAIN] epoch: 2572, iter: 203150/250000, loss: 0.2818, lr: 0.002216, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6354 samples/sec | ETA 07:20:30
2023-02-05 00:26:51 [INFO]	[TRAIN] epoch: 2572, iter: 203160/250000, loss: 0.2930, lr: 0.002215, batch_cost: 0.5648, reader_cost: 0.00011, ips: 10.6241 samples/sec | ETA 07:20:53
2023-02-05 00:26:57 [INFO]	[TRAIN] epoch: 2572, iter: 203170/250000, loss: 0.3104, lr: 0.002215, batch_cost: 0.5928, reader_cost: 0.02788, ips: 10.1216 samples/sec | ETA 07:42:40
2023-02-05 00:27:02 [INFO]	[TRAIN] epoch: 2572, iter: 203180/250000, loss: 0.2820, lr: 0.002214, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6341 samples/sec | ETA 07:20:16
2023-02-05 00:27:08 [INFO]	[TRAIN] epoch: 2573, iter: 203190/250000, loss: 0.2430, lr: 0.002214, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6274 samples/sec | ETA 07:20:27
2023-02-05 00:27:14 [INFO]	[TRAIN] epoch: 2573, iter: 203200/250000, loss: 0.2219, lr: 0.002214, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6257 samples/sec | ETA 07:20:26
2023-02-05 00:27:19 [INFO]	[TRAIN] epoch: 2573, iter: 203210/250000, loss: 0.2099, lr: 0.002213, batch_cost: 0.5642, reader_cost: 0.00011, ips: 10.6342 samples/sec | ETA 07:19:59
2023-02-05 00:27:25 [INFO]	[TRAIN] epoch: 2573, iter: 203220/250000, loss: 0.2177, lr: 0.002213, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6350 samples/sec | ETA 07:19:51
2023-02-05 00:27:31 [INFO]	[TRAIN] epoch: 2573, iter: 203230/250000, loss: 0.1725, lr: 0.002212, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6312 samples/sec | ETA 07:19:55
2023-02-05 00:27:36 [INFO]	[TRAIN] epoch: 2573, iter: 203240/250000, loss: 0.2418, lr: 0.002212, batch_cost: 0.5892, reader_cost: 0.02477, ips: 10.1834 samples/sec | ETA 07:39:10
2023-02-05 00:27:42 [INFO]	[TRAIN] epoch: 2573, iter: 203250/250000, loss: 0.1879, lr: 0.002211, batch_cost: 0.5643, reader_cost: 0.00019, ips: 10.6332 samples/sec | ETA 07:19:39
2023-02-05 00:27:48 [INFO]	[TRAIN] epoch: 2573, iter: 203260/250000, loss: 0.1943, lr: 0.002211, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6410 samples/sec | ETA 07:19:14
2023-02-05 00:27:53 [INFO]	[TRAIN] epoch: 2574, iter: 203270/250000, loss: 0.2809, lr: 0.002211, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6329 samples/sec | ETA 07:19:29
2023-02-05 00:27:59 [INFO]	[TRAIN] epoch: 2574, iter: 203280/250000, loss: 0.2286, lr: 0.002210, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6291 samples/sec | ETA 07:19:32
2023-02-05 00:28:05 [INFO]	[TRAIN] epoch: 2574, iter: 203290/250000, loss: 0.3323, lr: 0.002210, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6293 samples/sec | ETA 07:19:26
2023-02-05 00:28:10 [INFO]	[TRAIN] epoch: 2574, iter: 203300/250000, loss: 0.2109, lr: 0.002209, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6356 samples/sec | ETA 07:19:05
2023-02-05 00:28:16 [INFO]	[TRAIN] epoch: 2574, iter: 203310/250000, loss: 0.2289, lr: 0.002209, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6309 samples/sec | ETA 07:19:11
2023-02-05 00:28:22 [INFO]	[TRAIN] epoch: 2574, iter: 203320/250000, loss: 0.2394, lr: 0.002208, batch_cost: 0.5988, reader_cost: 0.03458, ips: 10.0206 samples/sec | ETA 07:45:50
2023-02-05 00:28:28 [INFO]	[TRAIN] epoch: 2574, iter: 203330/250000, loss: 0.1931, lr: 0.002208, batch_cost: 0.5654, reader_cost: 0.00018, ips: 10.6113 samples/sec | ETA 07:19:48
2023-02-05 00:28:33 [INFO]	[TRAIN] epoch: 2574, iter: 203340/250000, loss: 0.1777, lr: 0.002208, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6359 samples/sec | ETA 07:18:42
2023-02-05 00:28:39 [INFO]	[TRAIN] epoch: 2575, iter: 203350/250000, loss: 0.1949, lr: 0.002207, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6371 samples/sec | ETA 07:18:33
2023-02-05 00:28:44 [INFO]	[TRAIN] epoch: 2575, iter: 203360/250000, loss: 0.2094, lr: 0.002207, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6282 samples/sec | ETA 07:18:49
2023-02-05 00:28:50 [INFO]	[TRAIN] epoch: 2575, iter: 203370/250000, loss: 0.1849, lr: 0.002206, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6346 samples/sec | ETA 07:18:28
2023-02-05 00:28:56 [INFO]	[TRAIN] epoch: 2575, iter: 203380/250000, loss: 0.2436, lr: 0.002206, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6293 samples/sec | ETA 07:18:35
2023-02-05 00:29:01 [INFO]	[TRAIN] epoch: 2575, iter: 203390/250000, loss: 0.2086, lr: 0.002205, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6327 samples/sec | ETA 07:18:21
2023-02-05 00:29:07 [INFO]	[TRAIN] epoch: 2575, iter: 203400/250000, loss: 0.2345, lr: 0.002205, batch_cost: 0.5916, reader_cost: 0.02717, ips: 10.1418 samples/sec | ETA 07:39:29
2023-02-05 00:29:13 [INFO]	[TRAIN] epoch: 2575, iter: 203410/250000, loss: 0.2335, lr: 0.002205, batch_cost: 0.5648, reader_cost: 0.00011, ips: 10.6240 samples/sec | ETA 07:18:32
2023-02-05 00:29:19 [INFO]	[TRAIN] epoch: 2575, iter: 203420/250000, loss: 0.2274, lr: 0.002204, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6356 samples/sec | ETA 07:17:57
2023-02-05 00:29:24 [INFO]	[TRAIN] epoch: 2576, iter: 203430/250000, loss: 0.2082, lr: 0.002204, batch_cost: 0.5636, reader_cost: 0.00009, ips: 10.6456 samples/sec | ETA 07:17:27
2023-02-05 00:29:30 [INFO]	[TRAIN] epoch: 2576, iter: 203440/250000, loss: 0.2911, lr: 0.002203, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6335 samples/sec | ETA 07:17:51
2023-02-05 00:29:36 [INFO]	[TRAIN] epoch: 2576, iter: 203450/250000, loss: 0.2127, lr: 0.002203, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6333 samples/sec | ETA 07:17:46
2023-02-05 00:29:41 [INFO]	[TRAIN] epoch: 2576, iter: 203460/250000, loss: 0.2264, lr: 0.002202, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6303 samples/sec | ETA 07:17:48
2023-02-05 00:29:47 [INFO]	[TRAIN] epoch: 2576, iter: 203470/250000, loss: 0.2094, lr: 0.002202, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6288 samples/sec | ETA 07:17:46
2023-02-05 00:29:53 [INFO]	[TRAIN] epoch: 2576, iter: 203480/250000, loss: 0.1875, lr: 0.002202, batch_cost: 0.5917, reader_cost: 0.02749, ips: 10.1409 samples/sec | ETA 07:38:44
2023-02-05 00:29:58 [INFO]	[TRAIN] epoch: 2576, iter: 203490/250000, loss: 0.1949, lr: 0.002201, batch_cost: 0.5647, reader_cost: 0.00015, ips: 10.6245 samples/sec | ETA 07:17:45
2023-02-05 00:30:04 [INFO]	[TRAIN] epoch: 2576, iter: 203500/250000, loss: 0.1586, lr: 0.002201, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6282 samples/sec | ETA 07:17:30
2023-02-05 00:30:10 [INFO]	[TRAIN] epoch: 2577, iter: 203510/250000, loss: 0.1908, lr: 0.002200, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6381 samples/sec | ETA 07:17:00
2023-02-05 00:30:15 [INFO]	[TRAIN] epoch: 2577, iter: 203520/250000, loss: 0.1980, lr: 0.002200, batch_cost: 0.5644, reader_cost: 0.00011, ips: 10.6309 samples/sec | ETA 07:17:12
2023-02-05 00:30:21 [INFO]	[TRAIN] epoch: 2577, iter: 203530/250000, loss: 0.2658, lr: 0.002199, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6310 samples/sec | ETA 07:17:07
2023-02-05 00:30:27 [INFO]	[TRAIN] epoch: 2577, iter: 203540/250000, loss: 0.2482, lr: 0.002199, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6265 samples/sec | ETA 07:17:12
2023-02-05 00:30:32 [INFO]	[TRAIN] epoch: 2577, iter: 203550/250000, loss: 0.2028, lr: 0.002199, batch_cost: 0.5643, reader_cost: 0.00011, ips: 10.6333 samples/sec | ETA 07:16:50
2023-02-05 00:30:38 [INFO]	[TRAIN] epoch: 2577, iter: 203560/250000, loss: 0.2469, lr: 0.002198, batch_cost: 0.5898, reader_cost: 0.02545, ips: 10.1735 samples/sec | ETA 07:36:28
2023-02-05 00:30:44 [INFO]	[TRAIN] epoch: 2577, iter: 203570/250000, loss: 0.2616, lr: 0.002198, batch_cost: 0.5649, reader_cost: 0.00011, ips: 10.6207 samples/sec | ETA 07:17:09
2023-02-05 00:30:49 [INFO]	[TRAIN] epoch: 2577, iter: 203580/250000, loss: 0.2618, lr: 0.002197, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6335 samples/sec | ETA 07:16:32
2023-02-05 00:30:55 [INFO]	[TRAIN] epoch: 2578, iter: 203590/250000, loss: 0.3088, lr: 0.002197, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6389 samples/sec | ETA 07:16:13
2023-02-05 00:31:01 [INFO]	[TRAIN] epoch: 2578, iter: 203600/250000, loss: 0.4148, lr: 0.002196, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6325 samples/sec | ETA 07:16:23
2023-02-05 00:31:06 [INFO]	[TRAIN] epoch: 2578, iter: 203610/250000, loss: 0.3189, lr: 0.002196, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6343 samples/sec | ETA 07:16:13
2023-02-05 00:31:12 [INFO]	[TRAIN] epoch: 2578, iter: 203620/250000, loss: 0.2981, lr: 0.002196, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6277 samples/sec | ETA 07:16:24
2023-02-05 00:31:18 [INFO]	[TRAIN] epoch: 2578, iter: 203630/250000, loss: 0.2531, lr: 0.002195, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6240 samples/sec | ETA 07:16:27
2023-02-05 00:31:24 [INFO]	[TRAIN] epoch: 2578, iter: 203640/250000, loss: 0.2263, lr: 0.002195, batch_cost: 0.5943, reader_cost: 0.02985, ips: 10.0965 samples/sec | ETA 07:39:10
2023-02-05 00:31:29 [INFO]	[TRAIN] epoch: 2578, iter: 203650/250000, loss: 0.2806, lr: 0.002194, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6344 samples/sec | ETA 07:15:51
2023-02-05 00:31:35 [INFO]	[TRAIN] epoch: 2578, iter: 203660/250000, loss: 0.2705, lr: 0.002194, batch_cost: 0.5638, reader_cost: 0.00010, ips: 10.6415 samples/sec | ETA 07:15:27
2023-02-05 00:31:41 [INFO]	[TRAIN] epoch: 2579, iter: 203670/250000, loss: 0.2274, lr: 0.002194, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6387 samples/sec | ETA 07:15:29
2023-02-05 00:31:46 [INFO]	[TRAIN] epoch: 2579, iter: 203680/250000, loss: 0.2094, lr: 0.002193, batch_cost: 0.5641, reader_cost: 0.00011, ips: 10.6358 samples/sec | ETA 07:15:30
2023-02-05 00:31:52 [INFO]	[TRAIN] epoch: 2579, iter: 203690/250000, loss: 0.3166, lr: 0.002193, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6230 samples/sec | ETA 07:15:56
2023-02-05 00:31:57 [INFO]	[TRAIN] epoch: 2579, iter: 203700/250000, loss: 0.2424, lr: 0.002192, batch_cost: 0.5641, reader_cost: 0.00011, ips: 10.6359 samples/sec | ETA 07:15:19
2023-02-05 00:32:03 [INFO]	[TRAIN] epoch: 2579, iter: 203710/250000, loss: 0.2460, lr: 0.002192, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6350 samples/sec | ETA 07:15:15
2023-02-05 00:32:09 [INFO]	[TRAIN] epoch: 2579, iter: 203720/250000, loss: 0.1908, lr: 0.002191, batch_cost: 0.5869, reader_cost: 0.02290, ips: 10.2232 samples/sec | ETA 07:32:41
2023-02-05 00:32:15 [INFO]	[TRAIN] epoch: 2579, iter: 203730/250000, loss: 0.2922, lr: 0.002191, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6304 samples/sec | ETA 07:15:15
2023-02-05 00:32:20 [INFO]	[TRAIN] epoch: 2579, iter: 203740/250000, loss: 0.2070, lr: 0.002191, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6319 samples/sec | ETA 07:15:06
2023-02-05 00:32:26 [INFO]	[TRAIN] epoch: 2580, iter: 203750/250000, loss: 0.2683, lr: 0.002190, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6317 samples/sec | ETA 07:15:01
2023-02-05 00:32:32 [INFO]	[TRAIN] epoch: 2580, iter: 203760/250000, loss: 0.2477, lr: 0.002190, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6361 samples/sec | ETA 07:14:44
2023-02-05 00:32:37 [INFO]	[TRAIN] epoch: 2580, iter: 203770/250000, loss: 0.2885, lr: 0.002189, batch_cost: 0.5642, reader_cost: 0.00011, ips: 10.6354 samples/sec | ETA 07:14:40
2023-02-05 00:32:43 [INFO]	[TRAIN] epoch: 2580, iter: 203780/250000, loss: 0.2626, lr: 0.002189, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6347 samples/sec | ETA 07:14:37
2023-02-05 00:32:48 [INFO]	[TRAIN] epoch: 2580, iter: 203790/250000, loss: 0.2515, lr: 0.002188, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6270 samples/sec | ETA 07:14:50
2023-02-05 00:32:54 [INFO]	[TRAIN] epoch: 2580, iter: 203800/250000, loss: 0.2407, lr: 0.002188, batch_cost: 0.5944, reader_cost: 0.02984, ips: 10.0946 samples/sec | ETA 07:37:40
2023-02-05 00:33:00 [INFO]	[TRAIN] epoch: 2580, iter: 203810/250000, loss: 0.1759, lr: 0.002188, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6337 samples/sec | ETA 07:14:22
2023-02-05 00:33:06 [INFO]	[TRAIN] epoch: 2580, iter: 203820/250000, loss: 0.2608, lr: 0.002187, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6281 samples/sec | ETA 07:14:30
2023-02-05 00:33:11 [INFO]	[TRAIN] epoch: 2581, iter: 203830/250000, loss: 0.2196, lr: 0.002187, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6366 samples/sec | ETA 07:14:04
2023-02-05 00:33:17 [INFO]	[TRAIN] epoch: 2581, iter: 203840/250000, loss: 0.2880, lr: 0.002186, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6267 samples/sec | ETA 07:14:22
2023-02-05 00:33:23 [INFO]	[TRAIN] epoch: 2581, iter: 203850/250000, loss: 0.2322, lr: 0.002186, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6337 samples/sec | ETA 07:13:59
2023-02-05 00:33:28 [INFO]	[TRAIN] epoch: 2581, iter: 203860/250000, loss: 0.2976, lr: 0.002185, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6253 samples/sec | ETA 07:14:14
2023-02-05 00:33:34 [INFO]	[TRAIN] epoch: 2581, iter: 203870/250000, loss: 0.3295, lr: 0.002185, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6334 samples/sec | ETA 07:13:49
2023-02-05 00:33:40 [INFO]	[TRAIN] epoch: 2581, iter: 203880/250000, loss: 0.2679, lr: 0.002185, batch_cost: 0.5938, reader_cost: 0.02766, ips: 10.1044 samples/sec | ETA 07:36:26
2023-02-05 00:33:46 [INFO]	[TRAIN] epoch: 2581, iter: 203890/250000, loss: 0.2331, lr: 0.002184, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6314 samples/sec | ETA 07:13:42
2023-02-05 00:33:51 [INFO]	[TRAIN] epoch: 2582, iter: 203900/250000, loss: 0.3516, lr: 0.002184, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6363 samples/sec | ETA 07:13:25
2023-02-05 00:33:57 [INFO]	[TRAIN] epoch: 2582, iter: 203910/250000, loss: 0.2622, lr: 0.002183, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6338 samples/sec | ETA 07:13:25
2023-02-05 00:34:02 [INFO]	[TRAIN] epoch: 2582, iter: 203920/250000, loss: 0.2844, lr: 0.002183, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6339 samples/sec | ETA 07:13:19
2023-02-05 00:34:08 [INFO]	[TRAIN] epoch: 2582, iter: 203930/250000, loss: 0.2674, lr: 0.002182, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6317 samples/sec | ETA 07:13:19
2023-02-05 00:34:14 [INFO]	[TRAIN] epoch: 2582, iter: 203940/250000, loss: 0.2642, lr: 0.002182, batch_cost: 0.5645, reader_cost: 0.00011, ips: 10.6295 samples/sec | ETA 07:13:19
2023-02-05 00:34:19 [INFO]	[TRAIN] epoch: 2582, iter: 203950/250000, loss: 0.2613, lr: 0.002182, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6417 samples/sec | ETA 07:12:43
2023-02-05 00:34:25 [INFO]	[TRAIN] epoch: 2582, iter: 203960/250000, loss: 0.2727, lr: 0.002181, batch_cost: 0.5907, reader_cost: 0.02560, ips: 10.1566 samples/sec | ETA 07:33:17
2023-02-05 00:34:31 [INFO]	[TRAIN] epoch: 2582, iter: 203970/250000, loss: 0.2709, lr: 0.002181, batch_cost: 0.5646, reader_cost: 0.00011, ips: 10.6268 samples/sec | ETA 07:13:09
2023-02-05 00:34:37 [INFO]	[TRAIN] epoch: 2583, iter: 203980/250000, loss: 0.4402, lr: 0.002180, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6258 samples/sec | ETA 07:13:05
2023-02-05 00:34:42 [INFO]	[TRAIN] epoch: 2583, iter: 203990/250000, loss: 0.2709, lr: 0.002180, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6370 samples/sec | ETA 07:12:32
2023-02-05 00:34:48 [INFO]	[TRAIN] epoch: 2583, iter: 204000/250000, loss: 0.2840, lr: 0.002179, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6359 samples/sec | ETA 07:12:29
2023-02-05 00:34:48 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1233 - reader cost: 0.0226 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1477 - reader cost: 0.0114 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1554 - reader cost: 0.0076 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1573 - reader cost: 0.0057 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1584 - reader cost: 0.0046 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1598 - reader cost: 0.0038 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1595 - reader cost: 0.0033 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1603 - reader cost: 0.0029 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1619 - reader cost: 0.002610/36 [=======>......................] - ETA: 4s - batch_cost: 0.1617 - reader cost: 0.002311/36 [========>.....................] - ETA: 4s - batch_cost: 0.1621 - reader cost: 0.002112/36 [=========>....................] - ETA: 3s - batch_cost: 0.1617 - reader cost: 0.002013/36 [=========>....................] - ETA: 3s - batch_cost: 0.1623 - reader cost: 0.001814/36 [==========>...................] - ETA: 3s - batch_cost: 0.1626 - reader cost: 0.001715/36 [===========>..................] - ETA: 3s - batch_cost: 0.1628 - reader cost: 0.001616/36 [============>.................] - ETA: 3s - batch_cost: 0.1634 - reader cost: 0.001517/36 [=============>................] - ETA: 3s - batch_cost: 0.1635 - reader cost: 0.001418/36 [==============>...............] - ETA: 2s - batch_cost: 0.1639 - reader cost: 0.001319/36 [==============>...............] - ETA: 2s - batch_cost: 0.1635 - reader cost: 0.001320/36 [===============>..............] - ETA: 2s - batch_cost: 0.1634 - reader cost: 0.001221/36 [================>.............] - ETA: 2s - batch_cost: 0.1633 - reader cost: 0.001122/36 [=================>............] - ETA: 2s - batch_cost: 0.1638 - reader cost: 0.001123/36 [==================>...........] - ETA: 2s - batch_cost: 0.1644 - reader cost: 0.001124/36 [===================>..........] - ETA: 1s - batch_cost: 0.1644 - reader cost: 0.001025/36 [===================>..........] - ETA: 1s - batch_cost: 0.1647 - reader cost: 9.7373e-0426/36 [====================>.........] - ETA: 1s - batch_cost: 0.1650 - reader cost: 9.3888e-0427/36 [=====================>........] - ETA: 1s - batch_cost: 0.1651 - reader cost: 9.0671e-0428/36 [======================>.......] - ETA: 1s - batch_cost: 0.1655 - reader cost: 8.7681e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1656 - reader cost: 8.4896e-0430/36 [========================>.....] - ETA: 0s - batch_cost: 0.1657 - reader cost: 8.2292e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1658 - reader cost: 7.9850e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1657 - reader cost: 7.7580e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1655 - reader cost: 7.5422e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1653 - reader cost: 7.3390e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1653 - reader cost: 7.1474e-0436/36 [==============================] - 6s 166ms/step - batch_cost: 0.1654 - reader cost: 6.9663e-04
2023-02-05 00:34:54 [INFO]	[EVAL] #Images: 36 mIoU: 0.8460 Acc: 0.9857 Kappa: 0.9485 Dice: 0.9108
2023-02-05 00:34:54 [INFO]	[EVAL] Class IoU: 
[0.9857 0.9202 0.88   0.6719 0.6246 0.9666 0.8733]
2023-02-05 00:34:54 [INFO]	[EVAL] Class Precision: 
[0.9936 0.9667 0.9262 0.8461 0.8318 0.9737 0.9039]
2023-02-05 00:34:54 [INFO]	[EVAL] Class Recall: 
[0.992  0.9503 0.9463 0.7654 0.7148 0.9925 0.9627]
2023-02-05 00:34:55 [INFO]	[EVAL] The model with the best validation mIoU (0.8460) was saved at iter 204000.
2023-02-05 00:35:00 [INFO]	[TRAIN] epoch: 2583, iter: 204010/250000, loss: 0.3085, lr: 0.002179, batch_cost: 0.5636, reader_cost: 0.00011, ips: 10.6466 samples/sec | ETA 07:11:58
2023-02-05 00:35:06 [INFO]	[TRAIN] epoch: 2583, iter: 204020/250000, loss: 0.3277, lr: 0.002179, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6379 samples/sec | ETA 07:12:13
2023-02-05 00:35:12 [INFO]	[TRAIN] epoch: 2583, iter: 204030/250000, loss: 0.2956, lr: 0.002178, batch_cost: 0.5910, reader_cost: 0.02754, ips: 10.1526 samples/sec | ETA 07:32:47
2023-02-05 00:35:18 [INFO]	[TRAIN] epoch: 2583, iter: 204040/250000, loss: 0.2897, lr: 0.002178, batch_cost: 0.5644, reader_cost: 0.00020, ips: 10.6317 samples/sec | ETA 07:12:17
2023-02-05 00:35:23 [INFO]	[TRAIN] epoch: 2583, iter: 204050/250000, loss: 0.3466, lr: 0.002177, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6349 samples/sec | ETA 07:12:04
2023-02-05 00:35:29 [INFO]	[TRAIN] epoch: 2584, iter: 204060/250000, loss: 0.3152, lr: 0.002177, batch_cost: 0.5638, reader_cost: 0.00010, ips: 10.6428 samples/sec | ETA 07:11:39
2023-02-05 00:35:35 [INFO]	[TRAIN] epoch: 2584, iter: 204070/250000, loss: 0.3283, lr: 0.002176, batch_cost: 0.5638, reader_cost: 0.00010, ips: 10.6427 samples/sec | ETA 07:11:33
2023-02-05 00:35:40 [INFO]	[TRAIN] epoch: 2584, iter: 204080/250000, loss: 0.2603, lr: 0.002176, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6400 samples/sec | ETA 07:11:34
2023-02-05 00:35:46 [INFO]	[TRAIN] epoch: 2584, iter: 204090/250000, loss: 0.3023, lr: 0.002176, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6281 samples/sec | ETA 07:11:58
2023-02-05 00:35:52 [INFO]	[TRAIN] epoch: 2584, iter: 204100/250000, loss: 0.2923, lr: 0.002175, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6352 samples/sec | ETA 07:11:35
2023-02-05 00:35:57 [INFO]	[TRAIN] epoch: 2584, iter: 204110/250000, loss: 0.2873, lr: 0.002175, batch_cost: 0.5960, reader_cost: 0.03207, ips: 10.0665 samples/sec | ETA 07:35:52
2023-02-05 00:36:03 [INFO]	[TRAIN] epoch: 2584, iter: 204120/250000, loss: 0.2299, lr: 0.002174, batch_cost: 0.5645, reader_cost: 0.00011, ips: 10.6298 samples/sec | ETA 07:11:37
2023-02-05 00:36:09 [INFO]	[TRAIN] epoch: 2584, iter: 204130/250000, loss: 0.2797, lr: 0.002174, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6386 samples/sec | ETA 07:11:09
2023-02-05 00:36:14 [INFO]	[TRAIN] epoch: 2585, iter: 204140/250000, loss: 0.3150, lr: 0.002173, batch_cost: 0.5640, reader_cost: 0.00011, ips: 10.6375 samples/sec | ETA 07:11:06
2023-02-05 00:36:20 [INFO]	[TRAIN] epoch: 2585, iter: 204150/250000, loss: 0.2229, lr: 0.002173, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6368 samples/sec | ETA 07:11:03
2023-02-05 00:36:26 [INFO]	[TRAIN] epoch: 2585, iter: 204160/250000, loss: 0.2930, lr: 0.002173, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6285 samples/sec | ETA 07:11:17
2023-02-05 00:36:31 [INFO]	[TRAIN] epoch: 2585, iter: 204170/250000, loss: 0.2593, lr: 0.002172, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6329 samples/sec | ETA 07:11:01
2023-02-05 00:36:37 [INFO]	[TRAIN] epoch: 2585, iter: 204180/250000, loss: 0.2668, lr: 0.002172, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6369 samples/sec | ETA 07:10:45
2023-02-05 00:36:43 [INFO]	[TRAIN] epoch: 2585, iter: 204190/250000, loss: 0.2982, lr: 0.002171, batch_cost: 0.5891, reader_cost: 0.02487, ips: 10.1847 samples/sec | ETA 07:29:47
2023-02-05 00:36:49 [INFO]	[TRAIN] epoch: 2585, iter: 204200/250000, loss: 0.2767, lr: 0.002171, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6123 samples/sec | ETA 07:11:34
2023-02-05 00:36:54 [INFO]	[TRAIN] epoch: 2585, iter: 204210/250000, loss: 0.2052, lr: 0.002170, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6357 samples/sec | ETA 07:10:31
2023-02-05 00:37:00 [INFO]	[TRAIN] epoch: 2586, iter: 204220/250000, loss: 0.2315, lr: 0.002170, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6384 samples/sec | ETA 07:10:19
2023-02-05 00:37:05 [INFO]	[TRAIN] epoch: 2586, iter: 204230/250000, loss: 0.2076, lr: 0.002170, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6313 samples/sec | ETA 07:10:31
2023-02-05 00:37:11 [INFO]	[TRAIN] epoch: 2586, iter: 204240/250000, loss: 0.2649, lr: 0.002169, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6288 samples/sec | ETA 07:10:31
2023-02-05 00:37:17 [INFO]	[TRAIN] epoch: 2586, iter: 204250/250000, loss: 0.2237, lr: 0.002169, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6300 samples/sec | ETA 07:10:23
2023-02-05 00:37:22 [INFO]	[TRAIN] epoch: 2586, iter: 204260/250000, loss: 0.2751, lr: 0.002168, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6308 samples/sec | ETA 07:10:15
2023-02-05 00:37:28 [INFO]	[TRAIN] epoch: 2586, iter: 204270/250000, loss: 0.2397, lr: 0.002168, batch_cost: 0.6024, reader_cost: 0.03790, ips: 9.9595 samples/sec | ETA 07:39:09
2023-02-05 00:37:34 [INFO]	[TRAIN] epoch: 2586, iter: 204280/250000, loss: 0.2467, lr: 0.002167, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6194 samples/sec | ETA 07:10:32
2023-02-05 00:37:40 [INFO]	[TRAIN] epoch: 2586, iter: 204290/250000, loss: 0.2543, lr: 0.002167, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6368 samples/sec | ETA 07:09:44
2023-02-05 00:37:45 [INFO]	[TRAIN] epoch: 2587, iter: 204300/250000, loss: 0.1858, lr: 0.002167, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6360 samples/sec | ETA 07:09:40
2023-02-05 00:37:51 [INFO]	[TRAIN] epoch: 2587, iter: 204310/250000, loss: 0.2095, lr: 0.002166, batch_cost: 0.5645, reader_cost: 0.00013, ips: 10.6294 samples/sec | ETA 07:09:50
2023-02-05 00:37:57 [INFO]	[TRAIN] epoch: 2587, iter: 204320/250000, loss: 0.2686, lr: 0.002166, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6284 samples/sec | ETA 07:09:47
2023-02-05 00:38:02 [INFO]	[TRAIN] epoch: 2587, iter: 204330/250000, loss: 0.3537, lr: 0.002165, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6294 samples/sec | ETA 07:09:39
2023-02-05 00:38:08 [INFO]	[TRAIN] epoch: 2587, iter: 204340/250000, loss: 0.2617, lr: 0.002165, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6267 samples/sec | ETA 07:09:40
2023-02-05 00:38:14 [INFO]	[TRAIN] epoch: 2587, iter: 204350/250000, loss: 0.3619, lr: 0.002165, batch_cost: 0.5977, reader_cost: 0.03259, ips: 10.0389 samples/sec | ETA 07:34:43
2023-02-05 00:38:20 [INFO]	[TRAIN] epoch: 2587, iter: 204360/250000, loss: 0.2584, lr: 0.002164, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6320 samples/sec | ETA 07:09:16
2023-02-05 00:38:25 [INFO]	[TRAIN] epoch: 2587, iter: 204370/250000, loss: 0.2609, lr: 0.002164, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6333 samples/sec | ETA 07:09:07
2023-02-05 00:38:31 [INFO]	[TRAIN] epoch: 2588, iter: 204380/250000, loss: 0.3014, lr: 0.002163, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6327 samples/sec | ETA 07:09:03
2023-02-05 00:38:36 [INFO]	[TRAIN] epoch: 2588, iter: 204390/250000, loss: 0.2074, lr: 0.002163, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6241 samples/sec | ETA 07:09:18
2023-02-05 00:38:42 [INFO]	[TRAIN] epoch: 2588, iter: 204400/250000, loss: 0.2677, lr: 0.002162, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6388 samples/sec | ETA 07:08:37
2023-02-05 00:38:48 [INFO]	[TRAIN] epoch: 2588, iter: 204410/250000, loss: 0.2570, lr: 0.002162, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6392 samples/sec | ETA 07:08:30
2023-02-05 00:38:53 [INFO]	[TRAIN] epoch: 2588, iter: 204420/250000, loss: 0.2932, lr: 0.002162, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6289 samples/sec | ETA 07:08:49
2023-02-05 00:38:59 [INFO]	[TRAIN] epoch: 2588, iter: 204430/250000, loss: 0.2108, lr: 0.002161, batch_cost: 0.5918, reader_cost: 0.02753, ips: 10.1384 samples/sec | ETA 07:29:28
2023-02-05 00:39:05 [INFO]	[TRAIN] epoch: 2588, iter: 204440/250000, loss: 0.2971, lr: 0.002161, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6366 samples/sec | ETA 07:08:19
2023-02-05 00:39:11 [INFO]	[TRAIN] epoch: 2588, iter: 204450/250000, loss: 0.1993, lr: 0.002160, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6278 samples/sec | ETA 07:08:35
2023-02-05 00:39:16 [INFO]	[TRAIN] epoch: 2589, iter: 204460/250000, loss: 0.2212, lr: 0.002160, batch_cost: 0.5642, reader_cost: 0.00011, ips: 10.6342 samples/sec | ETA 07:08:14
2023-02-05 00:39:22 [INFO]	[TRAIN] epoch: 2589, iter: 204470/250000, loss: 0.1846, lr: 0.002159, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6355 samples/sec | ETA 07:08:05
2023-02-05 00:39:28 [INFO]	[TRAIN] epoch: 2589, iter: 204480/250000, loss: 0.2093, lr: 0.002159, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6394 samples/sec | ETA 07:07:50
2023-02-05 00:39:33 [INFO]	[TRAIN] epoch: 2589, iter: 204490/250000, loss: 0.2249, lr: 0.002159, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6269 samples/sec | ETA 07:08:15
2023-02-05 00:39:39 [INFO]	[TRAIN] epoch: 2589, iter: 204500/250000, loss: 0.1915, lr: 0.002158, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6299 samples/sec | ETA 07:08:02
2023-02-05 00:39:45 [INFO]	[TRAIN] epoch: 2589, iter: 204510/250000, loss: 0.2035, lr: 0.002158, batch_cost: 0.5898, reader_cost: 0.02547, ips: 10.1724 samples/sec | ETA 07:27:11
2023-02-05 00:39:50 [INFO]	[TRAIN] epoch: 2589, iter: 204520/250000, loss: 0.2488, lr: 0.002157, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6362 samples/sec | ETA 07:07:35
2023-02-05 00:39:56 [INFO]	[TRAIN] epoch: 2589, iter: 204530/250000, loss: 0.2322, lr: 0.002157, batch_cost: 0.5643, reader_cost: 0.00013, ips: 10.6322 samples/sec | ETA 07:07:39
2023-02-05 00:40:02 [INFO]	[TRAIN] epoch: 2590, iter: 204540/250000, loss: 0.2065, lr: 0.002156, batch_cost: 0.5644, reader_cost: 0.00011, ips: 10.6307 samples/sec | ETA 07:07:37
2023-02-05 00:40:07 [INFO]	[TRAIN] epoch: 2590, iter: 204550/250000, loss: 0.2492, lr: 0.002156, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6296 samples/sec | ETA 07:07:34
2023-02-05 00:40:13 [INFO]	[TRAIN] epoch: 2590, iter: 204560/250000, loss: 0.3055, lr: 0.002156, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6313 samples/sec | ETA 07:07:25
2023-02-05 00:40:19 [INFO]	[TRAIN] epoch: 2590, iter: 204570/250000, loss: 0.2798, lr: 0.002155, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6403 samples/sec | ETA 07:06:57
2023-02-05 00:40:24 [INFO]	[TRAIN] epoch: 2590, iter: 204580/250000, loss: 0.3118, lr: 0.002155, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6308 samples/sec | ETA 07:07:14
2023-02-05 00:40:30 [INFO]	[TRAIN] epoch: 2590, iter: 204590/250000, loss: 0.2777, lr: 0.002154, batch_cost: 0.5910, reader_cost: 0.02591, ips: 10.1526 samples/sec | ETA 07:27:16
2023-02-05 00:40:36 [INFO]	[TRAIN] epoch: 2590, iter: 204600/250000, loss: 0.2277, lr: 0.002154, batch_cost: 0.5635, reader_cost: 0.00010, ips: 10.6478 samples/sec | ETA 07:06:22
2023-02-05 00:40:41 [INFO]	[TRAIN] epoch: 2590, iter: 204610/250000, loss: 0.2409, lr: 0.002153, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6404 samples/sec | ETA 07:06:34
2023-02-05 00:40:47 [INFO]	[TRAIN] epoch: 2591, iter: 204620/250000, loss: 0.2384, lr: 0.002153, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6280 samples/sec | ETA 07:06:59
2023-02-05 00:40:53 [INFO]	[TRAIN] epoch: 2591, iter: 204630/250000, loss: 0.2360, lr: 0.002153, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6321 samples/sec | ETA 07:06:43
2023-02-05 00:40:58 [INFO]	[TRAIN] epoch: 2591, iter: 204640/250000, loss: 0.2447, lr: 0.002152, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6330 samples/sec | ETA 07:06:35
2023-02-05 00:41:04 [INFO]	[TRAIN] epoch: 2591, iter: 204650/250000, loss: 0.2310, lr: 0.002152, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6363 samples/sec | ETA 07:06:22
2023-02-05 00:41:10 [INFO]	[TRAIN] epoch: 2591, iter: 204660/250000, loss: 0.2134, lr: 0.002151, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6400 samples/sec | ETA 07:06:07
2023-02-05 00:41:16 [INFO]	[TRAIN] epoch: 2591, iter: 204670/250000, loss: 0.2799, lr: 0.002151, batch_cost: 0.5941, reader_cost: 0.03000, ips: 10.0991 samples/sec | ETA 07:28:51
2023-02-05 00:41:21 [INFO]	[TRAIN] epoch: 2591, iter: 204680/250000, loss: 0.2552, lr: 0.002150, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6360 samples/sec | ETA 07:06:06
2023-02-05 00:41:27 [INFO]	[TRAIN] epoch: 2592, iter: 204690/250000, loss: 0.2393, lr: 0.002150, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6296 samples/sec | ETA 07:06:15
2023-02-05 00:41:33 [INFO]	[TRAIN] epoch: 2592, iter: 204700/250000, loss: 0.4084, lr: 0.002150, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6280 samples/sec | ETA 07:06:13
2023-02-05 00:41:38 [INFO]	[TRAIN] epoch: 2592, iter: 204710/250000, loss: 0.2813, lr: 0.002149, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6296 samples/sec | ETA 07:06:04
2023-02-05 00:41:44 [INFO]	[TRAIN] epoch: 2592, iter: 204720/250000, loss: 0.2671, lr: 0.002149, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6383 samples/sec | ETA 07:05:37
2023-02-05 00:41:49 [INFO]	[TRAIN] epoch: 2592, iter: 204730/250000, loss: 0.3116, lr: 0.002148, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6361 samples/sec | ETA 07:05:37
2023-02-05 00:41:55 [INFO]	[TRAIN] epoch: 2592, iter: 204740/250000, loss: 0.2258, lr: 0.002148, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6316 samples/sec | ETA 07:05:42
2023-02-05 00:42:01 [INFO]	[TRAIN] epoch: 2592, iter: 204750/250000, loss: 0.2189, lr: 0.002147, batch_cost: 0.5911, reader_cost: 0.02573, ips: 10.1510 samples/sec | ETA 07:25:46
2023-02-05 00:42:07 [INFO]	[TRAIN] epoch: 2592, iter: 204760/250000, loss: 0.3292, lr: 0.002147, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6394 samples/sec | ETA 07:05:12
2023-02-05 00:42:12 [INFO]	[TRAIN] epoch: 2593, iter: 204770/250000, loss: 0.2794, lr: 0.002147, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6335 samples/sec | ETA 07:05:21
2023-02-05 00:42:18 [INFO]	[TRAIN] epoch: 2593, iter: 204780/250000, loss: 0.2098, lr: 0.002146, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6347 samples/sec | ETA 07:05:12
2023-02-05 00:42:24 [INFO]	[TRAIN] epoch: 2593, iter: 204790/250000, loss: 0.1938, lr: 0.002146, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6269 samples/sec | ETA 07:05:25
2023-02-05 00:42:29 [INFO]	[TRAIN] epoch: 2593, iter: 204800/250000, loss: 0.2014, lr: 0.002145, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6240 samples/sec | ETA 07:05:27
2023-02-05 00:42:35 [INFO]	[TRAIN] epoch: 2593, iter: 204810/250000, loss: 0.2221, lr: 0.002145, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6373 samples/sec | ETA 07:04:49
2023-02-05 00:42:41 [INFO]	[TRAIN] epoch: 2593, iter: 204820/250000, loss: 0.1738, lr: 0.002144, batch_cost: 0.5934, reader_cost: 0.02972, ips: 10.1109 samples/sec | ETA 07:26:50
2023-02-05 00:42:46 [INFO]	[TRAIN] epoch: 2593, iter: 204830/250000, loss: 0.2886, lr: 0.002144, batch_cost: 0.5646, reader_cost: 0.00019, ips: 10.6261 samples/sec | ETA 07:05:05
2023-02-05 00:42:52 [INFO]	[TRAIN] epoch: 2593, iter: 204840/250000, loss: 0.1940, lr: 0.002144, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6353 samples/sec | ETA 07:04:37
2023-02-05 00:42:58 [INFO]	[TRAIN] epoch: 2594, iter: 204850/250000, loss: 0.2661, lr: 0.002143, batch_cost: 0.5641, reader_cost: 0.00011, ips: 10.6370 samples/sec | ETA 07:04:27
2023-02-05 00:43:03 [INFO]	[TRAIN] epoch: 2594, iter: 204860/250000, loss: 0.2136, lr: 0.002143, batch_cost: 0.5645, reader_cost: 0.00011, ips: 10.6284 samples/sec | ETA 07:04:42
2023-02-05 00:43:09 [INFO]	[TRAIN] epoch: 2594, iter: 204870/250000, loss: 0.2233, lr: 0.002142, batch_cost: 0.5645, reader_cost: 0.00011, ips: 10.6295 samples/sec | ETA 07:04:34
2023-02-05 00:43:15 [INFO]	[TRAIN] epoch: 2594, iter: 204880/250000, loss: 0.1865, lr: 0.002142, batch_cost: 0.5637, reader_cost: 0.00010, ips: 10.6435 samples/sec | ETA 07:03:55
2023-02-05 00:43:20 [INFO]	[TRAIN] epoch: 2594, iter: 204890/250000, loss: 0.2269, lr: 0.002141, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6358 samples/sec | ETA 07:04:07
2023-02-05 00:43:26 [INFO]	[TRAIN] epoch: 2594, iter: 204900/250000, loss: 0.1890, lr: 0.002141, batch_cost: 0.5919, reader_cost: 0.02778, ips: 10.1374 samples/sec | ETA 07:24:53
2023-02-05 00:43:32 [INFO]	[TRAIN] epoch: 2594, iter: 204910/250000, loss: 0.1927, lr: 0.002141, batch_cost: 0.5638, reader_cost: 0.00017, ips: 10.6418 samples/sec | ETA 07:03:42
2023-02-05 00:43:38 [INFO]	[TRAIN] epoch: 2594, iter: 204920/250000, loss: 0.2583, lr: 0.002140, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6312 samples/sec | ETA 07:04:02
2023-02-05 00:43:43 [INFO]	[TRAIN] epoch: 2595, iter: 204930/250000, loss: 0.1787, lr: 0.002140, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6188 samples/sec | ETA 07:04:26
2023-02-05 00:43:49 [INFO]	[TRAIN] epoch: 2595, iter: 204940/250000, loss: 0.2059, lr: 0.002139, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6085 samples/sec | ETA 07:04:45
2023-02-05 00:43:54 [INFO]	[TRAIN] epoch: 2595, iter: 204950/250000, loss: 0.1607, lr: 0.002139, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6058 samples/sec | ETA 07:04:46
2023-02-05 00:44:00 [INFO]	[TRAIN] epoch: 2595, iter: 204960/250000, loss: 0.2232, lr: 0.002138, batch_cost: 0.5663, reader_cost: 0.00010, ips: 10.5949 samples/sec | ETA 07:05:06
2023-02-05 00:44:06 [INFO]	[TRAIN] epoch: 2595, iter: 204970/250000, loss: 0.1719, lr: 0.002138, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5976 samples/sec | ETA 07:04:54
2023-02-05 00:44:12 [INFO]	[TRAIN] epoch: 2595, iter: 204980/250000, loss: 0.2034, lr: 0.002138, batch_cost: 0.5953, reader_cost: 0.02973, ips: 10.0782 samples/sec | ETA 07:26:42
2023-02-05 00:44:17 [INFO]	[TRAIN] epoch: 2595, iter: 204990/250000, loss: 0.2054, lr: 0.002137, batch_cost: 0.5642, reader_cost: 0.00011, ips: 10.6341 samples/sec | ETA 07:03:15
2023-02-05 00:44:23 [INFO]	[TRAIN] epoch: 2595, iter: 205000/250000, loss: 0.2277, lr: 0.002137, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6335 samples/sec | ETA 07:03:11
2023-02-05 00:44:29 [INFO]	[TRAIN] epoch: 2596, iter: 205010/250000, loss: 0.2975, lr: 0.002136, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6332 samples/sec | ETA 07:03:06
2023-02-05 00:44:34 [INFO]	[TRAIN] epoch: 2596, iter: 205020/250000, loss: 0.1995, lr: 0.002136, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6333 samples/sec | ETA 07:03:00
2023-02-05 00:44:40 [INFO]	[TRAIN] epoch: 2596, iter: 205030/250000, loss: 0.2310, lr: 0.002135, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6327 samples/sec | ETA 07:02:56
2023-02-05 00:44:46 [INFO]	[TRAIN] epoch: 2596, iter: 205040/250000, loss: 0.2260, lr: 0.002135, batch_cost: 0.5637, reader_cost: 0.00010, ips: 10.6436 samples/sec | ETA 07:02:24
2023-02-05 00:44:51 [INFO]	[TRAIN] epoch: 2596, iter: 205050/250000, loss: 0.2444, lr: 0.002135, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6293 samples/sec | ETA 07:02:53
2023-02-05 00:44:57 [INFO]	[TRAIN] epoch: 2596, iter: 205060/250000, loss: 0.3133, lr: 0.002134, batch_cost: 0.5999, reader_cost: 0.03533, ips: 10.0016 samples/sec | ETA 07:29:19
2023-02-05 00:45:03 [INFO]	[TRAIN] epoch: 2596, iter: 205070/250000, loss: 0.2681, lr: 0.002134, batch_cost: 0.5644, reader_cost: 0.00014, ips: 10.6305 samples/sec | ETA 07:02:39
2023-02-05 00:45:09 [INFO]	[TRAIN] epoch: 2596, iter: 205080/250000, loss: 0.3078, lr: 0.002133, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6378 samples/sec | ETA 07:02:16
2023-02-05 00:45:14 [INFO]	[TRAIN] epoch: 2597, iter: 205090/250000, loss: 0.3456, lr: 0.002133, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6334 samples/sec | ETA 07:02:20
2023-02-05 00:45:20 [INFO]	[TRAIN] epoch: 2597, iter: 205100/250000, loss: 0.3113, lr: 0.002132, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6380 samples/sec | ETA 07:02:04
2023-02-05 00:45:25 [INFO]	[TRAIN] epoch: 2597, iter: 205110/250000, loss: 0.2216, lr: 0.002132, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6308 samples/sec | ETA 07:02:15
2023-02-05 00:45:31 [INFO]	[TRAIN] epoch: 2597, iter: 205120/250000, loss: 0.2493, lr: 0.002132, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6315 samples/sec | ETA 07:02:08
2023-02-05 00:45:37 [INFO]	[TRAIN] epoch: 2597, iter: 205130/250000, loss: 0.2049, lr: 0.002131, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6269 samples/sec | ETA 07:02:13
2023-02-05 00:45:43 [INFO]	[TRAIN] epoch: 2597, iter: 205140/250000, loss: 0.2082, lr: 0.002131, batch_cost: 0.5922, reader_cost: 0.02818, ips: 10.1316 samples/sec | ETA 07:22:46
2023-02-05 00:45:48 [INFO]	[TRAIN] epoch: 2597, iter: 205150/250000, loss: 0.2298, lr: 0.002130, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6298 samples/sec | ETA 07:01:55
2023-02-05 00:45:54 [INFO]	[TRAIN] epoch: 2597, iter: 205160/250000, loss: 0.2611, lr: 0.002130, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6331 samples/sec | ETA 07:01:42
2023-02-05 00:46:00 [INFO]	[TRAIN] epoch: 2598, iter: 205170/250000, loss: 0.2151, lr: 0.002129, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6298 samples/sec | ETA 07:01:44
2023-02-05 00:46:05 [INFO]	[TRAIN] epoch: 2598, iter: 205180/250000, loss: 0.2049, lr: 0.002129, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6323 samples/sec | ETA 07:01:32
2023-02-05 00:46:11 [INFO]	[TRAIN] epoch: 2598, iter: 205190/250000, loss: 0.2975, lr: 0.002129, batch_cost: 0.5645, reader_cost: 0.00011, ips: 10.6283 samples/sec | ETA 07:01:36
2023-02-05 00:46:17 [INFO]	[TRAIN] epoch: 2598, iter: 205200/250000, loss: 0.2678, lr: 0.002128, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6254 samples/sec | ETA 07:01:37
2023-02-05 00:46:22 [INFO]	[TRAIN] epoch: 2598, iter: 205210/250000, loss: 0.2406, lr: 0.002128, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6358 samples/sec | ETA 07:01:07
2023-02-05 00:46:28 [INFO]	[TRAIN] epoch: 2598, iter: 205220/250000, loss: 0.2464, lr: 0.002127, batch_cost: 0.5963, reader_cost: 0.03116, ips: 10.0621 samples/sec | ETA 07:25:02
2023-02-05 00:46:34 [INFO]	[TRAIN] epoch: 2598, iter: 205230/250000, loss: 0.3020, lr: 0.002127, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6270 samples/sec | ETA 07:01:17
2023-02-05 00:46:39 [INFO]	[TRAIN] epoch: 2598, iter: 205240/250000, loss: 0.2545, lr: 0.002126, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6275 samples/sec | ETA 07:01:10
2023-02-05 00:46:45 [INFO]	[TRAIN] epoch: 2599, iter: 205250/250000, loss: 0.2655, lr: 0.002126, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6340 samples/sec | ETA 07:00:49
2023-02-05 00:46:51 [INFO]	[TRAIN] epoch: 2599, iter: 205260/250000, loss: 0.2121, lr: 0.002126, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6324 samples/sec | ETA 07:00:47
2023-02-05 00:46:56 [INFO]	[TRAIN] epoch: 2599, iter: 205270/250000, loss: 0.2149, lr: 0.002125, batch_cost: 0.5637, reader_cost: 0.00010, ips: 10.6445 samples/sec | ETA 07:00:12
2023-02-05 00:47:02 [INFO]	[TRAIN] epoch: 2599, iter: 205280/250000, loss: 0.2236, lr: 0.002125, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6301 samples/sec | ETA 07:00:41
2023-02-05 00:47:08 [INFO]	[TRAIN] epoch: 2599, iter: 205290/250000, loss: 0.1902, lr: 0.002124, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6313 samples/sec | ETA 07:00:33
2023-02-05 00:47:14 [INFO]	[TRAIN] epoch: 2599, iter: 205300/250000, loss: 0.2056, lr: 0.002124, batch_cost: 0.5982, reader_cost: 0.03351, ips: 10.0307 samples/sec | ETA 07:25:37
2023-02-05 00:47:19 [INFO]	[TRAIN] epoch: 2599, iter: 205310/250000, loss: 0.2368, lr: 0.002123, batch_cost: 0.5646, reader_cost: 0.00012, ips: 10.6274 samples/sec | ETA 07:00:30
2023-02-05 00:47:25 [INFO]	[TRAIN] epoch: 2599, iter: 205320/250000, loss: 0.2466, lr: 0.002123, batch_cost: 0.5643, reader_cost: 0.00011, ips: 10.6332 samples/sec | ETA 07:00:11
2023-02-05 00:47:31 [INFO]	[TRAIN] epoch: 2600, iter: 205330/250000, loss: 0.2232, lr: 0.002123, batch_cost: 0.5643, reader_cost: 0.00020, ips: 10.6321 samples/sec | ETA 07:00:08
2023-02-05 00:47:36 [INFO]	[TRAIN] epoch: 2600, iter: 205340/250000, loss: 0.2386, lr: 0.002122, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6271 samples/sec | ETA 07:00:14
2023-02-05 00:47:42 [INFO]	[TRAIN] epoch: 2600, iter: 205350/250000, loss: 0.2149, lr: 0.002122, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6283 samples/sec | ETA 07:00:06
2023-02-05 00:47:47 [INFO]	[TRAIN] epoch: 2600, iter: 205360/250000, loss: 0.2064, lr: 0.002121, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6321 samples/sec | ETA 06:59:51
2023-02-05 00:47:53 [INFO]	[TRAIN] epoch: 2600, iter: 205370/250000, loss: 0.2311, lr: 0.002121, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6314 samples/sec | ETA 06:59:47
2023-02-05 00:47:59 [INFO]	[TRAIN] epoch: 2600, iter: 205380/250000, loss: 0.1801, lr: 0.002121, batch_cost: 0.5884, reader_cost: 0.02401, ips: 10.1973 samples/sec | ETA 07:17:33
2023-02-05 00:48:05 [INFO]	[TRAIN] epoch: 2600, iter: 205390/250000, loss: 0.2066, lr: 0.002120, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6300 samples/sec | ETA 06:59:39
2023-02-05 00:48:10 [INFO]	[TRAIN] epoch: 2600, iter: 205400/250000, loss: 0.2771, lr: 0.002120, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6290 samples/sec | ETA 06:59:36
2023-02-05 00:48:16 [INFO]	[TRAIN] epoch: 2601, iter: 205410/250000, loss: 0.2316, lr: 0.002119, batch_cost: 0.5636, reader_cost: 0.00009, ips: 10.6455 samples/sec | ETA 06:58:51
2023-02-05 00:48:22 [INFO]	[TRAIN] epoch: 2601, iter: 205420/250000, loss: 0.2874, lr: 0.002119, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6280 samples/sec | ETA 06:59:27
2023-02-05 00:48:27 [INFO]	[TRAIN] epoch: 2601, iter: 205430/250000, loss: 0.2239, lr: 0.002118, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5992 samples/sec | ETA 07:00:30
2023-02-05 00:48:33 [INFO]	[TRAIN] epoch: 2601, iter: 205440/250000, loss: 0.2597, lr: 0.002118, batch_cost: 0.5662, reader_cost: 0.00017, ips: 10.5966 samples/sec | ETA 07:00:30
2023-02-05 00:48:39 [INFO]	[TRAIN] epoch: 2601, iter: 205450/250000, loss: 0.2380, lr: 0.002118, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6025 samples/sec | ETA 07:00:11
2023-02-05 00:48:45 [INFO]	[TRAIN] epoch: 2601, iter: 205460/250000, loss: 0.2323, lr: 0.002117, batch_cost: 0.5937, reader_cost: 0.02767, ips: 10.1063 samples/sec | ETA 07:20:42
2023-02-05 00:48:50 [INFO]	[TRAIN] epoch: 2601, iter: 205470/250000, loss: 0.2487, lr: 0.002117, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6120 samples/sec | ETA 06:59:37
2023-02-05 00:48:56 [INFO]	[TRAIN] epoch: 2602, iter: 205480/250000, loss: 0.1973, lr: 0.002116, batch_cost: 0.5663, reader_cost: 0.00010, ips: 10.5956 samples/sec | ETA 07:00:10
2023-02-05 00:49:01 [INFO]	[TRAIN] epoch: 2602, iter: 205490/250000, loss: 0.2524, lr: 0.002116, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6029 samples/sec | ETA 06:59:47
2023-02-05 00:49:07 [INFO]	[TRAIN] epoch: 2602, iter: 205500/250000, loss: 0.2269, lr: 0.002115, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6118 samples/sec | ETA 06:59:20
2023-02-05 00:49:13 [INFO]	[TRAIN] epoch: 2602, iter: 205510/250000, loss: 0.2293, lr: 0.002115, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6091 samples/sec | ETA 06:59:21
2023-02-05 00:49:18 [INFO]	[TRAIN] epoch: 2602, iter: 205520/250000, loss: 0.2095, lr: 0.002115, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6064 samples/sec | ETA 06:59:22
2023-02-05 00:49:24 [INFO]	[TRAIN] epoch: 2602, iter: 205530/250000, loss: 0.1904, lr: 0.002114, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5996 samples/sec | ETA 06:59:32
2023-02-05 00:49:30 [INFO]	[TRAIN] epoch: 2602, iter: 205540/250000, loss: 0.2246, lr: 0.002114, batch_cost: 0.5961, reader_cost: 0.03168, ips: 10.0649 samples/sec | ETA 07:21:43
2023-02-05 00:49:36 [INFO]	[TRAIN] epoch: 2602, iter: 205550/250000, loss: 0.2222, lr: 0.002113, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6075 samples/sec | ETA 06:59:02
2023-02-05 00:49:41 [INFO]	[TRAIN] epoch: 2603, iter: 205560/250000, loss: 0.2197, lr: 0.002113, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6119 samples/sec | ETA 06:58:46
2023-02-05 00:49:47 [INFO]	[TRAIN] epoch: 2603, iter: 205570/250000, loss: 0.2410, lr: 0.002112, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6039 samples/sec | ETA 06:58:59
2023-02-05 00:49:53 [INFO]	[TRAIN] epoch: 2603, iter: 205580/250000, loss: 0.2057, lr: 0.002112, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6108 samples/sec | ETA 06:58:37
2023-02-05 00:49:58 [INFO]	[TRAIN] epoch: 2603, iter: 205590/250000, loss: 0.2248, lr: 0.002112, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6056 samples/sec | ETA 06:58:44
2023-02-05 00:50:04 [INFO]	[TRAIN] epoch: 2603, iter: 205600/250000, loss: 0.1985, lr: 0.002111, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6057 samples/sec | ETA 06:58:38
2023-02-05 00:50:10 [INFO]	[TRAIN] epoch: 2603, iter: 205610/250000, loss: 0.2094, lr: 0.002111, batch_cost: 0.5974, reader_cost: 0.03142, ips: 10.0432 samples/sec | ETA 07:21:59
2023-02-05 00:50:16 [INFO]	[TRAIN] epoch: 2603, iter: 205620/250000, loss: 0.2918, lr: 0.002110, batch_cost: 0.5660, reader_cost: 0.00019, ips: 10.6013 samples/sec | ETA 06:58:37
2023-02-05 00:50:21 [INFO]	[TRAIN] epoch: 2603, iter: 205630/250000, loss: 0.1692, lr: 0.002110, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6077 samples/sec | ETA 06:58:16
2023-02-05 00:50:27 [INFO]	[TRAIN] epoch: 2604, iter: 205640/250000, loss: 0.2040, lr: 0.002109, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6029 samples/sec | ETA 06:58:22
2023-02-05 00:50:33 [INFO]	[TRAIN] epoch: 2604, iter: 205650/250000, loss: 0.2610, lr: 0.002109, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 06:58:08
2023-02-05 00:50:38 [INFO]	[TRAIN] epoch: 2604, iter: 205660/250000, loss: 0.2214, lr: 0.002109, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6094 samples/sec | ETA 06:57:55
2023-02-05 00:50:44 [INFO]	[TRAIN] epoch: 2604, iter: 205670/250000, loss: 0.2189, lr: 0.002108, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6023 samples/sec | ETA 06:58:07
2023-02-05 00:50:50 [INFO]	[TRAIN] epoch: 2604, iter: 205680/250000, loss: 0.2223, lr: 0.002108, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5970 samples/sec | ETA 06:58:13
2023-02-05 00:50:56 [INFO]	[TRAIN] epoch: 2604, iter: 205690/250000, loss: 0.2348, lr: 0.002107, batch_cost: 0.5953, reader_cost: 0.02968, ips: 10.0797 samples/sec | ETA 07:19:35
2023-02-05 00:51:01 [INFO]	[TRAIN] epoch: 2604, iter: 205700/250000, loss: 0.2226, lr: 0.002107, batch_cost: 0.5643, reader_cost: 0.00018, ips: 10.6334 samples/sec | ETA 06:56:36
2023-02-05 00:51:07 [INFO]	[TRAIN] epoch: 2604, iter: 205710/250000, loss: 0.2309, lr: 0.002106, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6381 samples/sec | ETA 06:56:20
2023-02-05 00:51:13 [INFO]	[TRAIN] epoch: 2605, iter: 205720/250000, loss: 0.2265, lr: 0.002106, batch_cost: 0.5655, reader_cost: 0.00011, ips: 10.6102 samples/sec | ETA 06:57:20
2023-02-05 00:51:18 [INFO]	[TRAIN] epoch: 2605, iter: 205730/250000, loss: 0.2833, lr: 0.002106, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6023 samples/sec | ETA 06:57:33
2023-02-05 00:51:24 [INFO]	[TRAIN] epoch: 2605, iter: 205740/250000, loss: 0.2841, lr: 0.002105, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6120 samples/sec | ETA 06:57:04
2023-02-05 00:51:29 [INFO]	[TRAIN] epoch: 2605, iter: 205750/250000, loss: 0.2306, lr: 0.002105, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6115 samples/sec | ETA 06:57:00
2023-02-05 00:51:35 [INFO]	[TRAIN] epoch: 2605, iter: 205760/250000, loss: 0.2508, lr: 0.002104, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6050 samples/sec | ETA 06:57:09
2023-02-05 00:51:41 [INFO]	[TRAIN] epoch: 2605, iter: 205770/250000, loss: 0.2231, lr: 0.002104, batch_cost: 0.5879, reader_cost: 0.02281, ips: 10.2063 samples/sec | ETA 07:13:21
2023-02-05 00:51:47 [INFO]	[TRAIN] epoch: 2605, iter: 205780/250000, loss: 0.3004, lr: 0.002103, batch_cost: 0.5657, reader_cost: 0.00016, ips: 10.6072 samples/sec | ETA 06:56:53
2023-02-05 00:51:52 [INFO]	[TRAIN] epoch: 2605, iter: 205790/250000, loss: 0.2259, lr: 0.002103, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6072 samples/sec | ETA 06:56:47
2023-02-05 00:51:58 [INFO]	[TRAIN] epoch: 2606, iter: 205800/250000, loss: 0.3031, lr: 0.002103, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6107 samples/sec | ETA 06:56:33
2023-02-05 00:52:04 [INFO]	[TRAIN] epoch: 2606, iter: 205810/250000, loss: 0.2249, lr: 0.002102, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6074 samples/sec | ETA 06:56:35
2023-02-05 00:52:09 [INFO]	[TRAIN] epoch: 2606, iter: 205820/250000, loss: 0.2407, lr: 0.002102, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6120 samples/sec | ETA 06:56:19
2023-02-05 00:52:15 [INFO]	[TRAIN] epoch: 2606, iter: 205830/250000, loss: 0.2452, lr: 0.002101, batch_cost: 0.5654, reader_cost: 0.00011, ips: 10.6111 samples/sec | ETA 06:56:15
2023-02-05 00:52:21 [INFO]	[TRAIN] epoch: 2606, iter: 205840/250000, loss: 0.2124, lr: 0.002101, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6058 samples/sec | ETA 06:56:22
2023-02-05 00:52:27 [INFO]	[TRAIN] epoch: 2606, iter: 205850/250000, loss: 0.3480, lr: 0.002100, batch_cost: 0.5925, reader_cost: 0.02740, ips: 10.1261 samples/sec | ETA 07:16:00
2023-02-05 00:52:32 [INFO]	[TRAIN] epoch: 2606, iter: 205860/250000, loss: 0.3040, lr: 0.002100, batch_cost: 0.5652, reader_cost: 0.00014, ips: 10.6152 samples/sec | ETA 06:55:49
2023-02-05 00:52:38 [INFO]	[TRAIN] epoch: 2606, iter: 205870/250000, loss: 0.2167, lr: 0.002100, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6086 samples/sec | ETA 06:55:59
2023-02-05 00:52:43 [INFO]	[TRAIN] epoch: 2607, iter: 205880/250000, loss: 0.2835, lr: 0.002099, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6067 samples/sec | ETA 06:55:57
2023-02-05 00:52:49 [INFO]	[TRAIN] epoch: 2607, iter: 205890/250000, loss: 0.2966, lr: 0.002099, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6135 samples/sec | ETA 06:55:36
2023-02-05 00:52:55 [INFO]	[TRAIN] epoch: 2607, iter: 205900/250000, loss: 0.2763, lr: 0.002098, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6156 samples/sec | ETA 06:55:25
2023-02-05 00:53:00 [INFO]	[TRAIN] epoch: 2607, iter: 205910/250000, loss: 0.2431, lr: 0.002098, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6110 samples/sec | ETA 06:55:30
2023-02-05 00:53:06 [INFO]	[TRAIN] epoch: 2607, iter: 205920/250000, loss: 0.3468, lr: 0.002097, batch_cost: 0.5657, reader_cost: 0.00011, ips: 10.6058 samples/sec | ETA 06:55:37
2023-02-05 00:53:12 [INFO]	[TRAIN] epoch: 2607, iter: 205930/250000, loss: 0.2087, lr: 0.002097, batch_cost: 0.6001, reader_cost: 0.03452, ips: 9.9976 samples/sec | ETA 07:20:48
2023-02-05 00:53:18 [INFO]	[TRAIN] epoch: 2607, iter: 205940/250000, loss: 0.2323, lr: 0.002097, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6176 samples/sec | ETA 06:54:58
2023-02-05 00:53:23 [INFO]	[TRAIN] epoch: 2607, iter: 205950/250000, loss: 0.2313, lr: 0.002096, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6106 samples/sec | ETA 06:55:09
2023-02-05 00:53:29 [INFO]	[TRAIN] epoch: 2608, iter: 205960/250000, loss: 0.2874, lr: 0.002096, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6077 samples/sec | ETA 06:55:10
2023-02-05 00:53:35 [INFO]	[TRAIN] epoch: 2608, iter: 205970/250000, loss: 0.2820, lr: 0.002095, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6172 samples/sec | ETA 06:54:42
2023-02-05 00:53:40 [INFO]	[TRAIN] epoch: 2608, iter: 205980/250000, loss: 0.2524, lr: 0.002095, batch_cost: 0.5660, reader_cost: 0.00011, ips: 10.6005 samples/sec | ETA 06:55:15
2023-02-05 00:53:46 [INFO]	[TRAIN] epoch: 2608, iter: 205990/250000, loss: 0.2620, lr: 0.002094, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6042 samples/sec | ETA 06:55:01
2023-02-05 00:53:52 [INFO]	[TRAIN] epoch: 2608, iter: 206000/250000, loss: 0.2673, lr: 0.002094, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6098 samples/sec | ETA 06:54:42
2023-02-05 00:53:52 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1288 - reader cost: 0.0252 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1541 - reader cost: 0.0127 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1600 - reader cost: 0.0085 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1598 - reader cost: 0.0064 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1603 - reader cost: 0.0051 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1627 - reader cost: 0.0043 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1624 - reader cost: 0.0037 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1634 - reader cost: 0.0032 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1649 - reader cost: 0.002910/36 [=======>......................] - ETA: 4s - batch_cost: 0.1646 - reader cost: 0.002611/36 [========>.....................] - ETA: 4s - batch_cost: 0.1654 - reader cost: 0.002412/36 [=========>....................] - ETA: 3s - batch_cost: 0.1655 - reader cost: 0.002213/36 [=========>....................] - ETA: 3s - batch_cost: 0.1658 - reader cost: 0.002014/36 [==========>...................] - ETA: 3s - batch_cost: 0.1664 - reader cost: 0.001915/36 [===========>..................] - ETA: 3s - batch_cost: 0.1664 - reader cost: 0.001816/36 [============>.................] - ETA: 3s - batch_cost: 0.1672 - reader cost: 0.001617/36 [=============>................] - ETA: 3s - batch_cost: 0.1674 - reader cost: 0.001618/36 [==============>...............] - ETA: 3s - batch_cost: 0.1679 - reader cost: 0.001519/36 [==============>...............] - ETA: 2s - batch_cost: 0.1676 - reader cost: 0.001420/36 [===============>..............] - ETA: 2s - batch_cost: 0.1675 - reader cost: 0.001321/36 [================>.............] - ETA: 2s - batch_cost: 0.1675 - reader cost: 0.001322/36 [=================>............] - ETA: 2s - batch_cost: 0.1676 - reader cost: 0.001223/36 [==================>...........] - ETA: 2s - batch_cost: 0.1681 - reader cost: 0.001224/36 [===================>..........] - ETA: 2s - batch_cost: 0.1680 - reader cost: 0.001125/36 [===================>..........] - ETA: 1s - batch_cost: 0.1681 - reader cost: 0.001126/36 [====================>.........] - ETA: 1s - batch_cost: 0.1682 - reader cost: 0.001027/36 [=====================>........] - ETA: 1s - batch_cost: 0.1684 - reader cost: 0.001028/36 [======================>.......] - ETA: 1s - batch_cost: 0.1686 - reader cost: 9.7431e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1687 - reader cost: 9.4309e-0430/36 [========================>.....] - ETA: 1s - batch_cost: 0.1686 - reader cost: 9.1392e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1686 - reader cost: 8.8665e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1686 - reader cost: 8.6119e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1683 - reader cost: 8.3723e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1682 - reader cost: 8.1455e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1682 - reader cost: 7.9316e-0436/36 [==============================] - 6s 168ms/step - batch_cost: 0.1683 - reader cost: 7.7324e-04
2023-02-05 00:53:58 [INFO]	[EVAL] #Images: 36 mIoU: 0.8498 Acc: 0.9847 Kappa: 0.9448 Dice: 0.9139
2023-02-05 00:53:58 [INFO]	[EVAL] Class IoU: 
[0.9839 0.9082 0.8818 0.6398 0.6997 0.9714 0.864 ]
2023-02-05 00:53:58 [INFO]	[EVAL] Class Precision: 
[0.992  0.9479 0.9452 0.7378 0.8215 0.983  0.9264]
2023-02-05 00:53:58 [INFO]	[EVAL] Class Recall: 
[0.9918 0.9559 0.9293 0.828  0.8252 0.9881 0.9277]
2023-02-05 00:54:00 [INFO]	[EVAL] The model with the best validation mIoU (0.8498) was saved at iter 206000.
2023-02-05 00:54:06 [INFO]	[TRAIN] epoch: 2608, iter: 206010/250000, loss: 0.2437, lr: 0.002094, batch_cost: 0.5885, reader_cost: 0.02268, ips: 10.1963 samples/sec | ETA 07:11:25
2023-02-05 00:54:11 [INFO]	[TRAIN] epoch: 2608, iter: 206020/250000, loss: 0.2476, lr: 0.002093, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6292 samples/sec | ETA 06:53:45
2023-02-05 00:54:17 [INFO]	[TRAIN] epoch: 2608, iter: 206030/250000, loss: 0.1895, lr: 0.002093, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6392 samples/sec | ETA 06:53:17
2023-02-05 00:54:23 [INFO]	[TRAIN] epoch: 2609, iter: 206040/250000, loss: 0.2125, lr: 0.002092, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6345 samples/sec | ETA 06:53:22
2023-02-05 00:54:28 [INFO]	[TRAIN] epoch: 2609, iter: 206050/250000, loss: 0.2493, lr: 0.002092, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6381 samples/sec | ETA 06:53:08
2023-02-05 00:54:34 [INFO]	[TRAIN] epoch: 2609, iter: 206060/250000, loss: 0.2856, lr: 0.002091, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6195 samples/sec | ETA 06:53:46
2023-02-05 00:54:40 [INFO]	[TRAIN] epoch: 2609, iter: 206070/250000, loss: 0.2526, lr: 0.002091, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6353 samples/sec | ETA 06:53:03
2023-02-05 00:54:45 [INFO]	[TRAIN] epoch: 2609, iter: 206080/250000, loss: 0.1875, lr: 0.002091, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6261 samples/sec | ETA 06:53:19
2023-02-05 00:54:51 [INFO]	[TRAIN] epoch: 2609, iter: 206090/250000, loss: 0.2377, lr: 0.002090, batch_cost: 0.5980, reader_cost: 0.03363, ips: 10.0339 samples/sec | ETA 07:17:37
2023-02-05 00:54:57 [INFO]	[TRAIN] epoch: 2609, iter: 206100/250000, loss: 0.1841, lr: 0.002090, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6364 samples/sec | ETA 06:52:43
2023-02-05 00:55:02 [INFO]	[TRAIN] epoch: 2609, iter: 206110/250000, loss: 0.3215, lr: 0.002089, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6255 samples/sec | ETA 06:53:03
2023-02-05 00:55:08 [INFO]	[TRAIN] epoch: 2610, iter: 206120/250000, loss: 0.2839, lr: 0.002089, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6292 samples/sec | ETA 06:52:49
2023-02-05 00:55:14 [INFO]	[TRAIN] epoch: 2610, iter: 206130/250000, loss: 0.1794, lr: 0.002088, batch_cost: 0.5637, reader_cost: 0.00009, ips: 10.6437 samples/sec | ETA 06:52:10
2023-02-05 00:55:19 [INFO]	[TRAIN] epoch: 2610, iter: 206140/250000, loss: 0.2200, lr: 0.002088, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6158 samples/sec | ETA 06:53:09
2023-02-05 00:55:25 [INFO]	[TRAIN] epoch: 2610, iter: 206150/250000, loss: 0.1925, lr: 0.002088, batch_cost: 0.5662, reader_cost: 0.00011, ips: 10.5965 samples/sec | ETA 06:53:48
2023-02-05 00:55:31 [INFO]	[TRAIN] epoch: 2610, iter: 206160/250000, loss: 0.1771, lr: 0.002087, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6052 samples/sec | ETA 06:53:22
2023-02-05 00:55:37 [INFO]	[TRAIN] epoch: 2610, iter: 206170/250000, loss: 0.1828, lr: 0.002087, batch_cost: 0.5945, reader_cost: 0.02961, ips: 10.0928 samples/sec | ETA 07:14:16
2023-02-05 00:55:42 [INFO]	[TRAIN] epoch: 2610, iter: 206180/250000, loss: 0.2953, lr: 0.002086, batch_cost: 0.5637, reader_cost: 0.00010, ips: 10.6443 samples/sec | ETA 06:51:40
2023-02-05 00:55:48 [INFO]	[TRAIN] epoch: 2610, iter: 206190/250000, loss: 0.2283, lr: 0.002086, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6298 samples/sec | ETA 06:52:08
2023-02-05 00:55:54 [INFO]	[TRAIN] epoch: 2611, iter: 206200/250000, loss: 0.1941, lr: 0.002085, batch_cost: 0.5642, reader_cost: 0.00011, ips: 10.6342 samples/sec | ETA 06:51:52
2023-02-05 00:55:59 [INFO]	[TRAIN] epoch: 2611, iter: 206210/250000, loss: 0.2149, lr: 0.002085, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6276 samples/sec | ETA 06:52:02
2023-02-05 00:56:05 [INFO]	[TRAIN] epoch: 2611, iter: 206220/250000, loss: 0.2150, lr: 0.002085, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6336 samples/sec | ETA 06:51:42
2023-02-05 00:56:11 [INFO]	[TRAIN] epoch: 2611, iter: 206230/250000, loss: 0.2759, lr: 0.002084, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6379 samples/sec | ETA 06:51:27
2023-02-05 00:56:16 [INFO]	[TRAIN] epoch: 2611, iter: 206240/250000, loss: 0.2434, lr: 0.002084, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6404 samples/sec | ETA 06:51:15
2023-02-05 00:56:22 [INFO]	[TRAIN] epoch: 2611, iter: 206250/250000, loss: 0.1976, lr: 0.002083, batch_cost: 0.5929, reader_cost: 0.02814, ips: 10.1199 samples/sec | ETA 07:12:18
2023-02-05 00:56:28 [INFO]	[TRAIN] epoch: 2611, iter: 206260/250000, loss: 0.2803, lr: 0.002083, batch_cost: 0.5638, reader_cost: 0.00011, ips: 10.6415 samples/sec | ETA 06:51:01
2023-02-05 00:56:33 [INFO]	[TRAIN] epoch: 2612, iter: 206270/250000, loss: 0.1887, lr: 0.002082, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6320 samples/sec | ETA 06:51:18
2023-02-05 00:56:39 [INFO]	[TRAIN] epoch: 2612, iter: 206280/250000, loss: 0.1845, lr: 0.002082, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6335 samples/sec | ETA 06:51:09
2023-02-05 00:56:45 [INFO]	[TRAIN] epoch: 2612, iter: 206290/250000, loss: 0.2878, lr: 0.002082, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6284 samples/sec | ETA 06:51:15
2023-02-05 00:56:50 [INFO]	[TRAIN] epoch: 2612, iter: 206300/250000, loss: 0.2008, lr: 0.002081, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6339 samples/sec | ETA 06:50:56
2023-02-05 00:56:56 [INFO]	[TRAIN] epoch: 2612, iter: 206310/250000, loss: 0.2281, lr: 0.002081, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6355 samples/sec | ETA 06:50:47
2023-02-05 00:57:02 [INFO]	[TRAIN] epoch: 2612, iter: 206320/250000, loss: 0.2407, lr: 0.002080, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5984 samples/sec | ETA 06:52:08
2023-02-05 00:57:08 [INFO]	[TRAIN] epoch: 2612, iter: 206330/250000, loss: 0.2207, lr: 0.002080, batch_cost: 0.5994, reader_cost: 0.03452, ips: 10.0096 samples/sec | ETA 07:16:16
2023-02-05 00:57:13 [INFO]	[TRAIN] epoch: 2612, iter: 206340/250000, loss: 0.2061, lr: 0.002079, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6217 samples/sec | ETA 06:51:02
2023-02-05 00:57:19 [INFO]	[TRAIN] epoch: 2613, iter: 206350/250000, loss: 0.1869, lr: 0.002079, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6342 samples/sec | ETA 06:50:28
2023-02-05 00:57:25 [INFO]	[TRAIN] epoch: 2613, iter: 206360/250000, loss: 0.2087, lr: 0.002079, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6276 samples/sec | ETA 06:50:37
2023-02-05 00:57:30 [INFO]	[TRAIN] epoch: 2613, iter: 206370/250000, loss: 0.2071, lr: 0.002078, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6254 samples/sec | ETA 06:50:37
2023-02-05 00:57:36 [INFO]	[TRAIN] epoch: 2613, iter: 206380/250000, loss: 0.1927, lr: 0.002078, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6093 samples/sec | ETA 06:51:09
2023-02-05 00:57:41 [INFO]	[TRAIN] epoch: 2613, iter: 206390/250000, loss: 0.1883, lr: 0.002077, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6203 samples/sec | ETA 06:50:37
2023-02-05 00:57:47 [INFO]	[TRAIN] epoch: 2613, iter: 206400/250000, loss: 0.1722, lr: 0.002077, batch_cost: 0.5991, reader_cost: 0.03434, ips: 10.0147 samples/sec | ETA 07:15:21
2023-02-05 00:57:53 [INFO]	[TRAIN] epoch: 2613, iter: 206410/250000, loss: 0.2189, lr: 0.002076, batch_cost: 0.5648, reader_cost: 0.00018, ips: 10.6234 samples/sec | ETA 06:50:19
2023-02-05 00:57:59 [INFO]	[TRAIN] epoch: 2613, iter: 206420/250000, loss: 0.1953, lr: 0.002076, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6287 samples/sec | ETA 06:50:01
2023-02-05 00:58:04 [INFO]	[TRAIN] epoch: 2614, iter: 206430/250000, loss: 0.1674, lr: 0.002076, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6237 samples/sec | ETA 06:50:07
2023-02-05 00:58:10 [INFO]	[TRAIN] epoch: 2614, iter: 206440/250000, loss: 0.2163, lr: 0.002075, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6059 samples/sec | ETA 06:50:42
2023-02-05 00:58:16 [INFO]	[TRAIN] epoch: 2614, iter: 206450/250000, loss: 0.2584, lr: 0.002075, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6037 samples/sec | ETA 06:50:42
2023-02-05 00:58:21 [INFO]	[TRAIN] epoch: 2614, iter: 206460/250000, loss: 0.2858, lr: 0.002074, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6130 samples/sec | ETA 06:50:15
2023-02-05 00:58:27 [INFO]	[TRAIN] epoch: 2614, iter: 206470/250000, loss: 0.1760, lr: 0.002074, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6114 samples/sec | ETA 06:50:13
2023-02-05 00:58:33 [INFO]	[TRAIN] epoch: 2614, iter: 206480/250000, loss: 0.1821, lr: 0.002073, batch_cost: 0.5930, reader_cost: 0.02801, ips: 10.1173 samples/sec | ETA 07:10:09
2023-02-05 00:58:39 [INFO]	[TRAIN] epoch: 2614, iter: 206490/250000, loss: 0.2115, lr: 0.002073, batch_cost: 0.5648, reader_cost: 0.00014, ips: 10.6229 samples/sec | ETA 06:49:35
2023-02-05 00:58:44 [INFO]	[TRAIN] epoch: 2614, iter: 206500/250000, loss: 0.1741, lr: 0.002073, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6290 samples/sec | ETA 06:49:15
2023-02-05 00:58:50 [INFO]	[TRAIN] epoch: 2615, iter: 206510/250000, loss: 0.2115, lr: 0.002072, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6265 samples/sec | ETA 06:49:15
2023-02-05 00:58:56 [INFO]	[TRAIN] epoch: 2615, iter: 206520/250000, loss: 0.1934, lr: 0.002072, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6248 samples/sec | ETA 06:49:13
2023-02-05 00:59:01 [INFO]	[TRAIN] epoch: 2615, iter: 206530/250000, loss: 0.2147, lr: 0.002071, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6073 samples/sec | ETA 06:49:48
2023-02-05 00:59:07 [INFO]	[TRAIN] epoch: 2615, iter: 206540/250000, loss: 0.2081, lr: 0.002071, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6122 samples/sec | ETA 06:49:31
2023-02-05 00:59:13 [INFO]	[TRAIN] epoch: 2615, iter: 206550/250000, loss: 0.2378, lr: 0.002070, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6014 samples/sec | ETA 06:49:51
2023-02-05 00:59:19 [INFO]	[TRAIN] epoch: 2615, iter: 206560/250000, loss: 0.1928, lr: 0.002070, batch_cost: 0.5987, reader_cost: 0.03268, ips: 10.0213 samples/sec | ETA 07:13:28
2023-02-05 00:59:24 [INFO]	[TRAIN] epoch: 2615, iter: 206570/250000, loss: 0.1820, lr: 0.002070, batch_cost: 0.5650, reader_cost: 0.00043, ips: 10.6196 samples/sec | ETA 06:48:57
2023-02-05 00:59:30 [INFO]	[TRAIN] epoch: 2615, iter: 206580/250000, loss: 0.2293, lr: 0.002069, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6100 samples/sec | ETA 06:49:14
2023-02-05 00:59:35 [INFO]	[TRAIN] epoch: 2616, iter: 206590/250000, loss: 0.2023, lr: 0.002069, batch_cost: 0.5657, reader_cost: 0.00011, ips: 10.6069 samples/sec | ETA 06:49:15
2023-02-05 00:59:41 [INFO]	[TRAIN] epoch: 2616, iter: 206600/250000, loss: 0.2631, lr: 0.002068, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6159 samples/sec | ETA 06:48:49
2023-02-05 00:59:47 [INFO]	[TRAIN] epoch: 2616, iter: 206610/250000, loss: 0.1705, lr: 0.002068, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6077 samples/sec | ETA 06:49:02
2023-02-05 00:59:52 [INFO]	[TRAIN] epoch: 2616, iter: 206620/250000, loss: 0.2101, lr: 0.002067, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6076 samples/sec | ETA 06:48:57
2023-02-05 00:59:58 [INFO]	[TRAIN] epoch: 2616, iter: 206630/250000, loss: 0.2154, lr: 0.002067, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6127 samples/sec | ETA 06:48:39
2023-02-05 01:00:04 [INFO]	[TRAIN] epoch: 2616, iter: 206640/250000, loss: 0.2421, lr: 0.002067, batch_cost: 0.5967, reader_cost: 0.03103, ips: 10.0552 samples/sec | ETA 07:11:13
2023-02-05 01:00:10 [INFO]	[TRAIN] epoch: 2616, iter: 206650/250000, loss: 0.2472, lr: 0.002066, batch_cost: 0.5648, reader_cost: 0.00018, ips: 10.6225 samples/sec | ETA 06:48:05
2023-02-05 01:00:15 [INFO]	[TRAIN] epoch: 2616, iter: 206660/250000, loss: 0.2491, lr: 0.002066, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6226 samples/sec | ETA 06:47:59
2023-02-05 01:00:21 [INFO]	[TRAIN] epoch: 2617, iter: 206670/250000, loss: 0.2892, lr: 0.002065, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6284 samples/sec | ETA 06:47:40
2023-02-05 01:00:27 [INFO]	[TRAIN] epoch: 2617, iter: 206680/250000, loss: 0.2834, lr: 0.002065, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6122 samples/sec | ETA 06:48:12
2023-02-05 01:00:32 [INFO]	[TRAIN] epoch: 2617, iter: 206690/250000, loss: 0.3174, lr: 0.002064, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6108 samples/sec | ETA 06:48:10
2023-02-05 01:00:38 [INFO]	[TRAIN] epoch: 2617, iter: 206700/250000, loss: 0.2971, lr: 0.002064, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6024 samples/sec | ETA 06:48:23
2023-02-05 01:00:44 [INFO]	[TRAIN] epoch: 2617, iter: 206710/250000, loss: 0.2543, lr: 0.002064, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6172 samples/sec | ETA 06:47:44
2023-02-05 01:00:50 [INFO]	[TRAIN] epoch: 2617, iter: 206720/250000, loss: 0.3174, lr: 0.002063, batch_cost: 0.5906, reader_cost: 0.02569, ips: 10.1588 samples/sec | ETA 07:06:01
2023-02-05 01:00:55 [INFO]	[TRAIN] epoch: 2617, iter: 206730/250000, loss: 0.2829, lr: 0.002063, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6388 samples/sec | ETA 06:46:43
2023-02-05 01:01:01 [INFO]	[TRAIN] epoch: 2617, iter: 206740/250000, loss: 0.2610, lr: 0.002062, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6336 samples/sec | ETA 06:46:49
2023-02-05 01:01:06 [INFO]	[TRAIN] epoch: 2618, iter: 206750/250000, loss: 0.2466, lr: 0.002062, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6372 samples/sec | ETA 06:46:35
2023-02-05 01:01:12 [INFO]	[TRAIN] epoch: 2618, iter: 206760/250000, loss: 0.3535, lr: 0.002061, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6264 samples/sec | ETA 06:46:54
2023-02-05 01:01:18 [INFO]	[TRAIN] epoch: 2618, iter: 206770/250000, loss: 0.2436, lr: 0.002061, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6354 samples/sec | ETA 06:46:28
2023-02-05 01:01:23 [INFO]	[TRAIN] epoch: 2618, iter: 206780/250000, loss: 0.2920, lr: 0.002061, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6291 samples/sec | ETA 06:46:37
2023-02-05 01:01:29 [INFO]	[TRAIN] epoch: 2618, iter: 206790/250000, loss: 0.2524, lr: 0.002060, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6166 samples/sec | ETA 06:47:00
2023-02-05 01:01:35 [INFO]	[TRAIN] epoch: 2618, iter: 206800/250000, loss: 0.2033, lr: 0.002060, batch_cost: 0.5877, reader_cost: 0.02249, ips: 10.2087 samples/sec | ETA 07:03:10
2023-02-05 01:01:41 [INFO]	[TRAIN] epoch: 2618, iter: 206810/250000, loss: 0.2125, lr: 0.002059, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6314 samples/sec | ETA 06:46:14
2023-02-05 01:01:46 [INFO]	[TRAIN] epoch: 2618, iter: 206820/250000, loss: 0.2335, lr: 0.002059, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6371 samples/sec | ETA 06:45:56
2023-02-05 01:01:52 [INFO]	[TRAIN] epoch: 2619, iter: 206830/250000, loss: 0.2044, lr: 0.002058, batch_cost: 0.5645, reader_cost: 0.00011, ips: 10.6284 samples/sec | ETA 06:46:10
2023-02-05 01:01:57 [INFO]	[TRAIN] epoch: 2619, iter: 206840/250000, loss: 0.2433, lr: 0.002058, batch_cost: 0.5650, reader_cost: 0.00011, ips: 10.6188 samples/sec | ETA 06:46:27
2023-02-05 01:02:03 [INFO]	[TRAIN] epoch: 2619, iter: 206850/250000, loss: 0.2745, lr: 0.002058, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6096 samples/sec | ETA 06:46:42
2023-02-05 01:02:09 [INFO]	[TRAIN] epoch: 2619, iter: 206860/250000, loss: 0.2881, lr: 0.002057, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6082 samples/sec | ETA 06:46:39
2023-02-05 01:02:14 [INFO]	[TRAIN] epoch: 2619, iter: 206870/250000, loss: 0.2780, lr: 0.002057, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6060 samples/sec | ETA 06:46:39
2023-02-05 01:02:20 [INFO]	[TRAIN] epoch: 2619, iter: 206880/250000, loss: 0.2436, lr: 0.002056, batch_cost: 0.5989, reader_cost: 0.03308, ips: 10.0185 samples/sec | ETA 07:10:24
2023-02-05 01:02:26 [INFO]	[TRAIN] epoch: 2619, iter: 206890/250000, loss: 0.2573, lr: 0.002056, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6006 samples/sec | ETA 06:46:40
2023-02-05 01:02:32 [INFO]	[TRAIN] epoch: 2619, iter: 206900/250000, loss: 0.2075, lr: 0.002055, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6057 samples/sec | ETA 06:46:23
2023-02-05 01:02:37 [INFO]	[TRAIN] epoch: 2620, iter: 206910/250000, loss: 0.2375, lr: 0.002055, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6067 samples/sec | ETA 06:46:15
2023-02-05 01:02:43 [INFO]	[TRAIN] epoch: 2620, iter: 206920/250000, loss: 0.2561, lr: 0.002055, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6087 samples/sec | ETA 06:46:04
2023-02-05 01:02:49 [INFO]	[TRAIN] epoch: 2620, iter: 206930/250000, loss: 0.3102, lr: 0.002054, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6108 samples/sec | ETA 06:45:54
2023-02-05 01:02:54 [INFO]	[TRAIN] epoch: 2620, iter: 206940/250000, loss: 0.2508, lr: 0.002054, batch_cost: 0.5655, reader_cost: 0.00011, ips: 10.6102 samples/sec | ETA 06:45:50
2023-02-05 01:03:00 [INFO]	[TRAIN] epoch: 2620, iter: 206950/250000, loss: 0.1978, lr: 0.002053, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6041 samples/sec | ETA 06:45:58
2023-02-05 01:03:06 [INFO]	[TRAIN] epoch: 2620, iter: 206960/250000, loss: 0.2679, lr: 0.002053, batch_cost: 0.6032, reader_cost: 0.03821, ips: 9.9471 samples/sec | ETA 07:12:41
2023-02-05 01:03:12 [INFO]	[TRAIN] epoch: 2620, iter: 206970/250000, loss: 0.2425, lr: 0.002052, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6283 samples/sec | ETA 06:44:51
2023-02-05 01:03:17 [INFO]	[TRAIN] epoch: 2620, iter: 206980/250000, loss: 0.2354, lr: 0.002052, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6232 samples/sec | ETA 06:44:57
2023-02-05 01:03:23 [INFO]	[TRAIN] epoch: 2621, iter: 206990/250000, loss: 0.2169, lr: 0.002052, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6131 samples/sec | ETA 06:45:15
2023-02-05 01:03:29 [INFO]	[TRAIN] epoch: 2621, iter: 207000/250000, loss: 0.2101, lr: 0.002051, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6122 samples/sec | ETA 06:45:11
2023-02-05 01:03:34 [INFO]	[TRAIN] epoch: 2621, iter: 207010/250000, loss: 0.1797, lr: 0.002051, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6016 samples/sec | ETA 06:45:30
2023-02-05 01:03:40 [INFO]	[TRAIN] epoch: 2621, iter: 207020/250000, loss: 0.2411, lr: 0.002050, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6067 samples/sec | ETA 06:45:12
2023-02-05 01:03:46 [INFO]	[TRAIN] epoch: 2621, iter: 207030/250000, loss: 0.2220, lr: 0.002050, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6162 samples/sec | ETA 06:44:45
2023-02-05 01:03:52 [INFO]	[TRAIN] epoch: 2621, iter: 207040/250000, loss: 0.2014, lr: 0.002049, batch_cost: 0.5967, reader_cost: 0.03204, ips: 10.0560 samples/sec | ETA 07:07:12
2023-02-05 01:03:57 [INFO]	[TRAIN] epoch: 2621, iter: 207050/250000, loss: 0.1794, lr: 0.002049, batch_cost: 0.5656, reader_cost: 0.00011, ips: 10.6085 samples/sec | ETA 06:44:51
2023-02-05 01:04:03 [INFO]	[TRAIN] epoch: 2622, iter: 207060/250000, loss: 0.2333, lr: 0.002049, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6023 samples/sec | ETA 06:45:00
2023-02-05 01:04:09 [INFO]	[TRAIN] epoch: 2622, iter: 207070/250000, loss: 0.2010, lr: 0.002048, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6074 samples/sec | ETA 06:44:43
2023-02-05 01:04:14 [INFO]	[TRAIN] epoch: 2622, iter: 207080/250000, loss: 0.2317, lr: 0.002048, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6137 samples/sec | ETA 06:44:22
2023-02-05 01:04:20 [INFO]	[TRAIN] epoch: 2622, iter: 207090/250000, loss: 0.2882, lr: 0.002047, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6042 samples/sec | ETA 06:44:38
2023-02-05 01:04:26 [INFO]	[TRAIN] epoch: 2622, iter: 207100/250000, loss: 0.2739, lr: 0.002047, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6072 samples/sec | ETA 06:44:26
2023-02-05 01:04:31 [INFO]	[TRAIN] epoch: 2622, iter: 207110/250000, loss: 0.2204, lr: 0.002046, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6152 samples/sec | ETA 06:44:02
2023-02-05 01:04:37 [INFO]	[TRAIN] epoch: 2622, iter: 207120/250000, loss: 0.2551, lr: 0.002046, batch_cost: 0.5887, reader_cost: 0.02445, ips: 10.1913 samples/sec | ETA 07:00:45
2023-02-05 01:04:43 [INFO]	[TRAIN] epoch: 2622, iter: 207130/250000, loss: 0.2446, lr: 0.002046, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6376 samples/sec | ETA 06:43:00
2023-02-05 01:04:48 [INFO]	[TRAIN] epoch: 2623, iter: 207140/250000, loss: 0.2166, lr: 0.002045, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6339 samples/sec | ETA 06:43:03
2023-02-05 01:04:54 [INFO]	[TRAIN] epoch: 2623, iter: 207150/250000, loss: 0.2027, lr: 0.002045, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6146 samples/sec | ETA 06:43:41
2023-02-05 01:05:00 [INFO]	[TRAIN] epoch: 2623, iter: 207160/250000, loss: 0.1905, lr: 0.002044, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6083 samples/sec | ETA 06:43:50
2023-02-05 01:05:05 [INFO]	[TRAIN] epoch: 2623, iter: 207170/250000, loss: 0.2460, lr: 0.002044, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6136 samples/sec | ETA 06:43:32
2023-02-05 01:05:11 [INFO]	[TRAIN] epoch: 2623, iter: 207180/250000, loss: 0.2456, lr: 0.002043, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6125 samples/sec | ETA 06:43:29
2023-02-05 01:05:17 [INFO]	[TRAIN] epoch: 2623, iter: 207190/250000, loss: 0.2381, lr: 0.002043, batch_cost: 0.5953, reader_cost: 0.02978, ips: 10.0782 samples/sec | ETA 07:04:46
2023-02-05 01:05:23 [INFO]	[TRAIN] epoch: 2623, iter: 207200/250000, loss: 0.2831, lr: 0.002043, batch_cost: 0.5647, reader_cost: 0.00027, ips: 10.6253 samples/sec | ETA 06:42:48
2023-02-05 01:05:28 [INFO]	[TRAIN] epoch: 2623, iter: 207210/250000, loss: 0.1983, lr: 0.002042, batch_cost: 0.5655, reader_cost: 0.00011, ips: 10.6104 samples/sec | ETA 06:43:17
2023-02-05 01:05:34 [INFO]	[TRAIN] epoch: 2624, iter: 207220/250000, loss: 0.2164, lr: 0.002042, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6171 samples/sec | ETA 06:42:56
2023-02-05 01:05:40 [INFO]	[TRAIN] epoch: 2624, iter: 207230/250000, loss: 0.1765, lr: 0.002041, batch_cost: 0.5664, reader_cost: 0.00009, ips: 10.5938 samples/sec | ETA 06:43:43
2023-02-05 01:05:45 [INFO]	[TRAIN] epoch: 2624, iter: 207240/250000, loss: 0.2332, lr: 0.002041, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6107 samples/sec | ETA 06:42:59
2023-02-05 01:05:51 [INFO]	[TRAIN] epoch: 2624, iter: 207250/250000, loss: 0.2088, lr: 0.002040, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6164 samples/sec | ETA 06:42:40
2023-02-05 01:05:57 [INFO]	[TRAIN] epoch: 2624, iter: 207260/250000, loss: 0.2184, lr: 0.002040, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.5998 samples/sec | ETA 06:43:12
2023-02-05 01:06:03 [INFO]	[TRAIN] epoch: 2624, iter: 207270/250000, loss: 0.2450, lr: 0.002039, batch_cost: 0.6063, reader_cost: 0.04062, ips: 9.8962 samples/sec | ETA 07:11:46
2023-02-05 01:06:08 [INFO]	[TRAIN] epoch: 2624, iter: 207280/250000, loss: 0.2254, lr: 0.002039, batch_cost: 0.5652, reader_cost: 0.00015, ips: 10.6162 samples/sec | ETA 06:42:24
2023-02-05 01:06:14 [INFO]	[TRAIN] epoch: 2624, iter: 207290/250000, loss: 0.1720, lr: 0.002039, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6292 samples/sec | ETA 06:41:48
2023-02-05 01:06:20 [INFO]	[TRAIN] epoch: 2625, iter: 207300/250000, loss: 0.2926, lr: 0.002038, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6327 samples/sec | ETA 06:41:35
2023-02-05 01:06:25 [INFO]	[TRAIN] epoch: 2625, iter: 207310/250000, loss: 0.2585, lr: 0.002038, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6312 samples/sec | ETA 06:41:33
2023-02-05 01:06:31 [INFO]	[TRAIN] epoch: 2625, iter: 207320/250000, loss: 0.1966, lr: 0.002037, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5996 samples/sec | ETA 06:42:39
2023-02-05 01:06:37 [INFO]	[TRAIN] epoch: 2625, iter: 207330/250000, loss: 0.2179, lr: 0.002037, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6063 samples/sec | ETA 06:42:18
2023-02-05 01:06:42 [INFO]	[TRAIN] epoch: 2625, iter: 207340/250000, loss: 0.2096, lr: 0.002036, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6100 samples/sec | ETA 06:42:04
2023-02-05 01:06:48 [INFO]	[TRAIN] epoch: 2625, iter: 207350/250000, loss: 0.2243, lr: 0.002036, batch_cost: 0.5921, reader_cost: 0.02708, ips: 10.1327 samples/sec | ETA 07:00:54
2023-02-05 01:06:54 [INFO]	[TRAIN] epoch: 2625, iter: 207360/250000, loss: 0.2951, lr: 0.002036, batch_cost: 0.5655, reader_cost: 0.00013, ips: 10.6092 samples/sec | ETA 06:41:54
2023-02-05 01:06:59 [INFO]	[TRAIN] epoch: 2625, iter: 207370/250000, loss: 0.2432, lr: 0.002035, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6306 samples/sec | ETA 06:41:00
2023-02-05 01:07:05 [INFO]	[TRAIN] epoch: 2626, iter: 207380/250000, loss: 0.2340, lr: 0.002035, batch_cost: 0.5664, reader_cost: 0.00010, ips: 10.5929 samples/sec | ETA 06:42:20
2023-02-05 01:07:11 [INFO]	[TRAIN] epoch: 2626, iter: 207390/250000, loss: 0.2178, lr: 0.002034, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6107 samples/sec | ETA 06:41:34
2023-02-05 01:07:16 [INFO]	[TRAIN] epoch: 2626, iter: 207400/250000, loss: 0.2086, lr: 0.002034, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6107 samples/sec | ETA 06:41:28
2023-02-05 01:07:22 [INFO]	[TRAIN] epoch: 2626, iter: 207410/250000, loss: 0.2067, lr: 0.002033, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6025 samples/sec | ETA 06:41:41
2023-02-05 01:07:28 [INFO]	[TRAIN] epoch: 2626, iter: 207420/250000, loss: 0.2166, lr: 0.002033, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6179 samples/sec | ETA 06:41:01
2023-02-05 01:07:34 [INFO]	[TRAIN] epoch: 2626, iter: 207430/250000, loss: 0.2487, lr: 0.002033, batch_cost: 0.5923, reader_cost: 0.02723, ips: 10.1294 samples/sec | ETA 07:00:15
2023-02-05 01:07:39 [INFO]	[TRAIN] epoch: 2626, iter: 207440/250000, loss: 0.1669, lr: 0.002032, batch_cost: 0.5641, reader_cost: 0.00014, ips: 10.6357 samples/sec | ETA 06:40:09
2023-02-05 01:07:45 [INFO]	[TRAIN] epoch: 2626, iter: 207450/250000, loss: 0.2138, lr: 0.002032, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6352 samples/sec | ETA 06:40:05
2023-02-05 01:07:51 [INFO]	[TRAIN] epoch: 2627, iter: 207460/250000, loss: 0.2294, lr: 0.002031, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6329 samples/sec | ETA 06:40:04
2023-02-05 01:07:56 [INFO]	[TRAIN] epoch: 2627, iter: 207470/250000, loss: 0.2140, lr: 0.002031, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6334 samples/sec | ETA 06:39:57
2023-02-05 01:08:02 [INFO]	[TRAIN] epoch: 2627, iter: 207480/250000, loss: 0.3165, lr: 0.002030, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5957 samples/sec | ETA 06:41:17
2023-02-05 01:08:07 [INFO]	[TRAIN] epoch: 2627, iter: 207490/250000, loss: 0.1909, lr: 0.002030, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6031 samples/sec | ETA 06:40:55
2023-02-05 01:08:13 [INFO]	[TRAIN] epoch: 2627, iter: 207500/250000, loss: 0.2413, lr: 0.002030, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6142 samples/sec | ETA 06:40:24
2023-02-05 01:08:19 [INFO]	[TRAIN] epoch: 2627, iter: 207510/250000, loss: 0.2365, lr: 0.002029, batch_cost: 0.5932, reader_cost: 0.02789, ips: 10.1146 samples/sec | ETA 07:00:05
2023-02-05 01:08:25 [INFO]	[TRAIN] epoch: 2627, iter: 207520/250000, loss: 0.2759, lr: 0.002029, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6217 samples/sec | ETA 06:39:56
2023-02-05 01:08:30 [INFO]	[TRAIN] epoch: 2627, iter: 207530/250000, loss: 0.2804, lr: 0.002028, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5996 samples/sec | ETA 06:40:40
2023-02-05 01:08:36 [INFO]	[TRAIN] epoch: 2628, iter: 207540/250000, loss: 0.1905, lr: 0.002028, batch_cost: 0.5653, reader_cost: 0.00011, ips: 10.6144 samples/sec | ETA 06:40:01
2023-02-05 01:08:42 [INFO]	[TRAIN] epoch: 2628, iter: 207550/250000, loss: 0.2367, lr: 0.002027, batch_cost: 0.5655, reader_cost: 0.00011, ips: 10.6104 samples/sec | ETA 06:40:04
2023-02-05 01:08:47 [INFO]	[TRAIN] epoch: 2628, iter: 207560/250000, loss: 0.2011, lr: 0.002027, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6010 samples/sec | ETA 06:40:20
2023-02-05 01:08:53 [INFO]	[TRAIN] epoch: 2628, iter: 207570/250000, loss: 0.1798, lr: 0.002027, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6160 samples/sec | ETA 06:39:40
2023-02-05 01:08:59 [INFO]	[TRAIN] epoch: 2628, iter: 207580/250000, loss: 0.1920, lr: 0.002026, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6115 samples/sec | ETA 06:39:45
2023-02-05 01:09:05 [INFO]	[TRAIN] epoch: 2628, iter: 207590/250000, loss: 0.2016, lr: 0.002026, batch_cost: 0.5879, reader_cost: 0.02216, ips: 10.2055 samples/sec | ETA 06:55:33
2023-02-05 01:09:10 [INFO]	[TRAIN] epoch: 2628, iter: 207600/250000, loss: 0.1834, lr: 0.002025, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6158 samples/sec | ETA 06:39:24
2023-02-05 01:09:16 [INFO]	[TRAIN] epoch: 2628, iter: 207610/250000, loss: 0.2003, lr: 0.002025, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6126 samples/sec | ETA 06:39:25
2023-02-05 01:09:22 [INFO]	[TRAIN] epoch: 2629, iter: 207620/250000, loss: 0.1634, lr: 0.002024, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6073 samples/sec | ETA 06:39:32
2023-02-05 01:09:27 [INFO]	[TRAIN] epoch: 2629, iter: 207630/250000, loss: 0.2292, lr: 0.002024, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6036 samples/sec | ETA 06:39:34
2023-02-05 01:09:33 [INFO]	[TRAIN] epoch: 2629, iter: 207640/250000, loss: 0.1905, lr: 0.002024, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6048 samples/sec | ETA 06:39:26
2023-02-05 01:09:38 [INFO]	[TRAIN] epoch: 2629, iter: 207650/250000, loss: 0.2726, lr: 0.002023, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6138 samples/sec | ETA 06:39:00
2023-02-05 01:09:44 [INFO]	[TRAIN] epoch: 2629, iter: 207660/250000, loss: 0.2070, lr: 0.002023, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6071 samples/sec | ETA 06:39:10
2023-02-05 01:09:50 [INFO]	[TRAIN] epoch: 2629, iter: 207670/250000, loss: 0.1950, lr: 0.002022, batch_cost: 0.5961, reader_cost: 0.03025, ips: 10.0647 samples/sec | ETA 07:00:34
2023-02-05 01:09:56 [INFO]	[TRAIN] epoch: 2629, iter: 207680/250000, loss: 0.2295, lr: 0.002022, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6364 samples/sec | ETA 06:37:52
2023-02-05 01:10:01 [INFO]	[TRAIN] epoch: 2629, iter: 207690/250000, loss: 0.1920, lr: 0.002021, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6360 samples/sec | ETA 06:37:47
2023-02-05 01:10:07 [INFO]	[TRAIN] epoch: 2630, iter: 207700/250000, loss: 0.1985, lr: 0.002021, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6279 samples/sec | ETA 06:38:00
2023-02-05 01:10:13 [INFO]	[TRAIN] epoch: 2630, iter: 207710/250000, loss: 0.1903, lr: 0.002021, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6253 samples/sec | ETA 06:38:00
2023-02-05 01:10:18 [INFO]	[TRAIN] epoch: 2630, iter: 207720/250000, loss: 0.1939, lr: 0.002020, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6328 samples/sec | ETA 06:37:38
2023-02-05 01:10:24 [INFO]	[TRAIN] epoch: 2630, iter: 207730/250000, loss: 0.1901, lr: 0.002020, batch_cost: 0.5639, reader_cost: 0.00011, ips: 10.6405 samples/sec | ETA 06:37:15
2023-02-05 01:10:30 [INFO]	[TRAIN] epoch: 2630, iter: 207740/250000, loss: 0.1968, lr: 0.002019, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6070 samples/sec | ETA 06:38:25
2023-02-05 01:10:35 [INFO]	[TRAIN] epoch: 2630, iter: 207750/250000, loss: 0.1975, lr: 0.002019, batch_cost: 0.5878, reader_cost: 0.02305, ips: 10.2068 samples/sec | ETA 06:53:56
2023-02-05 01:10:41 [INFO]	[TRAIN] epoch: 2630, iter: 207760/250000, loss: 0.1809, lr: 0.002018, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6346 samples/sec | ETA 06:37:11
2023-02-05 01:10:47 [INFO]	[TRAIN] epoch: 2630, iter: 207770/250000, loss: 0.2302, lr: 0.002018, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6394 samples/sec | ETA 06:36:55
2023-02-05 01:10:52 [INFO]	[TRAIN] epoch: 2631, iter: 207780/250000, loss: 0.1774, lr: 0.002018, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6284 samples/sec | ETA 06:37:14
2023-02-05 01:10:58 [INFO]	[TRAIN] epoch: 2631, iter: 207790/250000, loss: 0.1826, lr: 0.002017, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6058 samples/sec | ETA 06:37:59
2023-02-05 01:11:04 [INFO]	[TRAIN] epoch: 2631, iter: 207800/250000, loss: 0.1898, lr: 0.002017, batch_cost: 0.5657, reader_cost: 0.00011, ips: 10.6067 samples/sec | ETA 06:37:51
2023-02-05 01:11:09 [INFO]	[TRAIN] epoch: 2631, iter: 207810/250000, loss: 0.2095, lr: 0.002016, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6155 samples/sec | ETA 06:37:26
2023-02-05 01:11:15 [INFO]	[TRAIN] epoch: 2631, iter: 207820/250000, loss: 0.1836, lr: 0.002016, batch_cost: 0.5658, reader_cost: 0.00018, ips: 10.6052 samples/sec | ETA 06:37:43
2023-02-05 01:11:21 [INFO]	[TRAIN] epoch: 2631, iter: 207830/250000, loss: 0.2148, lr: 0.002015, batch_cost: 0.5939, reader_cost: 0.02962, ips: 10.1036 samples/sec | ETA 06:57:22
2023-02-05 01:11:27 [INFO]	[TRAIN] epoch: 2631, iter: 207840/250000, loss: 0.2039, lr: 0.002015, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6022 samples/sec | ETA 06:37:39
2023-02-05 01:11:32 [INFO]	[TRAIN] epoch: 2632, iter: 207850/250000, loss: 0.1758, lr: 0.002015, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6086 samples/sec | ETA 06:37:19
2023-02-05 01:11:38 [INFO]	[TRAIN] epoch: 2632, iter: 207860/250000, loss: 0.2324, lr: 0.002014, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6181 samples/sec | ETA 06:36:52
2023-02-05 01:11:44 [INFO]	[TRAIN] epoch: 2632, iter: 207870/250000, loss: 0.1818, lr: 0.002014, batch_cost: 0.5658, reader_cost: 0.00011, ips: 10.6035 samples/sec | ETA 06:37:19
2023-02-05 01:11:49 [INFO]	[TRAIN] epoch: 2632, iter: 207880/250000, loss: 0.2451, lr: 0.002013, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6059 samples/sec | ETA 06:37:08
2023-02-05 01:11:55 [INFO]	[TRAIN] epoch: 2632, iter: 207890/250000, loss: 0.2408, lr: 0.002013, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6143 samples/sec | ETA 06:36:43
2023-02-05 01:12:01 [INFO]	[TRAIN] epoch: 2632, iter: 207900/250000, loss: 0.1892, lr: 0.002012, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6064 samples/sec | ETA 06:36:55
2023-02-05 01:12:06 [INFO]	[TRAIN] epoch: 2632, iter: 207910/250000, loss: 0.2001, lr: 0.002012, batch_cost: 0.5905, reader_cost: 0.02602, ips: 10.1608 samples/sec | ETA 06:54:14
2023-02-05 01:12:12 [INFO]	[TRAIN] epoch: 2632, iter: 207920/250000, loss: 0.2221, lr: 0.002012, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6284 samples/sec | ETA 06:35:55
2023-02-05 01:12:18 [INFO]	[TRAIN] epoch: 2633, iter: 207930/250000, loss: 0.1687, lr: 0.002011, batch_cost: 0.5646, reader_cost: 0.00011, ips: 10.6272 samples/sec | ETA 06:35:52
2023-02-05 01:12:23 [INFO]	[TRAIN] epoch: 2633, iter: 207940/250000, loss: 0.2116, lr: 0.002011, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6308 samples/sec | ETA 06:35:38
2023-02-05 01:12:29 [INFO]	[TRAIN] epoch: 2633, iter: 207950/250000, loss: 0.2027, lr: 0.002010, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6108 samples/sec | ETA 06:36:17
2023-02-05 01:12:35 [INFO]	[TRAIN] epoch: 2633, iter: 207960/250000, loss: 0.2443, lr: 0.002010, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6140 samples/sec | ETA 06:36:04
2023-02-05 01:12:40 [INFO]	[TRAIN] epoch: 2633, iter: 207970/250000, loss: 0.2104, lr: 0.002009, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6072 samples/sec | ETA 06:36:14
2023-02-05 01:12:46 [INFO]	[TRAIN] epoch: 2633, iter: 207980/250000, loss: 0.2548, lr: 0.002009, batch_cost: 0.5990, reader_cost: 0.03286, ips: 10.0166 samples/sec | ETA 06:59:30
2023-02-05 01:12:52 [INFO]	[TRAIN] epoch: 2633, iter: 207990/250000, loss: 0.1550, lr: 0.002009, batch_cost: 0.5642, reader_cost: 0.00011, ips: 10.6352 samples/sec | ETA 06:35:00
2023-02-05 01:12:58 [INFO]	[TRAIN] epoch: 2633, iter: 208000/250000, loss: 0.2429, lr: 0.002008, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6298 samples/sec | ETA 06:35:06
2023-02-05 01:12:58 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1242 - reader cost: 0.0227 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1502 - reader cost: 0.0114 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1570 - reader cost: 0.0076 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1580 - reader cost: 0.0057 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1587 - reader cost: 0.0046 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1615 - reader cost: 0.0039 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1613 - reader cost: 0.0033 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1615 - reader cost: 0.0029 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1624 - reader cost: 0.002610/36 [=======>......................] - ETA: 4s - batch_cost: 0.1624 - reader cost: 0.002311/36 [========>.....................] - ETA: 4s - batch_cost: 0.1630 - reader cost: 0.002112/36 [=========>....................] - ETA: 3s - batch_cost: 0.1627 - reader cost: 0.002013/36 [=========>....................] - ETA: 3s - batch_cost: 0.1628 - reader cost: 0.001814/36 [==========>...................] - ETA: 3s - batch_cost: 0.1633 - reader cost: 0.001715/36 [===========>..................] - ETA: 3s - batch_cost: 0.1634 - reader cost: 0.001616/36 [============>.................] - ETA: 3s - batch_cost: 0.1639 - reader cost: 0.001517/36 [=============>................] - ETA: 3s - batch_cost: 0.1641 - reader cost: 0.001418/36 [==============>...............] - ETA: 2s - batch_cost: 0.1642 - reader cost: 0.001319/36 [==============>...............] - ETA: 2s - batch_cost: 0.1640 - reader cost: 0.001320/36 [===============>..............] - ETA: 2s - batch_cost: 0.1640 - reader cost: 0.001221/36 [================>.............] - ETA: 2s - batch_cost: 0.1642 - reader cost: 0.001222/36 [=================>............] - ETA: 2s - batch_cost: 0.1643 - reader cost: 0.001123/36 [==================>...........] - ETA: 2s - batch_cost: 0.1648 - reader cost: 0.001124/36 [===================>..........] - ETA: 1s - batch_cost: 0.1646 - reader cost: 0.001025/36 [===================>..........] - ETA: 1s - batch_cost: 0.1647 - reader cost: 9.8434e-0426/36 [====================>.........] - ETA: 1s - batch_cost: 0.1649 - reader cost: 9.4945e-0427/36 [=====================>........] - ETA: 1s - batch_cost: 0.1651 - reader cost: 9.1762e-0428/36 [======================>.......] - ETA: 1s - batch_cost: 0.1655 - reader cost: 8.8762e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1655 - reader cost: 8.5974e-0430/36 [========================>.....] - ETA: 0s - batch_cost: 0.1655 - reader cost: 8.3360e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1655 - reader cost: 8.0926e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1654 - reader cost: 7.8636e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1652 - reader cost: 7.6475e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1651 - reader cost: 7.4483e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1652 - reader cost: 7.2579e-0436/36 [==============================] - 6s 165ms/step - batch_cost: 0.1653 - reader cost: 7.0773e-04
2023-02-05 01:13:04 [INFO]	[EVAL] #Images: 36 mIoU: 0.8470 Acc: 0.9854 Kappa: 0.9468 Dice: 0.9119
2023-02-05 01:13:04 [INFO]	[EVAL] Class IoU: 
[0.9848 0.9186 0.8838 0.6784 0.6434 0.9715 0.8487]
2023-02-05 01:13:04 [INFO]	[EVAL] Class Precision: 
[0.9911 0.9709 0.9482 0.8397 0.8419 0.9805 0.9098]
2023-02-05 01:13:04 [INFO]	[EVAL] Class Recall: 
[0.9936 0.9446 0.9286 0.7793 0.7319 0.9907 0.9266]
2023-02-05 01:13:04 [INFO]	[EVAL] The model with the best validation mIoU (0.8498) was saved at iter 206000.
2023-02-05 01:13:10 [INFO]	[TRAIN] epoch: 2634, iter: 208010/250000, loss: 0.2054, lr: 0.002008, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6288 samples/sec | ETA 06:35:03
2023-02-05 01:13:15 [INFO]	[TRAIN] epoch: 2634, iter: 208020/250000, loss: 0.2027, lr: 0.002007, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6347 samples/sec | ETA 06:34:44
2023-02-05 01:13:21 [INFO]	[TRAIN] epoch: 2634, iter: 208030/250000, loss: 0.2209, lr: 0.002007, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6424 samples/sec | ETA 06:34:21
2023-02-05 01:13:26 [INFO]	[TRAIN] epoch: 2634, iter: 208040/250000, loss: 0.1539, lr: 0.002006, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6369 samples/sec | ETA 06:34:28
2023-02-05 01:13:32 [INFO]	[TRAIN] epoch: 2634, iter: 208050/250000, loss: 0.2125, lr: 0.002006, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6293 samples/sec | ETA 06:34:39
2023-02-05 01:13:38 [INFO]	[TRAIN] epoch: 2634, iter: 208060/250000, loss: 0.2389, lr: 0.002006, batch_cost: 0.5902, reader_cost: 0.02580, ips: 10.1655 samples/sec | ETA 06:52:34
2023-02-05 01:13:44 [INFO]	[TRAIN] epoch: 2634, iter: 208070/250000, loss: 0.1686, lr: 0.002005, batch_cost: 0.5639, reader_cost: 0.00014, ips: 10.6408 samples/sec | ETA 06:34:03
2023-02-05 01:13:49 [INFO]	[TRAIN] epoch: 2634, iter: 208080/250000, loss: 0.2094, lr: 0.002005, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6337 samples/sec | ETA 06:34:13
2023-02-05 01:13:55 [INFO]	[TRAIN] epoch: 2635, iter: 208090/250000, loss: 0.1755, lr: 0.002004, batch_cost: 0.5649, reader_cost: 0.00012, ips: 10.6213 samples/sec | ETA 06:34:35
2023-02-05 01:14:01 [INFO]	[TRAIN] epoch: 2635, iter: 208100/250000, loss: 0.1827, lr: 0.002004, batch_cost: 0.5658, reader_cost: 0.00011, ips: 10.6053 samples/sec | ETA 06:35:05
2023-02-05 01:14:06 [INFO]	[TRAIN] epoch: 2635, iter: 208110/250000, loss: 0.1785, lr: 0.002003, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6094 samples/sec | ETA 06:34:50
2023-02-05 01:14:12 [INFO]	[TRAIN] epoch: 2635, iter: 208120/250000, loss: 0.2119, lr: 0.002003, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6115 samples/sec | ETA 06:34:39
2023-02-05 01:14:18 [INFO]	[TRAIN] epoch: 2635, iter: 208130/250000, loss: 0.1709, lr: 0.002003, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6021 samples/sec | ETA 06:34:55
2023-02-05 01:14:23 [INFO]	[TRAIN] epoch: 2635, iter: 208140/250000, loss: 0.1704, lr: 0.002002, batch_cost: 0.5940, reader_cost: 0.02848, ips: 10.1013 samples/sec | ETA 06:54:24
2023-02-05 01:14:29 [INFO]	[TRAIN] epoch: 2635, iter: 208150/250000, loss: 0.2031, lr: 0.002002, batch_cost: 0.5656, reader_cost: 0.00014, ips: 10.6088 samples/sec | ETA 06:34:29
2023-02-05 01:14:35 [INFO]	[TRAIN] epoch: 2635, iter: 208160/250000, loss: 0.2205, lr: 0.002001, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6141 samples/sec | ETA 06:34:11
2023-02-05 01:14:40 [INFO]	[TRAIN] epoch: 2636, iter: 208170/250000, loss: 0.2634, lr: 0.002001, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6130 samples/sec | ETA 06:34:08
2023-02-05 01:14:46 [INFO]	[TRAIN] epoch: 2636, iter: 208180/250000, loss: 0.2160, lr: 0.002000, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6103 samples/sec | ETA 06:34:08
2023-02-05 01:14:52 [INFO]	[TRAIN] epoch: 2636, iter: 208190/250000, loss: 0.2602, lr: 0.002000, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6112 samples/sec | ETA 06:34:00
2023-02-05 01:14:57 [INFO]	[TRAIN] epoch: 2636, iter: 208200/250000, loss: 0.3692, lr: 0.002000, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6100 samples/sec | ETA 06:33:58
2023-02-05 01:15:03 [INFO]	[TRAIN] epoch: 2636, iter: 208210/250000, loss: 0.3069, lr: 0.001999, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6126 samples/sec | ETA 06:33:46
2023-02-05 01:15:09 [INFO]	[TRAIN] epoch: 2636, iter: 208220/250000, loss: 0.3064, lr: 0.001999, batch_cost: 0.5968, reader_cost: 0.03004, ips: 10.0533 samples/sec | ETA 06:55:35
2023-02-05 01:15:15 [INFO]	[TRAIN] epoch: 2636, iter: 208230/250000, loss: 0.3016, lr: 0.001998, batch_cost: 0.5659, reader_cost: 0.00059, ips: 10.6032 samples/sec | ETA 06:33:56
2023-02-05 01:15:20 [INFO]	[TRAIN] epoch: 2636, iter: 208240/250000, loss: 0.3247, lr: 0.001998, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6064 samples/sec | ETA 06:33:43
2023-02-05 01:15:26 [INFO]	[TRAIN] epoch: 2637, iter: 208250/250000, loss: 0.3459, lr: 0.001997, batch_cost: 0.5655, reader_cost: 0.00011, ips: 10.6107 samples/sec | ETA 06:33:28
2023-02-05 01:15:32 [INFO]	[TRAIN] epoch: 2637, iter: 208260/250000, loss: 0.3140, lr: 0.001997, batch_cost: 0.5657, reader_cost: 0.00012, ips: 10.6070 samples/sec | ETA 06:33:30
2023-02-05 01:15:37 [INFO]	[TRAIN] epoch: 2637, iter: 208270/250000, loss: 0.2204, lr: 0.001996, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6177 samples/sec | ETA 06:33:01
2023-02-05 01:15:43 [INFO]	[TRAIN] epoch: 2637, iter: 208280/250000, loss: 0.2749, lr: 0.001996, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6096 samples/sec | ETA 06:33:13
2023-02-05 01:15:49 [INFO]	[TRAIN] epoch: 2637, iter: 208290/250000, loss: 0.2726, lr: 0.001996, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6083 samples/sec | ETA 06:33:11
2023-02-05 01:15:55 [INFO]	[TRAIN] epoch: 2637, iter: 208300/250000, loss: 0.2217, lr: 0.001995, batch_cost: 0.5915, reader_cost: 0.02731, ips: 10.1444 samples/sec | ETA 06:51:03
2023-02-05 01:16:00 [INFO]	[TRAIN] epoch: 2637, iter: 208310/250000, loss: 0.2563, lr: 0.001995, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5969 samples/sec | ETA 06:33:25
2023-02-05 01:16:06 [INFO]	[TRAIN] epoch: 2637, iter: 208320/250000, loss: 0.2206, lr: 0.001994, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6038 samples/sec | ETA 06:33:03
2023-02-05 01:16:12 [INFO]	[TRAIN] epoch: 2638, iter: 208330/250000, loss: 0.2101, lr: 0.001994, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6083 samples/sec | ETA 06:32:48
2023-02-05 01:16:17 [INFO]	[TRAIN] epoch: 2638, iter: 208340/250000, loss: 0.2663, lr: 0.001993, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6116 samples/sec | ETA 06:32:35
2023-02-05 01:16:23 [INFO]	[TRAIN] epoch: 2638, iter: 208350/250000, loss: 0.2243, lr: 0.001993, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6060 samples/sec | ETA 06:32:42
2023-02-05 01:16:28 [INFO]	[TRAIN] epoch: 2638, iter: 208360/250000, loss: 0.2994, lr: 0.001993, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6049 samples/sec | ETA 06:32:38
2023-02-05 01:16:34 [INFO]	[TRAIN] epoch: 2638, iter: 208370/250000, loss: 0.2778, lr: 0.001992, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6100 samples/sec | ETA 06:32:21
2023-02-05 01:16:40 [INFO]	[TRAIN] epoch: 2638, iter: 208380/250000, loss: 0.2346, lr: 0.001992, batch_cost: 0.5860, reader_cost: 0.02047, ips: 10.2389 samples/sec | ETA 06:46:29
2023-02-05 01:16:46 [INFO]	[TRAIN] epoch: 2638, iter: 208390/250000, loss: 0.2345, lr: 0.001991, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6356 samples/sec | ETA 06:31:13
2023-02-05 01:16:51 [INFO]	[TRAIN] epoch: 2638, iter: 208400/250000, loss: 0.2123, lr: 0.001991, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6067 samples/sec | ETA 06:32:12
2023-02-05 01:16:57 [INFO]	[TRAIN] epoch: 2639, iter: 208410/250000, loss: 0.2087, lr: 0.001990, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6079 samples/sec | ETA 06:32:03
2023-02-05 01:17:03 [INFO]	[TRAIN] epoch: 2639, iter: 208420/250000, loss: 0.2675, lr: 0.001990, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6084 samples/sec | ETA 06:31:57
2023-02-05 01:17:08 [INFO]	[TRAIN] epoch: 2639, iter: 208430/250000, loss: 0.2172, lr: 0.001990, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6078 samples/sec | ETA 06:31:52
2023-02-05 01:17:14 [INFO]	[TRAIN] epoch: 2639, iter: 208440/250000, loss: 0.2323, lr: 0.001989, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6071 samples/sec | ETA 06:31:48
2023-02-05 01:17:20 [INFO]	[TRAIN] epoch: 2639, iter: 208450/250000, loss: 0.2792, lr: 0.001989, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6043 samples/sec | ETA 06:31:49
2023-02-05 01:17:26 [INFO]	[TRAIN] epoch: 2639, iter: 208460/250000, loss: 0.2096, lr: 0.001988, batch_cost: 0.5941, reader_cost: 0.02900, ips: 10.0990 samples/sec | ETA 06:51:19
2023-02-05 01:17:31 [INFO]	[TRAIN] epoch: 2639, iter: 208470/250000, loss: 0.2723, lr: 0.001988, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6340 samples/sec | ETA 06:30:32
2023-02-05 01:17:37 [INFO]	[TRAIN] epoch: 2639, iter: 208480/250000, loss: 0.2110, lr: 0.001987, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6275 samples/sec | ETA 06:30:41
2023-02-05 01:17:42 [INFO]	[TRAIN] epoch: 2640, iter: 208490/250000, loss: 0.2032, lr: 0.001987, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6159 samples/sec | ETA 06:31:01
2023-02-05 01:17:48 [INFO]	[TRAIN] epoch: 2640, iter: 208500/250000, loss: 0.2175, lr: 0.001987, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6061 samples/sec | ETA 06:31:17
2023-02-05 01:17:54 [INFO]	[TRAIN] epoch: 2640, iter: 208510/250000, loss: 0.1969, lr: 0.001986, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6065 samples/sec | ETA 06:31:10
2023-02-05 01:17:59 [INFO]	[TRAIN] epoch: 2640, iter: 208520/250000, loss: 0.2119, lr: 0.001986, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6039 samples/sec | ETA 06:31:10
2023-02-05 01:18:05 [INFO]	[TRAIN] epoch: 2640, iter: 208530/250000, loss: 0.3941, lr: 0.001985, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6130 samples/sec | ETA 06:30:44
2023-02-05 01:18:11 [INFO]	[TRAIN] epoch: 2640, iter: 208540/250000, loss: 0.4156, lr: 0.001985, batch_cost: 0.5936, reader_cost: 0.02722, ips: 10.1083 samples/sec | ETA 06:50:09
2023-02-05 01:18:17 [INFO]	[TRAIN] epoch: 2640, iter: 208550/250000, loss: 0.3377, lr: 0.001984, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6108 samples/sec | ETA 06:30:38
2023-02-05 01:18:22 [INFO]	[TRAIN] epoch: 2640, iter: 208560/250000, loss: 0.2758, lr: 0.001984, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6071 samples/sec | ETA 06:30:40
2023-02-05 01:18:28 [INFO]	[TRAIN] epoch: 2641, iter: 208570/250000, loss: 0.3130, lr: 0.001984, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6053 samples/sec | ETA 06:30:39
2023-02-05 01:18:34 [INFO]	[TRAIN] epoch: 2641, iter: 208580/250000, loss: 0.2291, lr: 0.001983, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6107 samples/sec | ETA 06:30:21
2023-02-05 01:18:39 [INFO]	[TRAIN] epoch: 2641, iter: 208590/250000, loss: 0.2488, lr: 0.001983, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6118 samples/sec | ETA 06:30:13
2023-02-05 01:18:45 [INFO]	[TRAIN] epoch: 2641, iter: 208600/250000, loss: 0.2248, lr: 0.001982, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6106 samples/sec | ETA 06:30:10
2023-02-05 01:18:51 [INFO]	[TRAIN] epoch: 2641, iter: 208610/250000, loss: 0.1932, lr: 0.001982, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6130 samples/sec | ETA 06:29:59
2023-02-05 01:18:57 [INFO]	[TRAIN] epoch: 2641, iter: 208620/250000, loss: 0.2310, lr: 0.001981, batch_cost: 0.5980, reader_cost: 0.03213, ips: 10.0330 samples/sec | ETA 06:52:26
2023-02-05 01:19:02 [INFO]	[TRAIN] epoch: 2641, iter: 208630/250000, loss: 0.1923, lr: 0.001981, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6180 samples/sec | ETA 06:29:37
2023-02-05 01:19:08 [INFO]	[TRAIN] epoch: 2642, iter: 208640/250000, loss: 0.2259, lr: 0.001981, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6103 samples/sec | ETA 06:29:48
2023-02-05 01:19:14 [INFO]	[TRAIN] epoch: 2642, iter: 208650/250000, loss: 0.2105, lr: 0.001980, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6081 samples/sec | ETA 06:29:47
2023-02-05 01:19:19 [INFO]	[TRAIN] epoch: 2642, iter: 208660/250000, loss: 0.2276, lr: 0.001980, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6197 samples/sec | ETA 06:29:16
2023-02-05 01:19:25 [INFO]	[TRAIN] epoch: 2642, iter: 208670/250000, loss: 0.1821, lr: 0.001979, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6038 samples/sec | ETA 06:29:45
2023-02-05 01:19:31 [INFO]	[TRAIN] epoch: 2642, iter: 208680/250000, loss: 0.2001, lr: 0.001979, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6142 samples/sec | ETA 06:29:17
2023-02-05 01:19:36 [INFO]	[TRAIN] epoch: 2642, iter: 208690/250000, loss: 0.2511, lr: 0.001978, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6121 samples/sec | ETA 06:29:16
2023-02-05 01:19:42 [INFO]	[TRAIN] epoch: 2642, iter: 208700/250000, loss: 0.2342, lr: 0.001978, batch_cost: 0.5918, reader_cost: 0.02642, ips: 10.1380 samples/sec | ETA 06:47:22
2023-02-05 01:19:48 [INFO]	[TRAIN] epoch: 2642, iter: 208710/250000, loss: 0.2577, lr: 0.001978, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6099 samples/sec | ETA 06:29:09
2023-02-05 01:19:53 [INFO]	[TRAIN] epoch: 2643, iter: 208720/250000, loss: 0.2245, lr: 0.001977, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6094 samples/sec | ETA 06:29:05
2023-02-05 01:19:59 [INFO]	[TRAIN] epoch: 2643, iter: 208730/250000, loss: 0.2015, lr: 0.001977, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6176 samples/sec | ETA 06:28:41
2023-02-05 01:20:05 [INFO]	[TRAIN] epoch: 2643, iter: 208740/250000, loss: 0.1783, lr: 0.001976, batch_cost: 0.5657, reader_cost: 0.00011, ips: 10.6065 samples/sec | ETA 06:29:00
2023-02-05 01:20:10 [INFO]	[TRAIN] epoch: 2643, iter: 208750/250000, loss: 0.1880, lr: 0.001976, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6083 samples/sec | ETA 06:28:50
2023-02-05 01:20:16 [INFO]	[TRAIN] epoch: 2643, iter: 208760/250000, loss: 0.1790, lr: 0.001975, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6141 samples/sec | ETA 06:28:32
2023-02-05 01:20:22 [INFO]	[TRAIN] epoch: 2643, iter: 208770/250000, loss: 0.1936, lr: 0.001975, batch_cost: 0.5891, reader_cost: 0.02400, ips: 10.1855 samples/sec | ETA 06:44:47
2023-02-05 01:20:28 [INFO]	[TRAIN] epoch: 2643, iter: 208780/250000, loss: 0.2029, lr: 0.001975, batch_cost: 0.5653, reader_cost: 0.00038, ips: 10.6145 samples/sec | ETA 06:28:20
2023-02-05 01:20:33 [INFO]	[TRAIN] epoch: 2643, iter: 208790/250000, loss: 0.1809, lr: 0.001974, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6193 samples/sec | ETA 06:28:03
2023-02-05 01:20:39 [INFO]	[TRAIN] epoch: 2644, iter: 208800/250000, loss: 0.1880, lr: 0.001974, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6044 samples/sec | ETA 06:28:31
2023-02-05 01:20:45 [INFO]	[TRAIN] epoch: 2644, iter: 208810/250000, loss: 0.2335, lr: 0.001973, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6035 samples/sec | ETA 06:28:27
2023-02-05 01:20:50 [INFO]	[TRAIN] epoch: 2644, iter: 208820/250000, loss: 0.1893, lr: 0.001973, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6071 samples/sec | ETA 06:28:13
2023-02-05 01:20:56 [INFO]	[TRAIN] epoch: 2644, iter: 208830/250000, loss: 0.1604, lr: 0.001972, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6086 samples/sec | ETA 06:28:04
2023-02-05 01:21:02 [INFO]	[TRAIN] epoch: 2644, iter: 208840/250000, loss: 0.2076, lr: 0.001972, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6042 samples/sec | ETA 06:28:08
2023-02-05 01:21:07 [INFO]	[TRAIN] epoch: 2644, iter: 208850/250000, loss: 0.2399, lr: 0.001971, batch_cost: 0.5904, reader_cost: 0.02557, ips: 10.1624 samples/sec | ETA 06:44:55
2023-02-05 01:21:13 [INFO]	[TRAIN] epoch: 2644, iter: 208860/250000, loss: 0.2587, lr: 0.001971, batch_cost: 0.5653, reader_cost: 0.00012, ips: 10.6141 samples/sec | ETA 06:27:35
2023-02-05 01:21:19 [INFO]	[TRAIN] epoch: 2644, iter: 208870/250000, loss: 0.2200, lr: 0.001971, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6088 samples/sec | ETA 06:27:41
2023-02-05 01:21:24 [INFO]	[TRAIN] epoch: 2645, iter: 208880/250000, loss: 0.2177, lr: 0.001970, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6138 samples/sec | ETA 06:27:25
2023-02-05 01:21:30 [INFO]	[TRAIN] epoch: 2645, iter: 208890/250000, loss: 0.1998, lr: 0.001970, batch_cost: 0.5655, reader_cost: 0.00011, ips: 10.6098 samples/sec | ETA 06:27:28
2023-02-05 01:21:36 [INFO]	[TRAIN] epoch: 2645, iter: 208900/250000, loss: 0.1777, lr: 0.001969, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6042 samples/sec | ETA 06:27:34
2023-02-05 01:21:41 [INFO]	[TRAIN] epoch: 2645, iter: 208910/250000, loss: 0.1993, lr: 0.001969, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6113 samples/sec | ETA 06:27:13
2023-02-05 01:21:47 [INFO]	[TRAIN] epoch: 2645, iter: 208920/250000, loss: 0.2061, lr: 0.001968, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6109 samples/sec | ETA 06:27:08
2023-02-05 01:21:53 [INFO]	[TRAIN] epoch: 2645, iter: 208930/250000, loss: 0.1476, lr: 0.001968, batch_cost: 0.5891, reader_cost: 0.02304, ips: 10.1857 samples/sec | ETA 06:43:12
2023-02-05 01:21:59 [INFO]	[TRAIN] epoch: 2645, iter: 208940/250000, loss: 0.2191, lr: 0.001968, batch_cost: 0.5654, reader_cost: 0.00014, ips: 10.6126 samples/sec | ETA 06:26:53
2023-02-05 01:22:04 [INFO]	[TRAIN] epoch: 2645, iter: 208950/250000, loss: 0.2150, lr: 0.001967, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6080 samples/sec | ETA 06:26:58
2023-02-05 01:22:10 [INFO]	[TRAIN] epoch: 2646, iter: 208960/250000, loss: 0.1793, lr: 0.001967, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6062 samples/sec | ETA 06:26:56
2023-02-05 01:22:16 [INFO]	[TRAIN] epoch: 2646, iter: 208970/250000, loss: 0.2126, lr: 0.001966, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6147 samples/sec | ETA 06:26:32
2023-02-05 01:22:21 [INFO]	[TRAIN] epoch: 2646, iter: 208980/250000, loss: 0.1754, lr: 0.001966, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6117 samples/sec | ETA 06:26:33
2023-02-05 01:22:27 [INFO]	[TRAIN] epoch: 2646, iter: 208990/250000, loss: 0.3162, lr: 0.001965, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6057 samples/sec | ETA 06:26:40
2023-02-05 01:22:32 [INFO]	[TRAIN] epoch: 2646, iter: 209000/250000, loss: 0.2908, lr: 0.001965, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6098 samples/sec | ETA 06:26:26
2023-02-05 01:22:38 [INFO]	[TRAIN] epoch: 2646, iter: 209010/250000, loss: 0.3169, lr: 0.001965, batch_cost: 0.5898, reader_cost: 0.02438, ips: 10.1735 samples/sec | ETA 06:42:54
2023-02-05 01:22:44 [INFO]	[TRAIN] epoch: 2646, iter: 209020/250000, loss: 0.3135, lr: 0.001964, batch_cost: 0.5662, reader_cost: 0.00015, ips: 10.5971 samples/sec | ETA 06:26:42
2023-02-05 01:22:50 [INFO]	[TRAIN] epoch: 2646, iter: 209030/250000, loss: 0.2510, lr: 0.001964, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6060 samples/sec | ETA 06:26:17
2023-02-05 01:22:55 [INFO]	[TRAIN] epoch: 2647, iter: 209040/250000, loss: 0.2113, lr: 0.001963, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5992 samples/sec | ETA 06:26:26
2023-02-05 01:23:01 [INFO]	[TRAIN] epoch: 2647, iter: 209050/250000, loss: 0.2143, lr: 0.001963, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5989 samples/sec | ETA 06:26:21
2023-02-05 01:23:07 [INFO]	[TRAIN] epoch: 2647, iter: 209060/250000, loss: 0.2352, lr: 0.001962, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6209 samples/sec | ETA 06:25:27
2023-02-05 01:23:12 [INFO]	[TRAIN] epoch: 2647, iter: 209070/250000, loss: 0.2609, lr: 0.001962, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6059 samples/sec | ETA 06:25:55
2023-02-05 01:23:18 [INFO]	[TRAIN] epoch: 2647, iter: 209080/250000, loss: 0.2285, lr: 0.001962, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6096 samples/sec | ETA 06:25:41
2023-02-05 01:23:24 [INFO]	[TRAIN] epoch: 2647, iter: 209090/250000, loss: 0.2341, lr: 0.001961, batch_cost: 0.5976, reader_cost: 0.03268, ips: 10.0396 samples/sec | ETA 06:47:29
2023-02-05 01:23:30 [INFO]	[TRAIN] epoch: 2647, iter: 209100/250000, loss: 0.2258, lr: 0.001961, batch_cost: 0.5647, reader_cost: 0.00032, ips: 10.6253 samples/sec | ETA 06:24:55
2023-02-05 01:23:35 [INFO]	[TRAIN] epoch: 2647, iter: 209110/250000, loss: 0.2222, lr: 0.001960, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6115 samples/sec | ETA 06:25:20
2023-02-05 01:23:41 [INFO]	[TRAIN] epoch: 2648, iter: 209120/250000, loss: 0.2045, lr: 0.001960, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6025 samples/sec | ETA 06:25:34
2023-02-05 01:23:47 [INFO]	[TRAIN] epoch: 2648, iter: 209130/250000, loss: 0.2142, lr: 0.001959, batch_cost: 0.5651, reader_cost: 0.00014, ips: 10.6184 samples/sec | ETA 06:24:53
2023-02-05 01:23:52 [INFO]	[TRAIN] epoch: 2648, iter: 209140/250000, loss: 0.1803, lr: 0.001959, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6115 samples/sec | ETA 06:25:03
2023-02-05 01:23:58 [INFO]	[TRAIN] epoch: 2648, iter: 209150/250000, loss: 0.2399, lr: 0.001959, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6123 samples/sec | ETA 06:24:55
2023-02-05 01:24:04 [INFO]	[TRAIN] epoch: 2648, iter: 209160/250000, loss: 0.2975, lr: 0.001958, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6088 samples/sec | ETA 06:24:57
2023-02-05 01:24:09 [INFO]	[TRAIN] epoch: 2648, iter: 209170/250000, loss: 0.3139, lr: 0.001958, batch_cost: 0.5906, reader_cost: 0.02433, ips: 10.1584 samples/sec | ETA 06:41:55
2023-02-05 01:24:15 [INFO]	[TRAIN] epoch: 2648, iter: 209180/250000, loss: 0.2696, lr: 0.001957, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6069 samples/sec | ETA 06:24:50
2023-02-05 01:24:21 [INFO]	[TRAIN] epoch: 2648, iter: 209190/250000, loss: 0.2783, lr: 0.001957, batch_cost: 0.5648, reader_cost: 0.00008, ips: 10.6228 samples/sec | ETA 06:24:10
2023-02-05 01:24:26 [INFO]	[TRAIN] epoch: 2649, iter: 209200/250000, loss: 0.3151, lr: 0.001956, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6076 samples/sec | ETA 06:24:37
2023-02-05 01:24:32 [INFO]	[TRAIN] epoch: 2649, iter: 209210/250000, loss: 0.2171, lr: 0.001956, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6125 samples/sec | ETA 06:24:21
2023-02-05 01:24:38 [INFO]	[TRAIN] epoch: 2649, iter: 209220/250000, loss: 0.2275, lr: 0.001956, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6029 samples/sec | ETA 06:24:36
2023-02-05 01:24:43 [INFO]	[TRAIN] epoch: 2649, iter: 209230/250000, loss: 0.2222, lr: 0.001955, batch_cost: 0.5655, reader_cost: 0.00012, ips: 10.6101 samples/sec | ETA 06:24:15
2023-02-05 01:24:49 [INFO]	[TRAIN] epoch: 2649, iter: 209240/250000, loss: 0.2358, lr: 0.001955, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6089 samples/sec | ETA 06:24:12
2023-02-05 01:24:55 [INFO]	[TRAIN] epoch: 2649, iter: 209250/250000, loss: 0.2791, lr: 0.001954, batch_cost: 0.5890, reader_cost: 0.02457, ips: 10.1872 samples/sec | ETA 06:40:00
2023-02-05 01:25:01 [INFO]	[TRAIN] epoch: 2649, iter: 209260/250000, loss: 0.2736, lr: 0.001954, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6130 samples/sec | ETA 06:23:52
2023-02-05 01:25:06 [INFO]	[TRAIN] epoch: 2649, iter: 209270/250000, loss: 0.3531, lr: 0.001953, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5961 samples/sec | ETA 06:24:23
2023-02-05 01:25:12 [INFO]	[TRAIN] epoch: 2650, iter: 209280/250000, loss: 0.2811, lr: 0.001953, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6030 samples/sec | ETA 06:24:02
2023-02-05 01:25:18 [INFO]	[TRAIN] epoch: 2650, iter: 209290/250000, loss: 0.3093, lr: 0.001953, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6153 samples/sec | ETA 06:23:30
2023-02-05 01:25:23 [INFO]	[TRAIN] epoch: 2650, iter: 209300/250000, loss: 0.2719, lr: 0.001952, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6070 samples/sec | ETA 06:23:42
2023-02-05 01:25:29 [INFO]	[TRAIN] epoch: 2650, iter: 209310/250000, loss: 0.3328, lr: 0.001952, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6064 samples/sec | ETA 06:23:38
2023-02-05 01:25:35 [INFO]	[TRAIN] epoch: 2650, iter: 209320/250000, loss: 0.2275, lr: 0.001951, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6132 samples/sec | ETA 06:23:17
2023-02-05 01:25:41 [INFO]	[TRAIN] epoch: 2650, iter: 209330/250000, loss: 0.2742, lr: 0.001951, batch_cost: 0.5989, reader_cost: 0.03376, ips: 10.0179 samples/sec | ETA 06:45:58
2023-02-05 01:25:46 [INFO]	[TRAIN] epoch: 2650, iter: 209340/250000, loss: 0.2178, lr: 0.001950, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6132 samples/sec | ETA 06:23:06
2023-02-05 01:25:52 [INFO]	[TRAIN] epoch: 2650, iter: 209350/250000, loss: 0.2433, lr: 0.001950, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6058 samples/sec | ETA 06:23:16
2023-02-05 01:25:57 [INFO]	[TRAIN] epoch: 2651, iter: 209360/250000, loss: 0.2523, lr: 0.001949, batch_cost: 0.5656, reader_cost: 0.00011, ips: 10.6090 samples/sec | ETA 06:23:04
2023-02-05 01:26:03 [INFO]	[TRAIN] epoch: 2651, iter: 209370/250000, loss: 0.2557, lr: 0.001949, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6152 samples/sec | ETA 06:22:45
2023-02-05 01:26:09 [INFO]	[TRAIN] epoch: 2651, iter: 209380/250000, loss: 0.2902, lr: 0.001949, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6050 samples/sec | ETA 06:23:01
2023-02-05 01:26:14 [INFO]	[TRAIN] epoch: 2651, iter: 209390/250000, loss: 0.2349, lr: 0.001948, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6203 samples/sec | ETA 06:22:22
2023-02-05 01:26:20 [INFO]	[TRAIN] epoch: 2651, iter: 209400/250000, loss: 0.2089, lr: 0.001948, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6064 samples/sec | ETA 06:22:47
2023-02-05 01:26:26 [INFO]	[TRAIN] epoch: 2651, iter: 209410/250000, loss: 0.2977, lr: 0.001947, batch_cost: 0.5941, reader_cost: 0.02937, ips: 10.1000 samples/sec | ETA 06:41:52
2023-02-05 01:26:32 [INFO]	[TRAIN] epoch: 2651, iter: 209420/250000, loss: 0.2171, lr: 0.001947, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6143 samples/sec | ETA 06:22:18
2023-02-05 01:26:37 [INFO]	[TRAIN] epoch: 2652, iter: 209430/250000, loss: 0.1838, lr: 0.001946, batch_cost: 0.5659, reader_cost: 0.00011, ips: 10.6031 samples/sec | ETA 06:22:37
2023-02-05 01:26:43 [INFO]	[TRAIN] epoch: 2652, iter: 209440/250000, loss: 0.2463, lr: 0.001946, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6105 samples/sec | ETA 06:22:15
2023-02-05 01:26:49 [INFO]	[TRAIN] epoch: 2652, iter: 209450/250000, loss: 0.1977, lr: 0.001946, batch_cost: 0.5654, reader_cost: 0.00011, ips: 10.6116 samples/sec | ETA 06:22:07
2023-02-05 01:26:54 [INFO]	[TRAIN] epoch: 2652, iter: 209460/250000, loss: 0.1913, lr: 0.001945, batch_cost: 0.5659, reader_cost: 0.00011, ips: 10.6019 samples/sec | ETA 06:22:23
2023-02-05 01:27:00 [INFO]	[TRAIN] epoch: 2652, iter: 209470/250000, loss: 0.2069, lr: 0.001945, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6129 samples/sec | ETA 06:21:53
2023-02-05 01:27:06 [INFO]	[TRAIN] epoch: 2652, iter: 209480/250000, loss: 0.2129, lr: 0.001944, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6104 samples/sec | ETA 06:21:53
2023-02-05 01:27:12 [INFO]	[TRAIN] epoch: 2652, iter: 209490/250000, loss: 0.2620, lr: 0.001944, batch_cost: 0.6024, reader_cost: 0.03814, ips: 9.9597 samples/sec | ETA 06:46:44
2023-02-05 01:27:17 [INFO]	[TRAIN] epoch: 2652, iter: 209500/250000, loss: 0.1908, lr: 0.001943, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6125 samples/sec | ETA 06:21:37
2023-02-05 01:27:23 [INFO]	[TRAIN] epoch: 2653, iter: 209510/250000, loss: 0.1813, lr: 0.001943, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6061 samples/sec | ETA 06:21:45
2023-02-05 01:27:29 [INFO]	[TRAIN] epoch: 2653, iter: 209520/250000, loss: 0.2738, lr: 0.001943, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6229 samples/sec | ETA 06:21:03
2023-02-05 01:27:34 [INFO]	[TRAIN] epoch: 2653, iter: 209530/250000, loss: 0.2100, lr: 0.001942, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6019 samples/sec | ETA 06:21:43
2023-02-05 01:27:40 [INFO]	[TRAIN] epoch: 2653, iter: 209540/250000, loss: 0.2184, lr: 0.001942, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6132 samples/sec | ETA 06:21:13
2023-02-05 01:27:46 [INFO]	[TRAIN] epoch: 2653, iter: 209550/250000, loss: 0.1888, lr: 0.001941, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6067 samples/sec | ETA 06:21:21
2023-02-05 01:27:52 [INFO]	[TRAIN] epoch: 2653, iter: 209560/250000, loss: 0.2243, lr: 0.001941, batch_cost: 0.5992, reader_cost: 0.03399, ips: 10.0130 samples/sec | ETA 06:43:52
2023-02-05 01:27:57 [INFO]	[TRAIN] epoch: 2653, iter: 209570/250000, loss: 0.2825, lr: 0.001940, batch_cost: 0.5653, reader_cost: 0.00011, ips: 10.6136 samples/sec | ETA 06:20:55
2023-02-05 01:28:03 [INFO]	[TRAIN] epoch: 2653, iter: 209580/250000, loss: 0.3399, lr: 0.001940, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5987 samples/sec | ETA 06:21:21
2023-02-05 01:28:09 [INFO]	[TRAIN] epoch: 2654, iter: 209590/250000, loss: 0.2407, lr: 0.001940, batch_cost: 0.5653, reader_cost: 0.00011, ips: 10.6146 samples/sec | ETA 06:20:42
2023-02-05 01:28:14 [INFO]	[TRAIN] epoch: 2654, iter: 209600/250000, loss: 0.3883, lr: 0.001939, batch_cost: 0.5651, reader_cost: 0.00012, ips: 10.6175 samples/sec | ETA 06:20:30
2023-02-05 01:28:20 [INFO]	[TRAIN] epoch: 2654, iter: 209610/250000, loss: 0.2605, lr: 0.001939, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5973 samples/sec | ETA 06:21:08
2023-02-05 01:28:26 [INFO]	[TRAIN] epoch: 2654, iter: 209620/250000, loss: 0.2018, lr: 0.001938, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6024 samples/sec | ETA 06:20:51
2023-02-05 01:28:31 [INFO]	[TRAIN] epoch: 2654, iter: 209630/250000, loss: 0.3175, lr: 0.001938, batch_cost: 0.5654, reader_cost: 0.00011, ips: 10.6123 samples/sec | ETA 06:20:24
2023-02-05 01:28:37 [INFO]	[TRAIN] epoch: 2654, iter: 209640/250000, loss: 0.2229, lr: 0.001937, batch_cost: 0.5937, reader_cost: 0.02836, ips: 10.1065 samples/sec | ETA 06:39:20
2023-02-05 01:28:43 [INFO]	[TRAIN] epoch: 2654, iter: 209650/250000, loss: 0.2127, lr: 0.001937, batch_cost: 0.5647, reader_cost: 0.00018, ips: 10.6247 samples/sec | ETA 06:19:46
2023-02-05 01:28:48 [INFO]	[TRAIN] epoch: 2654, iter: 209660/250000, loss: 0.2866, lr: 0.001937, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6033 samples/sec | ETA 06:20:26
2023-02-05 01:28:54 [INFO]	[TRAIN] epoch: 2655, iter: 209670/250000, loss: 0.2329, lr: 0.001936, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6128 samples/sec | ETA 06:20:00
2023-02-05 01:29:00 [INFO]	[TRAIN] epoch: 2655, iter: 209680/250000, loss: 0.2348, lr: 0.001936, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6149 samples/sec | ETA 06:19:50
2023-02-05 01:29:05 [INFO]	[TRAIN] epoch: 2655, iter: 209690/250000, loss: 0.2487, lr: 0.001935, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6022 samples/sec | ETA 06:20:12
2023-02-05 01:29:11 [INFO]	[TRAIN] epoch: 2655, iter: 209700/250000, loss: 0.2022, lr: 0.001935, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6115 samples/sec | ETA 06:19:46
2023-02-05 01:29:17 [INFO]	[TRAIN] epoch: 2655, iter: 209710/250000, loss: 0.2172, lr: 0.001934, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6136 samples/sec | ETA 06:19:36
2023-02-05 01:29:23 [INFO]	[TRAIN] epoch: 2655, iter: 209720/250000, loss: 0.2076, lr: 0.001934, batch_cost: 0.6014, reader_cost: 0.03564, ips: 9.9769 samples/sec | ETA 06:43:43
2023-02-05 01:29:28 [INFO]	[TRAIN] epoch: 2655, iter: 209730/250000, loss: 0.1970, lr: 0.001934, batch_cost: 0.5670, reader_cost: 0.00011, ips: 10.5822 samples/sec | ETA 06:20:32
2023-02-05 01:29:34 [INFO]	[TRAIN] epoch: 2655, iter: 209740/250000, loss: 0.2169, lr: 0.001933, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6037 samples/sec | ETA 06:19:40
2023-02-05 01:29:40 [INFO]	[TRAIN] epoch: 2656, iter: 209750/250000, loss: 0.1934, lr: 0.001933, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6004 samples/sec | ETA 06:19:42
2023-02-05 01:29:45 [INFO]	[TRAIN] epoch: 2656, iter: 209760/250000, loss: 0.1849, lr: 0.001932, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6198 samples/sec | ETA 06:18:54
2023-02-05 01:29:51 [INFO]	[TRAIN] epoch: 2656, iter: 209770/250000, loss: 0.2100, lr: 0.001932, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6028 samples/sec | ETA 06:19:25
2023-02-05 01:29:57 [INFO]	[TRAIN] epoch: 2656, iter: 209780/250000, loss: 0.2351, lr: 0.001931, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5989 samples/sec | ETA 06:19:28
2023-02-05 01:30:02 [INFO]	[TRAIN] epoch: 2656, iter: 209790/250000, loss: 0.2742, lr: 0.001931, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6150 samples/sec | ETA 06:18:48
2023-02-05 01:30:08 [INFO]	[TRAIN] epoch: 2656, iter: 209800/250000, loss: 0.2137, lr: 0.001930, batch_cost: 0.5915, reader_cost: 0.02638, ips: 10.1441 samples/sec | ETA 06:36:17
2023-02-05 01:30:14 [INFO]	[TRAIN] epoch: 2656, iter: 209810/250000, loss: 0.1870, lr: 0.001930, batch_cost: 0.5656, reader_cost: 0.00012, ips: 10.6078 samples/sec | ETA 06:18:52
2023-02-05 01:30:20 [INFO]	[TRAIN] epoch: 2656, iter: 209820/250000, loss: 0.2434, lr: 0.001930, batch_cost: 0.5657, reader_cost: 0.00011, ips: 10.6069 samples/sec | ETA 06:18:48
2023-02-05 01:30:25 [INFO]	[TRAIN] epoch: 2657, iter: 209830/250000, loss: 0.2659, lr: 0.001929, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6049 samples/sec | ETA 06:18:47
2023-02-05 01:30:31 [INFO]	[TRAIN] epoch: 2657, iter: 209840/250000, loss: 0.1834, lr: 0.001929, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6077 samples/sec | ETA 06:18:35
2023-02-05 01:30:37 [INFO]	[TRAIN] epoch: 2657, iter: 209850/250000, loss: 0.2019, lr: 0.001928, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6203 samples/sec | ETA 06:18:02
2023-02-05 01:30:42 [INFO]	[TRAIN] epoch: 2657, iter: 209860/250000, loss: 0.2279, lr: 0.001928, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5997 samples/sec | ETA 06:18:41
2023-02-05 01:30:48 [INFO]	[TRAIN] epoch: 2657, iter: 209870/250000, loss: 0.1949, lr: 0.001927, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5987 samples/sec | ETA 06:18:37
2023-02-05 01:30:54 [INFO]	[TRAIN] epoch: 2657, iter: 209880/250000, loss: 0.1735, lr: 0.001927, batch_cost: 0.5895, reader_cost: 0.02296, ips: 10.1785 samples/sec | ETA 06:34:09
2023-02-05 01:30:59 [INFO]	[TRAIN] epoch: 2657, iter: 209890/250000, loss: 0.1714, lr: 0.001927, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6051 samples/sec | ETA 06:18:12
2023-02-05 01:31:05 [INFO]	[TRAIN] epoch: 2657, iter: 209900/250000, loss: 0.1824, lr: 0.001926, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6104 samples/sec | ETA 06:17:55
2023-02-05 01:31:11 [INFO]	[TRAIN] epoch: 2658, iter: 209910/250000, loss: 0.1718, lr: 0.001926, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6143 samples/sec | ETA 06:17:41
2023-02-05 01:31:16 [INFO]	[TRAIN] epoch: 2658, iter: 209920/250000, loss: 0.1798, lr: 0.001925, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6045 samples/sec | ETA 06:17:57
2023-02-05 01:31:22 [INFO]	[TRAIN] epoch: 2658, iter: 209930/250000, loss: 0.1568, lr: 0.001925, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6035 samples/sec | ETA 06:17:53
2023-02-05 01:31:28 [INFO]	[TRAIN] epoch: 2658, iter: 209940/250000, loss: 0.1734, lr: 0.001924, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6148 samples/sec | ETA 06:17:23
2023-02-05 01:31:33 [INFO]	[TRAIN] epoch: 2658, iter: 209950/250000, loss: 0.2667, lr: 0.001924, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6043 samples/sec | ETA 06:17:40
2023-02-05 01:31:39 [INFO]	[TRAIN] epoch: 2658, iter: 209960/250000, loss: 0.2351, lr: 0.001924, batch_cost: 0.5942, reader_cost: 0.02777, ips: 10.0968 samples/sec | ETA 06:36:33
2023-02-05 01:31:45 [INFO]	[TRAIN] epoch: 2658, iter: 209970/250000, loss: 0.2176, lr: 0.001923, batch_cost: 0.5663, reader_cost: 0.00010, ips: 10.5960 samples/sec | ETA 06:17:47
2023-02-05 01:31:51 [INFO]	[TRAIN] epoch: 2658, iter: 209980/250000, loss: 0.1848, lr: 0.001923, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6141 samples/sec | ETA 06:17:02
2023-02-05 01:31:56 [INFO]	[TRAIN] epoch: 2659, iter: 209990/250000, loss: 0.1817, lr: 0.001922, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6098 samples/sec | ETA 06:17:06
2023-02-05 01:32:02 [INFO]	[TRAIN] epoch: 2659, iter: 210000/250000, loss: 0.1769, lr: 0.001922, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6041 samples/sec | ETA 06:17:12
2023-02-05 01:32:02 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1234 - reader cost: 0.0231 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1497 - reader cost: 0.0116 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1585 - reader cost: 0.0078 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1583 - reader cost: 0.0058 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1597 - reader cost: 0.0047 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1618 - reader cost: 0.0039 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1617 - reader cost: 0.0034 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1619 - reader cost: 0.0030 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1629 - reader cost: 0.002610/36 [=======>......................] - ETA: 4s - batch_cost: 0.1627 - reader cost: 0.002411/36 [========>.....................] - ETA: 4s - batch_cost: 0.1634 - reader cost: 0.002212/36 [=========>....................] - ETA: 3s - batch_cost: 0.1630 - reader cost: 0.002013/36 [=========>....................] - ETA: 3s - batch_cost: 0.1634 - reader cost: 0.001814/36 [==========>...................] - ETA: 3s - batch_cost: 0.1639 - reader cost: 0.001715/36 [===========>..................] - ETA: 3s - batch_cost: 0.1638 - reader cost: 0.001616/36 [============>.................] - ETA: 3s - batch_cost: 0.1648 - reader cost: 0.001517/36 [=============>................] - ETA: 3s - batch_cost: 0.1648 - reader cost: 0.001418/36 [==============>...............] - ETA: 2s - batch_cost: 0.1651 - reader cost: 0.001419/36 [==============>...............] - ETA: 2s - batch_cost: 0.1648 - reader cost: 0.001320/36 [===============>..............] - ETA: 2s - batch_cost: 0.1646 - reader cost: 0.001221/36 [================>.............] - ETA: 2s - batch_cost: 0.1647 - reader cost: 0.001222/36 [=================>............] - ETA: 2s - batch_cost: 0.1650 - reader cost: 0.001123/36 [==================>...........] - ETA: 2s - batch_cost: 0.1655 - reader cost: 0.001124/36 [===================>..........] - ETA: 1s - batch_cost: 0.1656 - reader cost: 0.001025/36 [===================>..........] - ETA: 1s - batch_cost: 0.1657 - reader cost: 9.9821e-0426/36 [====================>.........] - ETA: 1s - batch_cost: 0.1658 - reader cost: 9.6250e-0427/36 [=====================>........] - ETA: 1s - batch_cost: 0.1660 - reader cost: 9.2943e-0428/36 [======================>.......] - ETA: 1s - batch_cost: 0.1662 - reader cost: 8.9924e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1663 - reader cost: 8.7068e-0430/36 [========================>.....] - ETA: 0s - batch_cost: 0.1663 - reader cost: 8.4402e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1662 - reader cost: 8.1909e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1662 - reader cost: 7.9572e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1660 - reader cost: 7.7405e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1659 - reader cost: 7.5320e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1661 - reader cost: 7.3356e-0436/36 [==============================] - 6s 166ms/step - batch_cost: 0.1663 - reader cost: 7.1503e-04
2023-02-05 01:32:08 [INFO]	[EVAL] #Images: 36 mIoU: 0.8574 Acc: 0.9856 Kappa: 0.9479 Dice: 0.9194
2023-02-05 01:32:08 [INFO]	[EVAL] Class IoU: 
[0.9852 0.9153 0.8874 0.7175 0.6816 0.9719 0.8431]
2023-02-05 01:32:08 [INFO]	[EVAL] Class Precision: 
[0.9922 0.9645 0.939  0.8332 0.8441 0.9793 0.9182]
2023-02-05 01:32:08 [INFO]	[EVAL] Class Recall: 
[0.9928 0.9472 0.9417 0.8379 0.7797 0.9923 0.9115]
2023-02-05 01:32:09 [INFO]	[EVAL] The model with the best validation mIoU (0.8574) was saved at iter 210000.
2023-02-05 01:32:15 [INFO]	[TRAIN] epoch: 2659, iter: 210010/250000, loss: 0.1841, lr: 0.001921, batch_cost: 0.5635, reader_cost: 0.00011, ips: 10.6485 samples/sec | ETA 06:15:32
2023-02-05 01:32:20 [INFO]	[TRAIN] epoch: 2659, iter: 210020/250000, loss: 0.1690, lr: 0.001921, batch_cost: 0.5635, reader_cost: 0.00011, ips: 10.6477 samples/sec | ETA 06:15:28
2023-02-05 01:32:26 [INFO]	[TRAIN] epoch: 2659, iter: 210030/250000, loss: 0.3018, lr: 0.001921, batch_cost: 0.5638, reader_cost: 0.00010, ips: 10.6414 samples/sec | ETA 06:15:36
2023-02-05 01:32:32 [INFO]	[TRAIN] epoch: 2659, iter: 210040/250000, loss: 0.2865, lr: 0.001920, batch_cost: 0.5994, reader_cost: 0.03591, ips: 10.0102 samples/sec | ETA 06:39:11
2023-02-05 01:32:37 [INFO]	[TRAIN] epoch: 2659, iter: 210050/250000, loss: 0.2320, lr: 0.001920, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6358 samples/sec | ETA 06:15:37
2023-02-05 01:32:43 [INFO]	[TRAIN] epoch: 2659, iter: 210060/250000, loss: 0.2222, lr: 0.001919, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6122 samples/sec | ETA 06:16:21
2023-02-05 01:32:49 [INFO]	[TRAIN] epoch: 2660, iter: 210070/250000, loss: 0.2170, lr: 0.001919, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6096 samples/sec | ETA 06:16:21
2023-02-05 01:32:54 [INFO]	[TRAIN] epoch: 2660, iter: 210080/250000, loss: 0.2360, lr: 0.001918, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6201 samples/sec | ETA 06:15:53
2023-02-05 01:33:00 [INFO]	[TRAIN] epoch: 2660, iter: 210090/250000, loss: 0.2037, lr: 0.001918, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6132 samples/sec | ETA 06:16:02
2023-02-05 01:33:06 [INFO]	[TRAIN] epoch: 2660, iter: 210100/250000, loss: 0.2324, lr: 0.001918, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6120 samples/sec | ETA 06:15:59
2023-02-05 01:33:11 [INFO]	[TRAIN] epoch: 2660, iter: 210110/250000, loss: 0.1831, lr: 0.001917, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5989 samples/sec | ETA 06:16:21
2023-02-05 01:33:17 [INFO]	[TRAIN] epoch: 2660, iter: 210120/250000, loss: 0.1949, lr: 0.001917, batch_cost: 0.5940, reader_cost: 0.02801, ips: 10.1018 samples/sec | ETA 06:34:46
2023-02-05 01:33:23 [INFO]	[TRAIN] epoch: 2660, iter: 210130/250000, loss: 0.1817, lr: 0.001916, batch_cost: 0.5653, reader_cost: 0.00011, ips: 10.6141 samples/sec | ETA 06:15:38
2023-02-05 01:33:29 [INFO]	[TRAIN] epoch: 2660, iter: 210140/250000, loss: 0.1809, lr: 0.001916, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6106 samples/sec | ETA 06:15:39
2023-02-05 01:33:34 [INFO]	[TRAIN] epoch: 2661, iter: 210150/250000, loss: 0.1780, lr: 0.001915, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6098 samples/sec | ETA 06:15:35
2023-02-05 01:33:40 [INFO]	[TRAIN] epoch: 2661, iter: 210160/250000, loss: 0.1694, lr: 0.001915, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6106 samples/sec | ETA 06:15:28
2023-02-05 01:33:46 [INFO]	[TRAIN] epoch: 2661, iter: 210170/250000, loss: 0.1892, lr: 0.001914, batch_cost: 0.5654, reader_cost: 0.00011, ips: 10.6128 samples/sec | ETA 06:15:18
2023-02-05 01:33:51 [INFO]	[TRAIN] epoch: 2661, iter: 210180/250000, loss: 0.2000, lr: 0.001914, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6156 samples/sec | ETA 06:15:06
2023-02-05 01:33:57 [INFO]	[TRAIN] epoch: 2661, iter: 210190/250000, loss: 0.2284, lr: 0.001914, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6045 samples/sec | ETA 06:15:24
2023-02-05 01:34:03 [INFO]	[TRAIN] epoch: 2661, iter: 210200/250000, loss: 0.2176, lr: 0.001913, batch_cost: 0.5898, reader_cost: 0.02429, ips: 10.1726 samples/sec | ETA 06:31:14
2023-02-05 01:34:08 [INFO]	[TRAIN] epoch: 2661, iter: 210210/250000, loss: 0.2054, lr: 0.001913, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6087 samples/sec | ETA 06:15:04
2023-02-05 01:34:14 [INFO]	[TRAIN] epoch: 2662, iter: 210220/250000, loss: 0.2289, lr: 0.001912, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6042 samples/sec | ETA 06:15:07
2023-02-05 01:34:20 [INFO]	[TRAIN] epoch: 2662, iter: 210230/250000, loss: 0.2098, lr: 0.001912, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6198 samples/sec | ETA 06:14:29
2023-02-05 01:34:25 [INFO]	[TRAIN] epoch: 2662, iter: 210240/250000, loss: 0.1897, lr: 0.001911, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6089 samples/sec | ETA 06:14:46
2023-02-05 01:34:31 [INFO]	[TRAIN] epoch: 2662, iter: 210250/250000, loss: 0.2710, lr: 0.001911, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5996 samples/sec | ETA 06:15:00
2023-02-05 01:34:37 [INFO]	[TRAIN] epoch: 2662, iter: 210260/250000, loss: 0.1734, lr: 0.001911, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6149 samples/sec | ETA 06:14:22
2023-02-05 01:34:42 [INFO]	[TRAIN] epoch: 2662, iter: 210270/250000, loss: 0.1872, lr: 0.001910, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6101 samples/sec | ETA 06:14:27
2023-02-05 01:34:48 [INFO]	[TRAIN] epoch: 2662, iter: 210280/250000, loss: 0.1946, lr: 0.001910, batch_cost: 0.5938, reader_cost: 0.02792, ips: 10.1050 samples/sec | ETA 06:33:04
2023-02-05 01:34:54 [INFO]	[TRAIN] epoch: 2662, iter: 210290/250000, loss: 0.2104, lr: 0.001909, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6114 samples/sec | ETA 06:14:13
2023-02-05 01:35:00 [INFO]	[TRAIN] epoch: 2663, iter: 210300/250000, loss: 0.3057, lr: 0.001909, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6036 samples/sec | ETA 06:14:23
2023-02-05 01:35:05 [INFO]	[TRAIN] epoch: 2663, iter: 210310/250000, loss: 0.3154, lr: 0.001908, batch_cost: 0.5656, reader_cost: 0.00011, ips: 10.6078 samples/sec | ETA 06:14:09
2023-02-05 01:35:11 [INFO]	[TRAIN] epoch: 2663, iter: 210320/250000, loss: 0.2265, lr: 0.001908, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6160 samples/sec | ETA 06:13:46
2023-02-05 01:35:17 [INFO]	[TRAIN] epoch: 2663, iter: 210330/250000, loss: 0.2260, lr: 0.001908, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6005 samples/sec | ETA 06:14:13
2023-02-05 01:35:22 [INFO]	[TRAIN] epoch: 2663, iter: 210340/250000, loss: 0.2537, lr: 0.001907, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6179 samples/sec | ETA 06:13:31
2023-02-05 01:35:28 [INFO]	[TRAIN] epoch: 2663, iter: 210350/250000, loss: 0.2138, lr: 0.001907, batch_cost: 0.5921, reader_cost: 0.02659, ips: 10.1337 samples/sec | ETA 06:31:16
2023-02-05 01:35:34 [INFO]	[TRAIN] epoch: 2663, iter: 210360/250000, loss: 0.2180, lr: 0.001906, batch_cost: 0.5676, reader_cost: 0.00015, ips: 10.5712 samples/sec | ETA 06:14:58
2023-02-05 01:35:40 [INFO]	[TRAIN] epoch: 2663, iter: 210370/250000, loss: 0.2858, lr: 0.001906, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6133 samples/sec | ETA 06:13:23
2023-02-05 01:35:45 [INFO]	[TRAIN] epoch: 2664, iter: 210380/250000, loss: 0.2269, lr: 0.001905, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6099 samples/sec | ETA 06:13:25
2023-02-05 01:35:51 [INFO]	[TRAIN] epoch: 2664, iter: 210390/250000, loss: 0.2903, lr: 0.001905, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6102 samples/sec | ETA 06:13:19
2023-02-05 01:35:57 [INFO]	[TRAIN] epoch: 2664, iter: 210400/250000, loss: 0.2159, lr: 0.001905, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6107 samples/sec | ETA 06:13:12
2023-02-05 01:36:02 [INFO]	[TRAIN] epoch: 2664, iter: 210410/250000, loss: 0.1992, lr: 0.001904, batch_cost: 0.5658, reader_cost: 0.00011, ips: 10.6053 samples/sec | ETA 06:13:18
2023-02-05 01:36:08 [INFO]	[TRAIN] epoch: 2664, iter: 210420/250000, loss: 0.3214, lr: 0.001904, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6130 samples/sec | ETA 06:12:56
2023-02-05 01:36:14 [INFO]	[TRAIN] epoch: 2664, iter: 210430/250000, loss: 0.2498, lr: 0.001903, batch_cost: 0.5943, reader_cost: 0.02857, ips: 10.0952 samples/sec | ETA 06:31:58
2023-02-05 01:36:19 [INFO]	[TRAIN] epoch: 2664, iter: 210440/250000, loss: 0.2333, lr: 0.001903, batch_cost: 0.5670, reader_cost: 0.00013, ips: 10.5826 samples/sec | ETA 06:13:49
2023-02-05 01:36:25 [INFO]	[TRAIN] epoch: 2664, iter: 210450/250000, loss: 0.2084, lr: 0.001902, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6069 samples/sec | ETA 06:12:52
2023-02-05 01:36:31 [INFO]	[TRAIN] epoch: 2665, iter: 210460/250000, loss: 0.1893, lr: 0.001902, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6151 samples/sec | ETA 06:12:29
2023-02-05 01:36:36 [INFO]	[TRAIN] epoch: 2665, iter: 210470/250000, loss: 0.2031, lr: 0.001902, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6088 samples/sec | ETA 06:12:36
2023-02-05 01:36:42 [INFO]	[TRAIN] epoch: 2665, iter: 210480/250000, loss: 0.2052, lr: 0.001901, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6082 samples/sec | ETA 06:12:32
2023-02-05 01:36:48 [INFO]	[TRAIN] epoch: 2665, iter: 210490/250000, loss: 0.2329, lr: 0.001901, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6079 samples/sec | ETA 06:12:27
2023-02-05 01:36:53 [INFO]	[TRAIN] epoch: 2665, iter: 210500/250000, loss: 0.2164, lr: 0.001900, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6101 samples/sec | ETA 06:12:17
2023-02-05 01:36:59 [INFO]	[TRAIN] epoch: 2665, iter: 210510/250000, loss: 0.1903, lr: 0.001900, batch_cost: 0.5931, reader_cost: 0.02754, ips: 10.1157 samples/sec | ETA 06:30:22
2023-02-05 01:37:05 [INFO]	[TRAIN] epoch: 2665, iter: 210520/250000, loss: 0.1861, lr: 0.001899, batch_cost: 0.5655, reader_cost: 0.00014, ips: 10.6106 samples/sec | ETA 06:12:04
2023-02-05 01:37:11 [INFO]	[TRAIN] epoch: 2665, iter: 210530/250000, loss: 0.2195, lr: 0.001899, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6122 samples/sec | ETA 06:11:55
2023-02-05 01:37:16 [INFO]	[TRAIN] epoch: 2666, iter: 210540/250000, loss: 0.1985, lr: 0.001898, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6074 samples/sec | ETA 06:12:00
2023-02-05 01:37:22 [INFO]	[TRAIN] epoch: 2666, iter: 210550/250000, loss: 0.1949, lr: 0.001898, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6144 samples/sec | ETA 06:11:39
2023-02-05 01:37:28 [INFO]	[TRAIN] epoch: 2666, iter: 210560/250000, loss: 0.1913, lr: 0.001898, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6122 samples/sec | ETA 06:11:38
2023-02-05 01:37:33 [INFO]	[TRAIN] epoch: 2666, iter: 210570/250000, loss: 0.1552, lr: 0.001897, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6030 samples/sec | ETA 06:11:52
2023-02-05 01:37:39 [INFO]	[TRAIN] epoch: 2666, iter: 210580/250000, loss: 0.1890, lr: 0.001897, batch_cost: 0.5659, reader_cost: 0.00011, ips: 10.6032 samples/sec | ETA 06:11:46
2023-02-05 01:37:45 [INFO]	[TRAIN] epoch: 2666, iter: 210590/250000, loss: 0.2030, lr: 0.001896, batch_cost: 0.5941, reader_cost: 0.02930, ips: 10.1000 samples/sec | ETA 06:30:11
2023-02-05 01:37:50 [INFO]	[TRAIN] epoch: 2666, iter: 210600/250000, loss: 0.2542, lr: 0.001896, batch_cost: 0.5670, reader_cost: 0.00011, ips: 10.5821 samples/sec | ETA 06:12:19
2023-02-05 01:37:56 [INFO]	[TRAIN] epoch: 2666, iter: 210610/250000, loss: 0.1976, lr: 0.001895, batch_cost: 0.5657, reader_cost: 0.00011, ips: 10.6065 samples/sec | ETA 06:11:22
2023-02-05 01:38:02 [INFO]	[TRAIN] epoch: 2667, iter: 210620/250000, loss: 0.1734, lr: 0.001895, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6152 samples/sec | ETA 06:10:58
2023-02-05 01:38:07 [INFO]	[TRAIN] epoch: 2667, iter: 210630/250000, loss: 0.2413, lr: 0.001895, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6103 samples/sec | ETA 06:11:03
2023-02-05 01:38:13 [INFO]	[TRAIN] epoch: 2667, iter: 210640/250000, loss: 0.1780, lr: 0.001894, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6090 samples/sec | ETA 06:11:00
2023-02-05 01:38:19 [INFO]	[TRAIN] epoch: 2667, iter: 210650/250000, loss: 0.1781, lr: 0.001894, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6054 samples/sec | ETA 06:11:02
2023-02-05 01:38:24 [INFO]	[TRAIN] epoch: 2667, iter: 210660/250000, loss: 0.2148, lr: 0.001893, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6086 samples/sec | ETA 06:10:49
2023-02-05 01:38:30 [INFO]	[TRAIN] epoch: 2667, iter: 210670/250000, loss: 0.2125, lr: 0.001893, batch_cost: 0.5920, reader_cost: 0.02676, ips: 10.1355 samples/sec | ETA 06:28:02
2023-02-05 01:38:36 [INFO]	[TRAIN] epoch: 2667, iter: 210680/250000, loss: 0.2031, lr: 0.001892, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6161 samples/sec | ETA 06:10:22
2023-02-05 01:38:42 [INFO]	[TRAIN] epoch: 2667, iter: 210690/250000, loss: 0.1743, lr: 0.001892, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6034 samples/sec | ETA 06:10:43
2023-02-05 01:38:47 [INFO]	[TRAIN] epoch: 2668, iter: 210700/250000, loss: 0.1750, lr: 0.001892, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6128 samples/sec | ETA 06:10:18
2023-02-05 01:38:53 [INFO]	[TRAIN] epoch: 2668, iter: 210710/250000, loss: 0.2081, lr: 0.001891, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6098 samples/sec | ETA 06:10:19
2023-02-05 01:38:59 [INFO]	[TRAIN] epoch: 2668, iter: 210720/250000, loss: 0.1916, lr: 0.001891, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6047 samples/sec | ETA 06:10:24
2023-02-05 01:39:04 [INFO]	[TRAIN] epoch: 2668, iter: 210730/250000, loss: 0.1986, lr: 0.001890, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6105 samples/sec | ETA 06:10:06
2023-02-05 01:39:10 [INFO]	[TRAIN] epoch: 2668, iter: 210740/250000, loss: 0.1613, lr: 0.001890, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6036 samples/sec | ETA 06:10:15
2023-02-05 01:39:16 [INFO]	[TRAIN] epoch: 2668, iter: 210750/250000, loss: 0.2198, lr: 0.001889, batch_cost: 0.5944, reader_cost: 0.02874, ips: 10.0944 samples/sec | ETA 06:28:49
2023-02-05 01:39:22 [INFO]	[TRAIN] epoch: 2668, iter: 210760/250000, loss: 0.2209, lr: 0.001889, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6117 samples/sec | ETA 06:09:46
2023-02-05 01:39:27 [INFO]	[TRAIN] epoch: 2668, iter: 210770/250000, loss: 0.2145, lr: 0.001889, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6127 samples/sec | ETA 06:09:38
2023-02-05 01:39:33 [INFO]	[TRAIN] epoch: 2669, iter: 210780/250000, loss: 0.2148, lr: 0.001888, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 06:09:50
2023-02-05 01:39:39 [INFO]	[TRAIN] epoch: 2669, iter: 210790/250000, loss: 0.4325, lr: 0.001888, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6119 samples/sec | ETA 06:09:29
2023-02-05 01:39:44 [INFO]	[TRAIN] epoch: 2669, iter: 210800/250000, loss: 0.2990, lr: 0.001887, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6132 samples/sec | ETA 06:09:21
2023-02-05 01:39:50 [INFO]	[TRAIN] epoch: 2669, iter: 210810/250000, loss: 0.2437, lr: 0.001887, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6006 samples/sec | ETA 06:09:41
2023-02-05 01:39:55 [INFO]	[TRAIN] epoch: 2669, iter: 210820/250000, loss: 0.2291, lr: 0.001886, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6055 samples/sec | ETA 06:09:25
2023-02-05 01:40:01 [INFO]	[TRAIN] epoch: 2669, iter: 210830/250000, loss: 0.3138, lr: 0.001886, batch_cost: 0.5916, reader_cost: 0.02659, ips: 10.1422 samples/sec | ETA 06:26:12
2023-02-05 01:40:07 [INFO]	[TRAIN] epoch: 2669, iter: 210840/250000, loss: 0.2136, lr: 0.001885, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6021 samples/sec | ETA 06:09:21
2023-02-05 01:40:13 [INFO]	[TRAIN] epoch: 2669, iter: 210850/250000, loss: 0.2003, lr: 0.001885, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6068 samples/sec | ETA 06:09:06
2023-02-05 01:40:18 [INFO]	[TRAIN] epoch: 2670, iter: 210860/250000, loss: 0.2485, lr: 0.001885, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6145 samples/sec | ETA 06:08:44
2023-02-05 01:40:24 [INFO]	[TRAIN] epoch: 2670, iter: 210870/250000, loss: 0.2221, lr: 0.001884, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6083 samples/sec | ETA 06:08:51
2023-02-05 01:40:30 [INFO]	[TRAIN] epoch: 2670, iter: 210880/250000, loss: 0.1979, lr: 0.001884, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6097 samples/sec | ETA 06:08:43
2023-02-05 01:40:35 [INFO]	[TRAIN] epoch: 2670, iter: 210890/250000, loss: 0.2445, lr: 0.001883, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6155 samples/sec | ETA 06:08:25
2023-02-05 01:40:41 [INFO]	[TRAIN] epoch: 2670, iter: 210900/250000, loss: 0.2664, lr: 0.001883, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6046 samples/sec | ETA 06:08:42
2023-02-05 01:40:47 [INFO]	[TRAIN] epoch: 2670, iter: 210910/250000, loss: 0.2133, lr: 0.001882, batch_cost: 0.6080, reader_cost: 0.03981, ips: 9.8680 samples/sec | ETA 06:36:07
2023-02-05 01:40:53 [INFO]	[TRAIN] epoch: 2670, iter: 210920/250000, loss: 0.2138, lr: 0.001882, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6099 samples/sec | ETA 06:08:20
2023-02-05 01:40:58 [INFO]	[TRAIN] epoch: 2670, iter: 210930/250000, loss: 0.2420, lr: 0.001882, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6110 samples/sec | ETA 06:08:12
2023-02-05 01:41:04 [INFO]	[TRAIN] epoch: 2671, iter: 210940/250000, loss: 0.1978, lr: 0.001881, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6061 samples/sec | ETA 06:08:16
2023-02-05 01:41:10 [INFO]	[TRAIN] epoch: 2671, iter: 210950/250000, loss: 0.1861, lr: 0.001881, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6175 samples/sec | ETA 06:07:47
2023-02-05 01:41:15 [INFO]	[TRAIN] epoch: 2671, iter: 210960/250000, loss: 0.1934, lr: 0.001880, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6162 samples/sec | ETA 06:07:44
2023-02-05 01:41:21 [INFO]	[TRAIN] epoch: 2671, iter: 210970/250000, loss: 0.1844, lr: 0.001880, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5997 samples/sec | ETA 06:08:13
2023-02-05 01:41:27 [INFO]	[TRAIN] epoch: 2671, iter: 210980/250000, loss: 0.2371, lr: 0.001879, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6108 samples/sec | ETA 06:07:44
2023-02-05 01:41:33 [INFO]	[TRAIN] epoch: 2671, iter: 210990/250000, loss: 0.2448, lr: 0.001879, batch_cost: 0.6014, reader_cost: 0.03685, ips: 9.9774 samples/sec | ETA 06:30:58
2023-02-05 01:41:38 [INFO]	[TRAIN] epoch: 2671, iter: 211000/250000, loss: 0.2643, lr: 0.001879, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5987 samples/sec | ETA 06:07:58
2023-02-05 01:41:44 [INFO]	[TRAIN] epoch: 2672, iter: 211010/250000, loss: 0.2170, lr: 0.001878, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6059 samples/sec | ETA 06:07:37
2023-02-05 01:41:50 [INFO]	[TRAIN] epoch: 2672, iter: 211020/250000, loss: 0.2274, lr: 0.001878, batch_cost: 0.5658, reader_cost: 0.00011, ips: 10.6044 samples/sec | ETA 06:07:34
2023-02-05 01:41:55 [INFO]	[TRAIN] epoch: 2672, iter: 211030/250000, loss: 0.1856, lr: 0.001877, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6097 samples/sec | ETA 06:07:18
2023-02-05 01:42:01 [INFO]	[TRAIN] epoch: 2672, iter: 211040/250000, loss: 0.2200, lr: 0.001877, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6065 samples/sec | ETA 06:07:19
2023-02-05 01:42:07 [INFO]	[TRAIN] epoch: 2672, iter: 211050/250000, loss: 0.2043, lr: 0.001876, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6062 samples/sec | ETA 06:07:14
2023-02-05 01:42:12 [INFO]	[TRAIN] epoch: 2672, iter: 211060/250000, loss: 0.2059, lr: 0.001876, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6102 samples/sec | ETA 06:07:00
2023-02-05 01:42:18 [INFO]	[TRAIN] epoch: 2672, iter: 211070/250000, loss: 0.2968, lr: 0.001876, batch_cost: 0.5942, reader_cost: 0.02895, ips: 10.0975 samples/sec | ETA 06:25:32
2023-02-05 01:42:24 [INFO]	[TRAIN] epoch: 2672, iter: 211080/250000, loss: 0.2133, lr: 0.001875, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6289 samples/sec | ETA 06:06:10
2023-02-05 01:42:30 [INFO]	[TRAIN] epoch: 2673, iter: 211090/250000, loss: 0.1938, lr: 0.001875, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6238 samples/sec | ETA 06:06:15
2023-02-05 01:42:35 [INFO]	[TRAIN] epoch: 2673, iter: 211100/250000, loss: 0.2287, lr: 0.001874, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6132 samples/sec | ETA 06:06:31
2023-02-05 01:42:41 [INFO]	[TRAIN] epoch: 2673, iter: 211110/250000, loss: 0.2935, lr: 0.001874, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5977 samples/sec | ETA 06:06:57
2023-02-05 01:42:46 [INFO]	[TRAIN] epoch: 2673, iter: 211120/250000, loss: 0.2318, lr: 0.001873, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6144 samples/sec | ETA 06:06:17
2023-02-05 01:42:52 [INFO]	[TRAIN] epoch: 2673, iter: 211130/250000, loss: 0.2739, lr: 0.001873, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6176 samples/sec | ETA 06:06:05
2023-02-05 01:42:58 [INFO]	[TRAIN] epoch: 2673, iter: 211140/250000, loss: 0.2733, lr: 0.001872, batch_cost: 0.5958, reader_cost: 0.03009, ips: 10.0699 samples/sec | ETA 06:25:54
2023-02-05 01:43:04 [INFO]	[TRAIN] epoch: 2673, iter: 211150/250000, loss: 0.1751, lr: 0.001872, batch_cost: 0.5666, reader_cost: 0.00019, ips: 10.5903 samples/sec | ETA 06:06:50
2023-02-05 01:43:09 [INFO]	[TRAIN] epoch: 2673, iter: 211160/250000, loss: 0.1864, lr: 0.001872, batch_cost: 0.5649, reader_cost: 0.00008, ips: 10.6218 samples/sec | ETA 06:05:39
2023-02-05 01:43:15 [INFO]	[TRAIN] epoch: 2674, iter: 211170/250000, loss: 0.2308, lr: 0.001871, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6112 samples/sec | ETA 06:05:56
2023-02-05 01:43:21 [INFO]	[TRAIN] epoch: 2674, iter: 211180/250000, loss: 0.1705, lr: 0.001871, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6106 samples/sec | ETA 06:05:51
2023-02-05 01:43:26 [INFO]	[TRAIN] epoch: 2674, iter: 211190/250000, loss: 0.2208, lr: 0.001870, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6079 samples/sec | ETA 06:05:51
2023-02-05 01:43:32 [INFO]	[TRAIN] epoch: 2674, iter: 211200/250000, loss: 0.2401, lr: 0.001870, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6136 samples/sec | ETA 06:05:34
2023-02-05 01:43:38 [INFO]	[TRAIN] epoch: 2674, iter: 211210/250000, loss: 0.1878, lr: 0.001869, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6165 samples/sec | ETA 06:05:22
2023-02-05 01:43:44 [INFO]	[TRAIN] epoch: 2674, iter: 211220/250000, loss: 0.1990, lr: 0.001869, batch_cost: 0.5974, reader_cost: 0.03170, ips: 10.0433 samples/sec | ETA 06:26:07
2023-02-05 01:43:49 [INFO]	[TRAIN] epoch: 2674, iter: 211230/250000, loss: 0.1967, lr: 0.001869, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6233 samples/sec | ETA 06:04:57
2023-02-05 01:43:55 [INFO]	[TRAIN] epoch: 2674, iter: 211240/250000, loss: 0.2946, lr: 0.001868, batch_cost: 0.5647, reader_cost: 0.00008, ips: 10.6247 samples/sec | ETA 06:04:48
2023-02-05 01:44:01 [INFO]	[TRAIN] epoch: 2675, iter: 211250/250000, loss: 0.2484, lr: 0.001868, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6406 samples/sec | ETA 06:04:10
2023-02-05 01:44:06 [INFO]	[TRAIN] epoch: 2675, iter: 211260/250000, loss: 0.1894, lr: 0.001867, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6299 samples/sec | ETA 06:04:26
2023-02-05 01:44:12 [INFO]	[TRAIN] epoch: 2675, iter: 211270/250000, loss: 0.2032, lr: 0.001867, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6246 samples/sec | ETA 06:04:31
2023-02-05 01:44:18 [INFO]	[TRAIN] epoch: 2675, iter: 211280/250000, loss: 0.2142, lr: 0.001866, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6041 samples/sec | ETA 06:05:08
2023-02-05 01:44:23 [INFO]	[TRAIN] epoch: 2675, iter: 211290/250000, loss: 0.2437, lr: 0.001866, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6078 samples/sec | ETA 06:04:55
2023-02-05 01:44:29 [INFO]	[TRAIN] epoch: 2675, iter: 211300/250000, loss: 0.2596, lr: 0.001866, batch_cost: 0.5920, reader_cost: 0.02702, ips: 10.1352 samples/sec | ETA 06:21:50
2023-02-05 01:44:35 [INFO]	[TRAIN] epoch: 2675, iter: 211310/250000, loss: 0.3122, lr: 0.001865, batch_cost: 0.5640, reader_cost: 0.00014, ips: 10.6383 samples/sec | ETA 06:03:41
2023-02-05 01:44:40 [INFO]	[TRAIN] epoch: 2675, iter: 211320/250000, loss: 0.2429, lr: 0.001865, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6390 samples/sec | ETA 06:03:34
2023-02-05 01:44:46 [INFO]	[TRAIN] epoch: 2676, iter: 211330/250000, loss: 0.2887, lr: 0.001864, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6311 samples/sec | ETA 06:03:44
2023-02-05 01:44:52 [INFO]	[TRAIN] epoch: 2676, iter: 211340/250000, loss: 0.2000, lr: 0.001864, batch_cost: 0.5664, reader_cost: 0.00010, ips: 10.5924 samples/sec | ETA 06:04:58
2023-02-05 01:44:57 [INFO]	[TRAIN] epoch: 2676, iter: 211350/250000, loss: 0.2746, lr: 0.001863, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6034 samples/sec | ETA 06:04:30
2023-02-05 01:45:03 [INFO]	[TRAIN] epoch: 2676, iter: 211360/250000, loss: 0.2251, lr: 0.001863, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6094 samples/sec | ETA 06:04:12
2023-02-05 01:45:09 [INFO]	[TRAIN] epoch: 2676, iter: 211370/250000, loss: 0.3019, lr: 0.001863, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6114 samples/sec | ETA 06:04:02
2023-02-05 01:45:15 [INFO]	[TRAIN] epoch: 2676, iter: 211380/250000, loss: 0.3563, lr: 0.001862, batch_cost: 0.5934, reader_cost: 0.02790, ips: 10.1119 samples/sec | ETA 06:21:55
2023-02-05 01:45:20 [INFO]	[TRAIN] epoch: 2676, iter: 211390/250000, loss: 0.3080, lr: 0.001862, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6236 samples/sec | ETA 06:03:26
2023-02-05 01:45:26 [INFO]	[TRAIN] epoch: 2676, iter: 211400/250000, loss: 0.2284, lr: 0.001861, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6306 samples/sec | ETA 06:03:06
2023-02-05 01:45:32 [INFO]	[TRAIN] epoch: 2677, iter: 211410/250000, loss: 0.2463, lr: 0.001861, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6313 samples/sec | ETA 06:02:58
2023-02-05 01:45:37 [INFO]	[TRAIN] epoch: 2677, iter: 211420/250000, loss: 0.2779, lr: 0.001860, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6235 samples/sec | ETA 06:03:09
2023-02-05 01:45:43 [INFO]	[TRAIN] epoch: 2677, iter: 211430/250000, loss: 0.2460, lr: 0.001860, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6027 samples/sec | ETA 06:03:46
2023-02-05 01:45:49 [INFO]	[TRAIN] epoch: 2677, iter: 211440/250000, loss: 0.2291, lr: 0.001859, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6075 samples/sec | ETA 06:03:30
2023-02-05 01:45:54 [INFO]	[TRAIN] epoch: 2677, iter: 211450/250000, loss: 0.2670, lr: 0.001859, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6092 samples/sec | ETA 06:03:21
2023-02-05 01:46:00 [INFO]	[TRAIN] epoch: 2677, iter: 211460/250000, loss: 0.2048, lr: 0.001859, batch_cost: 0.5882, reader_cost: 0.02290, ips: 10.2005 samples/sec | ETA 06:17:49
2023-02-05 01:46:06 [INFO]	[TRAIN] epoch: 2677, iter: 211470/250000, loss: 0.2299, lr: 0.001858, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6313 samples/sec | ETA 06:02:25
2023-02-05 01:46:11 [INFO]	[TRAIN] epoch: 2677, iter: 211480/250000, loss: 0.2240, lr: 0.001858, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6171 samples/sec | ETA 06:02:48
2023-02-05 01:46:17 [INFO]	[TRAIN] epoch: 2678, iter: 211490/250000, loss: 0.2530, lr: 0.001857, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6097 samples/sec | ETA 06:02:58
2023-02-05 01:46:23 [INFO]	[TRAIN] epoch: 2678, iter: 211500/250000, loss: 0.2719, lr: 0.001857, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5986 samples/sec | ETA 06:03:15
2023-02-05 01:46:28 [INFO]	[TRAIN] epoch: 2678, iter: 211510/250000, loss: 0.2126, lr: 0.001856, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6095 samples/sec | ETA 06:02:47
2023-02-05 01:46:34 [INFO]	[TRAIN] epoch: 2678, iter: 211520/250000, loss: 0.2200, lr: 0.001856, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6101 samples/sec | ETA 06:02:40
2023-02-05 01:46:40 [INFO]	[TRAIN] epoch: 2678, iter: 211530/250000, loss: 0.1966, lr: 0.001856, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6021 samples/sec | ETA 06:02:51
2023-02-05 01:46:46 [INFO]	[TRAIN] epoch: 2678, iter: 211540/250000, loss: 0.2171, lr: 0.001855, batch_cost: 0.5977, reader_cost: 0.03260, ips: 10.0381 samples/sec | ETA 06:23:08
2023-02-05 01:46:51 [INFO]	[TRAIN] epoch: 2678, iter: 211550/250000, loss: 0.2419, lr: 0.001855, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6256 samples/sec | ETA 06:01:51
2023-02-05 01:46:57 [INFO]	[TRAIN] epoch: 2678, iter: 211560/250000, loss: 0.3326, lr: 0.001854, batch_cost: 0.5659, reader_cost: 0.00008, ips: 10.6026 samples/sec | ETA 06:02:33
2023-02-05 01:47:03 [INFO]	[TRAIN] epoch: 2679, iter: 211570/250000, loss: 0.3040, lr: 0.001854, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6061 samples/sec | ETA 06:02:20
2023-02-05 01:47:08 [INFO]	[TRAIN] epoch: 2679, iter: 211580/250000, loss: 0.2827, lr: 0.001853, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6145 samples/sec | ETA 06:01:57
2023-02-05 01:47:14 [INFO]	[TRAIN] epoch: 2679, iter: 211590/250000, loss: 0.2143, lr: 0.001853, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6028 samples/sec | ETA 06:02:15
2023-02-05 01:47:20 [INFO]	[TRAIN] epoch: 2679, iter: 211600/250000, loss: 0.3644, lr: 0.001853, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5950 samples/sec | ETA 06:02:26
2023-02-05 01:47:25 [INFO]	[TRAIN] epoch: 2679, iter: 211610/250000, loss: 0.2172, lr: 0.001852, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6122 samples/sec | ETA 06:01:45
2023-02-05 01:47:31 [INFO]	[TRAIN] epoch: 2679, iter: 211620/250000, loss: 0.2526, lr: 0.001852, batch_cost: 0.5986, reader_cost: 0.03381, ips: 10.0226 samples/sec | ETA 06:22:56
2023-02-05 01:47:37 [INFO]	[TRAIN] epoch: 2679, iter: 211630/250000, loss: 0.2036, lr: 0.001851, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6251 samples/sec | ETA 06:01:07
2023-02-05 01:47:42 [INFO]	[TRAIN] epoch: 2679, iter: 211640/250000, loss: 0.2385, lr: 0.001851, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6018 samples/sec | ETA 06:01:49
2023-02-05 01:47:48 [INFO]	[TRAIN] epoch: 2680, iter: 211650/250000, loss: 0.2652, lr: 0.001850, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6141 samples/sec | ETA 06:01:18
2023-02-05 01:47:54 [INFO]	[TRAIN] epoch: 2680, iter: 211660/250000, loss: 0.1785, lr: 0.001850, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6091 samples/sec | ETA 06:01:23
2023-02-05 01:47:59 [INFO]	[TRAIN] epoch: 2680, iter: 211670/250000, loss: 0.2339, lr: 0.001849, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5984 samples/sec | ETA 06:01:39
2023-02-05 01:48:05 [INFO]	[TRAIN] epoch: 2680, iter: 211680/250000, loss: 0.2639, lr: 0.001849, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6060 samples/sec | ETA 06:01:18
2023-02-05 01:48:11 [INFO]	[TRAIN] epoch: 2680, iter: 211690/250000, loss: 0.2239, lr: 0.001849, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6009 samples/sec | ETA 06:01:23
2023-02-05 01:48:17 [INFO]	[TRAIN] epoch: 2680, iter: 211700/250000, loss: 0.2138, lr: 0.001848, batch_cost: 0.5879, reader_cost: 0.02221, ips: 10.2064 samples/sec | ETA 06:15:15
2023-02-05 01:48:22 [INFO]	[TRAIN] epoch: 2680, iter: 211710/250000, loss: 0.2247, lr: 0.001848, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6069 samples/sec | ETA 06:00:59
2023-02-05 01:48:28 [INFO]	[TRAIN] epoch: 2680, iter: 211720/250000, loss: 0.1851, lr: 0.001847, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6085 samples/sec | ETA 06:00:50
2023-02-05 01:48:34 [INFO]	[TRAIN] epoch: 2681, iter: 211730/250000, loss: 0.1755, lr: 0.001847, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6081 samples/sec | ETA 06:00:45
2023-02-05 01:48:39 [INFO]	[TRAIN] epoch: 2681, iter: 211740/250000, loss: 0.2054, lr: 0.001846, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6044 samples/sec | ETA 06:00:47
2023-02-05 01:48:45 [INFO]	[TRAIN] epoch: 2681, iter: 211750/250000, loss: 0.2274, lr: 0.001846, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5984 samples/sec | ETA 06:00:54
2023-02-05 01:48:51 [INFO]	[TRAIN] epoch: 2681, iter: 211760/250000, loss: 0.1768, lr: 0.001846, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5955 samples/sec | ETA 06:00:54
2023-02-05 01:48:56 [INFO]	[TRAIN] epoch: 2681, iter: 211770/250000, loss: 0.1754, lr: 0.001845, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6034 samples/sec | ETA 06:00:32
2023-02-05 01:49:02 [INFO]	[TRAIN] epoch: 2681, iter: 211780/250000, loss: 0.2277, lr: 0.001845, batch_cost: 0.5973, reader_cost: 0.03260, ips: 10.0446 samples/sec | ETA 06:20:30
2023-02-05 01:49:08 [INFO]	[TRAIN] epoch: 2681, iter: 211790/250000, loss: 0.2035, lr: 0.001844, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6187 samples/sec | ETA 05:59:50
2023-02-05 01:49:14 [INFO]	[TRAIN] epoch: 2682, iter: 211800/250000, loss: 0.2397, lr: 0.001844, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6271 samples/sec | ETA 05:59:27
2023-02-05 01:49:19 [INFO]	[TRAIN] epoch: 2682, iter: 211810/250000, loss: 0.2785, lr: 0.001843, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6287 samples/sec | ETA 05:59:18
2023-02-05 01:49:25 [INFO]	[TRAIN] epoch: 2682, iter: 211820/250000, loss: 0.1633, lr: 0.001843, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6104 samples/sec | ETA 05:59:50
2023-02-05 01:49:30 [INFO]	[TRAIN] epoch: 2682, iter: 211830/250000, loss: 0.2619, lr: 0.001843, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6126 samples/sec | ETA 05:59:39
2023-02-05 01:49:36 [INFO]	[TRAIN] epoch: 2682, iter: 211840/250000, loss: 0.2249, lr: 0.001842, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6021 samples/sec | ETA 05:59:55
2023-02-05 01:49:42 [INFO]	[TRAIN] epoch: 2682, iter: 211850/250000, loss: 0.2016, lr: 0.001842, batch_cost: 0.5662, reader_cost: 0.00008, ips: 10.5972 samples/sec | ETA 06:00:00
2023-02-05 01:49:48 [INFO]	[TRAIN] epoch: 2682, iter: 211860/250000, loss: 0.2506, lr: 0.001841, batch_cost: 0.5984, reader_cost: 0.03244, ips: 10.0260 samples/sec | ETA 06:20:24
2023-02-05 01:49:53 [INFO]	[TRAIN] epoch: 2682, iter: 211870/250000, loss: 0.1659, lr: 0.001841, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6042 samples/sec | ETA 05:59:34
2023-02-05 01:49:59 [INFO]	[TRAIN] epoch: 2683, iter: 211880/250000, loss: 0.2352, lr: 0.001840, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6097 samples/sec | ETA 05:59:17
2023-02-05 01:50:05 [INFO]	[TRAIN] epoch: 2683, iter: 211890/250000, loss: 0.1945, lr: 0.001840, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6110 samples/sec | ETA 05:59:09
2023-02-05 01:50:10 [INFO]	[TRAIN] epoch: 2683, iter: 211900/250000, loss: 0.1748, lr: 0.001839, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6042 samples/sec | ETA 05:59:17
2023-02-05 01:50:16 [INFO]	[TRAIN] epoch: 2683, iter: 211910/250000, loss: 0.2215, lr: 0.001839, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6144 samples/sec | ETA 05:58:51
2023-02-05 01:50:22 [INFO]	[TRAIN] epoch: 2683, iter: 211920/250000, loss: 0.2019, lr: 0.001839, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6122 samples/sec | ETA 05:58:49
2023-02-05 01:50:28 [INFO]	[TRAIN] epoch: 2683, iter: 211930/250000, loss: 0.1685, lr: 0.001838, batch_cost: 0.5932, reader_cost: 0.02728, ips: 10.1142 samples/sec | ETA 06:16:24
2023-02-05 01:50:33 [INFO]	[TRAIN] epoch: 2683, iter: 211940/250000, loss: 0.2019, lr: 0.001838, batch_cost: 0.5649, reader_cost: 0.00017, ips: 10.6209 samples/sec | ETA 05:58:21
2023-02-05 01:50:39 [INFO]	[TRAIN] epoch: 2683, iter: 211950/250000, loss: 0.1980, lr: 0.001837, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6255 samples/sec | ETA 05:58:05
2023-02-05 01:50:45 [INFO]	[TRAIN] epoch: 2684, iter: 211960/250000, loss: 0.1842, lr: 0.001837, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6278 samples/sec | ETA 05:57:55
2023-02-05 01:50:50 [INFO]	[TRAIN] epoch: 2684, iter: 211970/250000, loss: 0.1364, lr: 0.001836, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5991 samples/sec | ETA 05:58:48
2023-02-05 01:50:56 [INFO]	[TRAIN] epoch: 2684, iter: 211980/250000, loss: 0.1834, lr: 0.001836, batch_cost: 0.5659, reader_cost: 0.00008, ips: 10.6027 samples/sec | ETA 05:58:35
2023-02-05 01:51:02 [INFO]	[TRAIN] epoch: 2684, iter: 211990/250000, loss: 0.1857, lr: 0.001836, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6146 samples/sec | ETA 05:58:05
2023-02-05 01:51:07 [INFO]	[TRAIN] epoch: 2684, iter: 212000/250000, loss: 0.1721, lr: 0.001835, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6107 samples/sec | ETA 05:58:07
2023-02-05 01:51:07 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1321 - reader cost: 0.0329 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1531 - reader cost: 0.0165 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1601 - reader cost: 0.0110 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1605 - reader cost: 0.0083 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1611 - reader cost: 0.0066 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1623 - reader cost: 0.0056 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1616 - reader cost: 0.0048 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1614 - reader cost: 0.0042 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1626 - reader cost: 0.003710/36 [=======>......................] - ETA: 4s - batch_cost: 0.1623 - reader cost: 0.003411/36 [========>.....................] - ETA: 4s - batch_cost: 0.1628 - reader cost: 0.003112/36 [=========>....................] - ETA: 3s - batch_cost: 0.1623 - reader cost: 0.002813/36 [=========>....................] - ETA: 3s - batch_cost: 0.1627 - reader cost: 0.002614/36 [==========>...................] - ETA: 3s - batch_cost: 0.1632 - reader cost: 0.002415/36 [===========>..................] - ETA: 3s - batch_cost: 0.1632 - reader cost: 0.002316/36 [============>.................] - ETA: 3s - batch_cost: 0.1639 - reader cost: 0.002117/36 [=============>................] - ETA: 3s - batch_cost: 0.1642 - reader cost: 0.002018/36 [==============>...............] - ETA: 2s - batch_cost: 0.1643 - reader cost: 0.001919/36 [==============>...............] - ETA: 2s - batch_cost: 0.1642 - reader cost: 0.001820/36 [===============>..............] - ETA: 2s - batch_cost: 0.1641 - reader cost: 0.001721/36 [================>.............] - ETA: 2s - batch_cost: 0.1642 - reader cost: 0.001622/36 [=================>............] - ETA: 2s - batch_cost: 0.1642 - reader cost: 0.001623/36 [==================>...........] - ETA: 2s - batch_cost: 0.1648 - reader cost: 0.001524/36 [===================>..........] - ETA: 1s - batch_cost: 0.1650 - reader cost: 0.001425/36 [===================>..........] - ETA: 1s - batch_cost: 0.1652 - reader cost: 0.001426/36 [====================>.........] - ETA: 1s - batch_cost: 0.1655 - reader cost: 0.001327/36 [=====================>........] - ETA: 1s - batch_cost: 0.1656 - reader cost: 0.001328/36 [======================>.......] - ETA: 1s - batch_cost: 0.1659 - reader cost: 0.001329/36 [=======================>......] - ETA: 1s - batch_cost: 0.1660 - reader cost: 0.001230/36 [========================>.....] - ETA: 0s - batch_cost: 0.1661 - reader cost: 0.001231/36 [========================>.....] - ETA: 0s - batch_cost: 0.1660 - reader cost: 0.001132/36 [=========================>....] - ETA: 0s - batch_cost: 0.1659 - reader cost: 0.001133/36 [==========================>...] - ETA: 0s - batch_cost: 0.1657 - reader cost: 0.001134/36 [===========================>..] - ETA: 0s - batch_cost: 0.1655 - reader cost: 0.001035/36 [============================>.] - ETA: 0s - batch_cost: 0.1656 - reader cost: 0.001036/36 [==============================] - 6s 166ms/step - batch_cost: 0.1657 - reader cost: 9.8815e-04
2023-02-05 01:51:13 [INFO]	[EVAL] #Images: 36 mIoU: 0.8613 Acc: 0.9859 Kappa: 0.9488 Dice: 0.9219
2023-02-05 01:51:13 [INFO]	[EVAL] Class IoU: 
[0.9854 0.9128 0.8903 0.7105 0.7041 0.968  0.8581]
2023-02-05 01:51:13 [INFO]	[EVAL] Class Precision: 
[0.9926 0.9693 0.9392 0.8379 0.8573 0.973  0.9099]
2023-02-05 01:51:13 [INFO]	[EVAL] Class Recall: 
[0.9927 0.9399 0.9447 0.8237 0.7975 0.9948 0.9378]
2023-02-05 01:51:14 [INFO]	[EVAL] The model with the best validation mIoU (0.8613) was saved at iter 212000.
2023-02-05 01:51:20 [INFO]	[TRAIN] epoch: 2684, iter: 212010/250000, loss: 0.1732, lr: 0.001835, batch_cost: 0.5903, reader_cost: 0.02645, ips: 10.1642 samples/sec | ETA 06:13:45
2023-02-05 01:51:25 [INFO]	[TRAIN] epoch: 2684, iter: 212020/250000, loss: 0.2575, lr: 0.001834, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6242 samples/sec | ETA 05:57:29
2023-02-05 01:51:31 [INFO]	[TRAIN] epoch: 2684, iter: 212030/250000, loss: 0.2025, lr: 0.001834, batch_cost: 0.5635, reader_cost: 0.00008, ips: 10.6478 samples/sec | ETA 05:56:35
2023-02-05 01:51:37 [INFO]	[TRAIN] epoch: 2685, iter: 212040/250000, loss: 0.2552, lr: 0.001833, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6374 samples/sec | ETA 05:56:51
2023-02-05 01:51:42 [INFO]	[TRAIN] epoch: 2685, iter: 212050/250000, loss: 0.2500, lr: 0.001833, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6378 samples/sec | ETA 05:56:44
2023-02-05 01:51:48 [INFO]	[TRAIN] epoch: 2685, iter: 212060/250000, loss: 0.2642, lr: 0.001833, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6281 samples/sec | ETA 05:56:58
2023-02-05 01:51:54 [INFO]	[TRAIN] epoch: 2685, iter: 212070/250000, loss: 0.2531, lr: 0.001832, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6295 samples/sec | ETA 05:56:50
2023-02-05 01:51:59 [INFO]	[TRAIN] epoch: 2685, iter: 212080/250000, loss: 0.1886, lr: 0.001832, batch_cost: 0.5636, reader_cost: 0.00010, ips: 10.6453 samples/sec | ETA 05:56:12
2023-02-05 01:52:05 [INFO]	[TRAIN] epoch: 2685, iter: 212090/250000, loss: 0.1865, lr: 0.001831, batch_cost: 0.5903, reader_cost: 0.02651, ips: 10.1645 samples/sec | ETA 06:12:57
2023-02-05 01:52:11 [INFO]	[TRAIN] epoch: 2685, iter: 212100/250000, loss: 0.2773, lr: 0.001831, batch_cost: 0.5657, reader_cost: 0.00015, ips: 10.6060 samples/sec | ETA 05:57:20
2023-02-05 01:52:16 [INFO]	[TRAIN] epoch: 2685, iter: 212110/250000, loss: 0.1924, lr: 0.001830, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6357 samples/sec | ETA 05:56:15
2023-02-05 01:52:22 [INFO]	[TRAIN] epoch: 2686, iter: 212120/250000, loss: 0.2053, lr: 0.001830, batch_cost: 0.5642, reader_cost: 0.00016, ips: 10.6338 samples/sec | ETA 05:56:13
2023-02-05 01:52:28 [INFO]	[TRAIN] epoch: 2686, iter: 212130/250000, loss: 0.1907, lr: 0.001829, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6324 samples/sec | ETA 05:56:10
2023-02-05 01:52:33 [INFO]	[TRAIN] epoch: 2686, iter: 212140/250000, loss: 0.1988, lr: 0.001829, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6253 samples/sec | ETA 05:56:19
2023-02-05 01:52:39 [INFO]	[TRAIN] epoch: 2686, iter: 212150/250000, loss: 0.2140, lr: 0.001829, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6358 samples/sec | ETA 05:55:52
2023-02-05 01:52:45 [INFO]	[TRAIN] epoch: 2686, iter: 212160/250000, loss: 0.1904, lr: 0.001828, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6401 samples/sec | ETA 05:55:38
2023-02-05 01:52:51 [INFO]	[TRAIN] epoch: 2686, iter: 212170/250000, loss: 0.2121, lr: 0.001828, batch_cost: 0.5896, reader_cost: 0.02313, ips: 10.1764 samples/sec | ETA 06:11:44
2023-02-05 01:52:56 [INFO]	[TRAIN] epoch: 2686, iter: 212180/250000, loss: 0.1699, lr: 0.001827, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6230 samples/sec | ETA 05:56:01
2023-02-05 01:53:02 [INFO]	[TRAIN] epoch: 2686, iter: 212190/250000, loss: 0.2146, lr: 0.001827, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6269 samples/sec | ETA 05:55:47
2023-02-05 01:53:08 [INFO]	[TRAIN] epoch: 2687, iter: 212200/250000, loss: 0.1560, lr: 0.001826, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6311 samples/sec | ETA 05:55:33
2023-02-05 01:53:13 [INFO]	[TRAIN] epoch: 2687, iter: 212210/250000, loss: 0.1881, lr: 0.001826, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6174 samples/sec | ETA 05:55:55
2023-02-05 01:53:19 [INFO]	[TRAIN] epoch: 2687, iter: 212220/250000, loss: 0.2098, lr: 0.001826, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6060 samples/sec | ETA 05:56:12
2023-02-05 01:53:25 [INFO]	[TRAIN] epoch: 2687, iter: 212230/250000, loss: 0.1901, lr: 0.001825, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6172 samples/sec | ETA 05:55:44
2023-02-05 01:53:30 [INFO]	[TRAIN] epoch: 2687, iter: 212240/250000, loss: 0.2293, lr: 0.001825, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6124 samples/sec | ETA 05:55:48
2023-02-05 01:53:36 [INFO]	[TRAIN] epoch: 2687, iter: 212250/250000, loss: 0.2259, lr: 0.001824, batch_cost: 0.5974, reader_cost: 0.03224, ips: 10.0430 samples/sec | ETA 06:15:53
2023-02-05 01:53:42 [INFO]	[TRAIN] epoch: 2687, iter: 212260/250000, loss: 0.2446, lr: 0.001824, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6097 samples/sec | ETA 05:55:42
2023-02-05 01:53:47 [INFO]	[TRAIN] epoch: 2687, iter: 212270/250000, loss: 0.2239, lr: 0.001823, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6093 samples/sec | ETA 05:55:37
2023-02-05 01:53:53 [INFO]	[TRAIN] epoch: 2688, iter: 212280/250000, loss: 0.2191, lr: 0.001823, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6135 samples/sec | ETA 05:55:23
2023-02-05 01:53:59 [INFO]	[TRAIN] epoch: 2688, iter: 212290/250000, loss: 0.2331, lr: 0.001823, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6010 samples/sec | ETA 05:55:43
2023-02-05 01:54:04 [INFO]	[TRAIN] epoch: 2688, iter: 212300/250000, loss: 0.2943, lr: 0.001822, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6021 samples/sec | ETA 05:55:35
2023-02-05 01:54:10 [INFO]	[TRAIN] epoch: 2688, iter: 212310/250000, loss: 0.2450, lr: 0.001822, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6067 samples/sec | ETA 05:55:20
2023-02-05 01:54:16 [INFO]	[TRAIN] epoch: 2688, iter: 212320/250000, loss: 0.1941, lr: 0.001821, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6065 samples/sec | ETA 05:55:15
2023-02-05 01:54:22 [INFO]	[TRAIN] epoch: 2688, iter: 212330/250000, loss: 0.2273, lr: 0.001821, batch_cost: 0.5903, reader_cost: 0.02441, ips: 10.1644 samples/sec | ETA 06:10:36
2023-02-05 01:54:27 [INFO]	[TRAIN] epoch: 2688, iter: 212340/250000, loss: 0.2313, lr: 0.001820, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6336 samples/sec | ETA 05:54:09
2023-02-05 01:54:33 [INFO]	[TRAIN] epoch: 2688, iter: 212350/250000, loss: 0.1866, lr: 0.001820, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6223 samples/sec | ETA 05:54:26
2023-02-05 01:54:39 [INFO]	[TRAIN] epoch: 2689, iter: 212360/250000, loss: 0.1838, lr: 0.001819, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6313 samples/sec | ETA 05:54:02
2023-02-05 01:54:44 [INFO]	[TRAIN] epoch: 2689, iter: 212370/250000, loss: 0.1718, lr: 0.001819, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6094 samples/sec | ETA 05:54:41
2023-02-05 01:54:50 [INFO]	[TRAIN] epoch: 2689, iter: 212380/250000, loss: 0.1804, lr: 0.001819, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6101 samples/sec | ETA 05:54:34
2023-02-05 01:54:56 [INFO]	[TRAIN] epoch: 2689, iter: 212390/250000, loss: 0.2214, lr: 0.001818, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6073 samples/sec | ETA 05:54:34
2023-02-05 01:55:01 [INFO]	[TRAIN] epoch: 2689, iter: 212400/250000, loss: 0.1949, lr: 0.001818, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6077 samples/sec | ETA 05:54:27
2023-02-05 01:55:07 [INFO]	[TRAIN] epoch: 2689, iter: 212410/250000, loss: 0.2047, lr: 0.001817, batch_cost: 0.5962, reader_cost: 0.03123, ips: 10.0642 samples/sec | ETA 06:13:30
2023-02-05 01:55:13 [INFO]	[TRAIN] epoch: 2689, iter: 212420/250000, loss: 0.2087, lr: 0.001817, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6297 samples/sec | ETA 05:53:32
2023-02-05 01:55:18 [INFO]	[TRAIN] epoch: 2689, iter: 212430/250000, loss: 0.1756, lr: 0.001816, batch_cost: 0.5659, reader_cost: 0.00008, ips: 10.6017 samples/sec | ETA 05:54:22
2023-02-05 01:55:24 [INFO]	[TRAIN] epoch: 2690, iter: 212440/250000, loss: 0.2007, lr: 0.001816, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6007 samples/sec | ETA 05:54:19
2023-02-05 01:55:30 [INFO]	[TRAIN] epoch: 2690, iter: 212450/250000, loss: 0.2497, lr: 0.001816, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6161 samples/sec | ETA 05:53:42
2023-02-05 01:55:35 [INFO]	[TRAIN] epoch: 2690, iter: 212460/250000, loss: 0.1933, lr: 0.001815, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6102 samples/sec | ETA 05:53:48
2023-02-05 01:55:41 [INFO]	[TRAIN] epoch: 2690, iter: 212470/250000, loss: 0.1805, lr: 0.001815, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5980 samples/sec | ETA 05:54:07
2023-02-05 01:55:47 [INFO]	[TRAIN] epoch: 2690, iter: 212480/250000, loss: 0.1999, lr: 0.001814, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6138 samples/sec | ETA 05:53:30
2023-02-05 01:55:53 [INFO]	[TRAIN] epoch: 2690, iter: 212490/250000, loss: 0.1906, lr: 0.001814, batch_cost: 0.5900, reader_cost: 0.02480, ips: 10.1692 samples/sec | ETA 06:08:51
2023-02-05 01:55:58 [INFO]	[TRAIN] epoch: 2690, iter: 212500/250000, loss: 0.1628, lr: 0.001813, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6042 samples/sec | ETA 05:53:37
2023-02-05 01:56:04 [INFO]	[TRAIN] epoch: 2690, iter: 212510/250000, loss: 0.1947, lr: 0.001813, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6085 samples/sec | ETA 05:53:23
2023-02-05 01:56:10 [INFO]	[TRAIN] epoch: 2691, iter: 212520/250000, loss: 0.2852, lr: 0.001813, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6104 samples/sec | ETA 05:53:14
2023-02-05 01:56:15 [INFO]	[TRAIN] epoch: 2691, iter: 212530/250000, loss: 0.2475, lr: 0.001812, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6033 samples/sec | ETA 05:53:22
2023-02-05 01:56:21 [INFO]	[TRAIN] epoch: 2691, iter: 212540/250000, loss: 0.3313, lr: 0.001812, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 05:53:14
2023-02-05 01:56:27 [INFO]	[TRAIN] epoch: 2691, iter: 212550/250000, loss: 0.2079, lr: 0.001811, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 05:53:05
2023-02-05 01:56:32 [INFO]	[TRAIN] epoch: 2691, iter: 212560/250000, loss: 0.2747, lr: 0.001811, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6098 samples/sec | ETA 05:52:52
2023-02-05 01:56:38 [INFO]	[TRAIN] epoch: 2691, iter: 212570/250000, loss: 0.2778, lr: 0.001810, batch_cost: 0.5908, reader_cost: 0.02641, ips: 10.1560 samples/sec | ETA 06:08:33
2023-02-05 01:56:44 [INFO]	[TRAIN] epoch: 2691, iter: 212580/250000, loss: 0.2685, lr: 0.001810, batch_cost: 0.5648, reader_cost: 0.00008, ips: 10.6227 samples/sec | ETA 05:52:15
2023-02-05 01:56:49 [INFO]	[TRAIN] epoch: 2692, iter: 212590/250000, loss: 0.2168, lr: 0.001809, batch_cost: 0.5647, reader_cost: 0.00008, ips: 10.6247 samples/sec | ETA 05:52:06
2023-02-05 01:56:55 [INFO]	[TRAIN] epoch: 2692, iter: 212600/250000, loss: 0.1989, lr: 0.001809, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6375 samples/sec | ETA 05:51:35
2023-02-05 01:57:01 [INFO]	[TRAIN] epoch: 2692, iter: 212610/250000, loss: 0.3127, lr: 0.001809, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6335 samples/sec | ETA 05:51:37
2023-02-05 01:57:06 [INFO]	[TRAIN] epoch: 2692, iter: 212620/250000, loss: 0.2076, lr: 0.001808, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6291 samples/sec | ETA 05:51:40
2023-02-05 01:57:12 [INFO]	[TRAIN] epoch: 2692, iter: 212630/250000, loss: 0.2298, lr: 0.001808, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6342 samples/sec | ETA 05:51:24
2023-02-05 01:57:18 [INFO]	[TRAIN] epoch: 2692, iter: 212640/250000, loss: 0.1683, lr: 0.001807, batch_cost: 0.5646, reader_cost: 0.00008, ips: 10.6274 samples/sec | ETA 05:51:32
2023-02-05 01:57:24 [INFO]	[TRAIN] epoch: 2692, iter: 212650/250000, loss: 0.1747, lr: 0.001807, batch_cost: 0.5906, reader_cost: 0.02548, ips: 10.1595 samples/sec | ETA 06:07:38
2023-02-05 01:57:29 [INFO]	[TRAIN] epoch: 2692, iter: 212660/250000, loss: 0.2393, lr: 0.001806, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6286 samples/sec | ETA 05:51:18
2023-02-05 01:57:35 [INFO]	[TRAIN] epoch: 2693, iter: 212670/250000, loss: 0.2378, lr: 0.001806, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6271 samples/sec | ETA 05:51:16
2023-02-05 01:57:41 [INFO]	[TRAIN] epoch: 2693, iter: 212680/250000, loss: 0.2516, lr: 0.001806, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6382 samples/sec | ETA 05:50:48
2023-02-05 01:57:46 [INFO]	[TRAIN] epoch: 2693, iter: 212690/250000, loss: 0.1779, lr: 0.001805, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6395 samples/sec | ETA 05:50:40
2023-02-05 01:57:52 [INFO]	[TRAIN] epoch: 2693, iter: 212700/250000, loss: 0.2244, lr: 0.001805, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6321 samples/sec | ETA 05:50:49
2023-02-05 01:57:57 [INFO]	[TRAIN] epoch: 2693, iter: 212710/250000, loss: 0.2101, lr: 0.001804, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6297 samples/sec | ETA 05:50:48
2023-02-05 01:58:03 [INFO]	[TRAIN] epoch: 2693, iter: 212720/250000, loss: 0.1879, lr: 0.001804, batch_cost: 0.5909, reader_cost: 0.02662, ips: 10.1533 samples/sec | ETA 06:07:10
2023-02-05 01:58:09 [INFO]	[TRAIN] epoch: 2693, iter: 212730/250000, loss: 0.1908, lr: 0.001803, batch_cost: 0.5646, reader_cost: 0.00014, ips: 10.6263 samples/sec | ETA 05:50:43
2023-02-05 01:58:15 [INFO]	[TRAIN] epoch: 2693, iter: 212740/250000, loss: 0.1651, lr: 0.001803, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6343 samples/sec | ETA 05:50:22
2023-02-05 01:58:20 [INFO]	[TRAIN] epoch: 2694, iter: 212750/250000, loss: 0.1795, lr: 0.001803, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6302 samples/sec | ETA 05:50:24
2023-02-05 01:58:26 [INFO]	[TRAIN] epoch: 2694, iter: 212760/250000, loss: 0.1984, lr: 0.001802, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6319 samples/sec | ETA 05:50:15
2023-02-05 01:58:32 [INFO]	[TRAIN] epoch: 2694, iter: 212770/250000, loss: 0.2363, lr: 0.001802, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6415 samples/sec | ETA 05:49:51
2023-02-05 01:58:37 [INFO]	[TRAIN] epoch: 2694, iter: 212780/250000, loss: 0.2002, lr: 0.001801, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6303 samples/sec | ETA 05:50:07
2023-02-05 01:58:43 [INFO]	[TRAIN] epoch: 2694, iter: 212790/250000, loss: 0.2412, lr: 0.001801, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6335 samples/sec | ETA 05:49:55
2023-02-05 01:58:49 [INFO]	[TRAIN] epoch: 2694, iter: 212800/250000, loss: 0.1735, lr: 0.001800, batch_cost: 0.5895, reader_cost: 0.02499, ips: 10.1788 samples/sec | ETA 06:05:28
2023-02-05 01:58:54 [INFO]	[TRAIN] epoch: 2694, iter: 212810/250000, loss: 0.1788, lr: 0.001800, batch_cost: 0.5639, reader_cost: 0.00019, ips: 10.6396 samples/sec | ETA 05:49:32
2023-02-05 01:59:00 [INFO]	[TRAIN] epoch: 2694, iter: 212820/250000, loss: 0.2252, lr: 0.001799, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6368 samples/sec | ETA 05:49:32
2023-02-05 01:59:06 [INFO]	[TRAIN] epoch: 2695, iter: 212830/250000, loss: 0.2431, lr: 0.001799, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6243 samples/sec | ETA 05:49:51
2023-02-05 01:59:11 [INFO]	[TRAIN] epoch: 2695, iter: 212840/250000, loss: 0.2216, lr: 0.001799, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6244 samples/sec | ETA 05:49:45
2023-02-05 01:59:17 [INFO]	[TRAIN] epoch: 2695, iter: 212850/250000, loss: 0.2037, lr: 0.001798, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6066 samples/sec | ETA 05:50:15
2023-02-05 01:59:23 [INFO]	[TRAIN] epoch: 2695, iter: 212860/250000, loss: 0.1753, lr: 0.001798, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6019 samples/sec | ETA 05:50:18
2023-02-05 01:59:28 [INFO]	[TRAIN] epoch: 2695, iter: 212870/250000, loss: 0.1734, lr: 0.001797, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6115 samples/sec | ETA 05:49:54
2023-02-05 01:59:34 [INFO]	[TRAIN] epoch: 2695, iter: 212880/250000, loss: 0.2147, lr: 0.001797, batch_cost: 0.5953, reader_cost: 0.02991, ips: 10.0786 samples/sec | ETA 06:08:18
2023-02-05 01:59:40 [INFO]	[TRAIN] epoch: 2695, iter: 212890/250000, loss: 0.2243, lr: 0.001796, batch_cost: 0.5640, reader_cost: 0.00014, ips: 10.6389 samples/sec | ETA 05:48:48
2023-02-05 01:59:46 [INFO]	[TRAIN] epoch: 2695, iter: 212900/250000, loss: 0.1716, lr: 0.001796, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6314 samples/sec | ETA 05:48:57
2023-02-05 01:59:51 [INFO]	[TRAIN] epoch: 2696, iter: 212910/250000, loss: 0.1945, lr: 0.001796, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6063 samples/sec | ETA 05:49:41
2023-02-05 01:59:57 [INFO]	[TRAIN] epoch: 2696, iter: 212920/250000, loss: 0.2049, lr: 0.001795, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6070 samples/sec | ETA 05:49:34
2023-02-05 02:00:02 [INFO]	[TRAIN] epoch: 2696, iter: 212930/250000, loss: 0.3644, lr: 0.001795, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6047 samples/sec | ETA 05:49:33
2023-02-05 02:00:08 [INFO]	[TRAIN] epoch: 2696, iter: 212940/250000, loss: 0.2216, lr: 0.001794, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6090 samples/sec | ETA 05:49:19
2023-02-05 02:00:14 [INFO]	[TRAIN] epoch: 2696, iter: 212950/250000, loss: 0.2595, lr: 0.001794, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6123 samples/sec | ETA 05:49:07
2023-02-05 02:00:20 [INFO]	[TRAIN] epoch: 2696, iter: 212960/250000, loss: 0.2707, lr: 0.001793, batch_cost: 0.5904, reader_cost: 0.02547, ips: 10.1621 samples/sec | ETA 06:04:29
2023-02-05 02:00:25 [INFO]	[TRAIN] epoch: 2696, iter: 212970/250000, loss: 0.2080, lr: 0.001793, batch_cost: 0.5645, reader_cost: 0.00014, ips: 10.6297 samples/sec | ETA 05:48:21
2023-02-05 02:00:31 [INFO]	[TRAIN] epoch: 2696, iter: 212980/250000, loss: 0.2579, lr: 0.001792, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6264 samples/sec | ETA 05:48:22
2023-02-05 02:00:37 [INFO]	[TRAIN] epoch: 2697, iter: 212990/250000, loss: 0.2279, lr: 0.001792, batch_cost: 0.5646, reader_cost: 0.00008, ips: 10.6270 samples/sec | ETA 05:48:15
2023-02-05 02:00:42 [INFO]	[TRAIN] epoch: 2697, iter: 213000/250000, loss: 0.1894, lr: 0.001792, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6293 samples/sec | ETA 05:48:05
2023-02-05 02:00:48 [INFO]	[TRAIN] epoch: 2697, iter: 213010/250000, loss: 0.1959, lr: 0.001791, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6259 samples/sec | ETA 05:48:06
2023-02-05 02:00:54 [INFO]	[TRAIN] epoch: 2697, iter: 213020/250000, loss: 0.1820, lr: 0.001791, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6140 samples/sec | ETA 05:48:24
2023-02-05 02:00:59 [INFO]	[TRAIN] epoch: 2697, iter: 213030/250000, loss: 0.1884, lr: 0.001790, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6010 samples/sec | ETA 05:48:44
2023-02-05 02:01:05 [INFO]	[TRAIN] epoch: 2697, iter: 213040/250000, loss: 0.2583, lr: 0.001790, batch_cost: 0.5966, reader_cost: 0.03164, ips: 10.0564 samples/sec | ETA 06:07:31
2023-02-05 02:01:11 [INFO]	[TRAIN] epoch: 2697, iter: 213050/250000, loss: 0.1919, lr: 0.001789, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6408 samples/sec | ETA 05:47:14
2023-02-05 02:01:17 [INFO]	[TRAIN] epoch: 2697, iter: 213060/250000, loss: 0.2445, lr: 0.001789, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6323 samples/sec | ETA 05:47:26
2023-02-05 02:01:22 [INFO]	[TRAIN] epoch: 2698, iter: 213070/250000, loss: 0.2204, lr: 0.001789, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6170 samples/sec | ETA 05:47:50
2023-02-05 02:01:28 [INFO]	[TRAIN] epoch: 2698, iter: 213080/250000, loss: 0.1995, lr: 0.001788, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6057 samples/sec | ETA 05:48:06
2023-02-05 02:01:33 [INFO]	[TRAIN] epoch: 2698, iter: 213090/250000, loss: 0.2867, lr: 0.001788, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6153 samples/sec | ETA 05:47:42
2023-02-05 02:01:39 [INFO]	[TRAIN] epoch: 2698, iter: 213100/250000, loss: 0.2349, lr: 0.001787, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6107 samples/sec | ETA 05:47:45
2023-02-05 02:01:45 [INFO]	[TRAIN] epoch: 2698, iter: 213110/250000, loss: 0.2095, lr: 0.001787, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6057 samples/sec | ETA 05:47:49
2023-02-05 02:01:51 [INFO]	[TRAIN] epoch: 2698, iter: 213120/250000, loss: 0.2121, lr: 0.001786, batch_cost: 0.5970, reader_cost: 0.03213, ips: 10.0502 samples/sec | ETA 06:06:57
2023-02-05 02:01:56 [INFO]	[TRAIN] epoch: 2698, iter: 213130/250000, loss: 0.1991, lr: 0.001786, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6319 samples/sec | ETA 05:46:47
2023-02-05 02:02:02 [INFO]	[TRAIN] epoch: 2698, iter: 213140/250000, loss: 0.1931, lr: 0.001786, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6348 samples/sec | ETA 05:46:35
2023-02-05 02:02:08 [INFO]	[TRAIN] epoch: 2699, iter: 213150/250000, loss: 0.2928, lr: 0.001785, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6401 samples/sec | ETA 05:46:19
2023-02-05 02:02:13 [INFO]	[TRAIN] epoch: 2699, iter: 213160/250000, loss: 0.2610, lr: 0.001785, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6264 samples/sec | ETA 05:46:40
2023-02-05 02:02:19 [INFO]	[TRAIN] epoch: 2699, iter: 213170/250000, loss: 0.2544, lr: 0.001784, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6318 samples/sec | ETA 05:46:24
2023-02-05 02:02:25 [INFO]	[TRAIN] epoch: 2699, iter: 213180/250000, loss: 0.2083, lr: 0.001784, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6367 samples/sec | ETA 05:46:09
2023-02-05 02:02:30 [INFO]	[TRAIN] epoch: 2699, iter: 213190/250000, loss: 0.1722, lr: 0.001783, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6329 samples/sec | ETA 05:46:11
2023-02-05 02:02:36 [INFO]	[TRAIN] epoch: 2699, iter: 213200/250000, loss: 0.1907, lr: 0.001783, batch_cost: 0.5942, reader_cost: 0.03017, ips: 10.0969 samples/sec | ETA 06:04:28
2023-02-05 02:02:42 [INFO]	[TRAIN] epoch: 2699, iter: 213210/250000, loss: 0.2367, lr: 0.001782, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6379 samples/sec | ETA 05:45:50
2023-02-05 02:02:47 [INFO]	[TRAIN] epoch: 2699, iter: 213220/250000, loss: 0.2067, lr: 0.001782, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6342 samples/sec | ETA 05:45:51
2023-02-05 02:02:53 [INFO]	[TRAIN] epoch: 2700, iter: 213230/250000, loss: 0.2572, lr: 0.001782, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6307 samples/sec | ETA 05:45:53
2023-02-05 02:02:59 [INFO]	[TRAIN] epoch: 2700, iter: 213240/250000, loss: 0.1937, lr: 0.001781, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6300 samples/sec | ETA 05:45:48
2023-02-05 02:03:04 [INFO]	[TRAIN] epoch: 2700, iter: 213250/250000, loss: 0.1953, lr: 0.001781, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6390 samples/sec | ETA 05:45:25
2023-02-05 02:03:10 [INFO]	[TRAIN] epoch: 2700, iter: 213260/250000, loss: 0.1962, lr: 0.001780, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6404 samples/sec | ETA 05:45:17
2023-02-05 02:03:16 [INFO]	[TRAIN] epoch: 2700, iter: 213270/250000, loss: 0.2841, lr: 0.001780, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6369 samples/sec | ETA 05:45:18
2023-02-05 02:03:22 [INFO]	[TRAIN] epoch: 2700, iter: 213280/250000, loss: 0.1919, lr: 0.001779, batch_cost: 0.5931, reader_cost: 0.02955, ips: 10.1164 samples/sec | ETA 06:02:58
2023-02-05 02:03:27 [INFO]	[TRAIN] epoch: 2700, iter: 213290/250000, loss: 0.2351, lr: 0.001779, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6391 samples/sec | ETA 05:45:02
2023-02-05 02:03:33 [INFO]	[TRAIN] epoch: 2700, iter: 213300/250000, loss: 0.1589, lr: 0.001779, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6273 samples/sec | ETA 05:45:20
2023-02-05 02:03:39 [INFO]	[TRAIN] epoch: 2701, iter: 213310/250000, loss: 0.2400, lr: 0.001778, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6351 samples/sec | ETA 05:44:59
2023-02-05 02:03:44 [INFO]	[TRAIN] epoch: 2701, iter: 213320/250000, loss: 0.3103, lr: 0.001778, batch_cost: 0.5642, reader_cost: 0.00008, ips: 10.6349 samples/sec | ETA 05:44:54
2023-02-05 02:03:50 [INFO]	[TRAIN] epoch: 2701, iter: 213330/250000, loss: 0.3710, lr: 0.001777, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6340 samples/sec | ETA 05:44:50
2023-02-05 02:03:55 [INFO]	[TRAIN] epoch: 2701, iter: 213340/250000, loss: 0.4413, lr: 0.001777, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6348 samples/sec | ETA 05:44:42
2023-02-05 02:04:01 [INFO]	[TRAIN] epoch: 2701, iter: 213350/250000, loss: 0.2735, lr: 0.001776, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6335 samples/sec | ETA 05:44:40
2023-02-05 02:04:07 [INFO]	[TRAIN] epoch: 2701, iter: 213360/250000, loss: 0.3138, lr: 0.001776, batch_cost: 0.5880, reader_cost: 0.02338, ips: 10.2047 samples/sec | ETA 05:59:02
2023-02-05 02:04:13 [INFO]	[TRAIN] epoch: 2701, iter: 213370/250000, loss: 0.2251, lr: 0.001775, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6324 samples/sec | ETA 05:44:30
2023-02-05 02:04:18 [INFO]	[TRAIN] epoch: 2702, iter: 213380/250000, loss: 0.2372, lr: 0.001775, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6387 samples/sec | ETA 05:44:12
2023-02-05 02:04:24 [INFO]	[TRAIN] epoch: 2702, iter: 213390/250000, loss: 0.2697, lr: 0.001775, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6298 samples/sec | ETA 05:44:24
2023-02-05 02:04:30 [INFO]	[TRAIN] epoch: 2702, iter: 213400/250000, loss: 0.2342, lr: 0.001774, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6313 samples/sec | ETA 05:44:15
2023-02-05 02:04:35 [INFO]	[TRAIN] epoch: 2702, iter: 213410/250000, loss: 0.2794, lr: 0.001774, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6298 samples/sec | ETA 05:44:13
2023-02-05 02:04:41 [INFO]	[TRAIN] epoch: 2702, iter: 213420/250000, loss: 0.1970, lr: 0.001773, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6323 samples/sec | ETA 05:44:02
2023-02-05 02:04:46 [INFO]	[TRAIN] epoch: 2702, iter: 213430/250000, loss: 0.1829, lr: 0.001773, batch_cost: 0.5637, reader_cost: 0.00009, ips: 10.6442 samples/sec | ETA 05:43:34
2023-02-05 02:04:52 [INFO]	[TRAIN] epoch: 2702, iter: 213440/250000, loss: 0.2194, lr: 0.001772, batch_cost: 0.5954, reader_cost: 0.03089, ips: 10.0765 samples/sec | ETA 06:02:49
2023-02-05 02:04:58 [INFO]	[TRAIN] epoch: 2702, iter: 213450/250000, loss: 0.1828, lr: 0.001772, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6377 samples/sec | ETA 05:43:35
2023-02-05 02:05:04 [INFO]	[TRAIN] epoch: 2703, iter: 213460/250000, loss: 0.1688, lr: 0.001772, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6300 samples/sec | ETA 05:43:44
2023-02-05 02:05:09 [INFO]	[TRAIN] epoch: 2703, iter: 213470/250000, loss: 0.3807, lr: 0.001771, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6320 samples/sec | ETA 05:43:35
2023-02-05 02:05:15 [INFO]	[TRAIN] epoch: 2703, iter: 213480/250000, loss: 0.1712, lr: 0.001771, batch_cost: 0.5645, reader_cost: 0.00011, ips: 10.6294 samples/sec | ETA 05:43:34
2023-02-05 02:05:21 [INFO]	[TRAIN] epoch: 2703, iter: 213490/250000, loss: 0.1693, lr: 0.001770, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6297 samples/sec | ETA 05:43:28
2023-02-05 02:05:26 [INFO]	[TRAIN] epoch: 2703, iter: 213500/250000, loss: 0.2077, lr: 0.001770, batch_cost: 0.5638, reader_cost: 0.00010, ips: 10.6413 samples/sec | ETA 05:43:00
2023-02-05 02:05:32 [INFO]	[TRAIN] epoch: 2703, iter: 213510/250000, loss: 0.1913, lr: 0.001769, batch_cost: 0.5982, reader_cost: 0.03403, ips: 10.0302 samples/sec | ETA 06:03:48
2023-02-05 02:05:38 [INFO]	[TRAIN] epoch: 2703, iter: 213520/250000, loss: 0.2009, lr: 0.001769, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6305 samples/sec | ETA 05:43:09
2023-02-05 02:05:44 [INFO]	[TRAIN] epoch: 2703, iter: 213530/250000, loss: 0.1854, lr: 0.001769, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6314 samples/sec | ETA 05:43:02
2023-02-05 02:05:49 [INFO]	[TRAIN] epoch: 2704, iter: 213540/250000, loss: 0.1817, lr: 0.001768, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6339 samples/sec | ETA 05:42:51
2023-02-05 02:05:55 [INFO]	[TRAIN] epoch: 2704, iter: 213550/250000, loss: 0.2210, lr: 0.001768, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6405 samples/sec | ETA 05:42:33
2023-02-05 02:06:01 [INFO]	[TRAIN] epoch: 2704, iter: 213560/250000, loss: 0.1608, lr: 0.001767, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6341 samples/sec | ETA 05:42:40
2023-02-05 02:06:06 [INFO]	[TRAIN] epoch: 2704, iter: 213570/250000, loss: 0.2255, lr: 0.001767, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6345 samples/sec | ETA 05:42:33
2023-02-05 02:06:12 [INFO]	[TRAIN] epoch: 2704, iter: 213580/250000, loss: 0.1788, lr: 0.001766, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6326 samples/sec | ETA 05:42:31
2023-02-05 02:06:18 [INFO]	[TRAIN] epoch: 2704, iter: 213590/250000, loss: 0.2189, lr: 0.001766, batch_cost: 0.5943, reader_cost: 0.02958, ips: 10.0955 samples/sec | ETA 06:00:39
2023-02-05 02:06:23 [INFO]	[TRAIN] epoch: 2704, iter: 213600/250000, loss: 0.1804, lr: 0.001765, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6192 samples/sec | ETA 05:42:46
2023-02-05 02:06:29 [INFO]	[TRAIN] epoch: 2704, iter: 213610/250000, loss: 0.1809, lr: 0.001765, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6352 samples/sec | ETA 05:42:09
2023-02-05 02:06:35 [INFO]	[TRAIN] epoch: 2705, iter: 213620/250000, loss: 0.1814, lr: 0.001765, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6347 samples/sec | ETA 05:42:05
2023-02-05 02:06:40 [INFO]	[TRAIN] epoch: 2705, iter: 213630/250000, loss: 0.1518, lr: 0.001764, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6283 samples/sec | ETA 05:42:12
2023-02-05 02:06:46 [INFO]	[TRAIN] epoch: 2705, iter: 213640/250000, loss: 0.2400, lr: 0.001764, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6262 samples/sec | ETA 05:42:10
2023-02-05 02:06:52 [INFO]	[TRAIN] epoch: 2705, iter: 213650/250000, loss: 0.1740, lr: 0.001763, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6279 samples/sec | ETA 05:42:01
2023-02-05 02:06:57 [INFO]	[TRAIN] epoch: 2705, iter: 213660/250000, loss: 0.2699, lr: 0.001763, batch_cost: 0.5640, reader_cost: 0.00016, ips: 10.6379 samples/sec | ETA 05:41:36
2023-02-05 02:07:03 [INFO]	[TRAIN] epoch: 2705, iter: 213670/250000, loss: 0.2170, lr: 0.001762, batch_cost: 0.5871, reader_cost: 0.02290, ips: 10.2189 samples/sec | ETA 05:55:30
2023-02-05 02:07:09 [INFO]	[TRAIN] epoch: 2705, iter: 213680/250000, loss: 0.1630, lr: 0.001762, batch_cost: 0.5644, reader_cost: 0.00013, ips: 10.6304 samples/sec | ETA 05:41:39
2023-02-05 02:07:14 [INFO]	[TRAIN] epoch: 2705, iter: 213690/250000, loss: 0.2305, lr: 0.001762, batch_cost: 0.5646, reader_cost: 0.00008, ips: 10.6265 samples/sec | ETA 05:41:41
2023-02-05 02:07:20 [INFO]	[TRAIN] epoch: 2706, iter: 213700/250000, loss: 0.2593, lr: 0.001761, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6296 samples/sec | ETA 05:41:30
2023-02-05 02:07:26 [INFO]	[TRAIN] epoch: 2706, iter: 213710/250000, loss: 0.1957, lr: 0.001761, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6401 samples/sec | ETA 05:41:04
2023-02-05 02:07:31 [INFO]	[TRAIN] epoch: 2706, iter: 213720/250000, loss: 0.2431, lr: 0.001760, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6337 samples/sec | ETA 05:41:10
2023-02-05 02:07:37 [INFO]	[TRAIN] epoch: 2706, iter: 213730/250000, loss: 0.2132, lr: 0.001760, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6327 samples/sec | ETA 05:41:06
2023-02-05 02:07:43 [INFO]	[TRAIN] epoch: 2706, iter: 213740/250000, loss: 0.2067, lr: 0.001759, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6311 samples/sec | ETA 05:41:04
2023-02-05 02:07:49 [INFO]	[TRAIN] epoch: 2706, iter: 213750/250000, loss: 0.2240, lr: 0.001759, batch_cost: 0.6002, reader_cost: 0.03549, ips: 9.9969 samples/sec | ETA 06:02:36
2023-02-05 02:07:54 [INFO]	[TRAIN] epoch: 2706, iter: 213760/250000, loss: 0.2639, lr: 0.001758, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6008 samples/sec | ETA 05:41:51
2023-02-05 02:08:00 [INFO]	[TRAIN] epoch: 2706, iter: 213770/250000, loss: 0.1898, lr: 0.001758, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6296 samples/sec | ETA 05:40:50
2023-02-05 02:08:06 [INFO]	[TRAIN] epoch: 2707, iter: 213780/250000, loss: 0.1867, lr: 0.001758, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6315 samples/sec | ETA 05:40:41
2023-02-05 02:08:11 [INFO]	[TRAIN] epoch: 2707, iter: 213790/250000, loss: 0.2221, lr: 0.001757, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6278 samples/sec | ETA 05:40:42
2023-02-05 02:08:17 [INFO]	[TRAIN] epoch: 2707, iter: 213800/250000, loss: 0.2291, lr: 0.001757, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6389 samples/sec | ETA 05:40:15
2023-02-05 02:08:23 [INFO]	[TRAIN] epoch: 2707, iter: 213810/250000, loss: 0.2484, lr: 0.001756, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6315 samples/sec | ETA 05:40:24
2023-02-05 02:08:28 [INFO]	[TRAIN] epoch: 2707, iter: 213820/250000, loss: 0.3374, lr: 0.001756, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6356 samples/sec | ETA 05:40:10
2023-02-05 02:08:34 [INFO]	[TRAIN] epoch: 2707, iter: 213830/250000, loss: 0.3621, lr: 0.001755, batch_cost: 0.6005, reader_cost: 0.03574, ips: 9.9910 samples/sec | ETA 06:02:01
2023-02-05 02:08:40 [INFO]	[TRAIN] epoch: 2707, iter: 213840/250000, loss: 0.2867, lr: 0.001755, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6271 samples/sec | ETA 05:40:15
2023-02-05 02:08:45 [INFO]	[TRAIN] epoch: 2707, iter: 213850/250000, loss: 0.2489, lr: 0.001755, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6368 samples/sec | ETA 05:39:51
2023-02-05 02:08:51 [INFO]	[TRAIN] epoch: 2708, iter: 213860/250000, loss: 0.2430, lr: 0.001754, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6384 samples/sec | ETA 05:39:42
2023-02-05 02:08:57 [INFO]	[TRAIN] epoch: 2708, iter: 213870/250000, loss: 0.2261, lr: 0.001754, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6276 samples/sec | ETA 05:39:57
2023-02-05 02:09:02 [INFO]	[TRAIN] epoch: 2708, iter: 213880/250000, loss: 0.2179, lr: 0.001753, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6274 samples/sec | ETA 05:39:52
2023-02-05 02:09:08 [INFO]	[TRAIN] epoch: 2708, iter: 213890/250000, loss: 0.2479, lr: 0.001753, batch_cost: 0.5640, reader_cost: 0.00008, ips: 10.6376 samples/sec | ETA 05:39:27
2023-02-05 02:09:14 [INFO]	[TRAIN] epoch: 2708, iter: 213900/250000, loss: 0.2294, lr: 0.001752, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6343 samples/sec | ETA 05:39:28
2023-02-05 02:09:20 [INFO]	[TRAIN] epoch: 2708, iter: 213910/250000, loss: 0.3134, lr: 0.001752, batch_cost: 0.5912, reader_cost: 0.02590, ips: 10.1486 samples/sec | ETA 05:55:36
2023-02-05 02:09:25 [INFO]	[TRAIN] epoch: 2708, iter: 213920/250000, loss: 0.3161, lr: 0.001751, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6365 samples/sec | ETA 05:39:12
2023-02-05 02:09:31 [INFO]	[TRAIN] epoch: 2708, iter: 213930/250000, loss: 0.3123, lr: 0.001751, batch_cost: 0.5638, reader_cost: 0.00010, ips: 10.6418 samples/sec | ETA 05:38:56
2023-02-05 02:09:36 [INFO]	[TRAIN] epoch: 2709, iter: 213940/250000, loss: 0.2653, lr: 0.001751, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6250 samples/sec | ETA 05:39:23
2023-02-05 02:09:42 [INFO]	[TRAIN] epoch: 2709, iter: 213950/250000, loss: 0.2466, lr: 0.001750, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6233 samples/sec | ETA 05:39:20
2023-02-05 02:09:48 [INFO]	[TRAIN] epoch: 2709, iter: 213960/250000, loss: 0.3057, lr: 0.001750, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6356 samples/sec | ETA 05:38:51
2023-02-05 02:09:53 [INFO]	[TRAIN] epoch: 2709, iter: 213970/250000, loss: 0.1818, lr: 0.001749, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6390 samples/sec | ETA 05:38:39
2023-02-05 02:09:59 [INFO]	[TRAIN] epoch: 2709, iter: 213980/250000, loss: 0.2000, lr: 0.001749, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6283 samples/sec | ETA 05:38:54
2023-02-05 02:10:05 [INFO]	[TRAIN] epoch: 2709, iter: 213990/250000, loss: 0.1624, lr: 0.001748, batch_cost: 0.5921, reader_cost: 0.02780, ips: 10.1336 samples/sec | ETA 05:55:21
2023-02-05 02:10:11 [INFO]	[TRAIN] epoch: 2709, iter: 214000/250000, loss: 0.2601, lr: 0.001748, batch_cost: 0.5639, reader_cost: 0.00008, ips: 10.6393 samples/sec | ETA 05:38:22
2023-02-05 02:10:11 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1257 - reader cost: 0.0283 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1499 - reader cost: 0.0142 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1562 - reader cost: 0.0095 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1572 - reader cost: 0.0071 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1578 - reader cost: 0.0057 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1602 - reader cost: 0.0048 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1604 - reader cost: 0.0041 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1612 - reader cost: 0.0036 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1625 - reader cost: 0.003210/36 [=======>......................] - ETA: 4s - batch_cost: 0.1625 - reader cost: 0.002911/36 [========>.....................] - ETA: 4s - batch_cost: 0.1633 - reader cost: 0.002612/36 [=========>....................] - ETA: 3s - batch_cost: 0.1628 - reader cost: 0.002413/36 [=========>....................] - ETA: 3s - batch_cost: 0.1631 - reader cost: 0.002214/36 [==========>...................] - ETA: 3s - batch_cost: 0.1636 - reader cost: 0.002115/36 [===========>..................] - ETA: 3s - batch_cost: 0.1635 - reader cost: 0.002016/36 [============>.................] - ETA: 3s - batch_cost: 0.1643 - reader cost: 0.001817/36 [=============>................] - ETA: 3s - batch_cost: 0.1645 - reader cost: 0.001718/36 [==============>...............] - ETA: 2s - batch_cost: 0.1646 - reader cost: 0.001619/36 [==============>...............] - ETA: 2s - batch_cost: 0.1645 - reader cost: 0.001620/36 [===============>..............] - ETA: 2s - batch_cost: 0.1644 - reader cost: 0.001521/36 [================>.............] - ETA: 2s - batch_cost: 0.1644 - reader cost: 0.001422/36 [=================>............] - ETA: 2s - batch_cost: 0.1643 - reader cost: 0.001423/36 [==================>...........] - ETA: 2s - batch_cost: 0.1650 - reader cost: 0.001324/36 [===================>..........] - ETA: 1s - batch_cost: 0.1649 - reader cost: 0.001325/36 [===================>..........] - ETA: 1s - batch_cost: 0.1652 - reader cost: 0.001226/36 [====================>.........] - ETA: 1s - batch_cost: 0.1653 - reader cost: 0.001227/36 [=====================>........] - ETA: 1s - batch_cost: 0.1655 - reader cost: 0.001128/36 [======================>.......] - ETA: 1s - batch_cost: 0.1657 - reader cost: 0.001129/36 [=======================>......] - ETA: 1s - batch_cost: 0.1658 - reader cost: 0.001030/36 [========================>.....] - ETA: 0s - batch_cost: 0.1658 - reader cost: 0.001031/36 [========================>.....] - ETA: 0s - batch_cost: 0.1660 - reader cost: 9.8560e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1659 - reader cost: 9.5747e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1658 - reader cost: 9.3079e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1657 - reader cost: 9.0585e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1659 - reader cost: 8.8177e-0436/36 [==============================] - 6s 166ms/step - batch_cost: 0.1660 - reader cost: 8.5892e-04
2023-02-05 02:10:17 [INFO]	[EVAL] #Images: 36 mIoU: 0.8617 Acc: 0.9861 Kappa: 0.9494 Dice: 0.9220
2023-02-05 02:10:17 [INFO]	[EVAL] Class IoU: 
[0.9855 0.9161 0.8906 0.7228 0.6873 0.9734 0.8563]
2023-02-05 02:10:17 [INFO]	[EVAL] Class Precision: 
[0.9918 0.968  0.9491 0.8291 0.8774 0.9835 0.9125]
2023-02-05 02:10:17 [INFO]	[EVAL] Class Recall: 
[0.9936 0.9447 0.9353 0.8494 0.7604 0.9896 0.9329]
2023-02-05 02:10:18 [INFO]	[EVAL] The model with the best validation mIoU (0.8617) was saved at iter 214000.
2023-02-05 02:10:24 [INFO]	[TRAIN] epoch: 2709, iter: 214010/250000, loss: 0.1682, lr: 0.001748, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6345 samples/sec | ETA 05:38:25
2023-02-05 02:10:29 [INFO]	[TRAIN] epoch: 2710, iter: 214020/250000, loss: 0.3098, lr: 0.001747, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6376 samples/sec | ETA 05:38:14
2023-02-05 02:10:35 [INFO]	[TRAIN] epoch: 2710, iter: 214030/250000, loss: 0.2020, lr: 0.001747, batch_cost: 0.5637, reader_cost: 0.00009, ips: 10.6438 samples/sec | ETA 05:37:56
2023-02-05 02:10:41 [INFO]	[TRAIN] epoch: 2710, iter: 214040/250000, loss: 0.1967, lr: 0.001746, batch_cost: 0.5638, reader_cost: 0.00010, ips: 10.6413 samples/sec | ETA 05:37:55
2023-02-05 02:10:46 [INFO]	[TRAIN] epoch: 2710, iter: 214050/250000, loss: 0.2327, lr: 0.001746, batch_cost: 0.5637, reader_cost: 0.00009, ips: 10.6441 samples/sec | ETA 05:37:44
2023-02-05 02:10:52 [INFO]	[TRAIN] epoch: 2710, iter: 214060/250000, loss: 0.2343, lr: 0.001745, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6365 samples/sec | ETA 05:37:53
2023-02-05 02:10:58 [INFO]	[TRAIN] epoch: 2710, iter: 214070/250000, loss: 0.2150, lr: 0.001745, batch_cost: 0.5904, reader_cost: 0.02645, ips: 10.1630 samples/sec | ETA 05:53:32
2023-02-05 02:11:04 [INFO]	[TRAIN] epoch: 2710, iter: 214080/250000, loss: 0.1779, lr: 0.001744, batch_cost: 0.5634, reader_cost: 0.00009, ips: 10.6503 samples/sec | ETA 05:37:16
2023-02-05 02:11:09 [INFO]	[TRAIN] epoch: 2710, iter: 214090/250000, loss: 0.2078, lr: 0.001744, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6352 samples/sec | ETA 05:37:39
2023-02-05 02:11:15 [INFO]	[TRAIN] epoch: 2711, iter: 214100/250000, loss: 0.1712, lr: 0.001744, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6310 samples/sec | ETA 05:37:41
2023-02-05 02:11:21 [INFO]	[TRAIN] epoch: 2711, iter: 214110/250000, loss: 0.1974, lr: 0.001743, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6329 samples/sec | ETA 05:37:32
2023-02-05 02:11:26 [INFO]	[TRAIN] epoch: 2711, iter: 214120/250000, loss: 0.1648, lr: 0.001743, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6354 samples/sec | ETA 05:37:21
2023-02-05 02:11:32 [INFO]	[TRAIN] epoch: 2711, iter: 214130/250000, loss: 0.1774, lr: 0.001742, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6394 samples/sec | ETA 05:37:08
2023-02-05 02:11:37 [INFO]	[TRAIN] epoch: 2711, iter: 214140/250000, loss: 0.2948, lr: 0.001742, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6349 samples/sec | ETA 05:37:11
2023-02-05 02:11:43 [INFO]	[TRAIN] epoch: 2711, iter: 214150/250000, loss: 0.1628, lr: 0.001741, batch_cost: 0.5894, reader_cost: 0.02387, ips: 10.1797 samples/sec | ETA 05:52:10
2023-02-05 02:11:49 [INFO]	[TRAIN] epoch: 2711, iter: 214160/250000, loss: 0.2911, lr: 0.001741, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6283 samples/sec | ETA 05:37:12
2023-02-05 02:11:55 [INFO]	[TRAIN] epoch: 2712, iter: 214170/250000, loss: 0.2066, lr: 0.001741, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6328 samples/sec | ETA 05:36:58
2023-02-05 02:12:00 [INFO]	[TRAIN] epoch: 2712, iter: 214180/250000, loss: 0.2395, lr: 0.001740, batch_cost: 0.5638, reader_cost: 0.00010, ips: 10.6419 samples/sec | ETA 05:36:35
2023-02-05 02:12:06 [INFO]	[TRAIN] epoch: 2712, iter: 214190/250000, loss: 0.1905, lr: 0.001740, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6323 samples/sec | ETA 05:36:48
2023-02-05 02:12:12 [INFO]	[TRAIN] epoch: 2712, iter: 214200/250000, loss: 0.2179, lr: 0.001739, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6316 samples/sec | ETA 05:36:43
2023-02-05 02:12:17 [INFO]	[TRAIN] epoch: 2712, iter: 214210/250000, loss: 0.1954, lr: 0.001739, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6300 samples/sec | ETA 05:36:41
2023-02-05 02:12:23 [INFO]	[TRAIN] epoch: 2712, iter: 214220/250000, loss: 0.1917, lr: 0.001738, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6366 samples/sec | ETA 05:36:23
2023-02-05 02:12:29 [INFO]	[TRAIN] epoch: 2712, iter: 214230/250000, loss: 0.1969, lr: 0.001738, batch_cost: 0.5960, reader_cost: 0.03203, ips: 10.0667 samples/sec | ETA 05:55:19
2023-02-05 02:12:34 [INFO]	[TRAIN] epoch: 2712, iter: 214240/250000, loss: 0.1600, lr: 0.001737, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6355 samples/sec | ETA 05:36:13
2023-02-05 02:12:40 [INFO]	[TRAIN] epoch: 2713, iter: 214250/250000, loss: 0.1812, lr: 0.001737, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6351 samples/sec | ETA 05:36:09
2023-02-05 02:12:46 [INFO]	[TRAIN] epoch: 2713, iter: 214260/250000, loss: 0.1953, lr: 0.001737, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6294 samples/sec | ETA 05:36:14
2023-02-05 02:12:51 [INFO]	[TRAIN] epoch: 2713, iter: 214270/250000, loss: 0.1842, lr: 0.001736, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6292 samples/sec | ETA 05:36:09
2023-02-05 02:12:57 [INFO]	[TRAIN] epoch: 2713, iter: 214280/250000, loss: 0.1618, lr: 0.001736, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6293 samples/sec | ETA 05:36:03
2023-02-05 02:13:03 [INFO]	[TRAIN] epoch: 2713, iter: 214290/250000, loss: 0.1691, lr: 0.001735, batch_cost: 0.5636, reader_cost: 0.00009, ips: 10.6467 samples/sec | ETA 05:35:24
2023-02-05 02:13:09 [INFO]	[TRAIN] epoch: 2713, iter: 214300/250000, loss: 0.1935, lr: 0.001735, batch_cost: 0.5863, reader_cost: 0.02284, ips: 10.2333 samples/sec | ETA 05:48:51
2023-02-05 02:13:14 [INFO]	[TRAIN] epoch: 2713, iter: 214310/250000, loss: 0.2053, lr: 0.001734, batch_cost: 0.5647, reader_cost: 0.00017, ips: 10.6247 samples/sec | ETA 05:35:54
2023-02-05 02:13:20 [INFO]	[TRAIN] epoch: 2713, iter: 214320/250000, loss: 0.1671, lr: 0.001734, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6303 samples/sec | ETA 05:35:38
2023-02-05 02:13:25 [INFO]	[TRAIN] epoch: 2714, iter: 214330/250000, loss: 0.1550, lr: 0.001734, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6288 samples/sec | ETA 05:35:35
2023-02-05 02:13:31 [INFO]	[TRAIN] epoch: 2714, iter: 214340/250000, loss: 0.1467, lr: 0.001733, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6366 samples/sec | ETA 05:35:15
2023-02-05 02:13:37 [INFO]	[TRAIN] epoch: 2714, iter: 214350/250000, loss: 0.1874, lr: 0.001733, batch_cost: 0.5639, reader_cost: 0.00008, ips: 10.6399 samples/sec | ETA 05:35:03
2023-02-05 02:13:42 [INFO]	[TRAIN] epoch: 2714, iter: 214360/250000, loss: 0.1518, lr: 0.001732, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6300 samples/sec | ETA 05:35:16
2023-02-05 02:13:48 [INFO]	[TRAIN] epoch: 2714, iter: 214370/250000, loss: 0.2009, lr: 0.001732, batch_cost: 0.5647, reader_cost: 0.00016, ips: 10.6252 samples/sec | ETA 05:35:20
2023-02-05 02:13:54 [INFO]	[TRAIN] epoch: 2714, iter: 214380/250000, loss: 0.2049, lr: 0.001731, batch_cost: 0.5948, reader_cost: 0.02934, ips: 10.0872 samples/sec | ETA 05:53:07
2023-02-05 02:14:00 [INFO]	[TRAIN] epoch: 2714, iter: 214390/250000, loss: 0.1741, lr: 0.001731, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6205 samples/sec | ETA 05:35:17
2023-02-05 02:14:05 [INFO]	[TRAIN] epoch: 2714, iter: 214400/250000, loss: 0.1652, lr: 0.001730, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6374 samples/sec | ETA 05:34:40
2023-02-05 02:14:11 [INFO]	[TRAIN] epoch: 2715, iter: 214410/250000, loss: 0.2201, lr: 0.001730, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6328 samples/sec | ETA 05:34:43
2023-02-05 02:14:17 [INFO]	[TRAIN] epoch: 2715, iter: 214420/250000, loss: 0.1487, lr: 0.001730, batch_cost: 0.5642, reader_cost: 0.00008, ips: 10.6351 samples/sec | ETA 05:34:33
2023-02-05 02:14:22 [INFO]	[TRAIN] epoch: 2715, iter: 214430/250000, loss: 0.2335, lr: 0.001729, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6310 samples/sec | ETA 05:34:35
2023-02-05 02:14:28 [INFO]	[TRAIN] epoch: 2715, iter: 214440/250000, loss: 0.2100, lr: 0.001729, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6110 samples/sec | ETA 05:35:07
2023-02-05 02:14:33 [INFO]	[TRAIN] epoch: 2715, iter: 214450/250000, loss: 0.2137, lr: 0.001728, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6015 samples/sec | ETA 05:35:19
2023-02-05 02:14:39 [INFO]	[TRAIN] epoch: 2715, iter: 214460/250000, loss: 0.2135, lr: 0.001728, batch_cost: 0.5917, reader_cost: 0.02601, ips: 10.1410 samples/sec | ETA 05:50:27
2023-02-05 02:14:45 [INFO]	[TRAIN] epoch: 2715, iter: 214470/250000, loss: 0.1981, lr: 0.001727, batch_cost: 0.5644, reader_cost: 0.00017, ips: 10.6316 samples/sec | ETA 05:34:11
2023-02-05 02:14:51 [INFO]	[TRAIN] epoch: 2715, iter: 214480/250000, loss: 0.1801, lr: 0.001727, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6254 samples/sec | ETA 05:34:17
2023-02-05 02:14:56 [INFO]	[TRAIN] epoch: 2716, iter: 214490/250000, loss: 0.1807, lr: 0.001727, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6292 samples/sec | ETA 05:34:04
2023-02-05 02:15:02 [INFO]	[TRAIN] epoch: 2716, iter: 214500/250000, loss: 0.2104, lr: 0.001726, batch_cost: 0.5660, reader_cost: 0.00008, ips: 10.6013 samples/sec | ETA 05:34:51
2023-02-05 02:15:08 [INFO]	[TRAIN] epoch: 2716, iter: 214510/250000, loss: 0.1648, lr: 0.001726, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6116 samples/sec | ETA 05:34:26
2023-02-05 02:15:13 [INFO]	[TRAIN] epoch: 2716, iter: 214520/250000, loss: 0.2045, lr: 0.001725, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6049 samples/sec | ETA 05:34:33
2023-02-05 02:15:19 [INFO]	[TRAIN] epoch: 2716, iter: 214530/250000, loss: 0.1891, lr: 0.001725, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6014 samples/sec | ETA 05:34:34
2023-02-05 02:15:25 [INFO]	[TRAIN] epoch: 2716, iter: 214540/250000, loss: 0.1788, lr: 0.001724, batch_cost: 0.5909, reader_cost: 0.02516, ips: 10.1545 samples/sec | ETA 05:49:12
2023-02-05 02:15:31 [INFO]	[TRAIN] epoch: 2716, iter: 214550/250000, loss: 0.2742, lr: 0.001724, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6056 samples/sec | ETA 05:34:15
2023-02-05 02:15:36 [INFO]	[TRAIN] epoch: 2716, iter: 214560/250000, loss: 0.2267, lr: 0.001723, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6132 samples/sec | ETA 05:33:55
2023-02-05 02:15:42 [INFO]	[TRAIN] epoch: 2717, iter: 214570/250000, loss: 0.2390, lr: 0.001723, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6104 samples/sec | ETA 05:33:55
2023-02-05 02:15:48 [INFO]	[TRAIN] epoch: 2717, iter: 214580/250000, loss: 0.1950, lr: 0.001723, batch_cost: 0.5665, reader_cost: 0.00010, ips: 10.5922 samples/sec | ETA 05:34:23
2023-02-05 02:15:53 [INFO]	[TRAIN] epoch: 2717, iter: 214590/250000, loss: 0.1690, lr: 0.001722, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6050 samples/sec | ETA 05:33:53
2023-02-05 02:15:59 [INFO]	[TRAIN] epoch: 2717, iter: 214600/250000, loss: 0.2164, lr: 0.001722, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6166 samples/sec | ETA 05:33:26
2023-02-05 02:16:04 [INFO]	[TRAIN] epoch: 2717, iter: 214610/250000, loss: 0.1706, lr: 0.001721, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6047 samples/sec | ETA 05:33:43
2023-02-05 02:16:10 [INFO]	[TRAIN] epoch: 2717, iter: 214620/250000, loss: 0.1728, lr: 0.001721, batch_cost: 0.5895, reader_cost: 0.02437, ips: 10.1778 samples/sec | ETA 05:47:37
2023-02-05 02:16:16 [INFO]	[TRAIN] epoch: 2717, iter: 214630/250000, loss: 0.2594, lr: 0.001720, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6406 samples/sec | ETA 05:32:24
2023-02-05 02:16:22 [INFO]	[TRAIN] epoch: 2717, iter: 214640/250000, loss: 0.2015, lr: 0.001720, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6338 samples/sec | ETA 05:32:31
2023-02-05 02:16:27 [INFO]	[TRAIN] epoch: 2718, iter: 214650/250000, loss: 0.2532, lr: 0.001720, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5975 samples/sec | ETA 05:33:34
2023-02-05 02:16:33 [INFO]	[TRAIN] epoch: 2718, iter: 214660/250000, loss: 0.1972, lr: 0.001719, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6068 samples/sec | ETA 05:33:11
2023-02-05 02:16:39 [INFO]	[TRAIN] epoch: 2718, iter: 214670/250000, loss: 0.2089, lr: 0.001719, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6149 samples/sec | ETA 05:32:49
2023-02-05 02:16:44 [INFO]	[TRAIN] epoch: 2718, iter: 214680/250000, loss: 0.1885, lr: 0.001718, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6083 samples/sec | ETA 05:32:56
2023-02-05 02:16:50 [INFO]	[TRAIN] epoch: 2718, iter: 214690/250000, loss: 0.1741, lr: 0.001718, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6009 samples/sec | ETA 05:33:05
2023-02-05 02:16:56 [INFO]	[TRAIN] epoch: 2718, iter: 214700/250000, loss: 0.2005, lr: 0.001717, batch_cost: 0.5909, reader_cost: 0.02550, ips: 10.1536 samples/sec | ETA 05:47:39
2023-02-05 02:17:02 [INFO]	[TRAIN] epoch: 2718, iter: 214710/250000, loss: 0.1692, lr: 0.001717, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6311 samples/sec | ETA 05:31:57
2023-02-05 02:17:07 [INFO]	[TRAIN] epoch: 2718, iter: 214720/250000, loss: 0.1497, lr: 0.001716, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6324 samples/sec | ETA 05:31:49
2023-02-05 02:17:13 [INFO]	[TRAIN] epoch: 2719, iter: 214730/250000, loss: 0.1446, lr: 0.001716, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6393 samples/sec | ETA 05:31:30
2023-02-05 02:17:18 [INFO]	[TRAIN] epoch: 2719, iter: 214740/250000, loss: 0.1937, lr: 0.001716, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6326 samples/sec | ETA 05:31:37
2023-02-05 02:17:24 [INFO]	[TRAIN] epoch: 2719, iter: 214750/250000, loss: 0.2083, lr: 0.001715, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6319 samples/sec | ETA 05:31:33
2023-02-05 02:17:30 [INFO]	[TRAIN] epoch: 2719, iter: 214760/250000, loss: 0.2413, lr: 0.001715, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6299 samples/sec | ETA 05:31:31
2023-02-05 02:17:35 [INFO]	[TRAIN] epoch: 2719, iter: 214770/250000, loss: 0.1570, lr: 0.001714, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6337 samples/sec | ETA 05:31:18
2023-02-05 02:17:41 [INFO]	[TRAIN] epoch: 2719, iter: 214780/250000, loss: 0.1659, lr: 0.001714, batch_cost: 0.5912, reader_cost: 0.02690, ips: 10.1491 samples/sec | ETA 05:47:01
2023-02-05 02:17:47 [INFO]	[TRAIN] epoch: 2719, iter: 214790/250000, loss: 0.1700, lr: 0.001713, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6294 samples/sec | ETA 05:31:14
2023-02-05 02:17:53 [INFO]	[TRAIN] epoch: 2719, iter: 214800/250000, loss: 0.2027, lr: 0.001713, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6310 samples/sec | ETA 05:31:06
2023-02-05 02:17:58 [INFO]	[TRAIN] epoch: 2720, iter: 214810/250000, loss: 0.1764, lr: 0.001713, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6257 samples/sec | ETA 05:31:10
2023-02-05 02:18:04 [INFO]	[TRAIN] epoch: 2720, iter: 214820/250000, loss: 0.2202, lr: 0.001712, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6313 samples/sec | ETA 05:30:54
2023-02-05 02:18:10 [INFO]	[TRAIN] epoch: 2720, iter: 214830/250000, loss: 0.1879, lr: 0.001712, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6200 samples/sec | ETA 05:31:10
2023-02-05 02:18:15 [INFO]	[TRAIN] epoch: 2720, iter: 214840/250000, loss: 0.1551, lr: 0.001711, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6291 samples/sec | ETA 05:30:47
2023-02-05 02:18:21 [INFO]	[TRAIN] epoch: 2720, iter: 214850/250000, loss: 0.2159, lr: 0.001711, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6247 samples/sec | ETA 05:30:49
2023-02-05 02:18:27 [INFO]	[TRAIN] epoch: 2720, iter: 214860/250000, loss: 0.2358, lr: 0.001710, batch_cost: 0.5928, reader_cost: 0.02789, ips: 10.1214 samples/sec | ETA 05:47:11
2023-02-05 02:18:32 [INFO]	[TRAIN] epoch: 2720, iter: 214870/250000, loss: 0.1865, lr: 0.001710, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6261 samples/sec | ETA 05:30:36
2023-02-05 02:18:38 [INFO]	[TRAIN] epoch: 2720, iter: 214880/250000, loss: 0.1769, lr: 0.001709, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6320 samples/sec | ETA 05:30:19
2023-02-05 02:18:44 [INFO]	[TRAIN] epoch: 2721, iter: 214890/250000, loss: 0.2430, lr: 0.001709, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6353 samples/sec | ETA 05:30:07
2023-02-05 02:18:49 [INFO]	[TRAIN] epoch: 2721, iter: 214900/250000, loss: 0.2031, lr: 0.001709, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6270 samples/sec | ETA 05:30:17
2023-02-05 02:18:55 [INFO]	[TRAIN] epoch: 2721, iter: 214910/250000, loss: 0.2083, lr: 0.001708, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6264 samples/sec | ETA 05:30:12
2023-02-05 02:19:01 [INFO]	[TRAIN] epoch: 2721, iter: 214920/250000, loss: 0.2125, lr: 0.001708, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6333 samples/sec | ETA 05:29:54
2023-02-05 02:19:06 [INFO]	[TRAIN] epoch: 2721, iter: 214930/250000, loss: 0.2431, lr: 0.001707, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6358 samples/sec | ETA 05:29:44
2023-02-05 02:19:12 [INFO]	[TRAIN] epoch: 2721, iter: 214940/250000, loss: 0.2084, lr: 0.001707, batch_cost: 0.5840, reader_cost: 0.01955, ips: 10.2743 samples/sec | ETA 05:41:14
2023-02-05 02:19:18 [INFO]	[TRAIN] epoch: 2721, iter: 214950/250000, loss: 0.2096, lr: 0.001706, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6361 samples/sec | ETA 05:29:32
2023-02-05 02:19:23 [INFO]	[TRAIN] epoch: 2722, iter: 214960/250000, loss: 0.2187, lr: 0.001706, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6275 samples/sec | ETA 05:29:42
2023-02-05 02:19:29 [INFO]	[TRAIN] epoch: 2722, iter: 214970/250000, loss: 0.1867, lr: 0.001706, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6291 samples/sec | ETA 05:29:33
2023-02-05 02:19:35 [INFO]	[TRAIN] epoch: 2722, iter: 214980/250000, loss: 0.2149, lr: 0.001705, batch_cost: 0.5643, reader_cost: 0.00011, ips: 10.6325 samples/sec | ETA 05:29:22
2023-02-05 02:19:40 [INFO]	[TRAIN] epoch: 2722, iter: 214990/250000, loss: 0.2717, lr: 0.001705, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6311 samples/sec | ETA 05:29:18
2023-02-05 02:19:46 [INFO]	[TRAIN] epoch: 2722, iter: 215000/250000, loss: 0.2072, lr: 0.001704, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6331 samples/sec | ETA 05:29:09
2023-02-05 02:19:52 [INFO]	[TRAIN] epoch: 2722, iter: 215010/250000, loss: 0.1967, lr: 0.001704, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6301 samples/sec | ETA 05:29:09
2023-02-05 02:19:57 [INFO]	[TRAIN] epoch: 2722, iter: 215020/250000, loss: 0.1840, lr: 0.001703, batch_cost: 0.5888, reader_cost: 0.02396, ips: 10.1894 samples/sec | ETA 05:43:17
2023-02-05 02:20:03 [INFO]	[TRAIN] epoch: 2722, iter: 215030/250000, loss: 0.2697, lr: 0.001703, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6381 samples/sec | ETA 05:28:43
2023-02-05 02:20:09 [INFO]	[TRAIN] epoch: 2723, iter: 215040/250000, loss: 0.2542, lr: 0.001702, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6285 samples/sec | ETA 05:28:55
2023-02-05 02:20:14 [INFO]	[TRAIN] epoch: 2723, iter: 215050/250000, loss: 0.1993, lr: 0.001702, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6346 samples/sec | ETA 05:28:38
2023-02-05 02:20:20 [INFO]	[TRAIN] epoch: 2723, iter: 215060/250000, loss: 0.2046, lr: 0.001702, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6240 samples/sec | ETA 05:28:52
2023-02-05 02:20:26 [INFO]	[TRAIN] epoch: 2723, iter: 215070/250000, loss: 0.1723, lr: 0.001701, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6320 samples/sec | ETA 05:28:32
2023-02-05 02:20:31 [INFO]	[TRAIN] epoch: 2723, iter: 215080/250000, loss: 0.1794, lr: 0.001701, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6351 samples/sec | ETA 05:28:20
2023-02-05 02:20:37 [INFO]	[TRAIN] epoch: 2723, iter: 215090/250000, loss: 0.1870, lr: 0.001700, batch_cost: 0.5866, reader_cost: 0.02190, ips: 10.2289 samples/sec | ETA 05:41:17
2023-02-05 02:20:43 [INFO]	[TRAIN] epoch: 2723, iter: 215100/250000, loss: 0.2099, lr: 0.001700, batch_cost: 0.5650, reader_cost: 0.00013, ips: 10.6196 samples/sec | ETA 05:28:38
2023-02-05 02:20:49 [INFO]	[TRAIN] epoch: 2723, iter: 215110/250000, loss: 0.2054, lr: 0.001699, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6262 samples/sec | ETA 05:28:20
2023-02-05 02:20:54 [INFO]	[TRAIN] epoch: 2724, iter: 215120/250000, loss: 0.1659, lr: 0.001699, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6370 samples/sec | ETA 05:27:54
2023-02-05 02:21:00 [INFO]	[TRAIN] epoch: 2724, iter: 215130/250000, loss: 0.2536, lr: 0.001699, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6379 samples/sec | ETA 05:27:47
2023-02-05 02:21:05 [INFO]	[TRAIN] epoch: 2724, iter: 215140/250000, loss: 0.2593, lr: 0.001698, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6340 samples/sec | ETA 05:27:49
2023-02-05 02:21:11 [INFO]	[TRAIN] epoch: 2724, iter: 215150/250000, loss: 0.2270, lr: 0.001698, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6188 samples/sec | ETA 05:28:11
2023-02-05 02:21:17 [INFO]	[TRAIN] epoch: 2724, iter: 215160/250000, loss: 0.2015, lr: 0.001697, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6311 samples/sec | ETA 05:27:43
2023-02-05 02:21:23 [INFO]	[TRAIN] epoch: 2724, iter: 215170/250000, loss: 0.2267, lr: 0.001697, batch_cost: 0.5936, reader_cost: 0.02914, ips: 10.1083 samples/sec | ETA 05:44:34
2023-02-05 02:21:28 [INFO]	[TRAIN] epoch: 2724, iter: 215180/250000, loss: 0.2627, lr: 0.001696, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6139 samples/sec | ETA 05:28:03
2023-02-05 02:21:34 [INFO]	[TRAIN] epoch: 2724, iter: 215190/250000, loss: 0.1829, lr: 0.001696, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6333 samples/sec | ETA 05:27:22
2023-02-05 02:21:40 [INFO]	[TRAIN] epoch: 2725, iter: 215200/250000, loss: 0.2017, lr: 0.001695, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6346 samples/sec | ETA 05:27:13
2023-02-05 02:21:45 [INFO]	[TRAIN] epoch: 2725, iter: 215210/250000, loss: 0.2407, lr: 0.001695, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6300 samples/sec | ETA 05:27:16
2023-02-05 02:21:51 [INFO]	[TRAIN] epoch: 2725, iter: 215220/250000, loss: 0.1899, lr: 0.001695, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6275 samples/sec | ETA 05:27:15
2023-02-05 02:21:57 [INFO]	[TRAIN] epoch: 2725, iter: 215230/250000, loss: 0.2075, lr: 0.001694, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6286 samples/sec | ETA 05:27:08
2023-02-05 02:22:02 [INFO]	[TRAIN] epoch: 2725, iter: 215240/250000, loss: 0.1680, lr: 0.001694, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6275 samples/sec | ETA 05:27:04
2023-02-05 02:22:08 [INFO]	[TRAIN] epoch: 2725, iter: 215250/250000, loss: 0.2144, lr: 0.001693, batch_cost: 0.5903, reader_cost: 0.02547, ips: 10.1651 samples/sec | ETA 05:41:51
2023-02-05 02:22:14 [INFO]	[TRAIN] epoch: 2725, iter: 215260/250000, loss: 0.2024, lr: 0.001693, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6301 samples/sec | ETA 05:26:48
2023-02-05 02:22:19 [INFO]	[TRAIN] epoch: 2725, iter: 215270/250000, loss: 0.1777, lr: 0.001692, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6375 samples/sec | ETA 05:26:29
2023-02-05 02:22:25 [INFO]	[TRAIN] epoch: 2726, iter: 215280/250000, loss: 0.1989, lr: 0.001692, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6362 samples/sec | ETA 05:26:25
2023-02-05 02:22:31 [INFO]	[TRAIN] epoch: 2726, iter: 215290/250000, loss: 0.1726, lr: 0.001692, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6281 samples/sec | ETA 05:26:35
2023-02-05 02:22:36 [INFO]	[TRAIN] epoch: 2726, iter: 215300/250000, loss: 0.2185, lr: 0.001691, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6293 samples/sec | ETA 05:26:27
2023-02-05 02:22:42 [INFO]	[TRAIN] epoch: 2726, iter: 215310/250000, loss: 0.1966, lr: 0.001691, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6309 samples/sec | ETA 05:26:18
2023-02-05 02:22:48 [INFO]	[TRAIN] epoch: 2726, iter: 215320/250000, loss: 0.2273, lr: 0.001690, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6309 samples/sec | ETA 05:26:13
2023-02-05 02:22:54 [INFO]	[TRAIN] epoch: 2726, iter: 215330/250000, loss: 0.2150, lr: 0.001690, batch_cost: 0.5937, reader_cost: 0.02950, ips: 10.1057 samples/sec | ETA 05:43:04
2023-02-05 02:22:59 [INFO]	[TRAIN] epoch: 2726, iter: 215340/250000, loss: 0.1646, lr: 0.001689, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6311 samples/sec | ETA 05:26:01
2023-02-05 02:23:05 [INFO]	[TRAIN] epoch: 2726, iter: 215350/250000, loss: 0.2126, lr: 0.001689, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6411 samples/sec | ETA 05:25:37
2023-02-05 02:23:10 [INFO]	[TRAIN] epoch: 2727, iter: 215360/250000, loss: 0.2148, lr: 0.001688, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6355 samples/sec | ETA 05:25:42
2023-02-05 02:23:16 [INFO]	[TRAIN] epoch: 2727, iter: 215370/250000, loss: 0.2354, lr: 0.001688, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6249 samples/sec | ETA 05:25:56
2023-02-05 02:23:22 [INFO]	[TRAIN] epoch: 2727, iter: 215380/250000, loss: 0.2455, lr: 0.001688, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6310 samples/sec | ETA 05:25:39
2023-02-05 02:23:27 [INFO]	[TRAIN] epoch: 2727, iter: 215390/250000, loss: 0.2808, lr: 0.001687, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6197 samples/sec | ETA 05:25:54
2023-02-05 02:23:33 [INFO]	[TRAIN] epoch: 2727, iter: 215400/250000, loss: 0.2480, lr: 0.001687, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6223 samples/sec | ETA 05:25:43
2023-02-05 02:23:39 [INFO]	[TRAIN] epoch: 2727, iter: 215410/250000, loss: 0.1863, lr: 0.001686, batch_cost: 0.5932, reader_cost: 0.02774, ips: 10.1145 samples/sec | ETA 05:41:59
2023-02-05 02:23:45 [INFO]	[TRAIN] epoch: 2727, iter: 215420/250000, loss: 0.2393, lr: 0.001686, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6275 samples/sec | ETA 05:25:23
2023-02-05 02:23:50 [INFO]	[TRAIN] epoch: 2727, iter: 215430/250000, loss: 0.1940, lr: 0.001685, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6135 samples/sec | ETA 05:25:42
2023-02-05 02:23:56 [INFO]	[TRAIN] epoch: 2728, iter: 215440/250000, loss: 0.2134, lr: 0.001685, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6017 samples/sec | ETA 05:25:59
2023-02-05 02:24:02 [INFO]	[TRAIN] epoch: 2728, iter: 215450/250000, loss: 0.1740, lr: 0.001684, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6116 samples/sec | ETA 05:25:35
2023-02-05 02:24:07 [INFO]	[TRAIN] epoch: 2728, iter: 215460/250000, loss: 0.1693, lr: 0.001684, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6128 samples/sec | ETA 05:25:27
2023-02-05 02:24:13 [INFO]	[TRAIN] epoch: 2728, iter: 215470/250000, loss: 0.1874, lr: 0.001684, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5993 samples/sec | ETA 05:25:46
2023-02-05 02:24:19 [INFO]	[TRAIN] epoch: 2728, iter: 215480/250000, loss: 0.1754, lr: 0.001683, batch_cost: 0.5660, reader_cost: 0.00008, ips: 10.6008 samples/sec | ETA 05:25:38
2023-02-05 02:24:25 [INFO]	[TRAIN] epoch: 2728, iter: 215490/250000, loss: 0.2140, lr: 0.001683, batch_cost: 0.5939, reader_cost: 0.02762, ips: 10.1021 samples/sec | ETA 05:41:36
2023-02-05 02:24:30 [INFO]	[TRAIN] epoch: 2728, iter: 215500/250000, loss: 0.2151, lr: 0.001682, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6140 samples/sec | ETA 05:25:02
2023-02-05 02:24:36 [INFO]	[TRAIN] epoch: 2728, iter: 215510/250000, loss: 0.2306, lr: 0.001682, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6007 samples/sec | ETA 05:25:21
2023-02-05 02:24:41 [INFO]	[TRAIN] epoch: 2729, iter: 215520/250000, loss: 0.2291, lr: 0.001681, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5975 samples/sec | ETA 05:25:21
2023-02-05 02:24:47 [INFO]	[TRAIN] epoch: 2729, iter: 215530/250000, loss: 0.2220, lr: 0.001681, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6049 samples/sec | ETA 05:25:02
2023-02-05 02:24:53 [INFO]	[TRAIN] epoch: 2729, iter: 215540/250000, loss: 0.2344, lr: 0.001681, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6107 samples/sec | ETA 05:24:46
2023-02-05 02:24:58 [INFO]	[TRAIN] epoch: 2729, iter: 215550/250000, loss: 0.2052, lr: 0.001680, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6068 samples/sec | ETA 05:24:47
2023-02-05 02:25:04 [INFO]	[TRAIN] epoch: 2729, iter: 215560/250000, loss: 0.2434, lr: 0.001680, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6062 samples/sec | ETA 05:24:43
2023-02-05 02:25:10 [INFO]	[TRAIN] epoch: 2729, iter: 215570/250000, loss: 0.1736, lr: 0.001679, batch_cost: 0.5948, reader_cost: 0.03027, ips: 10.0867 samples/sec | ETA 05:41:20
2023-02-05 02:25:16 [INFO]	[TRAIN] epoch: 2729, iter: 215580/250000, loss: 0.1838, lr: 0.001679, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6287 samples/sec | ETA 05:23:50
2023-02-05 02:25:21 [INFO]	[TRAIN] epoch: 2729, iter: 215590/250000, loss: 0.1717, lr: 0.001678, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6174 samples/sec | ETA 05:24:05
2023-02-05 02:25:27 [INFO]	[TRAIN] epoch: 2730, iter: 215600/250000, loss: 0.2221, lr: 0.001678, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6115 samples/sec | ETA 05:24:10
2023-02-05 02:25:33 [INFO]	[TRAIN] epoch: 2730, iter: 215610/250000, loss: 0.1674, lr: 0.001677, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6025 samples/sec | ETA 05:24:21
2023-02-05 02:25:38 [INFO]	[TRAIN] epoch: 2730, iter: 215620/250000, loss: 0.1884, lr: 0.001677, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6034 samples/sec | ETA 05:24:14
2023-02-05 02:25:44 [INFO]	[TRAIN] epoch: 2730, iter: 215630/250000, loss: 0.2159, lr: 0.001677, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6149 samples/sec | ETA 05:23:47
2023-02-05 02:25:50 [INFO]	[TRAIN] epoch: 2730, iter: 215640/250000, loss: 0.1733, lr: 0.001676, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6112 samples/sec | ETA 05:23:48
2023-02-05 02:25:56 [INFO]	[TRAIN] epoch: 2730, iter: 215650/250000, loss: 0.2271, lr: 0.001676, batch_cost: 0.5932, reader_cost: 0.02671, ips: 10.1153 samples/sec | ETA 05:39:35
2023-02-05 02:26:01 [INFO]	[TRAIN] epoch: 2730, iter: 215660/250000, loss: 0.2335, lr: 0.001675, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6116 samples/sec | ETA 05:23:36
2023-02-05 02:26:07 [INFO]	[TRAIN] epoch: 2730, iter: 215670/250000, loss: 0.2128, lr: 0.001675, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6110 samples/sec | ETA 05:23:31
2023-02-05 02:26:13 [INFO]	[TRAIN] epoch: 2731, iter: 215680/250000, loss: 0.1934, lr: 0.001674, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6042 samples/sec | ETA 05:23:38
2023-02-05 02:26:18 [INFO]	[TRAIN] epoch: 2731, iter: 215690/250000, loss: 0.2208, lr: 0.001674, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6115 samples/sec | ETA 05:23:19
2023-02-05 02:26:24 [INFO]	[TRAIN] epoch: 2731, iter: 215700/250000, loss: 0.2006, lr: 0.001674, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6080 samples/sec | ETA 05:23:20
2023-02-05 02:26:30 [INFO]	[TRAIN] epoch: 2731, iter: 215710/250000, loss: 0.1944, lr: 0.001673, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6084 samples/sec | ETA 05:23:14
2023-02-05 02:26:35 [INFO]	[TRAIN] epoch: 2731, iter: 215720/250000, loss: 0.1670, lr: 0.001673, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6047 samples/sec | ETA 05:23:15
2023-02-05 02:26:41 [INFO]	[TRAIN] epoch: 2731, iter: 215730/250000, loss: 0.1945, lr: 0.001672, batch_cost: 0.5891, reader_cost: 0.02476, ips: 10.1850 samples/sec | ETA 05:36:28
2023-02-05 02:26:47 [INFO]	[TRAIN] epoch: 2731, iter: 215740/250000, loss: 0.1848, lr: 0.001672, batch_cost: 0.5659, reader_cost: 0.00008, ips: 10.6019 samples/sec | ETA 05:23:09
2023-02-05 02:26:52 [INFO]	[TRAIN] epoch: 2732, iter: 215750/250000, loss: 0.1500, lr: 0.001671, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6212 samples/sec | ETA 05:22:28
2023-02-05 02:26:58 [INFO]	[TRAIN] epoch: 2732, iter: 215760/250000, loss: 0.2149, lr: 0.001671, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6077 samples/sec | ETA 05:22:47
2023-02-05 02:27:04 [INFO]	[TRAIN] epoch: 2732, iter: 215770/250000, loss: 0.1445, lr: 0.001670, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6091 samples/sec | ETA 05:22:38
2023-02-05 02:27:09 [INFO]	[TRAIN] epoch: 2732, iter: 215780/250000, loss: 0.1771, lr: 0.001670, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6119 samples/sec | ETA 05:22:28
2023-02-05 02:27:15 [INFO]	[TRAIN] epoch: 2732, iter: 215790/250000, loss: 0.1960, lr: 0.001670, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6139 samples/sec | ETA 05:22:18
2023-02-05 02:27:21 [INFO]	[TRAIN] epoch: 2732, iter: 215800/250000, loss: 0.1691, lr: 0.001669, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6123 samples/sec | ETA 05:22:16
2023-02-05 02:27:27 [INFO]	[TRAIN] epoch: 2732, iter: 215810/250000, loss: 0.2107, lr: 0.001669, batch_cost: 0.5910, reader_cost: 0.02665, ips: 10.1522 samples/sec | ETA 05:36:46
2023-02-05 02:27:32 [INFO]	[TRAIN] epoch: 2732, iter: 215820/250000, loss: 0.2138, lr: 0.001668, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6081 samples/sec | ETA 05:22:12
2023-02-05 02:27:38 [INFO]	[TRAIN] epoch: 2733, iter: 215830/250000, loss: 0.1770, lr: 0.001668, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5969 samples/sec | ETA 05:22:27
2023-02-05 02:27:44 [INFO]	[TRAIN] epoch: 2733, iter: 215840/250000, loss: 0.1545, lr: 0.001667, batch_cost: 0.5660, reader_cost: 0.00008, ips: 10.6010 samples/sec | ETA 05:22:13
2023-02-05 02:27:49 [INFO]	[TRAIN] epoch: 2733, iter: 215850/250000, loss: 0.1876, lr: 0.001667, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6070 samples/sec | ETA 05:21:57
2023-02-05 02:27:55 [INFO]	[TRAIN] epoch: 2733, iter: 215860/250000, loss: 0.2152, lr: 0.001666, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6139 samples/sec | ETA 05:21:39
2023-02-05 02:28:00 [INFO]	[TRAIN] epoch: 2733, iter: 215870/250000, loss: 0.1721, lr: 0.001666, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6041 samples/sec | ETA 05:21:51
2023-02-05 02:28:06 [INFO]	[TRAIN] epoch: 2733, iter: 215880/250000, loss: 0.2094, lr: 0.001666, batch_cost: 0.5941, reader_cost: 0.02840, ips: 10.0987 samples/sec | ETA 05:37:51
2023-02-05 02:28:12 [INFO]	[TRAIN] epoch: 2733, iter: 215890/250000, loss: 0.1624, lr: 0.001665, batch_cost: 0.5643, reader_cost: 0.00016, ips: 10.6319 samples/sec | ETA 05:20:49
2023-02-05 02:28:18 [INFO]	[TRAIN] epoch: 2733, iter: 215900/250000, loss: 0.1892, lr: 0.001665, batch_cost: 0.5648, reader_cost: 0.00008, ips: 10.6234 samples/sec | ETA 05:20:59
2023-02-05 02:28:23 [INFO]	[TRAIN] epoch: 2734, iter: 215910/250000, loss: 0.1887, lr: 0.001664, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6066 samples/sec | ETA 05:21:24
2023-02-05 02:28:29 [INFO]	[TRAIN] epoch: 2734, iter: 215920/250000, loss: 0.1948, lr: 0.001664, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6124 samples/sec | ETA 05:21:08
2023-02-05 02:28:35 [INFO]	[TRAIN] epoch: 2734, iter: 215930/250000, loss: 0.1373, lr: 0.001663, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6101 samples/sec | ETA 05:21:06
2023-02-05 02:28:40 [INFO]	[TRAIN] epoch: 2734, iter: 215940/250000, loss: 0.2277, lr: 0.001663, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6079 samples/sec | ETA 05:21:04
2023-02-05 02:28:46 [INFO]	[TRAIN] epoch: 2734, iter: 215950/250000, loss: 0.2520, lr: 0.001663, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6110 samples/sec | ETA 05:20:53
2023-02-05 02:28:52 [INFO]	[TRAIN] epoch: 2734, iter: 215960/250000, loss: 0.1872, lr: 0.001662, batch_cost: 0.5907, reader_cost: 0.02488, ips: 10.1573 samples/sec | ETA 05:35:07
2023-02-05 02:28:58 [INFO]	[TRAIN] epoch: 2734, iter: 215970/250000, loss: 0.1606, lr: 0.001662, batch_cost: 0.5658, reader_cost: 0.00014, ips: 10.6038 samples/sec | ETA 05:20:55
2023-02-05 02:29:03 [INFO]	[TRAIN] epoch: 2734, iter: 215980/250000, loss: 0.1759, lr: 0.001661, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6042 samples/sec | ETA 05:20:48
2023-02-05 02:29:09 [INFO]	[TRAIN] epoch: 2735, iter: 215990/250000, loss: 0.1397, lr: 0.001661, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6107 samples/sec | ETA 05:20:31
2023-02-05 02:29:15 [INFO]	[TRAIN] epoch: 2735, iter: 216000/250000, loss: 0.2045, lr: 0.001660, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6085 samples/sec | ETA 05:20:29
2023-02-05 02:29:15 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1249 - reader cost: 0.0245 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1510 - reader cost: 0.0123 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1576 - reader cost: 0.0082 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1579 - reader cost: 0.0062 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1589 - reader cost: 0.0050 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1610 - reader cost: 0.0042 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1608 - reader cost: 0.0036 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1610 - reader cost: 0.0031 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1625 - reader cost: 0.002810/36 [=======>......................] - ETA: 4s - batch_cost: 0.1627 - reader cost: 0.002511/36 [========>.....................] - ETA: 4s - batch_cost: 0.1634 - reader cost: 0.002312/36 [=========>....................] - ETA: 3s - batch_cost: 0.1630 - reader cost: 0.002113/36 [=========>....................] - ETA: 3s - batch_cost: 0.1634 - reader cost: 0.002014/36 [==========>...................] - ETA: 3s - batch_cost: 0.1637 - reader cost: 0.001815/36 [===========>..................] - ETA: 3s - batch_cost: 0.1636 - reader cost: 0.001716/36 [============>.................] - ETA: 3s - batch_cost: 0.1643 - reader cost: 0.001617/36 [=============>................] - ETA: 3s - batch_cost: 0.1645 - reader cost: 0.001518/36 [==============>...............] - ETA: 2s - batch_cost: 0.1646 - reader cost: 0.001419/36 [==============>...............] - ETA: 2s - batch_cost: 0.1646 - reader cost: 0.001420/36 [===============>..............] - ETA: 2s - batch_cost: 0.1647 - reader cost: 0.001321/36 [================>.............] - ETA: 2s - batch_cost: 0.1649 - reader cost: 0.001222/36 [=================>............] - ETA: 2s - batch_cost: 0.1651 - reader cost: 0.001223/36 [==================>...........] - ETA: 2s - batch_cost: 0.1655 - reader cost: 0.001124/36 [===================>..........] - ETA: 1s - batch_cost: 0.1655 - reader cost: 0.001125/36 [===================>..........] - ETA: 1s - batch_cost: 0.1656 - reader cost: 0.001126/36 [====================>.........] - ETA: 1s - batch_cost: 0.1656 - reader cost: 0.001027/36 [=====================>........] - ETA: 1s - batch_cost: 0.1655 - reader cost: 9.8366e-0428/36 [======================>.......] - ETA: 1s - batch_cost: 0.1656 - reader cost: 9.5102e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1655 - reader cost: 9.2115e-0430/36 [========================>.....] - ETA: 0s - batch_cost: 0.1654 - reader cost: 8.9285e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1654 - reader cost: 8.6679e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1652 - reader cost: 8.4236e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1651 - reader cost: 8.1875e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1651 - reader cost: 7.9644e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1650 - reader cost: 7.7551e-0436/36 [==============================] - 6s 165ms/step - batch_cost: 0.1650 - reader cost: 7.5556e-04
2023-02-05 02:29:20 [INFO]	[EVAL] #Images: 36 mIoU: 0.8566 Acc: 0.9850 Kappa: 0.9457 Dice: 0.9192
2023-02-05 02:29:20 [INFO]	[EVAL] Class IoU: 
[0.9844 0.9166 0.8831 0.7303 0.6876 0.9693 0.8252]
2023-02-05 02:29:20 [INFO]	[EVAL] Class Precision: 
[0.9919 0.9589 0.9406 0.8408 0.8126 0.9758 0.9215]
2023-02-05 02:29:20 [INFO]	[EVAL] Class Recall: 
[0.9924 0.9541 0.9353 0.8475 0.8173 0.9932 0.8875]
2023-02-05 02:29:21 [INFO]	[EVAL] The model with the best validation mIoU (0.8617) was saved at iter 214000.
2023-02-05 02:29:26 [INFO]	[TRAIN] epoch: 2735, iter: 216010/250000, loss: 0.1699, lr: 0.001660, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6410 samples/sec | ETA 05:19:25
2023-02-05 02:29:32 [INFO]	[TRAIN] epoch: 2735, iter: 216020/250000, loss: 0.1589, lr: 0.001659, batch_cost: 0.5636, reader_cost: 0.00009, ips: 10.6463 samples/sec | ETA 05:19:10
2023-02-05 02:29:38 [INFO]	[TRAIN] epoch: 2735, iter: 216030/250000, loss: 0.1786, lr: 0.001659, batch_cost: 0.5638, reader_cost: 0.00010, ips: 10.6412 samples/sec | ETA 05:19:13
2023-02-05 02:29:44 [INFO]	[TRAIN] epoch: 2735, iter: 216040/250000, loss: 0.1818, lr: 0.001659, batch_cost: 0.5951, reader_cost: 0.03081, ips: 10.0825 samples/sec | ETA 05:36:49
2023-02-05 02:29:49 [INFO]	[TRAIN] epoch: 2735, iter: 216050/250000, loss: 0.1728, lr: 0.001658, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6340 samples/sec | ETA 05:19:15
2023-02-05 02:29:55 [INFO]	[TRAIN] epoch: 2735, iter: 216060/250000, loss: 0.2485, lr: 0.001658, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6375 samples/sec | ETA 05:19:03
2023-02-05 02:30:01 [INFO]	[TRAIN] epoch: 2736, iter: 216070/250000, loss: 0.1939, lr: 0.001657, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6280 samples/sec | ETA 05:19:15
2023-02-05 02:30:06 [INFO]	[TRAIN] epoch: 2736, iter: 216080/250000, loss: 0.2065, lr: 0.001657, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6388 samples/sec | ETA 05:18:49
2023-02-05 02:30:12 [INFO]	[TRAIN] epoch: 2736, iter: 216090/250000, loss: 0.1958, lr: 0.001656, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6411 samples/sec | ETA 05:18:40
2023-02-05 02:30:17 [INFO]	[TRAIN] epoch: 2736, iter: 216100/250000, loss: 0.1765, lr: 0.001656, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6388 samples/sec | ETA 05:18:38
2023-02-05 02:30:23 [INFO]	[TRAIN] epoch: 2736, iter: 216110/250000, loss: 0.2110, lr: 0.001656, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6259 samples/sec | ETA 05:18:56
2023-02-05 02:30:29 [INFO]	[TRAIN] epoch: 2736, iter: 216120/250000, loss: 0.1695, lr: 0.001655, batch_cost: 0.5899, reader_cost: 0.02592, ips: 10.1719 samples/sec | ETA 05:33:04
2023-02-05 02:30:35 [INFO]	[TRAIN] epoch: 2736, iter: 216130/250000, loss: 0.1739, lr: 0.001655, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6406 samples/sec | ETA 05:18:18
2023-02-05 02:30:40 [INFO]	[TRAIN] epoch: 2736, iter: 216140/250000, loss: 0.2200, lr: 0.001654, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6379 samples/sec | ETA 05:18:17
2023-02-05 02:30:46 [INFO]	[TRAIN] epoch: 2737, iter: 216150/250000, loss: 0.1653, lr: 0.001654, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6336 samples/sec | ETA 05:18:19
2023-02-05 02:30:52 [INFO]	[TRAIN] epoch: 2737, iter: 216160/250000, loss: 0.1632, lr: 0.001653, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6294 samples/sec | ETA 05:18:21
2023-02-05 02:30:57 [INFO]	[TRAIN] epoch: 2737, iter: 216170/250000, loss: 0.2140, lr: 0.001653, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6318 samples/sec | ETA 05:18:11
2023-02-05 02:31:03 [INFO]	[TRAIN] epoch: 2737, iter: 216180/250000, loss: 0.1850, lr: 0.001652, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6340 samples/sec | ETA 05:18:02
2023-02-05 02:31:09 [INFO]	[TRAIN] epoch: 2737, iter: 216190/250000, loss: 0.2846, lr: 0.001652, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6188 samples/sec | ETA 05:18:23
2023-02-05 02:31:14 [INFO]	[TRAIN] epoch: 2737, iter: 216200/250000, loss: 0.2129, lr: 0.001652, batch_cost: 0.5888, reader_cost: 0.02358, ips: 10.1907 samples/sec | ETA 05:31:40
2023-02-05 02:31:20 [INFO]	[TRAIN] epoch: 2737, iter: 216210/250000, loss: 0.2084, lr: 0.001651, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6229 samples/sec | ETA 05:18:05
2023-02-05 02:31:26 [INFO]	[TRAIN] epoch: 2737, iter: 216220/250000, loss: 0.2231, lr: 0.001651, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6370 samples/sec | ETA 05:17:34
2023-02-05 02:31:31 [INFO]	[TRAIN] epoch: 2738, iter: 216230/250000, loss: 0.2168, lr: 0.001650, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6370 samples/sec | ETA 05:17:28
2023-02-05 02:31:37 [INFO]	[TRAIN] epoch: 2738, iter: 216240/250000, loss: 0.2073, lr: 0.001650, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5951 samples/sec | ETA 05:18:38
2023-02-05 02:31:43 [INFO]	[TRAIN] epoch: 2738, iter: 216250/250000, loss: 0.1714, lr: 0.001649, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6045 samples/sec | ETA 05:18:15
2023-02-05 02:31:48 [INFO]	[TRAIN] epoch: 2738, iter: 216260/250000, loss: 0.2224, lr: 0.001649, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6167 samples/sec | ETA 05:17:47
2023-02-05 02:31:54 [INFO]	[TRAIN] epoch: 2738, iter: 216270/250000, loss: 0.2737, lr: 0.001648, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6042 samples/sec | ETA 05:18:04
2023-02-05 02:32:00 [INFO]	[TRAIN] epoch: 2738, iter: 216280/250000, loss: 0.1525, lr: 0.001648, batch_cost: 0.5953, reader_cost: 0.02994, ips: 10.0783 samples/sec | ETA 05:34:34
2023-02-05 02:32:06 [INFO]	[TRAIN] epoch: 2738, iter: 216290/250000, loss: 0.2025, lr: 0.001648, batch_cost: 0.5657, reader_cost: 0.00013, ips: 10.6070 samples/sec | ETA 05:17:48
2023-02-05 02:32:11 [INFO]	[TRAIN] epoch: 2738, iter: 216300/250000, loss: 0.1990, lr: 0.001647, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6058 samples/sec | ETA 05:17:44
2023-02-05 02:32:17 [INFO]	[TRAIN] epoch: 2739, iter: 216310/250000, loss: 0.2694, lr: 0.001647, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6152 samples/sec | ETA 05:17:22
2023-02-05 02:32:23 [INFO]	[TRAIN] epoch: 2739, iter: 216320/250000, loss: 0.1862, lr: 0.001646, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6079 samples/sec | ETA 05:17:29
2023-02-05 02:32:28 [INFO]	[TRAIN] epoch: 2739, iter: 216330/250000, loss: 0.1745, lr: 0.001646, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6076 samples/sec | ETA 05:17:24
2023-02-05 02:32:34 [INFO]	[TRAIN] epoch: 2739, iter: 216340/250000, loss: 0.2389, lr: 0.001645, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6118 samples/sec | ETA 05:17:11
2023-02-05 02:32:39 [INFO]	[TRAIN] epoch: 2739, iter: 216350/250000, loss: 0.1827, lr: 0.001645, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6105 samples/sec | ETA 05:17:08
2023-02-05 02:32:45 [INFO]	[TRAIN] epoch: 2739, iter: 216360/250000, loss: 0.2040, lr: 0.001645, batch_cost: 0.5898, reader_cost: 0.02538, ips: 10.1728 samples/sec | ETA 05:30:41
2023-02-05 02:32:51 [INFO]	[TRAIN] epoch: 2739, iter: 216370/250000, loss: 0.1857, lr: 0.001644, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6340 samples/sec | ETA 05:16:14
2023-02-05 02:32:57 [INFO]	[TRAIN] epoch: 2739, iter: 216380/250000, loss: 0.1763, lr: 0.001644, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6288 samples/sec | ETA 05:16:18
2023-02-05 02:33:02 [INFO]	[TRAIN] epoch: 2740, iter: 216390/250000, loss: 0.1920, lr: 0.001643, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6283 samples/sec | ETA 05:16:13
2023-02-05 02:33:08 [INFO]	[TRAIN] epoch: 2740, iter: 216400/250000, loss: 0.2078, lr: 0.001643, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6407 samples/sec | ETA 05:15:46
2023-02-05 02:33:14 [INFO]	[TRAIN] epoch: 2740, iter: 216410/250000, loss: 0.1674, lr: 0.001642, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6389 samples/sec | ETA 05:15:43
2023-02-05 02:33:19 [INFO]	[TRAIN] epoch: 2740, iter: 216420/250000, loss: 0.1751, lr: 0.001642, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6334 samples/sec | ETA 05:15:47
2023-02-05 02:33:25 [INFO]	[TRAIN] epoch: 2740, iter: 216430/250000, loss: 0.2377, lr: 0.001641, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6280 samples/sec | ETA 05:15:51
2023-02-05 02:33:31 [INFO]	[TRAIN] epoch: 2740, iter: 216440/250000, loss: 0.1676, lr: 0.001641, batch_cost: 0.5882, reader_cost: 0.02426, ips: 10.2003 samples/sec | ETA 05:29:00
2023-02-05 02:33:36 [INFO]	[TRAIN] epoch: 2740, iter: 216450/250000, loss: 0.2132, lr: 0.001641, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6042 samples/sec | ETA 05:16:23
2023-02-05 02:33:42 [INFO]	[TRAIN] epoch: 2740, iter: 216460/250000, loss: 0.1877, lr: 0.001640, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6091 samples/sec | ETA 05:16:08
2023-02-05 02:33:48 [INFO]	[TRAIN] epoch: 2741, iter: 216470/250000, loss: 0.1899, lr: 0.001640, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6103 samples/sec | ETA 05:16:00
2023-02-05 02:33:53 [INFO]	[TRAIN] epoch: 2741, iter: 216480/250000, loss: 0.1544, lr: 0.001639, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6084 samples/sec | ETA 05:15:58
2023-02-05 02:33:59 [INFO]	[TRAIN] epoch: 2741, iter: 216490/250000, loss: 0.1643, lr: 0.001639, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6072 samples/sec | ETA 05:15:54
2023-02-05 02:34:05 [INFO]	[TRAIN] epoch: 2741, iter: 216500/250000, loss: 0.1876, lr: 0.001638, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6107 samples/sec | ETA 05:15:43
2023-02-05 02:34:10 [INFO]	[TRAIN] epoch: 2741, iter: 216510/250000, loss: 0.2011, lr: 0.001638, batch_cost: 0.5659, reader_cost: 0.00011, ips: 10.6031 samples/sec | ETA 05:15:50
2023-02-05 02:34:16 [INFO]	[TRAIN] epoch: 2741, iter: 216520/250000, loss: 0.2111, lr: 0.001637, batch_cost: 0.5867, reader_cost: 0.02233, ips: 10.2268 samples/sec | ETA 05:27:22
2023-02-05 02:34:22 [INFO]	[TRAIN] epoch: 2741, iter: 216530/250000, loss: 0.1871, lr: 0.001637, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6282 samples/sec | ETA 05:14:55
2023-02-05 02:34:28 [INFO]	[TRAIN] epoch: 2742, iter: 216540/250000, loss: 0.1500, lr: 0.001637, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6180 samples/sec | ETA 05:15:07
2023-02-05 02:34:33 [INFO]	[TRAIN] epoch: 2742, iter: 216550/250000, loss: 0.1550, lr: 0.001636, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6119 samples/sec | ETA 05:15:12
2023-02-05 02:34:39 [INFO]	[TRAIN] epoch: 2742, iter: 216560/250000, loss: 0.2115, lr: 0.001636, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6115 samples/sec | ETA 05:15:07
2023-02-05 02:34:45 [INFO]	[TRAIN] epoch: 2742, iter: 216570/250000, loss: 0.1703, lr: 0.001635, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 05:15:11
2023-02-05 02:34:50 [INFO]	[TRAIN] epoch: 2742, iter: 216580/250000, loss: 0.1484, lr: 0.001635, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6026 samples/sec | ETA 05:15:12
2023-02-05 02:34:56 [INFO]	[TRAIN] epoch: 2742, iter: 216590/250000, loss: 0.1688, lr: 0.001634, batch_cost: 0.5652, reader_cost: 0.00008, ips: 10.6164 samples/sec | ETA 05:14:42
2023-02-05 02:35:02 [INFO]	[TRAIN] epoch: 2742, iter: 216600/250000, loss: 0.1826, lr: 0.001634, batch_cost: 0.5927, reader_cost: 0.02858, ips: 10.1232 samples/sec | ETA 05:29:56
2023-02-05 02:35:07 [INFO]	[TRAIN] epoch: 2742, iter: 216610/250000, loss: 0.2094, lr: 0.001634, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6385 samples/sec | ETA 05:13:51
2023-02-05 02:35:13 [INFO]	[TRAIN] epoch: 2743, iter: 216620/250000, loss: 0.1569, lr: 0.001633, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6332 samples/sec | ETA 05:13:55
2023-02-05 02:35:19 [INFO]	[TRAIN] epoch: 2743, iter: 216630/250000, loss: 0.2290, lr: 0.001633, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6238 samples/sec | ETA 05:14:06
2023-02-05 02:35:24 [INFO]	[TRAIN] epoch: 2743, iter: 216640/250000, loss: 0.2634, lr: 0.001632, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6124 samples/sec | ETA 05:14:21
2023-02-05 02:35:30 [INFO]	[TRAIN] epoch: 2743, iter: 216650/250000, loss: 0.1764, lr: 0.001632, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6040 samples/sec | ETA 05:14:30
2023-02-05 02:35:36 [INFO]	[TRAIN] epoch: 2743, iter: 216660/250000, loss: 0.1331, lr: 0.001631, batch_cost: 0.5657, reader_cost: 0.00011, ips: 10.6058 samples/sec | ETA 05:14:21
2023-02-05 02:35:42 [INFO]	[TRAIN] epoch: 2743, iter: 216670/250000, loss: 0.2384, lr: 0.001631, batch_cost: 0.5986, reader_cost: 0.03300, ips: 10.0229 samples/sec | ETA 05:32:32
2023-02-05 02:35:47 [INFO]	[TRAIN] epoch: 2743, iter: 216680/250000, loss: 0.1706, lr: 0.001630, batch_cost: 0.5654, reader_cost: 0.00014, ips: 10.6117 samples/sec | ETA 05:13:59
2023-02-05 02:35:53 [INFO]	[TRAIN] epoch: 2743, iter: 216690/250000, loss: 0.1810, lr: 0.001630, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6366 samples/sec | ETA 05:13:09
2023-02-05 02:35:59 [INFO]	[TRAIN] epoch: 2744, iter: 216700/250000, loss: 0.1958, lr: 0.001630, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6078 samples/sec | ETA 05:13:55
2023-02-05 02:36:04 [INFO]	[TRAIN] epoch: 2744, iter: 216710/250000, loss: 0.1932, lr: 0.001629, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5981 samples/sec | ETA 05:14:06
2023-02-05 02:36:10 [INFO]	[TRAIN] epoch: 2744, iter: 216720/250000, loss: 0.2151, lr: 0.001629, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 05:13:46
2023-02-05 02:36:16 [INFO]	[TRAIN] epoch: 2744, iter: 216730/250000, loss: 0.2679, lr: 0.001628, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6104 samples/sec | ETA 05:13:33
2023-02-05 02:36:21 [INFO]	[TRAIN] epoch: 2744, iter: 216740/250000, loss: 0.1899, lr: 0.001628, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6059 samples/sec | ETA 05:13:35
2023-02-05 02:36:27 [INFO]	[TRAIN] epoch: 2744, iter: 216750/250000, loss: 0.1669, lr: 0.001627, batch_cost: 0.5968, reader_cost: 0.03159, ips: 10.0532 samples/sec | ETA 05:30:44
2023-02-05 02:36:33 [INFO]	[TRAIN] epoch: 2744, iter: 216760/250000, loss: 0.1964, lr: 0.001627, batch_cost: 0.5648, reader_cost: 0.00011, ips: 10.6239 samples/sec | ETA 05:12:52
2023-02-05 02:36:38 [INFO]	[TRAIN] epoch: 2744, iter: 216770/250000, loss: 0.2547, lr: 0.001626, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6067 samples/sec | ETA 05:13:17
2023-02-05 02:36:44 [INFO]	[TRAIN] epoch: 2745, iter: 216780/250000, loss: 0.1620, lr: 0.001626, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6069 samples/sec | ETA 05:13:11
2023-02-05 02:36:50 [INFO]	[TRAIN] epoch: 2745, iter: 216790/250000, loss: 0.2966, lr: 0.001626, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6119 samples/sec | ETA 05:12:57
2023-02-05 02:36:55 [INFO]	[TRAIN] epoch: 2745, iter: 216800/250000, loss: 0.1919, lr: 0.001625, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6127 samples/sec | ETA 05:12:49
2023-02-05 02:37:01 [INFO]	[TRAIN] epoch: 2745, iter: 216810/250000, loss: 0.1565, lr: 0.001625, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6022 samples/sec | ETA 05:13:02
2023-02-05 02:37:07 [INFO]	[TRAIN] epoch: 2745, iter: 216820/250000, loss: 0.2500, lr: 0.001624, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6036 samples/sec | ETA 05:12:54
2023-02-05 02:37:13 [INFO]	[TRAIN] epoch: 2745, iter: 216830/250000, loss: 0.1649, lr: 0.001624, batch_cost: 0.5998, reader_cost: 0.03451, ips: 10.0033 samples/sec | ETA 05:31:35
2023-02-05 02:37:18 [INFO]	[TRAIN] epoch: 2745, iter: 216840/250000, loss: 0.1946, lr: 0.001623, batch_cost: 0.5651, reader_cost: 0.00013, ips: 10.6185 samples/sec | ETA 05:12:17
2023-02-05 02:37:24 [INFO]	[TRAIN] epoch: 2745, iter: 216850/250000, loss: 0.2170, lr: 0.001623, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6310 samples/sec | ETA 05:11:49
2023-02-05 02:37:30 [INFO]	[TRAIN] epoch: 2746, iter: 216860/250000, loss: 0.2041, lr: 0.001622, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6253 samples/sec | ETA 05:11:53
2023-02-05 02:37:35 [INFO]	[TRAIN] epoch: 2746, iter: 216870/250000, loss: 0.1872, lr: 0.001622, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6057 samples/sec | ETA 05:12:22
2023-02-05 02:37:41 [INFO]	[TRAIN] epoch: 2746, iter: 216880/250000, loss: 0.2340, lr: 0.001622, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6000 samples/sec | ETA 05:12:27
2023-02-05 02:37:47 [INFO]	[TRAIN] epoch: 2746, iter: 216890/250000, loss: 0.1799, lr: 0.001621, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6018 samples/sec | ETA 05:12:18
2023-02-05 02:37:52 [INFO]	[TRAIN] epoch: 2746, iter: 216900/250000, loss: 0.1572, lr: 0.001621, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6039 samples/sec | ETA 05:12:09
2023-02-05 02:37:58 [INFO]	[TRAIN] epoch: 2746, iter: 216910/250000, loss: 0.1759, lr: 0.001620, batch_cost: 0.5974, reader_cost: 0.03242, ips: 10.0431 samples/sec | ETA 05:29:28
2023-02-05 02:38:04 [INFO]	[TRAIN] epoch: 2746, iter: 216920/250000, loss: 0.1365, lr: 0.001620, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6008 samples/sec | ETA 05:12:03
2023-02-05 02:38:10 [INFO]	[TRAIN] epoch: 2746, iter: 216930/250000, loss: 0.2057, lr: 0.001619, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6054 samples/sec | ETA 05:11:49
2023-02-05 02:38:15 [INFO]	[TRAIN] epoch: 2747, iter: 216940/250000, loss: 0.2268, lr: 0.001619, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6013 samples/sec | ETA 05:11:50
2023-02-05 02:38:21 [INFO]	[TRAIN] epoch: 2747, iter: 216950/250000, loss: 0.1562, lr: 0.001619, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6100 samples/sec | ETA 05:11:29
2023-02-05 02:38:27 [INFO]	[TRAIN] epoch: 2747, iter: 216960/250000, loss: 0.2283, lr: 0.001618, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6100 samples/sec | ETA 05:11:24
2023-02-05 02:38:32 [INFO]	[TRAIN] epoch: 2747, iter: 216970/250000, loss: 0.1800, lr: 0.001618, batch_cost: 0.5660, reader_cost: 0.00008, ips: 10.6013 samples/sec | ETA 05:11:33
2023-02-05 02:38:38 [INFO]	[TRAIN] epoch: 2747, iter: 216980/250000, loss: 0.1929, lr: 0.001617, batch_cost: 0.5663, reader_cost: 0.00008, ips: 10.5959 samples/sec | ETA 05:11:37
2023-02-05 02:38:44 [INFO]	[TRAIN] epoch: 2747, iter: 216990/250000, loss: 0.2632, lr: 0.001617, batch_cost: 0.5966, reader_cost: 0.03128, ips: 10.0566 samples/sec | ETA 05:28:14
2023-02-05 02:38:50 [INFO]	[TRAIN] epoch: 2747, iter: 217000/250000, loss: 0.2155, lr: 0.001616, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6292 samples/sec | ETA 05:10:27
2023-02-05 02:38:55 [INFO]	[TRAIN] epoch: 2747, iter: 217010/250000, loss: 0.2409, lr: 0.001616, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6374 samples/sec | ETA 05:10:07
2023-02-05 02:39:01 [INFO]	[TRAIN] epoch: 2748, iter: 217020/250000, loss: 0.1943, lr: 0.001615, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6270 samples/sec | ETA 05:10:20
2023-02-05 02:39:06 [INFO]	[TRAIN] epoch: 2748, iter: 217030/250000, loss: 0.2207, lr: 0.001615, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6040 samples/sec | ETA 05:10:55
2023-02-05 02:39:12 [INFO]	[TRAIN] epoch: 2748, iter: 217040/250000, loss: 0.2011, lr: 0.001615, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6177 samples/sec | ETA 05:10:25
2023-02-05 02:39:18 [INFO]	[TRAIN] epoch: 2748, iter: 217050/250000, loss: 0.1814, lr: 0.001614, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6076 samples/sec | ETA 05:10:37
2023-02-05 02:39:23 [INFO]	[TRAIN] epoch: 2748, iter: 217060/250000, loss: 0.1775, lr: 0.001614, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6011 samples/sec | ETA 05:10:43
2023-02-05 02:39:29 [INFO]	[TRAIN] epoch: 2748, iter: 217070/250000, loss: 0.1637, lr: 0.001613, batch_cost: 0.5945, reader_cost: 0.02916, ips: 10.0928 samples/sec | ETA 05:26:16
2023-02-05 02:39:35 [INFO]	[TRAIN] epoch: 2748, iter: 217080/250000, loss: 0.1732, lr: 0.001613, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6205 samples/sec | ETA 05:09:57
2023-02-05 02:39:41 [INFO]	[TRAIN] epoch: 2748, iter: 217090/250000, loss: 0.1785, lr: 0.001612, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6092 samples/sec | ETA 05:10:12
2023-02-05 02:39:46 [INFO]	[TRAIN] epoch: 2749, iter: 217100/250000, loss: 0.1591, lr: 0.001612, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6086 samples/sec | ETA 05:10:07
2023-02-05 02:39:52 [INFO]	[TRAIN] epoch: 2749, iter: 217110/250000, loss: 0.1632, lr: 0.001611, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6089 samples/sec | ETA 05:10:01
2023-02-05 02:39:58 [INFO]	[TRAIN] epoch: 2749, iter: 217120/250000, loss: 0.1769, lr: 0.001611, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6068 samples/sec | ETA 05:09:59
2023-02-05 02:40:03 [INFO]	[TRAIN] epoch: 2749, iter: 217130/250000, loss: 0.1768, lr: 0.001611, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6107 samples/sec | ETA 05:09:46
2023-02-05 02:40:09 [INFO]	[TRAIN] epoch: 2749, iter: 217140/250000, loss: 0.1755, lr: 0.001610, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6108 samples/sec | ETA 05:09:41
2023-02-05 02:40:15 [INFO]	[TRAIN] epoch: 2749, iter: 217150/250000, loss: 0.1575, lr: 0.001610, batch_cost: 0.5951, reader_cost: 0.03014, ips: 10.0824 samples/sec | ETA 05:25:49
2023-02-05 02:40:21 [INFO]	[TRAIN] epoch: 2749, iter: 217160/250000, loss: 0.1578, lr: 0.001609, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6217 samples/sec | ETA 05:09:10
2023-02-05 02:40:26 [INFO]	[TRAIN] epoch: 2749, iter: 217170/250000, loss: 0.1911, lr: 0.001609, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6269 samples/sec | ETA 05:08:55
2023-02-05 02:40:32 [INFO]	[TRAIN] epoch: 2750, iter: 217180/250000, loss: 0.1727, lr: 0.001608, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6000 samples/sec | ETA 05:09:37
2023-02-05 02:40:38 [INFO]	[TRAIN] epoch: 2750, iter: 217190/250000, loss: 0.2110, lr: 0.001608, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6082 samples/sec | ETA 05:09:17
2023-02-05 02:40:43 [INFO]	[TRAIN] epoch: 2750, iter: 217200/250000, loss: 0.2163, lr: 0.001608, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6160 samples/sec | ETA 05:08:58
2023-02-05 02:40:49 [INFO]	[TRAIN] epoch: 2750, iter: 217210/250000, loss: 0.2020, lr: 0.001607, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5944 samples/sec | ETA 05:09:30
2023-02-05 02:40:55 [INFO]	[TRAIN] epoch: 2750, iter: 217220/250000, loss: 0.2223, lr: 0.001607, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6000 samples/sec | ETA 05:09:14
2023-02-05 02:41:01 [INFO]	[TRAIN] epoch: 2750, iter: 217230/250000, loss: 0.2629, lr: 0.001606, batch_cost: 0.5970, reader_cost: 0.03236, ips: 10.0504 samples/sec | ETA 05:26:03
2023-02-05 02:41:06 [INFO]	[TRAIN] epoch: 2750, iter: 217240/250000, loss: 0.3375, lr: 0.001606, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6365 samples/sec | ETA 05:07:59
2023-02-05 02:41:12 [INFO]	[TRAIN] epoch: 2750, iter: 217250/250000, loss: 0.2042, lr: 0.001605, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6362 samples/sec | ETA 05:07:54
2023-02-05 02:41:17 [INFO]	[TRAIN] epoch: 2751, iter: 217260/250000, loss: 0.1744, lr: 0.001605, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6246 samples/sec | ETA 05:08:09
2023-02-05 02:41:23 [INFO]	[TRAIN] epoch: 2751, iter: 217270/250000, loss: 0.1966, lr: 0.001604, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6287 samples/sec | ETA 05:07:56
2023-02-05 02:41:29 [INFO]	[TRAIN] epoch: 2751, iter: 217280/250000, loss: 0.2017, lr: 0.001604, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6298 samples/sec | ETA 05:07:48
2023-02-05 02:41:34 [INFO]	[TRAIN] epoch: 2751, iter: 217290/250000, loss: 0.2336, lr: 0.001604, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6142 samples/sec | ETA 05:08:10
2023-02-05 02:41:40 [INFO]	[TRAIN] epoch: 2751, iter: 217300/250000, loss: 0.1998, lr: 0.001603, batch_cost: 0.5665, reader_cost: 0.00009, ips: 10.5913 samples/sec | ETA 05:08:44
2023-02-05 02:41:46 [INFO]	[TRAIN] epoch: 2751, iter: 217310/250000, loss: 0.2060, lr: 0.001603, batch_cost: 0.5901, reader_cost: 0.02545, ips: 10.1676 samples/sec | ETA 05:21:30
2023-02-05 02:41:52 [INFO]	[TRAIN] epoch: 2751, iter: 217320/250000, loss: 0.2224, lr: 0.001602, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6277 samples/sec | ETA 05:07:29
2023-02-05 02:41:57 [INFO]	[TRAIN] epoch: 2752, iter: 217330/250000, loss: 0.2128, lr: 0.001602, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6240 samples/sec | ETA 05:07:30
2023-02-05 02:42:03 [INFO]	[TRAIN] epoch: 2752, iter: 217340/250000, loss: 0.2518, lr: 0.001601, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6229 samples/sec | ETA 05:07:26
2023-02-05 02:42:09 [INFO]	[TRAIN] epoch: 2752, iter: 217350/250000, loss: 0.2303, lr: 0.001601, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6154 samples/sec | ETA 05:07:34
2023-02-05 02:42:14 [INFO]	[TRAIN] epoch: 2752, iter: 217360/250000, loss: 0.1735, lr: 0.001600, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6046 samples/sec | ETA 05:07:47
2023-02-05 02:42:20 [INFO]	[TRAIN] epoch: 2752, iter: 217370/250000, loss: 0.1914, lr: 0.001600, batch_cost: 0.5652, reader_cost: 0.00008, ips: 10.6153 samples/sec | ETA 05:07:23
2023-02-05 02:42:26 [INFO]	[TRAIN] epoch: 2752, iter: 217380/250000, loss: 0.1509, lr: 0.001600, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6058 samples/sec | ETA 05:07:34
2023-02-05 02:42:31 [INFO]	[TRAIN] epoch: 2752, iter: 217390/250000, loss: 0.2057, lr: 0.001599, batch_cost: 0.5926, reader_cost: 0.02667, ips: 10.1249 samples/sec | ETA 05:22:04
2023-02-05 02:42:37 [INFO]	[TRAIN] epoch: 2752, iter: 217400/250000, loss: 0.1555, lr: 0.001599, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6368 samples/sec | ETA 05:06:28
2023-02-05 02:42:43 [INFO]	[TRAIN] epoch: 2753, iter: 217410/250000, loss: 0.2056, lr: 0.001598, batch_cost: 0.5638, reader_cost: 0.00008, ips: 10.6417 samples/sec | ETA 05:06:14
2023-02-05 02:42:48 [INFO]	[TRAIN] epoch: 2753, iter: 217420/250000, loss: 0.1767, lr: 0.001598, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6372 samples/sec | ETA 05:06:16
2023-02-05 02:42:54 [INFO]	[TRAIN] epoch: 2753, iter: 217430/250000, loss: 0.1772, lr: 0.001597, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6227 samples/sec | ETA 05:06:36
2023-02-05 02:43:00 [INFO]	[TRAIN] epoch: 2753, iter: 217440/250000, loss: 0.2297, lr: 0.001597, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6272 samples/sec | ETA 05:06:23
2023-02-05 02:43:05 [INFO]	[TRAIN] epoch: 2753, iter: 217450/250000, loss: 0.1821, lr: 0.001596, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6289 samples/sec | ETA 05:06:14
2023-02-05 02:43:11 [INFO]	[TRAIN] epoch: 2753, iter: 217460/250000, loss: 0.1954, lr: 0.001596, batch_cost: 0.5927, reader_cost: 0.02774, ips: 10.1240 samples/sec | ETA 05:21:24
2023-02-05 02:43:17 [INFO]	[TRAIN] epoch: 2753, iter: 217470/250000, loss: 0.2035, lr: 0.001596, batch_cost: 0.5647, reader_cost: 0.00011, ips: 10.6259 samples/sec | ETA 05:06:08
2023-02-05 02:43:23 [INFO]	[TRAIN] epoch: 2753, iter: 217480/250000, loss: 0.1722, lr: 0.001595, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6339 samples/sec | ETA 05:05:48
2023-02-05 02:43:28 [INFO]	[TRAIN] epoch: 2754, iter: 217490/250000, loss: 0.1618, lr: 0.001595, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6248 samples/sec | ETA 05:05:58
2023-02-05 02:43:34 [INFO]	[TRAIN] epoch: 2754, iter: 217500/250000, loss: 0.1525, lr: 0.001594, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6242 samples/sec | ETA 05:05:54
2023-02-05 02:43:39 [INFO]	[TRAIN] epoch: 2754, iter: 217510/250000, loss: 0.1844, lr: 0.001594, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6222 samples/sec | ETA 05:05:52
2023-02-05 02:43:45 [INFO]	[TRAIN] epoch: 2754, iter: 217520/250000, loss: 0.1759, lr: 0.001593, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6307 samples/sec | ETA 05:05:31
2023-02-05 02:43:51 [INFO]	[TRAIN] epoch: 2754, iter: 217530/250000, loss: 0.1689, lr: 0.001593, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6294 samples/sec | ETA 05:05:28
2023-02-05 02:43:57 [INFO]	[TRAIN] epoch: 2754, iter: 217540/250000, loss: 0.1399, lr: 0.001593, batch_cost: 0.5935, reader_cost: 0.02774, ips: 10.1101 samples/sec | ETA 05:21:03
2023-02-05 02:44:02 [INFO]	[TRAIN] epoch: 2754, iter: 217550/250000, loss: 0.2053, lr: 0.001592, batch_cost: 0.5644, reader_cost: 0.00014, ips: 10.6312 samples/sec | ETA 05:05:14
2023-02-05 02:44:08 [INFO]	[TRAIN] epoch: 2754, iter: 217560/250000, loss: 0.2563, lr: 0.001592, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6253 samples/sec | ETA 05:05:18
2023-02-05 02:44:14 [INFO]	[TRAIN] epoch: 2755, iter: 217570/250000, loss: 0.2067, lr: 0.001591, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6219 samples/sec | ETA 05:05:18
2023-02-05 02:44:19 [INFO]	[TRAIN] epoch: 2755, iter: 217580/250000, loss: 0.1828, lr: 0.001591, batch_cost: 0.5647, reader_cost: 0.00008, ips: 10.6244 samples/sec | ETA 05:05:08
2023-02-05 02:44:25 [INFO]	[TRAIN] epoch: 2755, iter: 217590/250000, loss: 0.2182, lr: 0.001590, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6365 samples/sec | ETA 05:04:42
2023-02-05 02:44:31 [INFO]	[TRAIN] epoch: 2755, iter: 217600/250000, loss: 0.1739, lr: 0.001590, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6253 samples/sec | ETA 05:04:55
2023-02-05 02:44:36 [INFO]	[TRAIN] epoch: 2755, iter: 217610/250000, loss: 0.1533, lr: 0.001589, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6049 samples/sec | ETA 05:05:25
2023-02-05 02:44:42 [INFO]	[TRAIN] epoch: 2755, iter: 217620/250000, loss: 0.2092, lr: 0.001589, batch_cost: 0.5910, reader_cost: 0.02560, ips: 10.1520 samples/sec | ETA 05:18:57
2023-02-05 02:44:48 [INFO]	[TRAIN] epoch: 2755, iter: 217630/250000, loss: 0.1865, lr: 0.001589, batch_cost: 0.5647, reader_cost: 0.00013, ips: 10.6259 samples/sec | ETA 05:04:37
2023-02-05 02:44:53 [INFO]	[TRAIN] epoch: 2755, iter: 217640/250000, loss: 0.1808, lr: 0.001588, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6205 samples/sec | ETA 05:04:41
2023-02-05 02:44:59 [INFO]	[TRAIN] epoch: 2756, iter: 217650/250000, loss: 0.1823, lr: 0.001588, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6254 samples/sec | ETA 05:04:27
2023-02-05 02:45:05 [INFO]	[TRAIN] epoch: 2756, iter: 217660/250000, loss: 0.1814, lr: 0.001587, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6286 samples/sec | ETA 05:04:16
2023-02-05 02:45:10 [INFO]	[TRAIN] epoch: 2756, iter: 217670/250000, loss: 0.1478, lr: 0.001587, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6051 samples/sec | ETA 05:04:51
2023-02-05 02:45:16 [INFO]	[TRAIN] epoch: 2756, iter: 217680/250000, loss: 0.1578, lr: 0.001586, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6148 samples/sec | ETA 05:04:28
2023-02-05 02:45:22 [INFO]	[TRAIN] epoch: 2756, iter: 217690/250000, loss: 0.1591, lr: 0.001586, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6130 samples/sec | ETA 05:04:26
2023-02-05 02:45:28 [INFO]	[TRAIN] epoch: 2756, iter: 217700/250000, loss: 0.1984, lr: 0.001585, batch_cost: 0.5929, reader_cost: 0.02762, ips: 10.1197 samples/sec | ETA 05:19:10
2023-02-05 02:45:33 [INFO]	[TRAIN] epoch: 2756, iter: 217710/250000, loss: 0.1877, lr: 0.001585, batch_cost: 0.5655, reader_cost: 0.00018, ips: 10.6107 samples/sec | ETA 05:04:18
2023-02-05 02:45:39 [INFO]	[TRAIN] epoch: 2756, iter: 217720/250000, loss: 0.2116, lr: 0.001585, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6140 samples/sec | ETA 05:04:07
2023-02-05 02:45:45 [INFO]	[TRAIN] epoch: 2757, iter: 217730/250000, loss: 0.1686, lr: 0.001584, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5991 samples/sec | ETA 05:04:27
2023-02-05 02:45:50 [INFO]	[TRAIN] epoch: 2757, iter: 217740/250000, loss: 0.1536, lr: 0.001584, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6032 samples/sec | ETA 05:04:14
2023-02-05 02:45:56 [INFO]	[TRAIN] epoch: 2757, iter: 217750/250000, loss: 0.1565, lr: 0.001583, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6093 samples/sec | ETA 05:03:58
2023-02-05 02:46:02 [INFO]	[TRAIN] epoch: 2757, iter: 217760/250000, loss: 0.1764, lr: 0.001583, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6107 samples/sec | ETA 05:03:50
2023-02-05 02:46:07 [INFO]	[TRAIN] epoch: 2757, iter: 217770/250000, loss: 0.2097, lr: 0.001582, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6031 samples/sec | ETA 05:03:58
2023-02-05 02:46:13 [INFO]	[TRAIN] epoch: 2757, iter: 217780/250000, loss: 0.2109, lr: 0.001582, batch_cost: 0.5870, reader_cost: 0.02138, ips: 10.2219 samples/sec | ETA 05:15:12
2023-02-05 02:46:19 [INFO]	[TRAIN] epoch: 2757, iter: 217790/250000, loss: 0.1856, lr: 0.001581, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6317 samples/sec | ETA 05:02:57
2023-02-05 02:46:24 [INFO]	[TRAIN] epoch: 2757, iter: 217800/250000, loss: 0.1965, lr: 0.001581, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6230 samples/sec | ETA 05:03:06
2023-02-05 02:46:30 [INFO]	[TRAIN] epoch: 2758, iter: 217810/250000, loss: 0.1956, lr: 0.001581, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6266 samples/sec | ETA 05:02:55
2023-02-05 02:46:36 [INFO]	[TRAIN] epoch: 2758, iter: 217820/250000, loss: 0.1639, lr: 0.001580, batch_cost: 0.5637, reader_cost: 0.00009, ips: 10.6445 samples/sec | ETA 05:02:18
2023-02-05 02:46:41 [INFO]	[TRAIN] epoch: 2758, iter: 217830/250000, loss: 0.1628, lr: 0.001580, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6118 samples/sec | ETA 05:03:09
2023-02-05 02:46:47 [INFO]	[TRAIN] epoch: 2758, iter: 217840/250000, loss: 0.1795, lr: 0.001579, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6114 samples/sec | ETA 05:03:04
2023-02-05 02:46:53 [INFO]	[TRAIN] epoch: 2758, iter: 217850/250000, loss: 0.1666, lr: 0.001579, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6048 samples/sec | ETA 05:03:09
2023-02-05 02:46:59 [INFO]	[TRAIN] epoch: 2758, iter: 217860/250000, loss: 0.1687, lr: 0.001578, batch_cost: 0.5880, reader_cost: 0.02321, ips: 10.2045 samples/sec | ETA 05:14:57
2023-02-05 02:47:04 [INFO]	[TRAIN] epoch: 2758, iter: 217870/250000, loss: 0.1774, lr: 0.001578, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6373 samples/sec | ETA 05:02:02
2023-02-05 02:47:10 [INFO]	[TRAIN] epoch: 2758, iter: 217880/250000, loss: 0.1590, lr: 0.001577, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6349 samples/sec | ETA 05:02:01
2023-02-05 02:47:15 [INFO]	[TRAIN] epoch: 2759, iter: 217890/250000, loss: 0.1756, lr: 0.001577, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6073 samples/sec | ETA 05:02:43
2023-02-05 02:47:21 [INFO]	[TRAIN] epoch: 2759, iter: 217900/250000, loss: 0.1335, lr: 0.001577, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6047 samples/sec | ETA 05:02:41
2023-02-05 02:47:27 [INFO]	[TRAIN] epoch: 2759, iter: 217910/250000, loss: 0.1330, lr: 0.001576, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6101 samples/sec | ETA 05:02:26
2023-02-05 02:47:32 [INFO]	[TRAIN] epoch: 2759, iter: 217920/250000, loss: 0.1628, lr: 0.001576, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6070 samples/sec | ETA 05:02:26
2023-02-05 02:47:38 [INFO]	[TRAIN] epoch: 2759, iter: 217930/250000, loss: 0.1491, lr: 0.001575, batch_cost: 0.5658, reader_cost: 0.00029, ips: 10.6048 samples/sec | ETA 05:02:24
2023-02-05 02:47:44 [INFO]	[TRAIN] epoch: 2759, iter: 217940/250000, loss: 0.2161, lr: 0.001575, batch_cost: 0.5943, reader_cost: 0.02967, ips: 10.0962 samples/sec | ETA 05:17:32
2023-02-05 02:47:50 [INFO]	[TRAIN] epoch: 2759, iter: 217950/250000, loss: 0.1667, lr: 0.001574, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6313 samples/sec | ETA 05:01:28
2023-02-05 02:47:55 [INFO]	[TRAIN] epoch: 2759, iter: 217960/250000, loss: 0.3423, lr: 0.001574, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6292 samples/sec | ETA 05:01:26
2023-02-05 02:48:01 [INFO]	[TRAIN] epoch: 2760, iter: 217970/250000, loss: 0.1746, lr: 0.001574, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6309 samples/sec | ETA 05:01:17
2023-02-05 02:48:07 [INFO]	[TRAIN] epoch: 2760, iter: 217980/250000, loss: 0.1778, lr: 0.001573, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6234 samples/sec | ETA 05:01:24
2023-02-05 02:48:12 [INFO]	[TRAIN] epoch: 2760, iter: 217990/250000, loss: 0.1917, lr: 0.001573, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6104 samples/sec | ETA 05:01:41
2023-02-05 02:48:18 [INFO]	[TRAIN] epoch: 2760, iter: 218000/250000, loss: 0.2045, lr: 0.001572, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6087 samples/sec | ETA 05:01:38
2023-02-05 02:48:18 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1299 - reader cost: 0.0285 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1528 - reader cost: 0.0143 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1599 - reader cost: 0.0096 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1595 - reader cost: 0.0072 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1609 - reader cost: 0.0058 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1630 - reader cost: 0.0048 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1623 - reader cost: 0.0041 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1626 - reader cost: 0.0036 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1633 - reader cost: 0.003210/36 [=======>......................] - ETA: 4s - batch_cost: 0.1629 - reader cost: 0.002911/36 [========>.....................] - ETA: 4s - batch_cost: 0.1636 - reader cost: 0.002712/36 [=========>....................] - ETA: 3s - batch_cost: 0.1631 - reader cost: 0.002413/36 [=========>....................] - ETA: 3s - batch_cost: 0.1635 - reader cost: 0.002314/36 [==========>...................] - ETA: 3s - batch_cost: 0.1636 - reader cost: 0.002115/36 [===========>..................] - ETA: 3s - batch_cost: 0.1637 - reader cost: 0.002016/36 [============>.................] - ETA: 3s - batch_cost: 0.1647 - reader cost: 0.001917/36 [=============>................] - ETA: 3s - batch_cost: 0.1648 - reader cost: 0.001718/36 [==============>...............] - ETA: 2s - batch_cost: 0.1649 - reader cost: 0.001719/36 [==============>...............] - ETA: 2s - batch_cost: 0.1647 - reader cost: 0.001620/36 [===============>..............] - ETA: 2s - batch_cost: 0.1647 - reader cost: 0.001521/36 [================>.............] - ETA: 2s - batch_cost: 0.1648 - reader cost: 0.001422/36 [=================>............] - ETA: 2s - batch_cost: 0.1650 - reader cost: 0.001423/36 [==================>...........] - ETA: 2s - batch_cost: 0.1655 - reader cost: 0.001324/36 [===================>..........] - ETA: 1s - batch_cost: 0.1654 - reader cost: 0.001325/36 [===================>..........] - ETA: 1s - batch_cost: 0.1655 - reader cost: 0.001226/36 [====================>.........] - ETA: 1s - batch_cost: 0.1656 - reader cost: 0.001227/36 [=====================>........] - ETA: 1s - batch_cost: 0.1656 - reader cost: 0.001128/36 [======================>.......] - ETA: 1s - batch_cost: 0.1658 - reader cost: 0.001129/36 [=======================>......] - ETA: 1s - batch_cost: 0.1658 - reader cost: 0.001130/36 [========================>.....] - ETA: 0s - batch_cost: 0.1657 - reader cost: 0.001031/36 [========================>.....] - ETA: 0s - batch_cost: 0.1658 - reader cost: 9.9287e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1657 - reader cost: 9.6425e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1655 - reader cost: 9.3705e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1654 - reader cost: 9.1139e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1654 - reader cost: 8.8716e-0436/36 [==============================] - 6s 166ms/step - batch_cost: 0.1655 - reader cost: 8.6415e-04
2023-02-05 02:48:24 [INFO]	[EVAL] #Images: 36 mIoU: 0.8671 Acc: 0.9867 Kappa: 0.9522 Dice: 0.9254
2023-02-05 02:48:24 [INFO]	[EVAL] Class IoU: 
[0.9865 0.9237 0.8895 0.7015 0.7257 0.9696 0.8731]
2023-02-05 02:48:24 [INFO]	[EVAL] Class Precision: 
[0.9947 0.9512 0.9386 0.7993 0.8428 0.9766 0.9159]
2023-02-05 02:48:24 [INFO]	[EVAL] Class Recall: 
[0.9917 0.9696 0.9444 0.8516 0.8393 0.9927 0.9492]
2023-02-05 02:48:25 [INFO]	[EVAL] The model with the best validation mIoU (0.8671) was saved at iter 218000.
2023-02-05 02:48:30 [INFO]	[TRAIN] epoch: 2760, iter: 218010/250000, loss: 0.1834, lr: 0.001572, batch_cost: 0.5640, reader_cost: 0.00011, ips: 10.6386 samples/sec | ETA 05:00:41
2023-02-05 02:48:36 [INFO]	[TRAIN] epoch: 2760, iter: 218020/250000, loss: 0.2205, lr: 0.001571, batch_cost: 0.6000, reader_cost: 0.03594, ips: 9.9996 samples/sec | ETA 05:19:48
2023-02-05 02:48:42 [INFO]	[TRAIN] epoch: 2760, iter: 218030/250000, loss: 0.2333, lr: 0.001571, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6381 samples/sec | ETA 05:00:31
2023-02-05 02:48:48 [INFO]	[TRAIN] epoch: 2760, iter: 218040/250000, loss: 0.2665, lr: 0.001570, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6272 samples/sec | ETA 05:00:44
2023-02-05 02:48:53 [INFO]	[TRAIN] epoch: 2761, iter: 218050/250000, loss: 0.1975, lr: 0.001570, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6375 samples/sec | ETA 05:00:21
2023-02-05 02:48:59 [INFO]	[TRAIN] epoch: 2761, iter: 218060/250000, loss: 0.1749, lr: 0.001570, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6345 samples/sec | ETA 05:00:20
2023-02-05 02:49:04 [INFO]	[TRAIN] epoch: 2761, iter: 218070/250000, loss: 0.1907, lr: 0.001569, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6330 samples/sec | ETA 05:00:17
2023-02-05 02:49:10 [INFO]	[TRAIN] epoch: 2761, iter: 218080/250000, loss: 0.1867, lr: 0.001569, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6319 samples/sec | ETA 05:00:13
2023-02-05 02:49:16 [INFO]	[TRAIN] epoch: 2761, iter: 218090/250000, loss: 0.2232, lr: 0.001568, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6312 samples/sec | ETA 05:00:09
2023-02-05 02:49:22 [INFO]	[TRAIN] epoch: 2761, iter: 218100/250000, loss: 0.2329, lr: 0.001568, batch_cost: 0.5920, reader_cost: 0.02795, ips: 10.1344 samples/sec | ETA 05:14:46
2023-02-05 02:49:27 [INFO]	[TRAIN] epoch: 2761, iter: 218110/250000, loss: 0.1710, lr: 0.001567, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6379 samples/sec | ETA 04:59:46
2023-02-05 02:49:33 [INFO]	[TRAIN] epoch: 2762, iter: 218120/250000, loss: 0.2639, lr: 0.001567, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6309 samples/sec | ETA 04:59:52
2023-02-05 02:49:39 [INFO]	[TRAIN] epoch: 2762, iter: 218130/250000, loss: 0.2193, lr: 0.001566, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6268 samples/sec | ETA 04:59:54
2023-02-05 02:49:44 [INFO]	[TRAIN] epoch: 2762, iter: 218140/250000, loss: 0.1881, lr: 0.001566, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6414 samples/sec | ETA 04:59:23
2023-02-05 02:49:50 [INFO]	[TRAIN] epoch: 2762, iter: 218150/250000, loss: 0.1950, lr: 0.001566, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6361 samples/sec | ETA 04:59:27
2023-02-05 02:49:55 [INFO]	[TRAIN] epoch: 2762, iter: 218160/250000, loss: 0.2105, lr: 0.001565, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6263 samples/sec | ETA 04:59:37
2023-02-05 02:50:01 [INFO]	[TRAIN] epoch: 2762, iter: 218170/250000, loss: 0.2323, lr: 0.001565, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6339 samples/sec | ETA 04:59:19
2023-02-05 02:50:07 [INFO]	[TRAIN] epoch: 2762, iter: 218180/250000, loss: 0.1715, lr: 0.001564, batch_cost: 0.5920, reader_cost: 0.02763, ips: 10.1353 samples/sec | ETA 05:13:57
2023-02-05 02:50:13 [INFO]	[TRAIN] epoch: 2762, iter: 218190/250000, loss: 0.2098, lr: 0.001564, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6292 samples/sec | ETA 04:59:16
2023-02-05 02:50:18 [INFO]	[TRAIN] epoch: 2763, iter: 218200/250000, loss: 0.1517, lr: 0.001563, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6309 samples/sec | ETA 04:59:07
2023-02-05 02:50:24 [INFO]	[TRAIN] epoch: 2763, iter: 218210/250000, loss: 0.2074, lr: 0.001563, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6342 samples/sec | ETA 04:58:56
2023-02-05 02:50:30 [INFO]	[TRAIN] epoch: 2763, iter: 218220/250000, loss: 0.1508, lr: 0.001562, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6373 samples/sec | ETA 04:58:45
2023-02-05 02:50:35 [INFO]	[TRAIN] epoch: 2763, iter: 218230/250000, loss: 0.1790, lr: 0.001562, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6344 samples/sec | ETA 04:58:44
2023-02-05 02:50:41 [INFO]	[TRAIN] epoch: 2763, iter: 218240/250000, loss: 0.1981, lr: 0.001562, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6134 samples/sec | ETA 04:59:14
2023-02-05 02:50:47 [INFO]	[TRAIN] epoch: 2763, iter: 218250/250000, loss: 0.1915, lr: 0.001561, batch_cost: 0.6001, reader_cost: 0.03411, ips: 9.9976 samples/sec | ETA 05:17:34
2023-02-05 02:50:53 [INFO]	[TRAIN] epoch: 2763, iter: 218260/250000, loss: 0.2154, lr: 0.001561, batch_cost: 0.5657, reader_cost: 0.00014, ips: 10.6069 samples/sec | ETA 04:59:14
2023-02-05 02:50:58 [INFO]	[TRAIN] epoch: 2763, iter: 218270/250000, loss: 0.1886, lr: 0.001560, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6320 samples/sec | ETA 04:58:26
2023-02-05 02:51:04 [INFO]	[TRAIN] epoch: 2764, iter: 218280/250000, loss: 0.1877, lr: 0.001560, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6318 samples/sec | ETA 04:58:20
2023-02-05 02:51:10 [INFO]	[TRAIN] epoch: 2764, iter: 218290/250000, loss: 0.1545, lr: 0.001559, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6365 samples/sec | ETA 04:58:07
2023-02-05 02:51:15 [INFO]	[TRAIN] epoch: 2764, iter: 218300/250000, loss: 0.1717, lr: 0.001559, batch_cost: 0.5637, reader_cost: 0.00009, ips: 10.6437 samples/sec | ETA 04:57:49
2023-02-05 02:51:21 [INFO]	[TRAIN] epoch: 2764, iter: 218310/250000, loss: 0.1523, lr: 0.001558, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6321 samples/sec | ETA 04:58:03
2023-02-05 02:51:26 [INFO]	[TRAIN] epoch: 2764, iter: 218320/250000, loss: 0.1779, lr: 0.001558, batch_cost: 0.5640, reader_cost: 0.00008, ips: 10.6384 samples/sec | ETA 04:57:47
2023-02-05 02:51:32 [INFO]	[TRAIN] epoch: 2764, iter: 218330/250000, loss: 0.1850, lr: 0.001558, batch_cost: 0.5919, reader_cost: 0.02732, ips: 10.1375 samples/sec | ETA 05:12:24
2023-02-05 02:51:38 [INFO]	[TRAIN] epoch: 2764, iter: 218340/250000, loss: 0.2419, lr: 0.001557, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6121 samples/sec | ETA 04:58:20
2023-02-05 02:51:44 [INFO]	[TRAIN] epoch: 2764, iter: 218350/250000, loss: 0.2005, lr: 0.001557, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6039 samples/sec | ETA 04:58:28
2023-02-05 02:51:49 [INFO]	[TRAIN] epoch: 2765, iter: 218360/250000, loss: 0.1962, lr: 0.001556, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6075 samples/sec | ETA 04:58:16
2023-02-05 02:51:55 [INFO]	[TRAIN] epoch: 2765, iter: 218370/250000, loss: 0.2317, lr: 0.001556, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6191 samples/sec | ETA 04:57:51
2023-02-05 02:52:01 [INFO]	[TRAIN] epoch: 2765, iter: 218380/250000, loss: 0.1779, lr: 0.001555, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6069 samples/sec | ETA 04:58:06
2023-02-05 02:52:06 [INFO]	[TRAIN] epoch: 2765, iter: 218390/250000, loss: 0.2158, lr: 0.001555, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6035 samples/sec | ETA 04:58:06
2023-02-05 02:52:12 [INFO]	[TRAIN] epoch: 2765, iter: 218400/250000, loss: 0.1906, lr: 0.001554, batch_cost: 0.5648, reader_cost: 0.00008, ips: 10.6225 samples/sec | ETA 04:57:28
2023-02-05 02:52:18 [INFO]	[TRAIN] epoch: 2765, iter: 218410/250000, loss: 0.1810, lr: 0.001554, batch_cost: 0.5973, reader_cost: 0.03207, ips: 10.0457 samples/sec | ETA 05:14:27
2023-02-05 02:52:24 [INFO]	[TRAIN] epoch: 2765, iter: 218420/250000, loss: 0.2199, lr: 0.001554, batch_cost: 0.5647, reader_cost: 0.00014, ips: 10.6244 samples/sec | ETA 04:57:14
2023-02-05 02:52:29 [INFO]	[TRAIN] epoch: 2765, iter: 218430/250000, loss: 0.2115, lr: 0.001553, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6235 samples/sec | ETA 04:57:10
2023-02-05 02:52:35 [INFO]	[TRAIN] epoch: 2766, iter: 218440/250000, loss: 0.1970, lr: 0.001553, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6280 samples/sec | ETA 04:56:57
2023-02-05 02:52:41 [INFO]	[TRAIN] epoch: 2766, iter: 218450/250000, loss: 0.2084, lr: 0.001552, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6066 samples/sec | ETA 04:57:27
2023-02-05 02:52:46 [INFO]	[TRAIN] epoch: 2766, iter: 218460/250000, loss: 0.2082, lr: 0.001552, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6055 samples/sec | ETA 04:57:23
2023-02-05 02:52:52 [INFO]	[TRAIN] epoch: 2766, iter: 218470/250000, loss: 0.1746, lr: 0.001551, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6119 samples/sec | ETA 04:57:07
2023-02-05 02:52:57 [INFO]	[TRAIN] epoch: 2766, iter: 218480/250000, loss: 0.1593, lr: 0.001551, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6098 samples/sec | ETA 04:57:04
2023-02-05 02:53:03 [INFO]	[TRAIN] epoch: 2766, iter: 218490/250000, loss: 0.2132, lr: 0.001550, batch_cost: 0.5919, reader_cost: 0.02610, ips: 10.1373 samples/sec | ETA 05:10:49
2023-02-05 02:53:09 [INFO]	[TRAIN] epoch: 2766, iter: 218500/250000, loss: 0.1492, lr: 0.001550, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6178 samples/sec | ETA 04:56:40
2023-02-05 02:53:15 [INFO]	[TRAIN] epoch: 2766, iter: 218510/250000, loss: 0.1873, lr: 0.001550, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6108 samples/sec | ETA 04:56:46
2023-02-05 02:53:20 [INFO]	[TRAIN] epoch: 2767, iter: 218520/250000, loss: 0.1918, lr: 0.001549, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6117 samples/sec | ETA 04:56:39
2023-02-05 02:53:26 [INFO]	[TRAIN] epoch: 2767, iter: 218530/250000, loss: 0.2612, lr: 0.001549, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6061 samples/sec | ETA 04:56:42
2023-02-05 02:53:32 [INFO]	[TRAIN] epoch: 2767, iter: 218540/250000, loss: 0.2280, lr: 0.001548, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6114 samples/sec | ETA 04:56:28
2023-02-05 02:53:37 [INFO]	[TRAIN] epoch: 2767, iter: 218550/250000, loss: 0.2093, lr: 0.001548, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6078 samples/sec | ETA 04:56:28
2023-02-05 02:53:43 [INFO]	[TRAIN] epoch: 2767, iter: 218560/250000, loss: 0.1826, lr: 0.001547, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6015 samples/sec | ETA 04:56:33
2023-02-05 02:53:49 [INFO]	[TRAIN] epoch: 2767, iter: 218570/250000, loss: 0.2290, lr: 0.001547, batch_cost: 0.6041, reader_cost: 0.03896, ips: 9.9328 samples/sec | ETA 05:16:25
2023-02-05 02:53:55 [INFO]	[TRAIN] epoch: 2767, iter: 218580/250000, loss: 0.1763, lr: 0.001547, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6243 samples/sec | ETA 04:55:44
2023-02-05 02:54:00 [INFO]	[TRAIN] epoch: 2767, iter: 218590/250000, loss: 0.2306, lr: 0.001546, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6306 samples/sec | ETA 04:55:28
2023-02-05 02:54:06 [INFO]	[TRAIN] epoch: 2768, iter: 218600/250000, loss: 0.1566, lr: 0.001546, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6342 samples/sec | ETA 04:55:16
2023-02-05 02:54:12 [INFO]	[TRAIN] epoch: 2768, iter: 218610/250000, loss: 0.2063, lr: 0.001545, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6246 samples/sec | ETA 04:55:26
2023-02-05 02:54:17 [INFO]	[TRAIN] epoch: 2768, iter: 218620/250000, loss: 0.1968, lr: 0.001545, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6284 samples/sec | ETA 04:55:14
2023-02-05 02:54:23 [INFO]	[TRAIN] epoch: 2768, iter: 218630/250000, loss: 0.1752, lr: 0.001544, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6352 samples/sec | ETA 04:54:57
2023-02-05 02:54:29 [INFO]	[TRAIN] epoch: 2768, iter: 218640/250000, loss: 0.1860, lr: 0.001544, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6190 samples/sec | ETA 04:55:19
2023-02-05 02:54:34 [INFO]	[TRAIN] epoch: 2768, iter: 218650/250000, loss: 0.1620, lr: 0.001543, batch_cost: 0.5923, reader_cost: 0.02737, ips: 10.1302 samples/sec | ETA 05:09:28
2023-02-05 02:54:40 [INFO]	[TRAIN] epoch: 2768, iter: 218660/250000, loss: 0.2410, lr: 0.001543, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6218 samples/sec | ETA 04:55:03
2023-02-05 02:54:46 [INFO]	[TRAIN] epoch: 2768, iter: 218670/250000, loss: 0.1772, lr: 0.001543, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6027 samples/sec | ETA 04:55:29
2023-02-05 02:54:51 [INFO]	[TRAIN] epoch: 2769, iter: 218680/250000, loss: 0.1634, lr: 0.001542, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6110 samples/sec | ETA 04:55:09
2023-02-05 02:54:57 [INFO]	[TRAIN] epoch: 2769, iter: 218690/250000, loss: 0.2199, lr: 0.001542, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6198 samples/sec | ETA 04:54:49
2023-02-05 02:55:03 [INFO]	[TRAIN] epoch: 2769, iter: 218700/250000, loss: 0.1709, lr: 0.001541, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6170 samples/sec | ETA 04:54:48
2023-02-05 02:55:08 [INFO]	[TRAIN] epoch: 2769, iter: 218710/250000, loss: 0.1765, lr: 0.001541, batch_cost: 0.5659, reader_cost: 0.00008, ips: 10.6035 samples/sec | ETA 04:55:05
2023-02-05 02:55:14 [INFO]	[TRAIN] epoch: 2769, iter: 218720/250000, loss: 0.1792, lr: 0.001540, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6005 samples/sec | ETA 04:55:04
2023-02-05 02:55:20 [INFO]	[TRAIN] epoch: 2769, iter: 218730/250000, loss: 0.1563, lr: 0.001540, batch_cost: 0.5912, reader_cost: 0.02611, ips: 10.1488 samples/sec | ETA 05:08:06
2023-02-05 02:55:26 [INFO]	[TRAIN] epoch: 2769, iter: 218740/250000, loss: 0.1541, lr: 0.001539, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6309 samples/sec | ETA 04:54:02
2023-02-05 02:55:31 [INFO]	[TRAIN] epoch: 2769, iter: 218750/250000, loss: 0.1537, lr: 0.001539, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6330 samples/sec | ETA 04:53:53
2023-02-05 02:55:37 [INFO]	[TRAIN] epoch: 2770, iter: 218760/250000, loss: 0.1562, lr: 0.001539, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6203 samples/sec | ETA 04:54:09
2023-02-05 02:55:43 [INFO]	[TRAIN] epoch: 2770, iter: 218770/250000, loss: 0.2075, lr: 0.001538, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6114 samples/sec | ETA 04:54:18
2023-02-05 02:55:48 [INFO]	[TRAIN] epoch: 2770, iter: 218780/250000, loss: 0.1766, lr: 0.001538, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6076 samples/sec | ETA 04:54:19
2023-02-05 02:55:54 [INFO]	[TRAIN] epoch: 2770, iter: 218790/250000, loss: 0.1673, lr: 0.001537, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6205 samples/sec | ETA 04:53:51
2023-02-05 02:56:00 [INFO]	[TRAIN] epoch: 2770, iter: 218800/250000, loss: 0.1724, lr: 0.001537, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6089 samples/sec | ETA 04:54:05
2023-02-05 02:56:05 [INFO]	[TRAIN] epoch: 2770, iter: 218810/250000, loss: 0.1450, lr: 0.001536, batch_cost: 0.5907, reader_cost: 0.02537, ips: 10.1570 samples/sec | ETA 05:07:04
2023-02-05 02:56:11 [INFO]	[TRAIN] epoch: 2770, iter: 218820/250000, loss: 0.1669, lr: 0.001536, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6216 samples/sec | ETA 04:53:33
2023-02-05 02:56:17 [INFO]	[TRAIN] epoch: 2770, iter: 218830/250000, loss: 0.1552, lr: 0.001535, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6048 samples/sec | ETA 04:53:55
2023-02-05 02:56:22 [INFO]	[TRAIN] epoch: 2771, iter: 218840/250000, loss: 0.1784, lr: 0.001535, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5966 samples/sec | ETA 04:54:03
2023-02-05 02:56:28 [INFO]	[TRAIN] epoch: 2771, iter: 218850/250000, loss: 0.1542, lr: 0.001535, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6146 samples/sec | ETA 04:53:27
2023-02-05 02:56:34 [INFO]	[TRAIN] epoch: 2771, iter: 218860/250000, loss: 0.1387, lr: 0.001534, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6103 samples/sec | ETA 04:53:29
2023-02-05 02:56:39 [INFO]	[TRAIN] epoch: 2771, iter: 218870/250000, loss: 0.1797, lr: 0.001534, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6001 samples/sec | ETA 04:53:40
2023-02-05 02:56:45 [INFO]	[TRAIN] epoch: 2771, iter: 218880/250000, loss: 0.1934, lr: 0.001533, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6099 samples/sec | ETA 04:53:18
2023-02-05 02:56:51 [INFO]	[TRAIN] epoch: 2771, iter: 218890/250000, loss: 0.1514, lr: 0.001533, batch_cost: 0.5930, reader_cost: 0.02816, ips: 10.1188 samples/sec | ETA 05:07:26
2023-02-05 02:56:57 [INFO]	[TRAIN] epoch: 2771, iter: 218900/250000, loss: 0.2442, lr: 0.001532, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6322 samples/sec | ETA 04:52:30
2023-02-05 02:57:02 [INFO]	[TRAIN] epoch: 2772, iter: 218910/250000, loss: 0.1832, lr: 0.001532, batch_cost: 0.5650, reader_cost: 0.00008, ips: 10.6191 samples/sec | ETA 04:52:46
2023-02-05 02:57:08 [INFO]	[TRAIN] epoch: 2772, iter: 218920/250000, loss: 0.1920, lr: 0.001531, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6048 samples/sec | ETA 04:53:04
2023-02-05 02:57:14 [INFO]	[TRAIN] epoch: 2772, iter: 218930/250000, loss: 0.1933, lr: 0.001531, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6038 samples/sec | ETA 04:53:00
2023-02-05 02:57:19 [INFO]	[TRAIN] epoch: 2772, iter: 218940/250000, loss: 0.2495, lr: 0.001531, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6185 samples/sec | ETA 04:52:30
2023-02-05 02:57:25 [INFO]	[TRAIN] epoch: 2772, iter: 218950/250000, loss: 0.2183, lr: 0.001530, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6055 samples/sec | ETA 04:52:46
2023-02-05 02:57:31 [INFO]	[TRAIN] epoch: 2772, iter: 218960/250000, loss: 0.1700, lr: 0.001530, batch_cost: 0.5662, reader_cost: 0.00008, ips: 10.5965 samples/sec | ETA 04:52:55
2023-02-05 02:57:36 [INFO]	[TRAIN] epoch: 2772, iter: 218970/250000, loss: 0.2172, lr: 0.001529, batch_cost: 0.5950, reader_cost: 0.02923, ips: 10.0834 samples/sec | ETA 05:07:43
2023-02-05 02:57:42 [INFO]	[TRAIN] epoch: 2772, iter: 218980/250000, loss: 0.1945, lr: 0.001529, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6133 samples/sec | ETA 04:52:16
2023-02-05 02:57:48 [INFO]	[TRAIN] epoch: 2773, iter: 218990/250000, loss: 0.2094, lr: 0.001528, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6215 samples/sec | ETA 04:51:57
2023-02-05 02:57:53 [INFO]	[TRAIN] epoch: 2773, iter: 219000/250000, loss: 0.1832, lr: 0.001528, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6034 samples/sec | ETA 04:52:21
2023-02-05 02:57:59 [INFO]	[TRAIN] epoch: 2773, iter: 219010/250000, loss: 0.1955, lr: 0.001527, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6124 samples/sec | ETA 04:52:01
2023-02-05 02:58:05 [INFO]	[TRAIN] epoch: 2773, iter: 219020/250000, loss: 0.1811, lr: 0.001527, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6134 samples/sec | ETA 04:51:53
2023-02-05 02:58:10 [INFO]	[TRAIN] epoch: 2773, iter: 219030/250000, loss: 0.1767, lr: 0.001527, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6067 samples/sec | ETA 04:51:59
2023-02-05 02:58:16 [INFO]	[TRAIN] epoch: 2773, iter: 219040/250000, loss: 0.1969, lr: 0.001526, batch_cost: 0.5900, reader_cost: 0.02508, ips: 10.1692 samples/sec | ETA 05:04:26
2023-02-05 02:58:22 [INFO]	[TRAIN] epoch: 2773, iter: 219050/250000, loss: 0.1534, lr: 0.001526, batch_cost: 0.5647, reader_cost: 0.00018, ips: 10.6259 samples/sec | ETA 04:51:16
2023-02-05 02:58:28 [INFO]	[TRAIN] epoch: 2773, iter: 219060/250000, loss: 0.1747, lr: 0.001525, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6287 samples/sec | ETA 04:51:05
2023-02-05 02:58:33 [INFO]	[TRAIN] epoch: 2774, iter: 219070/250000, loss: 0.1776, lr: 0.001525, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6140 samples/sec | ETA 04:51:24
2023-02-05 02:58:39 [INFO]	[TRAIN] epoch: 2774, iter: 219080/250000, loss: 0.1901, lr: 0.001524, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6130 samples/sec | ETA 04:51:20
2023-02-05 02:58:45 [INFO]	[TRAIN] epoch: 2774, iter: 219090/250000, loss: 0.1718, lr: 0.001524, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6157 samples/sec | ETA 04:51:10
2023-02-05 02:58:50 [INFO]	[TRAIN] epoch: 2774, iter: 219100/250000, loss: 0.1881, lr: 0.001523, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6064 samples/sec | ETA 04:51:20
2023-02-05 02:58:56 [INFO]	[TRAIN] epoch: 2774, iter: 219110/250000, loss: 0.1670, lr: 0.001523, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6121 samples/sec | ETA 04:51:04
2023-02-05 02:59:02 [INFO]	[TRAIN] epoch: 2774, iter: 219120/250000, loss: 0.1624, lr: 0.001523, batch_cost: 0.5909, reader_cost: 0.02600, ips: 10.1541 samples/sec | ETA 05:04:06
2023-02-05 02:59:07 [INFO]	[TRAIN] epoch: 2774, iter: 219130/250000, loss: 0.1833, lr: 0.001522, batch_cost: 0.5661, reader_cost: 0.00019, ips: 10.5991 samples/sec | ETA 04:51:15
2023-02-05 02:59:13 [INFO]	[TRAIN] epoch: 2774, iter: 219140/250000, loss: 0.1848, lr: 0.001522, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6265 samples/sec | ETA 04:50:24
2023-02-05 02:59:19 [INFO]	[TRAIN] epoch: 2775, iter: 219150/250000, loss: 0.1530, lr: 0.001521, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6139 samples/sec | ETA 04:50:39
2023-02-05 02:59:24 [INFO]	[TRAIN] epoch: 2775, iter: 219160/250000, loss: 0.1991, lr: 0.001521, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 04:50:49
2023-02-05 02:59:30 [INFO]	[TRAIN] epoch: 2775, iter: 219170/250000, loss: 0.1891, lr: 0.001520, batch_cost: 0.5647, reader_cost: 0.00008, ips: 10.6248 samples/sec | ETA 04:50:10
2023-02-05 02:59:36 [INFO]	[TRAIN] epoch: 2775, iter: 219180/250000, loss: 0.1676, lr: 0.001520, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6109 samples/sec | ETA 04:50:27
2023-02-05 02:59:41 [INFO]	[TRAIN] epoch: 2775, iter: 219190/250000, loss: 0.2529, lr: 0.001519, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6072 samples/sec | ETA 04:50:27
2023-02-05 02:59:47 [INFO]	[TRAIN] epoch: 2775, iter: 219200/250000, loss: 0.1673, lr: 0.001519, batch_cost: 0.5982, reader_cost: 0.03331, ips: 10.0306 samples/sec | ETA 05:07:03
2023-02-05 02:59:53 [INFO]	[TRAIN] epoch: 2775, iter: 219210/250000, loss: 0.1590, lr: 0.001519, batch_cost: 0.5648, reader_cost: 0.00013, ips: 10.6239 samples/sec | ETA 04:49:49
2023-02-05 02:59:59 [INFO]	[TRAIN] epoch: 2775, iter: 219220/250000, loss: 0.1693, lr: 0.001518, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6317 samples/sec | ETA 04:49:30
2023-02-05 03:00:04 [INFO]	[TRAIN] epoch: 2776, iter: 219230/250000, loss: 0.1591, lr: 0.001518, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6255 samples/sec | ETA 04:49:35
2023-02-05 03:00:10 [INFO]	[TRAIN] epoch: 2776, iter: 219240/250000, loss: 0.1891, lr: 0.001517, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6089 samples/sec | ETA 04:49:56
2023-02-05 03:00:16 [INFO]	[TRAIN] epoch: 2776, iter: 219250/250000, loss: 0.1886, lr: 0.001517, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6139 samples/sec | ETA 04:49:42
2023-02-05 03:00:21 [INFO]	[TRAIN] epoch: 2776, iter: 219260/250000, loss: 0.1741, lr: 0.001516, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6114 samples/sec | ETA 04:49:41
2023-02-05 03:00:27 [INFO]	[TRAIN] epoch: 2776, iter: 219270/250000, loss: 0.1611, lr: 0.001516, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6056 samples/sec | ETA 04:49:45
2023-02-05 03:00:33 [INFO]	[TRAIN] epoch: 2776, iter: 219280/250000, loss: 0.1547, lr: 0.001515, batch_cost: 0.6088, reader_cost: 0.04406, ips: 9.8549 samples/sec | ETA 05:11:43
2023-02-05 03:00:39 [INFO]	[TRAIN] epoch: 2776, iter: 219290/250000, loss: 0.2110, lr: 0.001515, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6031 samples/sec | ETA 04:49:37
2023-02-05 03:00:44 [INFO]	[TRAIN] epoch: 2776, iter: 219300/250000, loss: 0.3071, lr: 0.001515, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6145 samples/sec | ETA 04:49:13
2023-02-05 03:00:50 [INFO]	[TRAIN] epoch: 2777, iter: 219310/250000, loss: 0.1814, lr: 0.001514, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6105 samples/sec | ETA 04:49:14
2023-02-05 03:00:56 [INFO]	[TRAIN] epoch: 2777, iter: 219320/250000, loss: 0.1610, lr: 0.001514, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6078 samples/sec | ETA 04:49:13
2023-02-05 03:01:01 [INFO]	[TRAIN] epoch: 2777, iter: 219330/250000, loss: 0.1799, lr: 0.001513, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6133 samples/sec | ETA 04:48:58
2023-02-05 03:01:07 [INFO]	[TRAIN] epoch: 2777, iter: 219340/250000, loss: 0.1472, lr: 0.001513, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6044 samples/sec | ETA 04:49:07
2023-02-05 03:01:13 [INFO]	[TRAIN] epoch: 2777, iter: 219350/250000, loss: 0.1901, lr: 0.001512, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6074 samples/sec | ETA 04:48:57
2023-02-05 03:01:18 [INFO]	[TRAIN] epoch: 2777, iter: 219360/250000, loss: 0.1869, lr: 0.001512, batch_cost: 0.5893, reader_cost: 0.02419, ips: 10.1818 samples/sec | ETA 05:00:55
2023-02-05 03:01:24 [INFO]	[TRAIN] epoch: 2777, iter: 219370/250000, loss: 0.1995, lr: 0.001511, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6239 samples/sec | ETA 04:48:18
2023-02-05 03:01:30 [INFO]	[TRAIN] epoch: 2777, iter: 219380/250000, loss: 0.1447, lr: 0.001511, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6317 samples/sec | ETA 04:48:00
2023-02-05 03:01:35 [INFO]	[TRAIN] epoch: 2778, iter: 219390/250000, loss: 0.1882, lr: 0.001511, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6229 samples/sec | ETA 04:48:09
2023-02-05 03:01:41 [INFO]	[TRAIN] epoch: 2778, iter: 219400/250000, loss: 0.2078, lr: 0.001510, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6146 samples/sec | ETA 04:48:16
2023-02-05 03:01:47 [INFO]	[TRAIN] epoch: 2778, iter: 219410/250000, loss: 0.1925, lr: 0.001510, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6027 samples/sec | ETA 04:48:30
2023-02-05 03:01:52 [INFO]	[TRAIN] epoch: 2778, iter: 219420/250000, loss: 0.1974, lr: 0.001509, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6094 samples/sec | ETA 04:48:14
2023-02-05 03:01:58 [INFO]	[TRAIN] epoch: 2778, iter: 219430/250000, loss: 0.2093, lr: 0.001509, batch_cost: 0.5652, reader_cost: 0.00008, ips: 10.6153 samples/sec | ETA 04:47:58
2023-02-05 03:02:04 [INFO]	[TRAIN] epoch: 2778, iter: 219440/250000, loss: 0.1728, lr: 0.001508, batch_cost: 0.5980, reader_cost: 0.03273, ips: 10.0334 samples/sec | ETA 05:04:34
2023-02-05 03:02:10 [INFO]	[TRAIN] epoch: 2778, iter: 219450/250000, loss: 0.2057, lr: 0.001508, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6180 samples/sec | ETA 04:47:43
2023-02-05 03:02:15 [INFO]	[TRAIN] epoch: 2778, iter: 219460/250000, loss: 0.1499, lr: 0.001507, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6095 samples/sec | ETA 04:47:51
2023-02-05 03:02:21 [INFO]	[TRAIN] epoch: 2779, iter: 219470/250000, loss: 0.3254, lr: 0.001507, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6142 samples/sec | ETA 04:47:38
2023-02-05 03:02:27 [INFO]	[TRAIN] epoch: 2779, iter: 219480/250000, loss: 0.2460, lr: 0.001507, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6105 samples/sec | ETA 04:47:38
2023-02-05 03:02:32 [INFO]	[TRAIN] epoch: 2779, iter: 219490/250000, loss: 0.1904, lr: 0.001506, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6067 samples/sec | ETA 04:47:38
2023-02-05 03:02:38 [INFO]	[TRAIN] epoch: 2779, iter: 219500/250000, loss: 0.1912, lr: 0.001506, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6185 samples/sec | ETA 04:47:14
2023-02-05 03:02:44 [INFO]	[TRAIN] epoch: 2779, iter: 219510/250000, loss: 0.1700, lr: 0.001505, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6028 samples/sec | ETA 04:47:33
2023-02-05 03:02:50 [INFO]	[TRAIN] epoch: 2779, iter: 219520/250000, loss: 0.2177, lr: 0.001505, batch_cost: 0.5995, reader_cost: 0.03452, ips: 10.0077 samples/sec | ETA 05:04:34
2023-02-05 03:02:55 [INFO]	[TRAIN] epoch: 2779, iter: 219530/250000, loss: 0.1498, lr: 0.001504, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6323 samples/sec | ETA 04:46:34
2023-02-05 03:03:01 [INFO]	[TRAIN] epoch: 2779, iter: 219540/250000, loss: 0.1975, lr: 0.001504, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6025 samples/sec | ETA 04:47:17
2023-02-05 03:03:07 [INFO]	[TRAIN] epoch: 2780, iter: 219550/250000, loss: 0.1627, lr: 0.001503, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6112 samples/sec | ETA 04:46:57
2023-02-05 03:03:12 [INFO]	[TRAIN] epoch: 2780, iter: 219560/250000, loss: 0.2004, lr: 0.001503, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6151 samples/sec | ETA 04:46:45
2023-02-05 03:03:18 [INFO]	[TRAIN] epoch: 2780, iter: 219570/250000, loss: 0.1566, lr: 0.001503, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6171 samples/sec | ETA 04:46:36
2023-02-05 03:03:24 [INFO]	[TRAIN] epoch: 2780, iter: 219580/250000, loss: 0.1770, lr: 0.001502, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6054 samples/sec | ETA 04:46:50
2023-02-05 03:03:29 [INFO]	[TRAIN] epoch: 2780, iter: 219590/250000, loss: 0.1508, lr: 0.001502, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6097 samples/sec | ETA 04:46:37
2023-02-05 03:03:35 [INFO]	[TRAIN] epoch: 2780, iter: 219600/250000, loss: 0.1420, lr: 0.001501, batch_cost: 0.5926, reader_cost: 0.02666, ips: 10.1241 samples/sec | ETA 05:00:16
2023-02-05 03:03:41 [INFO]	[TRAIN] epoch: 2780, iter: 219610/250000, loss: 0.1732, lr: 0.001501, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6077 samples/sec | ETA 04:46:29
2023-02-05 03:03:46 [INFO]	[TRAIN] epoch: 2780, iter: 219620/250000, loss: 0.1834, lr: 0.001500, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6214 samples/sec | ETA 04:46:01
2023-02-05 03:03:52 [INFO]	[TRAIN] epoch: 2781, iter: 219630/250000, loss: 0.1640, lr: 0.001500, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6136 samples/sec | ETA 04:46:08
2023-02-05 03:03:58 [INFO]	[TRAIN] epoch: 2781, iter: 219640/250000, loss: 0.1546, lr: 0.001499, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5989 samples/sec | ETA 04:46:26
2023-02-05 03:04:03 [INFO]	[TRAIN] epoch: 2781, iter: 219650/250000, loss: 0.1878, lr: 0.001499, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6113 samples/sec | ETA 04:46:00
2023-02-05 03:04:09 [INFO]	[TRAIN] epoch: 2781, iter: 219660/250000, loss: 0.1584, lr: 0.001499, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6140 samples/sec | ETA 04:45:50
2023-02-05 03:04:15 [INFO]	[TRAIN] epoch: 2781, iter: 219670/250000, loss: 0.1452, lr: 0.001498, batch_cost: 0.5658, reader_cost: 0.00008, ips: 10.6043 samples/sec | ETA 04:46:00
2023-02-05 03:04:21 [INFO]	[TRAIN] epoch: 2781, iter: 219680/250000, loss: 0.1733, lr: 0.001498, batch_cost: 0.6101, reader_cost: 0.04427, ips: 9.8343 samples/sec | ETA 05:08:18
2023-02-05 03:04:26 [INFO]	[TRAIN] epoch: 2781, iter: 219690/250000, loss: 0.2052, lr: 0.001497, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6126 samples/sec | ETA 04:45:36
2023-02-05 03:04:32 [INFO]	[TRAIN] epoch: 2782, iter: 219700/250000, loss: 0.1673, lr: 0.001497, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6144 samples/sec | ETA 04:45:27
2023-02-05 03:04:38 [INFO]	[TRAIN] epoch: 2782, iter: 219710/250000, loss: 0.1659, lr: 0.001496, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6023 samples/sec | ETA 04:45:41
2023-02-05 03:04:43 [INFO]	[TRAIN] epoch: 2782, iter: 219720/250000, loss: 0.1616, lr: 0.001496, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6212 samples/sec | ETA 04:45:05
2023-02-05 03:04:49 [INFO]	[TRAIN] epoch: 2782, iter: 219730/250000, loss: 0.1749, lr: 0.001495, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6104 samples/sec | ETA 04:45:17
2023-02-05 03:04:55 [INFO]	[TRAIN] epoch: 2782, iter: 219740/250000, loss: 0.2212, lr: 0.001495, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6009 samples/sec | ETA 04:45:26
2023-02-05 03:05:00 [INFO]	[TRAIN] epoch: 2782, iter: 219750/250000, loss: 0.1528, lr: 0.001495, batch_cost: 0.5651, reader_cost: 0.00008, ips: 10.6182 samples/sec | ETA 04:44:53
2023-02-05 03:05:06 [INFO]	[TRAIN] epoch: 2782, iter: 219760/250000, loss: 0.1761, lr: 0.001494, batch_cost: 0.5874, reader_cost: 0.02228, ips: 10.2141 samples/sec | ETA 04:56:03
2023-02-05 03:05:12 [INFO]	[TRAIN] epoch: 2782, iter: 219770/250000, loss: 0.2033, lr: 0.001494, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6125 samples/sec | ETA 04:44:51
2023-02-05 03:05:18 [INFO]	[TRAIN] epoch: 2783, iter: 219780/250000, loss: 0.1860, lr: 0.001493, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6025 samples/sec | ETA 04:45:01
2023-02-05 03:05:23 [INFO]	[TRAIN] epoch: 2783, iter: 219790/250000, loss: 0.1984, lr: 0.001493, batch_cost: 0.5651, reader_cost: 0.00008, ips: 10.6171 samples/sec | ETA 04:44:32
2023-02-05 03:05:29 [INFO]	[TRAIN] epoch: 2783, iter: 219800/250000, loss: 0.1582, lr: 0.001492, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6078 samples/sec | ETA 04:44:41
2023-02-05 03:05:35 [INFO]	[TRAIN] epoch: 2783, iter: 219810/250000, loss: 0.2149, lr: 0.001492, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6038 samples/sec | ETA 04:44:42
2023-02-05 03:05:40 [INFO]	[TRAIN] epoch: 2783, iter: 219820/250000, loss: 0.1536, lr: 0.001491, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6190 samples/sec | ETA 04:44:12
2023-02-05 03:05:46 [INFO]	[TRAIN] epoch: 2783, iter: 219830/250000, loss: 0.1757, lr: 0.001491, batch_cost: 0.5997, reader_cost: 0.03435, ips: 10.0045 samples/sec | ETA 05:01:33
2023-02-05 03:05:52 [INFO]	[TRAIN] epoch: 2783, iter: 219840/250000, loss: 0.1784, lr: 0.001491, batch_cost: 0.5647, reader_cost: 0.00024, ips: 10.6254 samples/sec | ETA 04:43:50
2023-02-05 03:05:57 [INFO]	[TRAIN] epoch: 2783, iter: 219850/250000, loss: 0.1508, lr: 0.001490, batch_cost: 0.5647, reader_cost: 0.00008, ips: 10.6251 samples/sec | ETA 04:43:45
2023-02-05 03:06:03 [INFO]	[TRAIN] epoch: 2784, iter: 219860/250000, loss: 0.1411, lr: 0.001490, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6322 samples/sec | ETA 04:43:28
2023-02-05 03:06:09 [INFO]	[TRAIN] epoch: 2784, iter: 219870/250000, loss: 0.1650, lr: 0.001489, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6047 samples/sec | ETA 04:44:07
2023-02-05 03:06:14 [INFO]	[TRAIN] epoch: 2784, iter: 219880/250000, loss: 0.2391, lr: 0.001489, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6045 samples/sec | ETA 04:44:01
2023-02-05 03:06:20 [INFO]	[TRAIN] epoch: 2784, iter: 219890/250000, loss: 0.1298, lr: 0.001488, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6064 samples/sec | ETA 04:43:53
2023-02-05 03:06:26 [INFO]	[TRAIN] epoch: 2784, iter: 219900/250000, loss: 0.1750, lr: 0.001488, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6118 samples/sec | ETA 04:43:38
2023-02-05 03:06:32 [INFO]	[TRAIN] epoch: 2784, iter: 219910/250000, loss: 0.1917, lr: 0.001487, batch_cost: 0.5942, reader_cost: 0.02889, ips: 10.0969 samples/sec | ETA 04:58:00
2023-02-05 03:06:37 [INFO]	[TRAIN] epoch: 2784, iter: 219920/250000, loss: 0.1633, lr: 0.001487, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6371 samples/sec | ETA 04:42:46
2023-02-05 03:06:43 [INFO]	[TRAIN] epoch: 2784, iter: 219930/250000, loss: 0.1658, lr: 0.001487, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6284 samples/sec | ETA 04:42:55
2023-02-05 03:06:49 [INFO]	[TRAIN] epoch: 2785, iter: 219940/250000, loss: 0.1553, lr: 0.001486, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6029 samples/sec | ETA 04:43:30
2023-02-05 03:06:54 [INFO]	[TRAIN] epoch: 2785, iter: 219950/250000, loss: 0.1827, lr: 0.001486, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6113 samples/sec | ETA 04:43:11
2023-02-05 03:07:00 [INFO]	[TRAIN] epoch: 2785, iter: 219960/250000, loss: 0.1671, lr: 0.001485, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6133 samples/sec | ETA 04:43:02
2023-02-05 03:07:06 [INFO]	[TRAIN] epoch: 2785, iter: 219970/250000, loss: 0.1863, lr: 0.001485, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5986 samples/sec | ETA 04:43:20
2023-02-05 03:07:11 [INFO]	[TRAIN] epoch: 2785, iter: 219980/250000, loss: 0.1883, lr: 0.001484, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6094 samples/sec | ETA 04:42:57
2023-02-05 03:07:17 [INFO]	[TRAIN] epoch: 2785, iter: 219990/250000, loss: 0.1963, lr: 0.001484, batch_cost: 0.5957, reader_cost: 0.02975, ips: 10.0716 samples/sec | ETA 04:57:57
2023-02-05 03:07:23 [INFO]	[TRAIN] epoch: 2785, iter: 220000/250000, loss: 0.1640, lr: 0.001483, batch_cost: 0.5644, reader_cost: 0.00013, ips: 10.6313 samples/sec | ETA 04:42:11
2023-02-05 03:07:23 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1226 - reader cost: 0.0235 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1470 - reader cost: 0.0118 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1550 - reader cost: 0.0079 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1565 - reader cost: 0.0059 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1580 - reader cost: 0.0048 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1605 - reader cost: 0.0040 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1600 - reader cost: 0.0034 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1613 - reader cost: 0.0030 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1622 - reader cost: 0.002710/36 [=======>......................] - ETA: 4s - batch_cost: 0.1619 - reader cost: 0.002411/36 [========>.....................] - ETA: 4s - batch_cost: 0.1628 - reader cost: 0.002212/36 [=========>....................] - ETA: 3s - batch_cost: 0.1626 - reader cost: 0.002013/36 [=========>....................] - ETA: 3s - batch_cost: 0.1631 - reader cost: 0.001914/36 [==========>...................] - ETA: 3s - batch_cost: 0.1634 - reader cost: 0.001715/36 [===========>..................] - ETA: 3s - batch_cost: 0.1636 - reader cost: 0.001616/36 [============>.................] - ETA: 3s - batch_cost: 0.1644 - reader cost: 0.001517/36 [=============>................] - ETA: 3s - batch_cost: 0.1648 - reader cost: 0.001518/36 [==============>...............] - ETA: 2s - batch_cost: 0.1649 - reader cost: 0.001419/36 [==============>...............] - ETA: 2s - batch_cost: 0.1648 - reader cost: 0.001320/36 [===============>..............] - ETA: 2s - batch_cost: 0.1648 - reader cost: 0.001221/36 [================>.............] - ETA: 2s - batch_cost: 0.1650 - reader cost: 0.001222/36 [=================>............] - ETA: 2s - batch_cost: 0.1653 - reader cost: 0.001123/36 [==================>...........] - ETA: 2s - batch_cost: 0.1658 - reader cost: 0.001124/36 [===================>..........] - ETA: 1s - batch_cost: 0.1658 - reader cost: 0.001125/36 [===================>..........] - ETA: 1s - batch_cost: 0.1659 - reader cost: 0.001026/36 [====================>.........] - ETA: 1s - batch_cost: 0.1660 - reader cost: 9.7572e-0427/36 [=====================>........] - ETA: 1s - batch_cost: 0.1661 - reader cost: 9.4275e-0428/36 [======================>.......] - ETA: 1s - batch_cost: 0.1662 - reader cost: 9.1228e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1662 - reader cost: 8.8308e-0430/36 [========================>.....] - ETA: 0s - batch_cost: 0.1661 - reader cost: 8.5592e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1662 - reader cost: 8.3050e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1661 - reader cost: 8.0706e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1659 - reader cost: 7.8449e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1659 - reader cost: 7.6323e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1659 - reader cost: 7.4360e-0436/36 [==============================] - 6s 166ms/step - batch_cost: 0.1660 - reader cost: 7.2510e-04
2023-02-05 03:07:29 [INFO]	[EVAL] #Images: 36 mIoU: 0.8653 Acc: 0.9862 Kappa: 0.9501 Dice: 0.9242
2023-02-05 03:07:29 [INFO]	[EVAL] Class IoU: 
[0.9855 0.9198 0.8901 0.7341 0.6883 0.9706 0.8687]
2023-02-05 03:07:29 [INFO]	[EVAL] Class Precision: 
[0.9927 0.9731 0.9431 0.8301 0.8398 0.9811 0.8989]
2023-02-05 03:07:29 [INFO]	[EVAL] Class Recall: 
[0.9927 0.9438 0.9406 0.8639 0.7924 0.9891 0.9628]
2023-02-05 03:07:29 [INFO]	[EVAL] The model with the best validation mIoU (0.8671) was saved at iter 218000.
2023-02-05 03:07:35 [INFO]	[TRAIN] epoch: 2785, iter: 220010/250000, loss: 0.2074, lr: 0.001483, batch_cost: 0.5638, reader_cost: 0.00010, ips: 10.6418 samples/sec | ETA 04:41:48
2023-02-05 03:07:40 [INFO]	[TRAIN] epoch: 2786, iter: 220020/250000, loss: 0.1280, lr: 0.001483, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6408 samples/sec | ETA 04:41:44
2023-02-05 03:07:46 [INFO]	[TRAIN] epoch: 2786, iter: 220030/250000, loss: 0.1537, lr: 0.001482, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6341 samples/sec | ETA 04:41:49
2023-02-05 03:07:52 [INFO]	[TRAIN] epoch: 2786, iter: 220040/250000, loss: 0.2323, lr: 0.001482, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6247 samples/sec | ETA 04:41:59
2023-02-05 03:07:57 [INFO]	[TRAIN] epoch: 2786, iter: 220050/250000, loss: 0.1639, lr: 0.001481, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6358 samples/sec | ETA 04:41:35
2023-02-05 03:08:03 [INFO]	[TRAIN] epoch: 2786, iter: 220060/250000, loss: 0.1941, lr: 0.001481, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6378 samples/sec | ETA 04:41:26
2023-02-05 03:08:09 [INFO]	[TRAIN] epoch: 2786, iter: 220070/250000, loss: 0.1521, lr: 0.001480, batch_cost: 0.5921, reader_cost: 0.02791, ips: 10.1334 samples/sec | ETA 04:55:21
2023-02-05 03:08:15 [INFO]	[TRAIN] epoch: 2786, iter: 220080/250000, loss: 0.2115, lr: 0.001480, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6292 samples/sec | ETA 04:41:29
2023-02-05 03:08:20 [INFO]	[TRAIN] epoch: 2786, iter: 220090/250000, loss: 0.1962, lr: 0.001479, batch_cost: 0.5639, reader_cost: 0.00008, ips: 10.6405 samples/sec | ETA 04:41:05
2023-02-05 03:08:26 [INFO]	[TRAIN] epoch: 2787, iter: 220100/250000, loss: 0.1846, lr: 0.001479, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6416 samples/sec | ETA 04:40:58
2023-02-05 03:08:31 [INFO]	[TRAIN] epoch: 2787, iter: 220110/250000, loss: 0.2064, lr: 0.001479, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6311 samples/sec | ETA 04:41:09
2023-02-05 03:08:37 [INFO]	[TRAIN] epoch: 2787, iter: 220120/250000, loss: 0.1594, lr: 0.001478, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6222 samples/sec | ETA 04:41:17
2023-02-05 03:08:43 [INFO]	[TRAIN] epoch: 2787, iter: 220130/250000, loss: 0.1586, lr: 0.001478, batch_cost: 0.5652, reader_cost: 0.00008, ips: 10.6162 samples/sec | ETA 04:41:21
2023-02-05 03:08:48 [INFO]	[TRAIN] epoch: 2787, iter: 220140/250000, loss: 0.1362, lr: 0.001477, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 04:41:34
2023-02-05 03:08:54 [INFO]	[TRAIN] epoch: 2787, iter: 220150/250000, loss: 0.1574, lr: 0.001477, batch_cost: 0.5943, reader_cost: 0.02803, ips: 10.0957 samples/sec | ETA 04:55:40
2023-02-05 03:09:00 [INFO]	[TRAIN] epoch: 2787, iter: 220160/250000, loss: 0.1941, lr: 0.001476, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6329 samples/sec | ETA 04:40:38
2023-02-05 03:09:06 [INFO]	[TRAIN] epoch: 2787, iter: 220170/250000, loss: 0.1424, lr: 0.001476, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6245 samples/sec | ETA 04:40:45
2023-02-05 03:09:11 [INFO]	[TRAIN] epoch: 2788, iter: 220180/250000, loss: 0.1552, lr: 0.001475, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6030 samples/sec | ETA 04:41:14
2023-02-05 03:09:17 [INFO]	[TRAIN] epoch: 2788, iter: 220190/250000, loss: 0.1785, lr: 0.001475, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6120 samples/sec | ETA 04:40:54
2023-02-05 03:09:23 [INFO]	[TRAIN] epoch: 2788, iter: 220200/250000, loss: 0.1668, lr: 0.001475, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6162 samples/sec | ETA 04:40:42
2023-02-05 03:09:28 [INFO]	[TRAIN] epoch: 2788, iter: 220210/250000, loss: 0.1521, lr: 0.001474, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5967 samples/sec | ETA 04:41:07
2023-02-05 03:09:34 [INFO]	[TRAIN] epoch: 2788, iter: 220220/250000, loss: 0.1657, lr: 0.001474, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6084 samples/sec | ETA 04:40:43
2023-02-05 03:09:40 [INFO]	[TRAIN] epoch: 2788, iter: 220230/250000, loss: 0.2060, lr: 0.001473, batch_cost: 0.5908, reader_cost: 0.02585, ips: 10.1565 samples/sec | ETA 04:53:06
2023-02-05 03:09:45 [INFO]	[TRAIN] epoch: 2788, iter: 220240/250000, loss: 0.1584, lr: 0.001473, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6266 samples/sec | ETA 04:40:03
2023-02-05 03:09:51 [INFO]	[TRAIN] epoch: 2788, iter: 220250/250000, loss: 0.1548, lr: 0.001472, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6229 samples/sec | ETA 04:40:03
2023-02-05 03:09:57 [INFO]	[TRAIN] epoch: 2789, iter: 220260/250000, loss: 0.1972, lr: 0.001472, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6057 samples/sec | ETA 04:40:24
2023-02-05 03:10:02 [INFO]	[TRAIN] epoch: 2789, iter: 220270/250000, loss: 0.1355, lr: 0.001471, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6117 samples/sec | ETA 04:40:09
2023-02-05 03:10:08 [INFO]	[TRAIN] epoch: 2789, iter: 220280/250000, loss: 0.1722, lr: 0.001471, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6135 samples/sec | ETA 04:40:01
2023-02-05 03:10:14 [INFO]	[TRAIN] epoch: 2789, iter: 220290/250000, loss: 0.1521, lr: 0.001471, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6069 samples/sec | ETA 04:40:06
2023-02-05 03:10:19 [INFO]	[TRAIN] epoch: 2789, iter: 220300/250000, loss: 0.1659, lr: 0.001470, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6127 samples/sec | ETA 04:39:51
2023-02-05 03:10:25 [INFO]	[TRAIN] epoch: 2789, iter: 220310/250000, loss: 0.2144, lr: 0.001470, batch_cost: 0.5915, reader_cost: 0.02529, ips: 10.1431 samples/sec | ETA 04:52:42
2023-02-05 03:10:31 [INFO]	[TRAIN] epoch: 2789, iter: 220320/250000, loss: 0.1706, lr: 0.001469, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6299 samples/sec | ETA 04:39:12
2023-02-05 03:10:37 [INFO]	[TRAIN] epoch: 2789, iter: 220330/250000, loss: 0.1671, lr: 0.001469, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6337 samples/sec | ETA 04:39:01
2023-02-05 03:10:42 [INFO]	[TRAIN] epoch: 2790, iter: 220340/250000, loss: 0.1840, lr: 0.001468, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6293 samples/sec | ETA 04:39:02
2023-02-05 03:10:48 [INFO]	[TRAIN] epoch: 2790, iter: 220350/250000, loss: 0.1418, lr: 0.001468, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6217 samples/sec | ETA 04:39:08
2023-02-05 03:10:54 [INFO]	[TRAIN] epoch: 2790, iter: 220360/250000, loss: 0.1709, lr: 0.001467, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6006 samples/sec | ETA 04:39:36
2023-02-05 03:10:59 [INFO]	[TRAIN] epoch: 2790, iter: 220370/250000, loss: 0.2080, lr: 0.001467, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5949 samples/sec | ETA 04:39:39
2023-02-05 03:11:05 [INFO]	[TRAIN] epoch: 2790, iter: 220380/250000, loss: 0.1596, lr: 0.001467, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5959 samples/sec | ETA 04:39:32
2023-02-05 03:11:11 [INFO]	[TRAIN] epoch: 2790, iter: 220390/250000, loss: 0.2019, lr: 0.001466, batch_cost: 0.5938, reader_cost: 0.02926, ips: 10.1044 samples/sec | ETA 04:53:02
2023-02-05 03:11:16 [INFO]	[TRAIN] epoch: 2790, iter: 220400/250000, loss: 0.2196, lr: 0.001466, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6390 samples/sec | ETA 04:38:13
2023-02-05 03:11:22 [INFO]	[TRAIN] epoch: 2790, iter: 220410/250000, loss: 0.1844, lr: 0.001465, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6140 samples/sec | ETA 04:38:46
2023-02-05 03:11:28 [INFO]	[TRAIN] epoch: 2791, iter: 220420/250000, loss: 0.2088, lr: 0.001465, batch_cost: 0.5661, reader_cost: 0.00008, ips: 10.5989 samples/sec | ETA 04:39:05
2023-02-05 03:11:33 [INFO]	[TRAIN] epoch: 2791, iter: 220430/250000, loss: 0.1804, lr: 0.001464, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6052 samples/sec | ETA 04:38:49
2023-02-05 03:11:39 [INFO]	[TRAIN] epoch: 2791, iter: 220440/250000, loss: 0.2256, lr: 0.001464, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6076 samples/sec | ETA 04:38:40
2023-02-05 03:11:45 [INFO]	[TRAIN] epoch: 2791, iter: 220450/250000, loss: 0.1878, lr: 0.001463, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6091 samples/sec | ETA 04:38:32
2023-02-05 03:11:50 [INFO]	[TRAIN] epoch: 2791, iter: 220460/250000, loss: 0.2081, lr: 0.001463, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6027 samples/sec | ETA 04:38:36
2023-02-05 03:11:56 [INFO]	[TRAIN] epoch: 2791, iter: 220470/250000, loss: 0.2069, lr: 0.001463, batch_cost: 0.5937, reader_cost: 0.02926, ips: 10.1060 samples/sec | ETA 04:52:12
2023-02-05 03:12:02 [INFO]	[TRAIN] epoch: 2791, iter: 220480/250000, loss: 0.2199, lr: 0.001462, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6414 samples/sec | ETA 04:37:24
2023-02-05 03:12:08 [INFO]	[TRAIN] epoch: 2792, iter: 220490/250000, loss: 0.1800, lr: 0.001462, batch_cost: 0.5649, reader_cost: 0.00008, ips: 10.6217 samples/sec | ETA 04:37:49
2023-02-05 03:12:13 [INFO]	[TRAIN] epoch: 2792, iter: 220500/250000, loss: 0.2012, lr: 0.001461, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6120 samples/sec | ETA 04:37:59
2023-02-05 03:12:19 [INFO]	[TRAIN] epoch: 2792, iter: 220510/250000, loss: 0.1475, lr: 0.001461, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6012 samples/sec | ETA 04:38:10
2023-02-05 03:12:25 [INFO]	[TRAIN] epoch: 2792, iter: 220520/250000, loss: 0.1576, lr: 0.001460, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6071 samples/sec | ETA 04:37:55
2023-02-05 03:12:30 [INFO]	[TRAIN] epoch: 2792, iter: 220530/250000, loss: 0.1462, lr: 0.001460, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6086 samples/sec | ETA 04:37:47
2023-02-05 03:12:36 [INFO]	[TRAIN] epoch: 2792, iter: 220540/250000, loss: 0.2010, lr: 0.001459, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6107 samples/sec | ETA 04:37:38
2023-02-05 03:12:42 [INFO]	[TRAIN] epoch: 2792, iter: 220550/250000, loss: 0.1933, lr: 0.001459, batch_cost: 0.5908, reader_cost: 0.02654, ips: 10.1565 samples/sec | ETA 04:49:57
2023-02-05 03:12:47 [INFO]	[TRAIN] epoch: 2792, iter: 220560/250000, loss: 0.1409, lr: 0.001459, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6284 samples/sec | ETA 04:36:59
2023-02-05 03:12:53 [INFO]	[TRAIN] epoch: 2793, iter: 220570/250000, loss: 0.1651, lr: 0.001458, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6288 samples/sec | ETA 04:36:53
2023-02-05 03:12:59 [INFO]	[TRAIN] epoch: 2793, iter: 220580/250000, loss: 0.1473, lr: 0.001458, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6292 samples/sec | ETA 04:36:47
2023-02-05 03:13:04 [INFO]	[TRAIN] epoch: 2793, iter: 220590/250000, loss: 0.1524, lr: 0.001457, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6326 samples/sec | ETA 04:36:36
2023-02-05 03:13:10 [INFO]	[TRAIN] epoch: 2793, iter: 220600/250000, loss: 0.1764, lr: 0.001457, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6314 samples/sec | ETA 04:36:32
2023-02-05 03:13:16 [INFO]	[TRAIN] epoch: 2793, iter: 220610/250000, loss: 0.1469, lr: 0.001456, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6251 samples/sec | ETA 04:36:36
2023-02-05 03:13:22 [INFO]	[TRAIN] epoch: 2793, iter: 220620/250000, loss: 0.1401, lr: 0.001456, batch_cost: 0.5902, reader_cost: 0.02537, ips: 10.1665 samples/sec | ETA 04:48:59
2023-02-05 03:13:27 [INFO]	[TRAIN] epoch: 2793, iter: 220630/250000, loss: 0.1601, lr: 0.001455, batch_cost: 0.5650, reader_cost: 0.00021, ips: 10.6204 samples/sec | ETA 04:36:32
2023-02-05 03:13:33 [INFO]	[TRAIN] epoch: 2793, iter: 220640/250000, loss: 0.1518, lr: 0.001455, batch_cost: 0.5646, reader_cost: 0.00008, ips: 10.6262 samples/sec | ETA 04:36:17
2023-02-05 03:13:39 [INFO]	[TRAIN] epoch: 2794, iter: 220650/250000, loss: 0.2109, lr: 0.001455, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6079 samples/sec | ETA 04:36:40
2023-02-05 03:13:44 [INFO]	[TRAIN] epoch: 2794, iter: 220660/250000, loss: 0.1521, lr: 0.001454, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6142 samples/sec | ETA 04:36:25
2023-02-05 03:13:50 [INFO]	[TRAIN] epoch: 2794, iter: 220670/250000, loss: 0.1756, lr: 0.001454, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6045 samples/sec | ETA 04:36:34
2023-02-05 03:13:56 [INFO]	[TRAIN] epoch: 2794, iter: 220680/250000, loss: 0.1857, lr: 0.001453, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6112 samples/sec | ETA 04:36:18
2023-02-05 03:14:01 [INFO]	[TRAIN] epoch: 2794, iter: 220690/250000, loss: 0.1659, lr: 0.001453, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6162 samples/sec | ETA 04:36:05
2023-02-05 03:14:07 [INFO]	[TRAIN] epoch: 2794, iter: 220700/250000, loss: 0.2392, lr: 0.001452, batch_cost: 0.6006, reader_cost: 0.03474, ips: 9.9901 samples/sec | ETA 04:53:17
2023-02-05 03:14:13 [INFO]	[TRAIN] epoch: 2794, iter: 220710/250000, loss: 0.2197, lr: 0.001452, batch_cost: 0.5648, reader_cost: 0.00022, ips: 10.6239 samples/sec | ETA 04:35:41
2023-02-05 03:14:18 [INFO]	[TRAIN] epoch: 2794, iter: 220720/250000, loss: 0.1338, lr: 0.001451, batch_cost: 0.5646, reader_cost: 0.00008, ips: 10.6275 samples/sec | ETA 04:35:30
2023-02-05 03:14:24 [INFO]	[TRAIN] epoch: 2795, iter: 220730/250000, loss: 0.2161, lr: 0.001451, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6134 samples/sec | ETA 04:35:47
2023-02-05 03:14:30 [INFO]	[TRAIN] epoch: 2795, iter: 220740/250000, loss: 0.1751, lr: 0.001450, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5964 samples/sec | ETA 04:36:07
2023-02-05 03:14:35 [INFO]	[TRAIN] epoch: 2795, iter: 220750/250000, loss: 0.1770, lr: 0.001450, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6016 samples/sec | ETA 04:35:54
2023-02-05 03:14:41 [INFO]	[TRAIN] epoch: 2795, iter: 220760/250000, loss: 0.1872, lr: 0.001450, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6118 samples/sec | ETA 04:35:32
2023-02-05 03:14:47 [INFO]	[TRAIN] epoch: 2795, iter: 220770/250000, loss: 0.1919, lr: 0.001449, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6095 samples/sec | ETA 04:35:30
2023-02-05 03:14:53 [INFO]	[TRAIN] epoch: 2795, iter: 220780/250000, loss: 0.1375, lr: 0.001449, batch_cost: 0.5871, reader_cost: 0.02174, ips: 10.2192 samples/sec | ETA 04:45:55
2023-02-05 03:14:58 [INFO]	[TRAIN] epoch: 2795, iter: 220790/250000, loss: 0.1974, lr: 0.001448, batch_cost: 0.5643, reader_cost: 0.00015, ips: 10.6335 samples/sec | ETA 04:34:41
2023-02-05 03:15:04 [INFO]	[TRAIN] epoch: 2795, iter: 220800/250000, loss: 0.1554, lr: 0.001448, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6331 samples/sec | ETA 04:34:36
2023-02-05 03:15:10 [INFO]	[TRAIN] epoch: 2796, iter: 220810/250000, loss: 0.1500, lr: 0.001447, batch_cost: 0.5648, reader_cost: 0.00008, ips: 10.6234 samples/sec | ETA 04:34:46
2023-02-05 03:15:15 [INFO]	[TRAIN] epoch: 2796, iter: 220820/250000, loss: 0.1921, lr: 0.001447, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6203 samples/sec | ETA 04:34:45
2023-02-05 03:15:21 [INFO]	[TRAIN] epoch: 2796, iter: 220830/250000, loss: 0.2103, lr: 0.001446, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6266 samples/sec | ETA 04:34:29
2023-02-05 03:15:27 [INFO]	[TRAIN] epoch: 2796, iter: 220840/250000, loss: 0.1553, lr: 0.001446, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6216 samples/sec | ETA 04:34:32
2023-02-05 03:15:32 [INFO]	[TRAIN] epoch: 2796, iter: 220850/250000, loss: 0.2075, lr: 0.001446, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6023 samples/sec | ETA 04:34:56
2023-02-05 03:15:38 [INFO]	[TRAIN] epoch: 2796, iter: 220860/250000, loss: 0.1763, lr: 0.001445, batch_cost: 0.5988, reader_cost: 0.03324, ips: 10.0193 samples/sec | ETA 04:50:50
2023-02-05 03:15:44 [INFO]	[TRAIN] epoch: 2796, iter: 220870/250000, loss: 0.1624, lr: 0.001445, batch_cost: 0.5645, reader_cost: 0.00013, ips: 10.6298 samples/sec | ETA 04:34:02
2023-02-05 03:15:49 [INFO]	[TRAIN] epoch: 2796, iter: 220880/250000, loss: 0.1452, lr: 0.001444, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6279 samples/sec | ETA 04:33:59
2023-02-05 03:15:55 [INFO]	[TRAIN] epoch: 2797, iter: 220890/250000, loss: 0.2042, lr: 0.001444, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6311 samples/sec | ETA 04:33:49
2023-02-05 03:16:01 [INFO]	[TRAIN] epoch: 2797, iter: 220900/250000, loss: 0.1477, lr: 0.001443, batch_cost: 0.5651, reader_cost: 0.00016, ips: 10.6182 samples/sec | ETA 04:34:03
2023-02-05 03:16:06 [INFO]	[TRAIN] epoch: 2797, iter: 220910/250000, loss: 0.1371, lr: 0.001443, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6296 samples/sec | ETA 04:33:40
2023-02-05 03:16:12 [INFO]	[TRAIN] epoch: 2797, iter: 220920/250000, loss: 0.1766, lr: 0.001442, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6355 samples/sec | ETA 04:33:25
2023-02-05 03:16:18 [INFO]	[TRAIN] epoch: 2797, iter: 220930/250000, loss: 0.2177, lr: 0.001442, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6304 samples/sec | ETA 04:33:27
2023-02-05 03:16:24 [INFO]	[TRAIN] epoch: 2797, iter: 220940/250000, loss: 0.1606, lr: 0.001442, batch_cost: 0.5923, reader_cost: 0.02720, ips: 10.1300 samples/sec | ETA 04:46:52
2023-02-05 03:16:29 [INFO]	[TRAIN] epoch: 2797, iter: 220950/250000, loss: 0.1571, lr: 0.001441, batch_cost: 0.5651, reader_cost: 0.00011, ips: 10.6180 samples/sec | ETA 04:33:35
2023-02-05 03:16:35 [INFO]	[TRAIN] epoch: 2797, iter: 220960/250000, loss: 0.1747, lr: 0.001441, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6038 samples/sec | ETA 04:33:51
2023-02-05 03:16:41 [INFO]	[TRAIN] epoch: 2798, iter: 220970/250000, loss: 0.1660, lr: 0.001440, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6047 samples/sec | ETA 04:33:44
2023-02-05 03:16:46 [INFO]	[TRAIN] epoch: 2798, iter: 220980/250000, loss: 0.1587, lr: 0.001440, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6179 samples/sec | ETA 04:33:18
2023-02-05 03:16:52 [INFO]	[TRAIN] epoch: 2798, iter: 220990/250000, loss: 0.2051, lr: 0.001439, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6073 samples/sec | ETA 04:33:29
2023-02-05 03:16:58 [INFO]	[TRAIN] epoch: 2798, iter: 221000/250000, loss: 0.1571, lr: 0.001439, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5952 samples/sec | ETA 04:33:42
2023-02-05 03:17:03 [INFO]	[TRAIN] epoch: 2798, iter: 221010/250000, loss: 0.1881, lr: 0.001438, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6126 samples/sec | ETA 04:33:10
2023-02-05 03:17:09 [INFO]	[TRAIN] epoch: 2798, iter: 221020/250000, loss: 0.1906, lr: 0.001438, batch_cost: 0.5990, reader_cost: 0.03409, ips: 10.0162 samples/sec | ETA 04:49:19
2023-02-05 03:17:15 [INFO]	[TRAIN] epoch: 2798, iter: 221030/250000, loss: 0.1572, lr: 0.001438, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6203 samples/sec | ETA 04:32:46
2023-02-05 03:17:20 [INFO]	[TRAIN] epoch: 2798, iter: 221040/250000, loss: 0.1871, lr: 0.001437, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6126 samples/sec | ETA 04:32:52
2023-02-05 03:17:26 [INFO]	[TRAIN] epoch: 2799, iter: 221050/250000, loss: 0.1618, lr: 0.001437, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6118 samples/sec | ETA 04:32:48
2023-02-05 03:17:32 [INFO]	[TRAIN] epoch: 2799, iter: 221060/250000, loss: 0.1509, lr: 0.001436, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6094 samples/sec | ETA 04:32:46
2023-02-05 03:17:37 [INFO]	[TRAIN] epoch: 2799, iter: 221070/250000, loss: 0.1839, lr: 0.001436, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6020 samples/sec | ETA 04:32:52
2023-02-05 03:17:43 [INFO]	[TRAIN] epoch: 2799, iter: 221080/250000, loss: 0.1911, lr: 0.001435, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6054 samples/sec | ETA 04:32:41
2023-02-05 03:17:49 [INFO]	[TRAIN] epoch: 2799, iter: 221090/250000, loss: 0.1671, lr: 0.001435, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5996 samples/sec | ETA 04:32:44
2023-02-05 03:17:55 [INFO]	[TRAIN] epoch: 2799, iter: 221100/250000, loss: 0.1863, lr: 0.001434, batch_cost: 0.6022, reader_cost: 0.03739, ips: 9.9633 samples/sec | ETA 04:50:03
2023-02-05 03:18:00 [INFO]	[TRAIN] epoch: 2799, iter: 221110/250000, loss: 0.1610, lr: 0.001434, batch_cost: 0.5646, reader_cost: 0.00008, ips: 10.6279 samples/sec | ETA 04:31:49
2023-02-05 03:18:06 [INFO]	[TRAIN] epoch: 2799, iter: 221120/250000, loss: 0.1711, lr: 0.001434, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6278 samples/sec | ETA 04:31:44
2023-02-05 03:18:12 [INFO]	[TRAIN] epoch: 2800, iter: 221130/250000, loss: 0.1751, lr: 0.001433, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6206 samples/sec | ETA 04:31:49
2023-02-05 03:18:17 [INFO]	[TRAIN] epoch: 2800, iter: 221140/250000, loss: 0.1345, lr: 0.001433, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6305 samples/sec | ETA 04:31:29
2023-02-05 03:18:23 [INFO]	[TRAIN] epoch: 2800, iter: 221150/250000, loss: 0.1729, lr: 0.001432, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6291 samples/sec | ETA 04:31:25
2023-02-05 03:18:29 [INFO]	[TRAIN] epoch: 2800, iter: 221160/250000, loss: 0.1503, lr: 0.001432, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6233 samples/sec | ETA 04:31:28
2023-02-05 03:18:34 [INFO]	[TRAIN] epoch: 2800, iter: 221170/250000, loss: 0.1462, lr: 0.001431, batch_cost: 0.5649, reader_cost: 0.00008, ips: 10.6220 samples/sec | ETA 04:31:25
2023-02-05 03:18:40 [INFO]	[TRAIN] epoch: 2800, iter: 221180/250000, loss: 0.1448, lr: 0.001431, batch_cost: 0.5864, reader_cost: 0.02138, ips: 10.2316 samples/sec | ETA 04:41:40
2023-02-05 03:18:46 [INFO]	[TRAIN] epoch: 2800, iter: 221190/250000, loss: 0.1905, lr: 0.001430, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6368 samples/sec | ETA 04:30:51
2023-02-05 03:18:51 [INFO]	[TRAIN] epoch: 2800, iter: 221200/250000, loss: 0.1975, lr: 0.001430, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6311 samples/sec | ETA 04:30:54
2023-02-05 03:18:57 [INFO]	[TRAIN] epoch: 2801, iter: 221210/250000, loss: 0.2385, lr: 0.001430, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6079 samples/sec | ETA 04:31:24
2023-02-05 03:19:03 [INFO]	[TRAIN] epoch: 2801, iter: 221220/250000, loss: 0.2644, lr: 0.001429, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6075 samples/sec | ETA 04:31:19
2023-02-05 03:19:08 [INFO]	[TRAIN] epoch: 2801, iter: 221230/250000, loss: 0.1882, lr: 0.001429, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6060 samples/sec | ETA 04:31:15
2023-02-05 03:19:14 [INFO]	[TRAIN] epoch: 2801, iter: 221240/250000, loss: 0.1730, lr: 0.001428, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6124 samples/sec | ETA 04:31:00
2023-02-05 03:19:20 [INFO]	[TRAIN] epoch: 2801, iter: 221250/250000, loss: 0.1824, lr: 0.001428, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6142 samples/sec | ETA 04:30:51
2023-02-05 03:19:26 [INFO]	[TRAIN] epoch: 2801, iter: 221260/250000, loss: 0.1862, lr: 0.001427, batch_cost: 0.5868, reader_cost: 0.02199, ips: 10.2243 samples/sec | ETA 04:41:05
2023-02-05 03:19:31 [INFO]	[TRAIN] epoch: 2801, iter: 221270/250000, loss: 0.1633, lr: 0.001427, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6254 samples/sec | ETA 04:30:23
2023-02-05 03:19:37 [INFO]	[TRAIN] epoch: 2802, iter: 221280/250000, loss: 0.2210, lr: 0.001426, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6279 samples/sec | ETA 04:30:13
2023-02-05 03:19:43 [INFO]	[TRAIN] epoch: 2802, iter: 221290/250000, loss: 0.1421, lr: 0.001426, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6323 samples/sec | ETA 04:30:01
2023-02-05 03:19:48 [INFO]	[TRAIN] epoch: 2802, iter: 221300/250000, loss: 0.1775, lr: 0.001425, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6082 samples/sec | ETA 04:30:32
2023-02-05 03:19:54 [INFO]	[TRAIN] epoch: 2802, iter: 221310/250000, loss: 0.1570, lr: 0.001425, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6059 samples/sec | ETA 04:30:30
2023-02-05 03:20:00 [INFO]	[TRAIN] epoch: 2802, iter: 221320/250000, loss: 0.1822, lr: 0.001425, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6118 samples/sec | ETA 04:30:15
2023-02-05 03:20:05 [INFO]	[TRAIN] epoch: 2802, iter: 221330/250000, loss: 0.2118, lr: 0.001424, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6007 samples/sec | ETA 04:30:27
2023-02-05 03:20:11 [INFO]	[TRAIN] epoch: 2802, iter: 221340/250000, loss: 0.1723, lr: 0.001424, batch_cost: 0.5951, reader_cost: 0.03072, ips: 10.0822 samples/sec | ETA 04:44:15
2023-02-05 03:20:17 [INFO]	[TRAIN] epoch: 2802, iter: 221350/250000, loss: 0.1827, lr: 0.001423, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6290 samples/sec | ETA 04:29:32
2023-02-05 03:20:22 [INFO]	[TRAIN] epoch: 2803, iter: 221360/250000, loss: 0.1383, lr: 0.001423, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6105 samples/sec | ETA 04:29:55
2023-02-05 03:20:28 [INFO]	[TRAIN] epoch: 2803, iter: 221370/250000, loss: 0.1852, lr: 0.001422, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6018 samples/sec | ETA 04:30:02
2023-02-05 03:20:34 [INFO]	[TRAIN] epoch: 2803, iter: 221380/250000, loss: 0.1464, lr: 0.001422, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6050 samples/sec | ETA 04:29:52
2023-02-05 03:20:39 [INFO]	[TRAIN] epoch: 2803, iter: 221390/250000, loss: 0.1439, lr: 0.001421, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6106 samples/sec | ETA 04:29:38
2023-02-05 03:20:45 [INFO]	[TRAIN] epoch: 2803, iter: 221400/250000, loss: 0.1944, lr: 0.001421, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6033 samples/sec | ETA 04:29:43
2023-02-05 03:20:51 [INFO]	[TRAIN] epoch: 2803, iter: 221410/250000, loss: 0.1965, lr: 0.001421, batch_cost: 0.5906, reader_cost: 0.02520, ips: 10.1599 samples/sec | ETA 04:41:24
2023-02-05 03:20:57 [INFO]	[TRAIN] epoch: 2803, iter: 221420/250000, loss: 0.1595, lr: 0.001420, batch_cost: 0.5660, reader_cost: 0.00014, ips: 10.6014 samples/sec | ETA 04:29:35
2023-02-05 03:21:02 [INFO]	[TRAIN] epoch: 2803, iter: 221430/250000, loss: 0.1795, lr: 0.001420, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6303 samples/sec | ETA 04:28:45
2023-02-05 03:21:08 [INFO]	[TRAIN] epoch: 2804, iter: 221440/250000, loss: 0.1480, lr: 0.001419, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6340 samples/sec | ETA 04:28:34
2023-02-05 03:21:14 [INFO]	[TRAIN] epoch: 2804, iter: 221450/250000, loss: 0.1455, lr: 0.001419, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6162 samples/sec | ETA 04:28:55
2023-02-05 03:21:19 [INFO]	[TRAIN] epoch: 2804, iter: 221460/250000, loss: 0.1934, lr: 0.001418, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6110 samples/sec | ETA 04:28:57
2023-02-05 03:21:25 [INFO]	[TRAIN] epoch: 2804, iter: 221470/250000, loss: 0.1622, lr: 0.001418, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6002 samples/sec | ETA 04:29:08
2023-02-05 03:21:31 [INFO]	[TRAIN] epoch: 2804, iter: 221480/250000, loss: 0.1753, lr: 0.001417, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6038 samples/sec | ETA 04:28:57
2023-02-05 03:21:36 [INFO]	[TRAIN] epoch: 2804, iter: 221490/250000, loss: 0.1430, lr: 0.001417, batch_cost: 0.5932, reader_cost: 0.02778, ips: 10.1142 samples/sec | ETA 04:41:52
2023-02-05 03:21:42 [INFO]	[TRAIN] epoch: 2804, iter: 221500/250000, loss: 0.1692, lr: 0.001417, batch_cost: 0.5646, reader_cost: 0.00015, ips: 10.6276 samples/sec | ETA 04:28:10
2023-02-05 03:21:48 [INFO]	[TRAIN] epoch: 2804, iter: 221510/250000, loss: 0.2296, lr: 0.001416, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6088 samples/sec | ETA 04:28:33
2023-02-05 03:21:53 [INFO]	[TRAIN] epoch: 2805, iter: 221520/250000, loss: 0.1791, lr: 0.001416, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6090 samples/sec | ETA 04:28:27
2023-02-05 03:21:59 [INFO]	[TRAIN] epoch: 2805, iter: 221530/250000, loss: 0.2294, lr: 0.001415, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6205 samples/sec | ETA 04:28:03
2023-02-05 03:22:05 [INFO]	[TRAIN] epoch: 2805, iter: 221540/250000, loss: 0.1785, lr: 0.001415, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6076 samples/sec | ETA 04:28:17
2023-02-05 03:22:10 [INFO]	[TRAIN] epoch: 2805, iter: 221550/250000, loss: 0.1705, lr: 0.001414, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6105 samples/sec | ETA 04:28:07
2023-02-05 03:22:16 [INFO]	[TRAIN] epoch: 2805, iter: 221560/250000, loss: 0.1698, lr: 0.001414, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6028 samples/sec | ETA 04:28:13
2023-02-05 03:22:22 [INFO]	[TRAIN] epoch: 2805, iter: 221570/250000, loss: 0.1717, lr: 0.001413, batch_cost: 0.5933, reader_cost: 0.02803, ips: 10.1125 samples/sec | ETA 04:41:08
2023-02-05 03:22:28 [INFO]	[TRAIN] epoch: 2805, iter: 221580/250000, loss: 0.1743, lr: 0.001413, batch_cost: 0.5653, reader_cost: 0.00013, ips: 10.6136 samples/sec | ETA 04:27:46
2023-02-05 03:22:33 [INFO]	[TRAIN] epoch: 2805, iter: 221590/250000, loss: 0.1958, lr: 0.001413, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6138 samples/sec | ETA 04:27:40
2023-02-05 03:22:39 [INFO]	[TRAIN] epoch: 2806, iter: 221600/250000, loss: 0.1773, lr: 0.001412, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6111 samples/sec | ETA 04:27:38
2023-02-05 03:22:45 [INFO]	[TRAIN] epoch: 2806, iter: 221610/250000, loss: 0.1586, lr: 0.001412, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6029 samples/sec | ETA 04:27:45
2023-02-05 03:22:50 [INFO]	[TRAIN] epoch: 2806, iter: 221620/250000, loss: 0.1607, lr: 0.001411, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6100 samples/sec | ETA 04:27:28
2023-02-05 03:22:56 [INFO]	[TRAIN] epoch: 2806, iter: 221630/250000, loss: 0.1530, lr: 0.001411, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6112 samples/sec | ETA 04:27:21
2023-02-05 03:23:02 [INFO]	[TRAIN] epoch: 2806, iter: 221640/250000, loss: 0.1560, lr: 0.001410, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6022 samples/sec | ETA 04:27:29
2023-02-05 03:23:08 [INFO]	[TRAIN] epoch: 2806, iter: 221650/250000, loss: 0.1600, lr: 0.001410, batch_cost: 0.5958, reader_cost: 0.03032, ips: 10.0708 samples/sec | ETA 04:41:30
2023-02-05 03:23:13 [INFO]	[TRAIN] epoch: 2806, iter: 221660/250000, loss: 0.1664, lr: 0.001409, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6326 samples/sec | ETA 04:26:32
2023-02-05 03:23:19 [INFO]	[TRAIN] epoch: 2806, iter: 221670/250000, loss: 0.1654, lr: 0.001409, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6137 samples/sec | ETA 04:26:55
2023-02-05 03:23:24 [INFO]	[TRAIN] epoch: 2807, iter: 221680/250000, loss: 0.2240, lr: 0.001408, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6022 samples/sec | ETA 04:27:06
2023-02-05 03:23:30 [INFO]	[TRAIN] epoch: 2807, iter: 221690/250000, loss: 0.1746, lr: 0.001408, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6116 samples/sec | ETA 04:26:47
2023-02-05 03:23:36 [INFO]	[TRAIN] epoch: 2807, iter: 221700/250000, loss: 0.1431, lr: 0.001408, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6152 samples/sec | ETA 04:26:35
2023-02-05 03:23:41 [INFO]	[TRAIN] epoch: 2807, iter: 221710/250000, loss: 0.1772, lr: 0.001407, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.5999 samples/sec | ETA 04:26:53
2023-02-05 03:23:47 [INFO]	[TRAIN] epoch: 2807, iter: 221720/250000, loss: 0.1391, lr: 0.001407, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6029 samples/sec | ETA 04:26:43
2023-02-05 03:23:53 [INFO]	[TRAIN] epoch: 2807, iter: 221730/250000, loss: 0.1411, lr: 0.001406, batch_cost: 0.5971, reader_cost: 0.03274, ips: 10.0481 samples/sec | ETA 04:41:20
2023-02-05 03:23:59 [INFO]	[TRAIN] epoch: 2807, iter: 221740/250000, loss: 0.1445, lr: 0.001406, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6296 samples/sec | ETA 04:25:51
2023-02-05 03:24:04 [INFO]	[TRAIN] epoch: 2807, iter: 221750/250000, loss: 0.1516, lr: 0.001405, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6311 samples/sec | ETA 04:25:43
2023-02-05 03:24:10 [INFO]	[TRAIN] epoch: 2808, iter: 221760/250000, loss: 0.1418, lr: 0.001405, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6286 samples/sec | ETA 04:25:41
2023-02-05 03:24:16 [INFO]	[TRAIN] epoch: 2808, iter: 221770/250000, loss: 0.1524, lr: 0.001404, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6128 samples/sec | ETA 04:25:59
2023-02-05 03:24:21 [INFO]	[TRAIN] epoch: 2808, iter: 221780/250000, loss: 0.1719, lr: 0.001404, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6133 samples/sec | ETA 04:25:53
2023-02-05 03:24:27 [INFO]	[TRAIN] epoch: 2808, iter: 221790/250000, loss: 0.1223, lr: 0.001404, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6090 samples/sec | ETA 04:25:54
2023-02-05 03:24:33 [INFO]	[TRAIN] epoch: 2808, iter: 221800/250000, loss: 0.1567, lr: 0.001403, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6048 samples/sec | ETA 04:25:55
2023-02-05 03:24:39 [INFO]	[TRAIN] epoch: 2808, iter: 221810/250000, loss: 0.1356, lr: 0.001403, batch_cost: 0.5933, reader_cost: 0.02869, ips: 10.1126 samples/sec | ETA 04:38:45
2023-02-05 03:24:44 [INFO]	[TRAIN] epoch: 2808, iter: 221820/250000, loss: 0.1553, lr: 0.001402, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6256 samples/sec | ETA 04:25:12
2023-02-05 03:24:50 [INFO]	[TRAIN] epoch: 2808, iter: 221830/250000, loss: 0.2119, lr: 0.001402, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6307 samples/sec | ETA 04:24:59
2023-02-05 03:24:56 [INFO]	[TRAIN] epoch: 2809, iter: 221840/250000, loss: 0.1507, lr: 0.001401, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6056 samples/sec | ETA 04:25:31
2023-02-05 03:25:01 [INFO]	[TRAIN] epoch: 2809, iter: 221850/250000, loss: 0.1522, lr: 0.001401, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6041 samples/sec | ETA 04:25:27
2023-02-05 03:25:07 [INFO]	[TRAIN] epoch: 2809, iter: 221860/250000, loss: 0.1431, lr: 0.001400, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6075 samples/sec | ETA 04:25:17
2023-02-05 03:25:13 [INFO]	[TRAIN] epoch: 2809, iter: 221870/250000, loss: 0.1711, lr: 0.001400, batch_cost: 0.5662, reader_cost: 0.00051, ips: 10.5962 samples/sec | ETA 04:25:28
2023-02-05 03:25:18 [INFO]	[TRAIN] epoch: 2809, iter: 221880/250000, loss: 0.1486, lr: 0.001400, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6021 samples/sec | ETA 04:25:13
2023-02-05 03:25:24 [INFO]	[TRAIN] epoch: 2809, iter: 221890/250000, loss: 0.1434, lr: 0.001399, batch_cost: 0.5976, reader_cost: 0.03279, ips: 10.0408 samples/sec | ETA 04:39:57
2023-02-05 03:25:30 [INFO]	[TRAIN] epoch: 2809, iter: 221900/250000, loss: 0.1400, lr: 0.001399, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6327 samples/sec | ETA 04:24:16
2023-02-05 03:25:35 [INFO]	[TRAIN] epoch: 2809, iter: 221910/250000, loss: 0.1530, lr: 0.001398, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6227 samples/sec | ETA 04:24:26
2023-02-05 03:25:41 [INFO]	[TRAIN] epoch: 2810, iter: 221920/250000, loss: 0.1602, lr: 0.001398, batch_cost: 0.5648, reader_cost: 0.00008, ips: 10.6224 samples/sec | ETA 04:24:20
2023-02-05 03:25:47 [INFO]	[TRAIN] epoch: 2810, iter: 221930/250000, loss: 0.1493, lr: 0.001397, batch_cost: 0.5646, reader_cost: 0.00011, ips: 10.6272 samples/sec | ETA 04:24:07
2023-02-05 03:25:52 [INFO]	[TRAIN] epoch: 2810, iter: 221940/250000, loss: 0.1395, lr: 0.001397, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6336 samples/sec | ETA 04:23:52
2023-02-05 03:25:58 [INFO]	[TRAIN] epoch: 2810, iter: 221950/250000, loss: 0.1482, lr: 0.001396, batch_cost: 0.5647, reader_cost: 0.00011, ips: 10.6246 samples/sec | ETA 04:24:00
2023-02-05 03:26:04 [INFO]	[TRAIN] epoch: 2810, iter: 221960/250000, loss: 0.2067, lr: 0.001396, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6250 samples/sec | ETA 04:23:54
2023-02-05 03:26:10 [INFO]	[TRAIN] epoch: 2810, iter: 221970/250000, loss: 0.1529, lr: 0.001395, batch_cost: 0.5907, reader_cost: 0.02614, ips: 10.1577 samples/sec | ETA 04:35:56
2023-02-05 03:26:15 [INFO]	[TRAIN] epoch: 2810, iter: 221980/250000, loss: 0.1469, lr: 0.001395, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6381 samples/sec | ETA 04:23:23
2023-02-05 03:26:21 [INFO]	[TRAIN] epoch: 2810, iter: 221990/250000, loss: 0.1655, lr: 0.001395, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6049 samples/sec | ETA 04:24:07
2023-02-05 03:26:27 [INFO]	[TRAIN] epoch: 2811, iter: 222000/250000, loss: 0.1645, lr: 0.001394, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6004 samples/sec | ETA 04:24:08
2023-02-05 03:26:27 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1243 - reader cost: 0.0223 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1493 - reader cost: 0.0112 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1565 - reader cost: 0.0075 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1567 - reader cost: 0.0056 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1578 - reader cost: 0.0045 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1600 - reader cost: 0.0038 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1596 - reader cost: 0.0033 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1599 - reader cost: 0.0029 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1612 - reader cost: 0.002510/36 [=======>......................] - ETA: 4s - batch_cost: 0.1609 - reader cost: 0.002311/36 [========>.....................] - ETA: 4s - batch_cost: 0.1616 - reader cost: 0.002112/36 [=========>....................] - ETA: 3s - batch_cost: 0.1615 - reader cost: 0.001913/36 [=========>....................] - ETA: 3s - batch_cost: 0.1619 - reader cost: 0.001814/36 [==========>...................] - ETA: 3s - batch_cost: 0.1623 - reader cost: 0.001715/36 [===========>..................] - ETA: 3s - batch_cost: 0.1627 - reader cost: 0.001616/36 [============>.................] - ETA: 3s - batch_cost: 0.1639 - reader cost: 0.001517/36 [=============>................] - ETA: 3s - batch_cost: 0.1642 - reader cost: 0.001418/36 [==============>...............] - ETA: 2s - batch_cost: 0.1644 - reader cost: 0.001319/36 [==============>...............] - ETA: 2s - batch_cost: 0.1642 - reader cost: 0.001220/36 [===============>..............] - ETA: 2s - batch_cost: 0.1642 - reader cost: 0.001221/36 [================>.............] - ETA: 2s - batch_cost: 0.1642 - reader cost: 0.001122/36 [=================>............] - ETA: 2s - batch_cost: 0.1644 - reader cost: 0.001123/36 [==================>...........] - ETA: 2s - batch_cost: 0.1650 - reader cost: 0.001024/36 [===================>..........] - ETA: 1s - batch_cost: 0.1649 - reader cost: 0.001025/36 [===================>..........] - ETA: 1s - batch_cost: 0.1651 - reader cost: 9.6595e-0426/36 [====================>.........] - ETA: 1s - batch_cost: 0.1652 - reader cost: 9.3199e-0427/36 [=====================>........] - ETA: 1s - batch_cost: 0.1654 - reader cost: 9.0069e-0428/36 [======================>.......] - ETA: 1s - batch_cost: 0.1657 - reader cost: 8.7100e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1658 - reader cost: 8.4336e-0430/36 [========================>.....] - ETA: 0s - batch_cost: 0.1656 - reader cost: 8.1754e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1656 - reader cost: 7.9347e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1656 - reader cost: 7.7090e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1653 - reader cost: 7.4991e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1652 - reader cost: 7.3013e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1652 - reader cost: 7.1156e-0436/36 [==============================] - 6s 165ms/step - batch_cost: 0.1653 - reader cost: 6.9352e-04
2023-02-05 03:26:32 [INFO]	[EVAL] #Images: 36 mIoU: 0.8682 Acc: 0.9864 Kappa: 0.9512 Dice: 0.9262
2023-02-05 03:26:32 [INFO]	[EVAL] Class IoU: 
[0.9861 0.9158 0.8913 0.7213 0.7176 0.9709 0.8743]
2023-02-05 03:26:32 [INFO]	[EVAL] Class Precision: 
[0.9944 0.9692 0.9305 0.8051 0.8215 0.9771 0.9015]
2023-02-05 03:26:32 [INFO]	[EVAL] Class Recall: 
[0.9916 0.9433 0.9548 0.8739 0.8501 0.9935 0.9667]
2023-02-05 03:26:33 [INFO]	[EVAL] The model with the best validation mIoU (0.8682) was saved at iter 222000.
2023-02-05 03:26:39 [INFO]	[TRAIN] epoch: 2811, iter: 222010/250000, loss: 0.1620, lr: 0.001394, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6396 samples/sec | ETA 04:23:04
2023-02-05 03:26:44 [INFO]	[TRAIN] epoch: 2811, iter: 222020/250000, loss: 0.1830, lr: 0.001393, batch_cost: 0.5635, reader_cost: 0.00010, ips: 10.6481 samples/sec | ETA 04:22:46
2023-02-05 03:26:50 [INFO]	[TRAIN] epoch: 2811, iter: 222030/250000, loss: 0.1891, lr: 0.001393, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6313 samples/sec | ETA 04:23:05
2023-02-05 03:26:56 [INFO]	[TRAIN] epoch: 2811, iter: 222040/250000, loss: 0.1818, lr: 0.001392, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6300 samples/sec | ETA 04:23:01
2023-02-05 03:27:02 [INFO]	[TRAIN] epoch: 2811, iter: 222050/250000, loss: 0.1787, lr: 0.001392, batch_cost: 0.5859, reader_cost: 0.02122, ips: 10.2400 samples/sec | ETA 04:32:57
2023-02-05 03:27:07 [INFO]	[TRAIN] epoch: 2811, iter: 222060/250000, loss: 0.1781, lr: 0.001391, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6240 samples/sec | ETA 04:22:59
2023-02-05 03:27:13 [INFO]	[TRAIN] epoch: 2812, iter: 222070/250000, loss: 0.1706, lr: 0.001391, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6406 samples/sec | ETA 04:22:29
2023-02-05 03:27:19 [INFO]	[TRAIN] epoch: 2812, iter: 222080/250000, loss: 0.1714, lr: 0.001391, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6333 samples/sec | ETA 04:22:34
2023-02-05 03:27:24 [INFO]	[TRAIN] epoch: 2812, iter: 222090/250000, loss: 0.1418, lr: 0.001390, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6257 samples/sec | ETA 04:22:39
2023-02-05 03:27:30 [INFO]	[TRAIN] epoch: 2812, iter: 222100/250000, loss: 0.2042, lr: 0.001390, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6325 samples/sec | ETA 04:22:24
2023-02-05 03:27:35 [INFO]	[TRAIN] epoch: 2812, iter: 222110/250000, loss: 0.1564, lr: 0.001389, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6320 samples/sec | ETA 04:22:19
2023-02-05 03:27:41 [INFO]	[TRAIN] epoch: 2812, iter: 222120/250000, loss: 0.1787, lr: 0.001389, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6322 samples/sec | ETA 04:22:13
2023-02-05 03:27:47 [INFO]	[TRAIN] epoch: 2812, iter: 222130/250000, loss: 0.1819, lr: 0.001388, batch_cost: 0.5928, reader_cost: 0.02810, ips: 10.1222 samples/sec | ETA 04:35:20
2023-02-05 03:27:53 [INFO]	[TRAIN] epoch: 2812, iter: 222140/250000, loss: 0.1798, lr: 0.001388, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6212 samples/sec | ETA 04:22:18
2023-02-05 03:27:58 [INFO]	[TRAIN] epoch: 2813, iter: 222150/250000, loss: 0.1455, lr: 0.001387, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6063 samples/sec | ETA 04:22:34
2023-02-05 03:28:04 [INFO]	[TRAIN] epoch: 2813, iter: 222160/250000, loss: 0.1911, lr: 0.001387, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6103 samples/sec | ETA 04:22:23
2023-02-05 03:28:10 [INFO]	[TRAIN] epoch: 2813, iter: 222170/250000, loss: 0.1769, lr: 0.001387, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6078 samples/sec | ETA 04:22:21
2023-02-05 03:28:15 [INFO]	[TRAIN] epoch: 2813, iter: 222180/250000, loss: 0.1448, lr: 0.001386, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6153 samples/sec | ETA 04:22:04
2023-02-05 03:28:21 [INFO]	[TRAIN] epoch: 2813, iter: 222190/250000, loss: 0.1517, lr: 0.001386, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6159 samples/sec | ETA 04:21:57
2023-02-05 03:28:27 [INFO]	[TRAIN] epoch: 2813, iter: 222200/250000, loss: 0.1800, lr: 0.001385, batch_cost: 0.5877, reader_cost: 0.02205, ips: 10.2089 samples/sec | ETA 04:32:18
2023-02-05 03:28:32 [INFO]	[TRAIN] epoch: 2813, iter: 222210/250000, loss: 0.1912, lr: 0.001385, batch_cost: 0.5653, reader_cost: 0.00013, ips: 10.6145 samples/sec | ETA 04:21:48
2023-02-05 03:28:38 [INFO]	[TRAIN] epoch: 2813, iter: 222220/250000, loss: 0.2297, lr: 0.001384, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6362 samples/sec | ETA 04:21:11
2023-02-05 03:28:44 [INFO]	[TRAIN] epoch: 2814, iter: 222230/250000, loss: 0.1920, lr: 0.001384, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6119 samples/sec | ETA 04:21:41
2023-02-05 03:28:49 [INFO]	[TRAIN] epoch: 2814, iter: 222240/250000, loss: 0.1548, lr: 0.001383, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6092 samples/sec | ETA 04:21:39
2023-02-05 03:28:55 [INFO]	[TRAIN] epoch: 2814, iter: 222250/250000, loss: 0.1744, lr: 0.001383, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6127 samples/sec | ETA 04:21:28
2023-02-05 03:29:01 [INFO]	[TRAIN] epoch: 2814, iter: 222260/250000, loss: 0.2143, lr: 0.001382, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6150 samples/sec | ETA 04:21:19
2023-02-05 03:29:06 [INFO]	[TRAIN] epoch: 2814, iter: 222270/250000, loss: 0.1493, lr: 0.001382, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6036 samples/sec | ETA 04:21:30
2023-02-05 03:29:12 [INFO]	[TRAIN] epoch: 2814, iter: 222280/250000, loss: 0.1799, lr: 0.001382, batch_cost: 0.5890, reader_cost: 0.02375, ips: 10.1862 samples/sec | ETA 04:32:08
2023-02-05 03:29:18 [INFO]	[TRAIN] epoch: 2814, iter: 222290/250000, loss: 0.1690, lr: 0.001381, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6319 samples/sec | ETA 04:20:37
2023-02-05 03:29:24 [INFO]	[TRAIN] epoch: 2814, iter: 222300/250000, loss: 0.1658, lr: 0.001381, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6001 samples/sec | ETA 04:21:19
2023-02-05 03:29:29 [INFO]	[TRAIN] epoch: 2815, iter: 222310/250000, loss: 0.1629, lr: 0.001380, batch_cost: 0.5663, reader_cost: 0.00010, ips: 10.5946 samples/sec | ETA 04:21:21
2023-02-05 03:29:35 [INFO]	[TRAIN] epoch: 2815, iter: 222320/250000, loss: 0.1926, lr: 0.001380, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6055 samples/sec | ETA 04:20:59
2023-02-05 03:29:41 [INFO]	[TRAIN] epoch: 2815, iter: 222330/250000, loss: 0.1609, lr: 0.001379, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6048 samples/sec | ETA 04:20:55
2023-02-05 03:29:46 [INFO]	[TRAIN] epoch: 2815, iter: 222340/250000, loss: 0.1651, lr: 0.001379, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6126 samples/sec | ETA 04:20:38
2023-02-05 03:29:52 [INFO]	[TRAIN] epoch: 2815, iter: 222350/250000, loss: 0.1632, lr: 0.001378, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6067 samples/sec | ETA 04:20:41
2023-02-05 03:29:58 [INFO]	[TRAIN] epoch: 2815, iter: 222360/250000, loss: 0.1586, lr: 0.001378, batch_cost: 0.5882, reader_cost: 0.02219, ips: 10.2014 samples/sec | ETA 04:30:56
2023-02-05 03:30:03 [INFO]	[TRAIN] epoch: 2815, iter: 222370/250000, loss: 0.1647, lr: 0.001378, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6243 samples/sec | ETA 04:20:03
2023-02-05 03:30:09 [INFO]	[TRAIN] epoch: 2815, iter: 222380/250000, loss: 0.1509, lr: 0.001377, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6319 samples/sec | ETA 04:19:46
2023-02-05 03:30:15 [INFO]	[TRAIN] epoch: 2816, iter: 222390/250000, loss: 0.1507, lr: 0.001377, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6339 samples/sec | ETA 04:19:38
2023-02-05 03:30:20 [INFO]	[TRAIN] epoch: 2816, iter: 222400/250000, loss: 0.1843, lr: 0.001376, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6252 samples/sec | ETA 04:19:45
2023-02-05 03:30:26 [INFO]	[TRAIN] epoch: 2816, iter: 222410/250000, loss: 0.1492, lr: 0.001376, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6270 samples/sec | ETA 04:19:37
2023-02-05 03:30:32 [INFO]	[TRAIN] epoch: 2816, iter: 222420/250000, loss: 0.1851, lr: 0.001375, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6138 samples/sec | ETA 04:19:51
2023-02-05 03:30:37 [INFO]	[TRAIN] epoch: 2816, iter: 222430/250000, loss: 0.1665, lr: 0.001375, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6157 samples/sec | ETA 04:19:42
2023-02-05 03:30:43 [INFO]	[TRAIN] epoch: 2816, iter: 222440/250000, loss: 0.1593, lr: 0.001374, batch_cost: 0.5839, reader_cost: 0.01883, ips: 10.2762 samples/sec | ETA 04:28:11
2023-02-05 03:30:49 [INFO]	[TRAIN] epoch: 2816, iter: 222450/250000, loss: 0.1774, lr: 0.001374, batch_cost: 0.5662, reader_cost: 0.00021, ips: 10.5974 samples/sec | ETA 04:19:58
2023-02-05 03:30:54 [INFO]	[TRAIN] epoch: 2816, iter: 222460/250000, loss: 0.1814, lr: 0.001374, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6107 samples/sec | ETA 04:19:32
2023-02-05 03:31:00 [INFO]	[TRAIN] epoch: 2817, iter: 222470/250000, loss: 0.1527, lr: 0.001373, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6082 samples/sec | ETA 04:19:30
2023-02-05 03:31:06 [INFO]	[TRAIN] epoch: 2817, iter: 222480/250000, loss: 0.1540, lr: 0.001373, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6052 samples/sec | ETA 04:19:29
2023-02-05 03:31:11 [INFO]	[TRAIN] epoch: 2817, iter: 222490/250000, loss: 0.1443, lr: 0.001372, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6078 samples/sec | ETA 04:19:20
2023-02-05 03:31:17 [INFO]	[TRAIN] epoch: 2817, iter: 222500/250000, loss: 0.2210, lr: 0.001372, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6055 samples/sec | ETA 04:19:17
2023-02-05 03:31:23 [INFO]	[TRAIN] epoch: 2817, iter: 222510/250000, loss: 0.1703, lr: 0.001371, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6077 samples/sec | ETA 04:19:09
2023-02-05 03:31:29 [INFO]	[TRAIN] epoch: 2817, iter: 222520/250000, loss: 0.1682, lr: 0.001371, batch_cost: 0.5878, reader_cost: 0.02264, ips: 10.2076 samples/sec | ETA 04:29:12
2023-02-05 03:31:34 [INFO]	[TRAIN] epoch: 2817, iter: 222530/250000, loss: 0.1229, lr: 0.001370, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6187 samples/sec | ETA 04:18:41
2023-02-05 03:31:40 [INFO]	[TRAIN] epoch: 2817, iter: 222540/250000, loss: 0.1590, lr: 0.001370, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6259 samples/sec | ETA 04:18:25
2023-02-05 03:31:46 [INFO]	[TRAIN] epoch: 2818, iter: 222550/250000, loss: 0.1630, lr: 0.001369, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6098 samples/sec | ETA 04:18:43
2023-02-05 03:31:51 [INFO]	[TRAIN] epoch: 2818, iter: 222560/250000, loss: 0.1606, lr: 0.001369, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6066 samples/sec | ETA 04:18:42
2023-02-05 03:31:57 [INFO]	[TRAIN] epoch: 2818, iter: 222570/250000, loss: 0.1388, lr: 0.001369, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6079 samples/sec | ETA 04:18:34
2023-02-05 03:32:03 [INFO]	[TRAIN] epoch: 2818, iter: 222580/250000, loss: 0.1458, lr: 0.001368, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6133 samples/sec | ETA 04:18:21
2023-02-05 03:32:08 [INFO]	[TRAIN] epoch: 2818, iter: 222590/250000, loss: 0.1516, lr: 0.001368, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6061 samples/sec | ETA 04:18:26
2023-02-05 03:32:14 [INFO]	[TRAIN] epoch: 2818, iter: 222600/250000, loss: 0.1395, lr: 0.001367, batch_cost: 0.5923, reader_cost: 0.02691, ips: 10.1295 samples/sec | ETA 04:30:29
2023-02-05 03:32:20 [INFO]	[TRAIN] epoch: 2818, iter: 222610/250000, loss: 0.1827, lr: 0.001367, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6285 samples/sec | ETA 04:17:42
2023-02-05 03:32:25 [INFO]	[TRAIN] epoch: 2818, iter: 222620/250000, loss: 0.1613, lr: 0.001366, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5967 samples/sec | ETA 04:18:22
2023-02-05 03:32:31 [INFO]	[TRAIN] epoch: 2819, iter: 222630/250000, loss: 0.1661, lr: 0.001366, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6060 samples/sec | ETA 04:18:03
2023-02-05 03:32:37 [INFO]	[TRAIN] epoch: 2819, iter: 222640/250000, loss: 0.1428, lr: 0.001365, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6005 samples/sec | ETA 04:18:06
2023-02-05 03:32:42 [INFO]	[TRAIN] epoch: 2819, iter: 222650/250000, loss: 0.1556, lr: 0.001365, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6078 samples/sec | ETA 04:17:49
2023-02-05 03:32:48 [INFO]	[TRAIN] epoch: 2819, iter: 222660/250000, loss: 0.1728, lr: 0.001365, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6146 samples/sec | ETA 04:17:34
2023-02-05 03:32:54 [INFO]	[TRAIN] epoch: 2819, iter: 222670/250000, loss: 0.1598, lr: 0.001364, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5961 samples/sec | ETA 04:17:55
2023-02-05 03:33:00 [INFO]	[TRAIN] epoch: 2819, iter: 222680/250000, loss: 0.1516, lr: 0.001364, batch_cost: 0.5914, reader_cost: 0.02585, ips: 10.1449 samples/sec | ETA 04:29:17
2023-02-05 03:33:05 [INFO]	[TRAIN] epoch: 2819, iter: 222690/250000, loss: 0.1596, lr: 0.001363, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6238 samples/sec | ETA 04:17:03
2023-02-05 03:33:11 [INFO]	[TRAIN] epoch: 2819, iter: 222700/250000, loss: 0.1885, lr: 0.001363, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6222 samples/sec | ETA 04:17:00
2023-02-05 03:33:17 [INFO]	[TRAIN] epoch: 2820, iter: 222710/250000, loss: 0.1800, lr: 0.001362, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6322 samples/sec | ETA 04:16:40
2023-02-05 03:33:22 [INFO]	[TRAIN] epoch: 2820, iter: 222720/250000, loss: 0.1819, lr: 0.001362, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6286 samples/sec | ETA 04:16:39
2023-02-05 03:33:28 [INFO]	[TRAIN] epoch: 2820, iter: 222730/250000, loss: 0.1734, lr: 0.001361, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6079 samples/sec | ETA 04:17:04
2023-02-05 03:33:34 [INFO]	[TRAIN] epoch: 2820, iter: 222740/250000, loss: 0.1899, lr: 0.001361, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6093 samples/sec | ETA 04:16:56
2023-02-05 03:33:39 [INFO]	[TRAIN] epoch: 2820, iter: 222750/250000, loss: 0.1541, lr: 0.001360, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6094 samples/sec | ETA 04:16:50
2023-02-05 03:33:45 [INFO]	[TRAIN] epoch: 2820, iter: 222760/250000, loss: 0.1596, lr: 0.001360, batch_cost: 0.5943, reader_cost: 0.02964, ips: 10.0959 samples/sec | ETA 04:29:48
2023-02-05 03:33:51 [INFO]	[TRAIN] epoch: 2820, iter: 222770/250000, loss: 0.1754, lr: 0.001360, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6393 samples/sec | ETA 04:15:56
2023-02-05 03:33:56 [INFO]	[TRAIN] epoch: 2820, iter: 222780/250000, loss: 0.1511, lr: 0.001359, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6330 samples/sec | ETA 04:15:59
2023-02-05 03:34:02 [INFO]	[TRAIN] epoch: 2821, iter: 222790/250000, loss: 0.1729, lr: 0.001359, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6312 samples/sec | ETA 04:15:56
2023-02-05 03:34:08 [INFO]	[TRAIN] epoch: 2821, iter: 222800/250000, loss: 0.1542, lr: 0.001358, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6279 samples/sec | ETA 04:15:55
2023-02-05 03:34:13 [INFO]	[TRAIN] epoch: 2821, iter: 222810/250000, loss: 0.2070, lr: 0.001358, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6350 samples/sec | ETA 04:15:39
2023-02-05 03:34:19 [INFO]	[TRAIN] epoch: 2821, iter: 222820/250000, loss: 0.1637, lr: 0.001357, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6391 samples/sec | ETA 04:15:28
2023-02-05 03:34:25 [INFO]	[TRAIN] epoch: 2821, iter: 222830/250000, loss: 0.1446, lr: 0.001357, batch_cost: 0.5651, reader_cost: 0.00008, ips: 10.6173 samples/sec | ETA 04:15:54
2023-02-05 03:34:30 [INFO]	[TRAIN] epoch: 2821, iter: 222840/250000, loss: 0.1691, lr: 0.001356, batch_cost: 0.5858, reader_cost: 0.02147, ips: 10.2424 samples/sec | ETA 04:25:10
2023-02-05 03:34:36 [INFO]	[TRAIN] epoch: 2821, iter: 222850/250000, loss: 0.1610, lr: 0.001356, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6327 samples/sec | ETA 04:15:20
2023-02-05 03:34:42 [INFO]	[TRAIN] epoch: 2822, iter: 222860/250000, loss: 0.1674, lr: 0.001356, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6194 samples/sec | ETA 04:15:34
2023-02-05 03:34:47 [INFO]	[TRAIN] epoch: 2822, iter: 222870/250000, loss: 0.1900, lr: 0.001355, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6358 samples/sec | ETA 04:15:04
2023-02-05 03:34:53 [INFO]	[TRAIN] epoch: 2822, iter: 222880/250000, loss: 0.1727, lr: 0.001355, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6254 samples/sec | ETA 04:15:14
2023-02-05 03:34:59 [INFO]	[TRAIN] epoch: 2822, iter: 222890/250000, loss: 0.1528, lr: 0.001354, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6258 samples/sec | ETA 04:15:07
2023-02-05 03:35:04 [INFO]	[TRAIN] epoch: 2822, iter: 222900/250000, loss: 0.1607, lr: 0.001354, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6019 samples/sec | ETA 04:15:36
2023-02-05 03:35:10 [INFO]	[TRAIN] epoch: 2822, iter: 222910/250000, loss: 0.1515, lr: 0.001353, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6043 samples/sec | ETA 04:15:27
2023-02-05 03:35:16 [INFO]	[TRAIN] epoch: 2822, iter: 222920/250000, loss: 0.1839, lr: 0.001353, batch_cost: 0.6018, reader_cost: 0.03728, ips: 9.9693 samples/sec | ETA 04:31:38
2023-02-05 03:35:22 [INFO]	[TRAIN] epoch: 2822, iter: 222930/250000, loss: 0.1599, lr: 0.001352, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6410 samples/sec | ETA 04:14:23
2023-02-05 03:35:27 [INFO]	[TRAIN] epoch: 2823, iter: 222940/250000, loss: 0.1926, lr: 0.001352, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6383 samples/sec | ETA 04:14:21
2023-02-05 03:35:33 [INFO]	[TRAIN] epoch: 2823, iter: 222950/250000, loss: 0.1766, lr: 0.001352, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6345 samples/sec | ETA 04:14:21
2023-02-05 03:35:39 [INFO]	[TRAIN] epoch: 2823, iter: 222960/250000, loss: 0.1926, lr: 0.001351, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6266 samples/sec | ETA 04:14:27
2023-02-05 03:35:44 [INFO]	[TRAIN] epoch: 2823, iter: 222970/250000, loss: 0.1402, lr: 0.001351, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6329 samples/sec | ETA 04:14:12
2023-02-05 03:35:50 [INFO]	[TRAIN] epoch: 2823, iter: 222980/250000, loss: 0.1536, lr: 0.001350, batch_cost: 0.5643, reader_cost: 0.00015, ips: 10.6322 samples/sec | ETA 04:14:08
2023-02-05 03:35:56 [INFO]	[TRAIN] epoch: 2823, iter: 222990/250000, loss: 0.1825, lr: 0.001350, batch_cost: 0.5921, reader_cost: 0.02777, ips: 10.1334 samples/sec | ETA 04:26:32
2023-02-05 03:36:01 [INFO]	[TRAIN] epoch: 2823, iter: 223000/250000, loss: 0.1821, lr: 0.001349, batch_cost: 0.5646, reader_cost: 0.00013, ips: 10.6276 samples/sec | ETA 04:14:03
2023-02-05 03:36:07 [INFO]	[TRAIN] epoch: 2823, iter: 223010/250000, loss: 0.1404, lr: 0.001349, batch_cost: 0.5641, reader_cost: 0.00008, ips: 10.6369 samples/sec | ETA 04:13:44
2023-02-05 03:36:13 [INFO]	[TRAIN] epoch: 2824, iter: 223020/250000, loss: 0.1652, lr: 0.001348, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6344 samples/sec | ETA 04:13:42
2023-02-05 03:36:18 [INFO]	[TRAIN] epoch: 2824, iter: 223030/250000, loss: 0.2343, lr: 0.001348, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6287 samples/sec | ETA 04:13:44
2023-02-05 03:36:24 [INFO]	[TRAIN] epoch: 2824, iter: 223040/250000, loss: 0.2923, lr: 0.001347, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6307 samples/sec | ETA 04:13:36
2023-02-05 03:36:30 [INFO]	[TRAIN] epoch: 2824, iter: 223050/250000, loss: 0.1885, lr: 0.001347, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6295 samples/sec | ETA 04:13:32
2023-02-05 03:36:35 [INFO]	[TRAIN] epoch: 2824, iter: 223060/250000, loss: 0.1663, lr: 0.001347, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6226 samples/sec | ETA 04:13:36
2023-02-05 03:36:41 [INFO]	[TRAIN] epoch: 2824, iter: 223070/250000, loss: 0.1894, lr: 0.001346, batch_cost: 0.5938, reader_cost: 0.02864, ips: 10.1038 samples/sec | ETA 04:26:31
2023-02-05 03:36:47 [INFO]	[TRAIN] epoch: 2824, iter: 223080/250000, loss: 0.1889, lr: 0.001346, batch_cost: 0.5642, reader_cost: 0.00015, ips: 10.6338 samples/sec | ETA 04:13:09
2023-02-05 03:36:53 [INFO]	[TRAIN] epoch: 2824, iter: 223090/250000, loss: 0.1848, lr: 0.001345, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6392 samples/sec | ETA 04:12:55
2023-02-05 03:36:58 [INFO]	[TRAIN] epoch: 2825, iter: 223100/250000, loss: 0.1846, lr: 0.001345, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6325 samples/sec | ETA 04:12:59
2023-02-05 03:37:04 [INFO]	[TRAIN] epoch: 2825, iter: 223110/250000, loss: 0.1555, lr: 0.001344, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5954 samples/sec | ETA 04:13:47
2023-02-05 03:37:10 [INFO]	[TRAIN] epoch: 2825, iter: 223120/250000, loss: 0.1262, lr: 0.001344, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6121 samples/sec | ETA 04:13:17
2023-02-05 03:37:15 [INFO]	[TRAIN] epoch: 2825, iter: 223130/250000, loss: 0.1554, lr: 0.001343, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6149 samples/sec | ETA 04:13:08
2023-02-05 03:37:21 [INFO]	[TRAIN] epoch: 2825, iter: 223140/250000, loss: 0.1261, lr: 0.001343, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5987 samples/sec | ETA 04:13:25
2023-02-05 03:37:27 [INFO]	[TRAIN] epoch: 2825, iter: 223150/250000, loss: 0.1620, lr: 0.001343, batch_cost: 0.5878, reader_cost: 0.02218, ips: 10.2077 samples/sec | ETA 04:23:02
2023-02-05 03:37:32 [INFO]	[TRAIN] epoch: 2825, iter: 223160/250000, loss: 0.1422, lr: 0.001342, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6263 samples/sec | ETA 04:12:34
2023-02-05 03:37:38 [INFO]	[TRAIN] epoch: 2825, iter: 223170/250000, loss: 0.1777, lr: 0.001342, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6297 samples/sec | ETA 04:12:24
2023-02-05 03:37:44 [INFO]	[TRAIN] epoch: 2826, iter: 223180/250000, loss: 0.1931, lr: 0.001341, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6267 samples/sec | ETA 04:12:22
2023-02-05 03:37:49 [INFO]	[TRAIN] epoch: 2826, iter: 223190/250000, loss: 0.1642, lr: 0.001341, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6273 samples/sec | ETA 04:12:16
2023-02-05 03:37:55 [INFO]	[TRAIN] epoch: 2826, iter: 223200/250000, loss: 0.1445, lr: 0.001340, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6306 samples/sec | ETA 04:12:06
2023-02-05 03:38:01 [INFO]	[TRAIN] epoch: 2826, iter: 223210/250000, loss: 0.1686, lr: 0.001340, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6203 samples/sec | ETA 04:12:15
2023-02-05 03:38:06 [INFO]	[TRAIN] epoch: 2826, iter: 223220/250000, loss: 0.1526, lr: 0.001339, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6296 samples/sec | ETA 04:11:56
2023-02-05 03:38:12 [INFO]	[TRAIN] epoch: 2826, iter: 223230/250000, loss: 0.1338, lr: 0.001339, batch_cost: 0.5939, reader_cost: 0.02924, ips: 10.1033 samples/sec | ETA 04:24:57
2023-02-05 03:38:18 [INFO]	[TRAIN] epoch: 2826, iter: 223240/250000, loss: 0.1803, lr: 0.001338, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6190 samples/sec | ETA 04:12:00
2023-02-05 03:38:23 [INFO]	[TRAIN] epoch: 2826, iter: 223250/250000, loss: 0.2001, lr: 0.001338, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6195 samples/sec | ETA 04:11:53
2023-02-05 03:38:29 [INFO]	[TRAIN] epoch: 2827, iter: 223260/250000, loss: 0.1640, lr: 0.001338, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6302 samples/sec | ETA 04:11:32
2023-02-05 03:38:35 [INFO]	[TRAIN] epoch: 2827, iter: 223270/250000, loss: 0.1621, lr: 0.001337, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6342 samples/sec | ETA 04:11:21
2023-02-05 03:38:40 [INFO]	[TRAIN] epoch: 2827, iter: 223280/250000, loss: 0.1404, lr: 0.001337, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6216 samples/sec | ETA 04:11:33
2023-02-05 03:38:46 [INFO]	[TRAIN] epoch: 2827, iter: 223290/250000, loss: 0.1809, lr: 0.001336, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6245 samples/sec | ETA 04:11:23
2023-02-05 03:38:52 [INFO]	[TRAIN] epoch: 2827, iter: 223300/250000, loss: 0.1586, lr: 0.001336, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6061 samples/sec | ETA 04:11:44
2023-02-05 03:38:58 [INFO]	[TRAIN] epoch: 2827, iter: 223310/250000, loss: 0.1693, lr: 0.001335, batch_cost: 0.5853, reader_cost: 0.02047, ips: 10.2510 samples/sec | ETA 04:20:21
2023-02-05 03:39:03 [INFO]	[TRAIN] epoch: 2827, iter: 223320/250000, loss: 0.1552, lr: 0.001335, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6341 samples/sec | ETA 04:10:53
2023-02-05 03:39:09 [INFO]	[TRAIN] epoch: 2827, iter: 223330/250000, loss: 0.1650, lr: 0.001334, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6197 samples/sec | ETA 04:11:08
2023-02-05 03:39:15 [INFO]	[TRAIN] epoch: 2828, iter: 223340/250000, loss: 0.1712, lr: 0.001334, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6162 samples/sec | ETA 04:11:07
2023-02-05 03:39:20 [INFO]	[TRAIN] epoch: 2828, iter: 223350/250000, loss: 0.1465, lr: 0.001334, batch_cost: 0.5658, reader_cost: 0.00011, ips: 10.6049 samples/sec | ETA 04:11:17
2023-02-05 03:39:26 [INFO]	[TRAIN] epoch: 2828, iter: 223360/250000, loss: 0.2122, lr: 0.001333, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6173 samples/sec | ETA 04:10:54
2023-02-05 03:39:31 [INFO]	[TRAIN] epoch: 2828, iter: 223370/250000, loss: 0.1559, lr: 0.001333, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6062 samples/sec | ETA 04:11:04
2023-02-05 03:39:37 [INFO]	[TRAIN] epoch: 2828, iter: 223380/250000, loss: 0.1566, lr: 0.001332, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6158 samples/sec | ETA 04:10:45
2023-02-05 03:39:43 [INFO]	[TRAIN] epoch: 2828, iter: 223390/250000, loss: 0.1532, lr: 0.001332, batch_cost: 0.5946, reader_cost: 0.02997, ips: 10.0906 samples/sec | ETA 04:23:42
2023-02-05 03:39:49 [INFO]	[TRAIN] epoch: 2828, iter: 223400/250000, loss: 0.1377, lr: 0.001331, batch_cost: 0.5654, reader_cost: 0.00013, ips: 10.6128 samples/sec | ETA 04:10:38
2023-02-05 03:39:54 [INFO]	[TRAIN] epoch: 2828, iter: 223410/250000, loss: 0.1658, lr: 0.001331, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6052 samples/sec | ETA 04:10:43
2023-02-05 03:40:00 [INFO]	[TRAIN] epoch: 2829, iter: 223420/250000, loss: 0.1991, lr: 0.001330, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6142 samples/sec | ETA 04:10:25
2023-02-05 03:40:06 [INFO]	[TRAIN] epoch: 2829, iter: 223430/250000, loss: 0.1880, lr: 0.001330, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6092 samples/sec | ETA 04:10:26
2023-02-05 03:40:11 [INFO]	[TRAIN] epoch: 2829, iter: 223440/250000, loss: 0.1785, lr: 0.001329, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6051 samples/sec | ETA 04:10:26
2023-02-05 03:40:17 [INFO]	[TRAIN] epoch: 2829, iter: 223450/250000, loss: 0.1773, lr: 0.001329, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6023 samples/sec | ETA 04:10:25
2023-02-05 03:40:23 [INFO]	[TRAIN] epoch: 2829, iter: 223460/250000, loss: 0.2060, lr: 0.001329, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6116 samples/sec | ETA 04:10:06
2023-02-05 03:40:29 [INFO]	[TRAIN] epoch: 2829, iter: 223470/250000, loss: 0.1473, lr: 0.001328, batch_cost: 0.5877, reader_cost: 0.02301, ips: 10.2096 samples/sec | ETA 04:19:51
2023-02-05 03:40:34 [INFO]	[TRAIN] epoch: 2829, iter: 223480/250000, loss: 0.1964, lr: 0.001328, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6222 samples/sec | ETA 04:09:39
2023-02-05 03:40:40 [INFO]	[TRAIN] epoch: 2829, iter: 223490/250000, loss: 0.1374, lr: 0.001327, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6127 samples/sec | ETA 04:09:47
2023-02-05 03:40:46 [INFO]	[TRAIN] epoch: 2830, iter: 223500/250000, loss: 0.1673, lr: 0.001327, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6159 samples/sec | ETA 04:09:37
2023-02-05 03:40:51 [INFO]	[TRAIN] epoch: 2830, iter: 223510/250000, loss: 0.1512, lr: 0.001326, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6105 samples/sec | ETA 04:09:39
2023-02-05 03:40:57 [INFO]	[TRAIN] epoch: 2830, iter: 223520/250000, loss: 0.1683, lr: 0.001326, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6134 samples/sec | ETA 04:09:29
2023-02-05 03:41:02 [INFO]	[TRAIN] epoch: 2830, iter: 223530/250000, loss: 0.1646, lr: 0.001325, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6083 samples/sec | ETA 04:09:31
2023-02-05 03:41:08 [INFO]	[TRAIN] epoch: 2830, iter: 223540/250000, loss: 0.1550, lr: 0.001325, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6088 samples/sec | ETA 04:09:24
2023-02-05 03:41:14 [INFO]	[TRAIN] epoch: 2830, iter: 223550/250000, loss: 0.1764, lr: 0.001324, batch_cost: 0.5998, reader_cost: 0.03481, ips: 10.0029 samples/sec | ETA 04:24:25
2023-02-05 03:41:20 [INFO]	[TRAIN] epoch: 2830, iter: 223560/250000, loss: 0.1485, lr: 0.001324, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6126 samples/sec | ETA 04:09:08
2023-02-05 03:41:25 [INFO]	[TRAIN] epoch: 2830, iter: 223570/250000, loss: 0.1673, lr: 0.001324, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6205 samples/sec | ETA 04:08:51
2023-02-05 03:41:31 [INFO]	[TRAIN] epoch: 2831, iter: 223580/250000, loss: 0.1939, lr: 0.001323, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6000 samples/sec | ETA 04:09:14
2023-02-05 03:41:37 [INFO]	[TRAIN] epoch: 2831, iter: 223590/250000, loss: 0.1735, lr: 0.001323, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6040 samples/sec | ETA 04:09:03
2023-02-05 03:41:42 [INFO]	[TRAIN] epoch: 2831, iter: 223600/250000, loss: 0.1675, lr: 0.001322, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6173 samples/sec | ETA 04:08:38
2023-02-05 03:41:48 [INFO]	[TRAIN] epoch: 2831, iter: 223610/250000, loss: 0.2690, lr: 0.001322, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6072 samples/sec | ETA 04:08:47
2023-02-05 03:41:54 [INFO]	[TRAIN] epoch: 2831, iter: 223620/250000, loss: 0.2106, lr: 0.001321, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6057 samples/sec | ETA 04:08:44
2023-02-05 03:42:00 [INFO]	[TRAIN] epoch: 2831, iter: 223630/250000, loss: 0.2081, lr: 0.001321, batch_cost: 0.5877, reader_cost: 0.02219, ips: 10.2097 samples/sec | ETA 04:18:16
2023-02-05 03:42:05 [INFO]	[TRAIN] epoch: 2831, iter: 223640/250000, loss: 0.2470, lr: 0.001320, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6043 samples/sec | ETA 04:08:34
2023-02-05 03:42:11 [INFO]	[TRAIN] epoch: 2832, iter: 223650/250000, loss: 0.1759, lr: 0.001320, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6074 samples/sec | ETA 04:08:24
2023-02-05 03:42:17 [INFO]	[TRAIN] epoch: 2832, iter: 223660/250000, loss: 0.1999, lr: 0.001320, batch_cost: 0.5651, reader_cost: 0.00008, ips: 10.6175 samples/sec | ETA 04:08:04
2023-02-05 03:42:22 [INFO]	[TRAIN] epoch: 2832, iter: 223670/250000, loss: 0.1739, lr: 0.001319, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6109 samples/sec | ETA 04:08:08
2023-02-05 03:42:28 [INFO]	[TRAIN] epoch: 2832, iter: 223680/250000, loss: 0.1570, lr: 0.001319, batch_cost: 0.5652, reader_cost: 0.00008, ips: 10.6151 samples/sec | ETA 04:07:56
2023-02-05 03:42:34 [INFO]	[TRAIN] epoch: 2832, iter: 223690/250000, loss: 0.2149, lr: 0.001318, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6022 samples/sec | ETA 04:08:09
2023-02-05 03:42:39 [INFO]	[TRAIN] epoch: 2832, iter: 223700/250000, loss: 0.1895, lr: 0.001318, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6050 samples/sec | ETA 04:07:59
2023-02-05 03:42:45 [INFO]	[TRAIN] epoch: 2832, iter: 223710/250000, loss: 0.1788, lr: 0.001317, batch_cost: 0.5945, reader_cost: 0.03012, ips: 10.0918 samples/sec | ETA 04:20:30
2023-02-05 03:42:51 [INFO]	[TRAIN] epoch: 2832, iter: 223720/250000, loss: 0.1648, lr: 0.001317, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6292 samples/sec | ETA 04:07:14
2023-02-05 03:42:56 [INFO]	[TRAIN] epoch: 2833, iter: 223730/250000, loss: 0.1866, lr: 0.001316, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6243 samples/sec | ETA 04:07:15
2023-02-05 03:43:02 [INFO]	[TRAIN] epoch: 2833, iter: 223740/250000, loss: 0.1663, lr: 0.001316, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6270 samples/sec | ETA 04:07:06
2023-02-05 03:43:08 [INFO]	[TRAIN] epoch: 2833, iter: 223750/250000, loss: 0.2460, lr: 0.001315, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6272 samples/sec | ETA 04:07:00
2023-02-05 03:43:13 [INFO]	[TRAIN] epoch: 2833, iter: 223760/250000, loss: 0.1837, lr: 0.001315, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6306 samples/sec | ETA 04:06:50
2023-02-05 03:43:19 [INFO]	[TRAIN] epoch: 2833, iter: 223770/250000, loss: 0.2357, lr: 0.001315, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6219 samples/sec | ETA 04:06:56
2023-02-05 03:43:25 [INFO]	[TRAIN] epoch: 2833, iter: 223780/250000, loss: 0.1836, lr: 0.001314, batch_cost: 0.5907, reader_cost: 0.02647, ips: 10.1574 samples/sec | ETA 04:18:08
2023-02-05 03:43:31 [INFO]	[TRAIN] epoch: 2833, iter: 223790/250000, loss: 0.1684, lr: 0.001314, batch_cost: 0.5647, reader_cost: 0.00021, ips: 10.6257 samples/sec | ETA 04:06:40
2023-02-05 03:43:36 [INFO]	[TRAIN] epoch: 2833, iter: 223800/250000, loss: 0.2038, lr: 0.001313, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6008 samples/sec | ETA 04:07:09
2023-02-05 03:43:42 [INFO]	[TRAIN] epoch: 2834, iter: 223810/250000, loss: 0.1856, lr: 0.001313, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6105 samples/sec | ETA 04:06:49
2023-02-05 03:43:48 [INFO]	[TRAIN] epoch: 2834, iter: 223820/250000, loss: 0.2097, lr: 0.001312, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6146 samples/sec | ETA 04:06:38
2023-02-05 03:43:53 [INFO]	[TRAIN] epoch: 2834, iter: 223830/250000, loss: 0.1799, lr: 0.001312, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6088 samples/sec | ETA 04:06:40
2023-02-05 03:43:59 [INFO]	[TRAIN] epoch: 2834, iter: 223840/250000, loss: 0.2303, lr: 0.001311, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6116 samples/sec | ETA 04:06:31
2023-02-05 03:44:05 [INFO]	[TRAIN] epoch: 2834, iter: 223850/250000, loss: 0.1700, lr: 0.001311, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6096 samples/sec | ETA 04:06:28
2023-02-05 03:44:10 [INFO]	[TRAIN] epoch: 2834, iter: 223860/250000, loss: 0.1752, lr: 0.001311, batch_cost: 0.5889, reader_cost: 0.02343, ips: 10.1879 samples/sec | ETA 04:16:34
2023-02-05 03:44:16 [INFO]	[TRAIN] epoch: 2834, iter: 223870/250000, loss: 0.1783, lr: 0.001310, batch_cost: 0.5653, reader_cost: 0.00022, ips: 10.6148 samples/sec | ETA 04:06:09
2023-02-05 03:44:22 [INFO]	[TRAIN] epoch: 2834, iter: 223880/250000, loss: 0.1691, lr: 0.001310, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6295 samples/sec | ETA 04:05:43
2023-02-05 03:44:27 [INFO]	[TRAIN] epoch: 2835, iter: 223890/250000, loss: 0.1653, lr: 0.001309, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6134 samples/sec | ETA 04:06:00
2023-02-05 03:44:33 [INFO]	[TRAIN] epoch: 2835, iter: 223900/250000, loss: 0.2370, lr: 0.001309, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 04:06:04
2023-02-05 03:44:39 [INFO]	[TRAIN] epoch: 2835, iter: 223910/250000, loss: 0.1946, lr: 0.001308, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6149 samples/sec | ETA 04:05:47
2023-02-05 03:44:44 [INFO]	[TRAIN] epoch: 2835, iter: 223920/250000, loss: 0.1839, lr: 0.001308, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6124 samples/sec | ETA 04:05:44
2023-02-05 03:44:50 [INFO]	[TRAIN] epoch: 2835, iter: 223930/250000, loss: 0.1636, lr: 0.001307, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6120 samples/sec | ETA 04:05:39
2023-02-05 03:44:56 [INFO]	[TRAIN] epoch: 2835, iter: 223940/250000, loss: 0.1780, lr: 0.001307, batch_cost: 0.5959, reader_cost: 0.03099, ips: 10.0689 samples/sec | ETA 04:18:48
2023-02-05 03:45:02 [INFO]	[TRAIN] epoch: 2835, iter: 223950/250000, loss: 0.1870, lr: 0.001306, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6220 samples/sec | ETA 04:05:14
2023-02-05 03:45:07 [INFO]	[TRAIN] epoch: 2835, iter: 223960/250000, loss: 0.1713, lr: 0.001306, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6269 samples/sec | ETA 04:05:02
2023-02-05 03:45:13 [INFO]	[TRAIN] epoch: 2836, iter: 223970/250000, loss: 0.1494, lr: 0.001306, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6327 samples/sec | ETA 04:04:48
2023-02-05 03:45:19 [INFO]	[TRAIN] epoch: 2836, iter: 223980/250000, loss: 0.1679, lr: 0.001305, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6278 samples/sec | ETA 04:04:49
2023-02-05 03:45:24 [INFO]	[TRAIN] epoch: 2836, iter: 223990/250000, loss: 0.1827, lr: 0.001305, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6133 samples/sec | ETA 04:05:04
2023-02-05 03:45:30 [INFO]	[TRAIN] epoch: 2836, iter: 224000/250000, loss: 0.1594, lr: 0.001304, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6070 samples/sec | ETA 04:05:07
2023-02-05 03:45:30 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1224 - reader cost: 0.0231 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1493 - reader cost: 0.0116 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1566 - reader cost: 0.0077 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1585 - reader cost: 0.0058 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1595 - reader cost: 0.0047 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1601 - reader cost: 0.0039 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1606 - reader cost: 0.0034 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1615 - reader cost: 0.0029 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1625 - reader cost: 0.002610/36 [=======>......................] - ETA: 4s - batch_cost: 0.1622 - reader cost: 0.002411/36 [========>.....................] - ETA: 4s - batch_cost: 0.1632 - reader cost: 0.002212/36 [=========>....................] - ETA: 3s - batch_cost: 0.1628 - reader cost: 0.002013/36 [=========>....................] - ETA: 3s - batch_cost: 0.1634 - reader cost: 0.001814/36 [==========>...................] - ETA: 3s - batch_cost: 0.1641 - reader cost: 0.001715/36 [===========>..................] - ETA: 3s - batch_cost: 0.1643 - reader cost: 0.001616/36 [============>.................] - ETA: 3s - batch_cost: 0.1654 - reader cost: 0.001517/36 [=============>................] - ETA: 3s - batch_cost: 0.1655 - reader cost: 0.001418/36 [==============>...............] - ETA: 2s - batch_cost: 0.1657 - reader cost: 0.001419/36 [==============>...............] - ETA: 2s - batch_cost: 0.1655 - reader cost: 0.001320/36 [===============>..............] - ETA: 2s - batch_cost: 0.1657 - reader cost: 0.001221/36 [================>.............] - ETA: 2s - batch_cost: 0.1658 - reader cost: 0.001222/36 [=================>............] - ETA: 2s - batch_cost: 0.1659 - reader cost: 0.001123/36 [==================>...........] - ETA: 2s - batch_cost: 0.1665 - reader cost: 0.001124/36 [===================>..........] - ETA: 1s - batch_cost: 0.1663 - reader cost: 0.001025/36 [===================>..........] - ETA: 1s - batch_cost: 0.1664 - reader cost: 9.9340e-0426/36 [====================>.........] - ETA: 1s - batch_cost: 0.1665 - reader cost: 9.5777e-0427/36 [=====================>........] - ETA: 1s - batch_cost: 0.1666 - reader cost: 9.2540e-0428/36 [======================>.......] - ETA: 1s - batch_cost: 0.1670 - reader cost: 8.9479e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1670 - reader cost: 8.6684e-0430/36 [========================>.....] - ETA: 1s - batch_cost: 0.1668 - reader cost: 8.4021e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1668 - reader cost: 8.1583e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1666 - reader cost: 7.9247e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1665 - reader cost: 7.7040e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1663 - reader cost: 7.4958e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1663 - reader cost: 7.3037e-0436/36 [==============================] - 6s 167ms/step - batch_cost: 0.1665 - reader cost: 7.1171e-04
2023-02-05 03:45:36 [INFO]	[EVAL] #Images: 36 mIoU: 0.8666 Acc: 0.9860 Kappa: 0.9495 Dice: 0.9254
2023-02-05 03:45:36 [INFO]	[EVAL] Class IoU: 
[0.9857 0.9043 0.8896 0.7304 0.7121 0.9727 0.8715]
2023-02-05 03:45:36 [INFO]	[EVAL] Class Precision: 
[0.993  0.9686 0.9296 0.8444 0.8634 0.9817 0.9155]
2023-02-05 03:45:36 [INFO]	[EVAL] Class Recall: 
[0.9926 0.9317 0.9539 0.8439 0.8025 0.9907 0.9477]
2023-02-05 03:45:36 [INFO]	[EVAL] The model with the best validation mIoU (0.8682) was saved at iter 222000.
2023-02-05 03:45:42 [INFO]	[TRAIN] epoch: 2836, iter: 224010/250000, loss: 0.1747, lr: 0.001304, batch_cost: 0.5636, reader_cost: 0.00010, ips: 10.6454 samples/sec | ETA 04:04:08
2023-02-05 03:45:48 [INFO]	[TRAIN] epoch: 2836, iter: 224020/250000, loss: 0.1607, lr: 0.001303, batch_cost: 0.5965, reader_cost: 0.03233, ips: 10.0585 samples/sec | ETA 04:18:17
2023-02-05 03:45:53 [INFO]	[TRAIN] epoch: 2836, iter: 224030/250000, loss: 0.2477, lr: 0.001303, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6334 samples/sec | ETA 04:04:13
2023-02-05 03:45:59 [INFO]	[TRAIN] epoch: 2836, iter: 224040/250000, loss: 0.1799, lr: 0.001302, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6254 samples/sec | ETA 04:04:19
2023-02-05 03:46:05 [INFO]	[TRAIN] epoch: 2837, iter: 224050/250000, loss: 0.1571, lr: 0.001302, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6091 samples/sec | ETA 04:04:36
2023-02-05 03:46:10 [INFO]	[TRAIN] epoch: 2837, iter: 224060/250000, loss: 0.2046, lr: 0.001301, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6156 samples/sec | ETA 04:04:21
2023-02-05 03:46:16 [INFO]	[TRAIN] epoch: 2837, iter: 224070/250000, loss: 0.1603, lr: 0.001301, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6121 samples/sec | ETA 04:04:20
2023-02-05 03:46:22 [INFO]	[TRAIN] epoch: 2837, iter: 224080/250000, loss: 0.1786, lr: 0.001301, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6240 samples/sec | ETA 04:03:58
2023-02-05 03:46:27 [INFO]	[TRAIN] epoch: 2837, iter: 224090/250000, loss: 0.1591, lr: 0.001300, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5992 samples/sec | ETA 04:04:27
2023-02-05 03:46:33 [INFO]	[TRAIN] epoch: 2837, iter: 224100/250000, loss: 0.1710, lr: 0.001300, batch_cost: 0.5973, reader_cost: 0.03197, ips: 10.0454 samples/sec | ETA 04:17:49
2023-02-05 03:46:39 [INFO]	[TRAIN] epoch: 2837, iter: 224110/250000, loss: 0.2165, lr: 0.001299, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6187 samples/sec | ETA 04:03:48
2023-02-05 03:46:44 [INFO]	[TRAIN] epoch: 2837, iter: 224120/250000, loss: 0.1792, lr: 0.001299, batch_cost: 0.5642, reader_cost: 0.00008, ips: 10.6351 samples/sec | ETA 04:03:20
2023-02-05 03:46:50 [INFO]	[TRAIN] epoch: 2838, iter: 224130/250000, loss: 0.1343, lr: 0.001298, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6044 samples/sec | ETA 04:03:57
2023-02-05 03:46:56 [INFO]	[TRAIN] epoch: 2838, iter: 224140/250000, loss: 0.1521, lr: 0.001298, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6104 samples/sec | ETA 04:03:43
2023-02-05 03:47:01 [INFO]	[TRAIN] epoch: 2838, iter: 224150/250000, loss: 0.1862, lr: 0.001297, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6114 samples/sec | ETA 04:03:36
2023-02-05 03:47:07 [INFO]	[TRAIN] epoch: 2838, iter: 224160/250000, loss: 0.1729, lr: 0.001297, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6187 samples/sec | ETA 04:03:20
2023-02-05 03:47:13 [INFO]	[TRAIN] epoch: 2838, iter: 224170/250000, loss: 0.1530, lr: 0.001297, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6025 samples/sec | ETA 04:03:37
2023-02-05 03:47:19 [INFO]	[TRAIN] epoch: 2838, iter: 224180/250000, loss: 0.1389, lr: 0.001296, batch_cost: 0.5990, reader_cost: 0.03188, ips: 10.0174 samples/sec | ETA 04:17:45
2023-02-05 03:47:24 [INFO]	[TRAIN] epoch: 2838, iter: 224190/250000, loss: 0.1467, lr: 0.001296, batch_cost: 0.5645, reader_cost: 0.00012, ips: 10.6286 samples/sec | ETA 04:02:50
2023-02-05 03:47:30 [INFO]	[TRAIN] epoch: 2838, iter: 224200/250000, loss: 0.1870, lr: 0.001295, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6208 samples/sec | ETA 04:02:55
2023-02-05 03:47:36 [INFO]	[TRAIN] epoch: 2839, iter: 224210/250000, loss: 0.2182, lr: 0.001295, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6099 samples/sec | ETA 04:03:04
2023-02-05 03:47:41 [INFO]	[TRAIN] epoch: 2839, iter: 224220/250000, loss: 0.1549, lr: 0.001294, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6142 samples/sec | ETA 04:02:52
2023-02-05 03:47:47 [INFO]	[TRAIN] epoch: 2839, iter: 224230/250000, loss: 0.1497, lr: 0.001294, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6132 samples/sec | ETA 04:02:48
2023-02-05 03:47:53 [INFO]	[TRAIN] epoch: 2839, iter: 224240/250000, loss: 0.1935, lr: 0.001293, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6131 samples/sec | ETA 04:02:43
2023-02-05 03:47:58 [INFO]	[TRAIN] epoch: 2839, iter: 224250/250000, loss: 0.1466, lr: 0.001293, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6007 samples/sec | ETA 04:02:54
2023-02-05 03:48:04 [INFO]	[TRAIN] epoch: 2839, iter: 224260/250000, loss: 0.1488, lr: 0.001292, batch_cost: 0.5934, reader_cost: 0.02744, ips: 10.1111 samples/sec | ETA 04:14:34
2023-02-05 03:48:10 [INFO]	[TRAIN] epoch: 2839, iter: 224270/250000, loss: 0.2132, lr: 0.001292, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6107 samples/sec | ETA 04:02:29
2023-02-05 03:48:16 [INFO]	[TRAIN] epoch: 2839, iter: 224280/250000, loss: 0.1609, lr: 0.001292, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6084 samples/sec | ETA 04:02:27
2023-02-05 03:48:21 [INFO]	[TRAIN] epoch: 2840, iter: 224290/250000, loss: 0.1856, lr: 0.001291, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6134 samples/sec | ETA 04:02:14
2023-02-05 03:48:27 [INFO]	[TRAIN] epoch: 2840, iter: 224300/250000, loss: 0.1884, lr: 0.001291, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 04:02:18
2023-02-05 03:48:33 [INFO]	[TRAIN] epoch: 2840, iter: 224310/250000, loss: 0.1653, lr: 0.001290, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6114 samples/sec | ETA 04:02:05
2023-02-05 03:48:38 [INFO]	[TRAIN] epoch: 2840, iter: 224320/250000, loss: 0.1680, lr: 0.001290, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6122 samples/sec | ETA 04:01:59
2023-02-05 03:48:44 [INFO]	[TRAIN] epoch: 2840, iter: 224330/250000, loss: 0.1722, lr: 0.001289, batch_cost: 0.5664, reader_cost: 0.00009, ips: 10.5925 samples/sec | ETA 04:02:20
2023-02-05 03:48:50 [INFO]	[TRAIN] epoch: 2840, iter: 224340/250000, loss: 0.2073, lr: 0.001289, batch_cost: 0.5896, reader_cost: 0.02497, ips: 10.1763 samples/sec | ETA 04:12:09
2023-02-05 03:48:55 [INFO]	[TRAIN] epoch: 2840, iter: 224350/250000, loss: 0.1646, lr: 0.001288, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6139 samples/sec | ETA 04:01:39
2023-02-05 03:49:01 [INFO]	[TRAIN] epoch: 2840, iter: 224360/250000, loss: 0.1614, lr: 0.001288, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6069 samples/sec | ETA 04:01:43
2023-02-05 03:49:07 [INFO]	[TRAIN] epoch: 2841, iter: 224370/250000, loss: 0.1647, lr: 0.001287, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6120 samples/sec | ETA 04:01:31
2023-02-05 03:49:12 [INFO]	[TRAIN] epoch: 2841, iter: 224380/250000, loss: 0.1592, lr: 0.001287, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6083 samples/sec | ETA 04:01:30
2023-02-05 03:49:18 [INFO]	[TRAIN] epoch: 2841, iter: 224390/250000, loss: 0.1773, lr: 0.001287, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6019 samples/sec | ETA 04:01:33
2023-02-05 03:49:24 [INFO]	[TRAIN] epoch: 2841, iter: 224400/250000, loss: 0.1654, lr: 0.001286, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6103 samples/sec | ETA 04:01:16
2023-02-05 03:49:29 [INFO]	[TRAIN] epoch: 2841, iter: 224410/250000, loss: 0.1417, lr: 0.001286, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6125 samples/sec | ETA 04:01:07
2023-02-05 03:49:35 [INFO]	[TRAIN] epoch: 2841, iter: 224420/250000, loss: 0.1673, lr: 0.001285, batch_cost: 0.6005, reader_cost: 0.03531, ips: 9.9912 samples/sec | ETA 04:16:01
2023-02-05 03:49:41 [INFO]	[TRAIN] epoch: 2841, iter: 224430/250000, loss: 0.1791, lr: 0.001285, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6354 samples/sec | ETA 04:00:25
2023-02-05 03:49:47 [INFO]	[TRAIN] epoch: 2842, iter: 224440/250000, loss: 0.1234, lr: 0.001284, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6189 samples/sec | ETA 04:00:42
2023-02-05 03:49:52 [INFO]	[TRAIN] epoch: 2842, iter: 224450/250000, loss: 0.1667, lr: 0.001284, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6236 samples/sec | ETA 04:00:30
2023-02-05 03:49:58 [INFO]	[TRAIN] epoch: 2842, iter: 224460/250000, loss: 0.1675, lr: 0.001283, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6264 samples/sec | ETA 04:00:20
2023-02-05 03:50:04 [INFO]	[TRAIN] epoch: 2842, iter: 224470/250000, loss: 0.1430, lr: 0.001283, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6270 samples/sec | ETA 04:00:14
2023-02-05 03:50:09 [INFO]	[TRAIN] epoch: 2842, iter: 224480/250000, loss: 0.1626, lr: 0.001283, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6058 samples/sec | ETA 04:00:37
2023-02-05 03:50:15 [INFO]	[TRAIN] epoch: 2842, iter: 224490/250000, loss: 0.1891, lr: 0.001282, batch_cost: 0.5661, reader_cost: 0.00008, ips: 10.5980 samples/sec | ETA 04:00:42
2023-02-05 03:50:21 [INFO]	[TRAIN] epoch: 2842, iter: 224500/250000, loss: 0.1559, lr: 0.001282, batch_cost: 0.5971, reader_cost: 0.03273, ips: 10.0482 samples/sec | ETA 04:13:46
2023-02-05 03:50:27 [INFO]	[TRAIN] epoch: 2842, iter: 224510/250000, loss: 0.2271, lr: 0.001281, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6388 samples/sec | ETA 03:59:35
2023-02-05 03:50:32 [INFO]	[TRAIN] epoch: 2843, iter: 224520/250000, loss: 0.1649, lr: 0.001281, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6265 samples/sec | ETA 03:59:46
2023-02-05 03:50:38 [INFO]	[TRAIN] epoch: 2843, iter: 224530/250000, loss: 0.1497, lr: 0.001280, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6049 samples/sec | ETA 04:00:10
2023-02-05 03:50:43 [INFO]	[TRAIN] epoch: 2843, iter: 224540/250000, loss: 0.1615, lr: 0.001280, batch_cost: 0.5660, reader_cost: 0.00008, ips: 10.6008 samples/sec | ETA 04:00:10
2023-02-05 03:50:49 [INFO]	[TRAIN] epoch: 2843, iter: 224550/250000, loss: 0.1377, lr: 0.001279, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6018 samples/sec | ETA 04:00:03
2023-02-05 03:50:55 [INFO]	[TRAIN] epoch: 2843, iter: 224560/250000, loss: 0.1734, lr: 0.001279, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6109 samples/sec | ETA 03:59:45
2023-02-05 03:51:01 [INFO]	[TRAIN] epoch: 2843, iter: 224570/250000, loss: 0.1474, lr: 0.001278, batch_cost: 0.5988, reader_cost: 0.03244, ips: 10.0198 samples/sec | ETA 04:13:47
2023-02-05 03:51:06 [INFO]	[TRAIN] epoch: 2843, iter: 224580/250000, loss: 0.1415, lr: 0.001278, batch_cost: 0.5643, reader_cost: 0.00026, ips: 10.6324 samples/sec | ETA 03:59:04
2023-02-05 03:51:12 [INFO]	[TRAIN] epoch: 2843, iter: 224590/250000, loss: 0.1538, lr: 0.001278, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6372 samples/sec | ETA 03:58:52
2023-02-05 03:51:18 [INFO]	[TRAIN] epoch: 2844, iter: 224600/250000, loss: 0.1576, lr: 0.001277, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6310 samples/sec | ETA 03:58:55
2023-02-05 03:51:23 [INFO]	[TRAIN] epoch: 2844, iter: 224610/250000, loss: 0.1327, lr: 0.001277, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6110 samples/sec | ETA 03:59:16
2023-02-05 03:51:29 [INFO]	[TRAIN] epoch: 2844, iter: 224620/250000, loss: 0.1501, lr: 0.001276, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 03:59:17
2023-02-05 03:51:35 [INFO]	[TRAIN] epoch: 2844, iter: 224630/250000, loss: 0.1510, lr: 0.001276, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6043 samples/sec | ETA 03:59:14
2023-02-05 03:51:40 [INFO]	[TRAIN] epoch: 2844, iter: 224640/250000, loss: 0.1602, lr: 0.001275, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6049 samples/sec | ETA 03:59:08
2023-02-05 03:51:46 [INFO]	[TRAIN] epoch: 2844, iter: 224650/250000, loss: 0.1606, lr: 0.001275, batch_cost: 0.5906, reader_cost: 0.02512, ips: 10.1595 samples/sec | ETA 04:09:31
2023-02-05 03:51:52 [INFO]	[TRAIN] epoch: 2844, iter: 224660/250000, loss: 0.1425, lr: 0.001274, batch_cost: 0.5644, reader_cost: 0.00015, ips: 10.6309 samples/sec | ETA 03:58:21
2023-02-05 03:51:58 [INFO]	[TRAIN] epoch: 2844, iter: 224670/250000, loss: 0.1579, lr: 0.001274, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6275 samples/sec | ETA 03:58:20
2023-02-05 03:52:03 [INFO]	[TRAIN] epoch: 2845, iter: 224680/250000, loss: 0.1737, lr: 0.001273, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6323 samples/sec | ETA 03:58:08
2023-02-05 03:52:09 [INFO]	[TRAIN] epoch: 2845, iter: 224690/250000, loss: 0.1693, lr: 0.001273, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6153 samples/sec | ETA 03:58:25
2023-02-05 03:52:15 [INFO]	[TRAIN] epoch: 2845, iter: 224700/250000, loss: 0.2202, lr: 0.001273, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6043 samples/sec | ETA 03:58:34
2023-02-05 03:52:20 [INFO]	[TRAIN] epoch: 2845, iter: 224710/250000, loss: 0.1991, lr: 0.001272, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5994 samples/sec | ETA 03:58:35
2023-02-05 03:52:26 [INFO]	[TRAIN] epoch: 2845, iter: 224720/250000, loss: 0.1687, lr: 0.001272, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6120 samples/sec | ETA 03:58:13
2023-02-05 03:52:32 [INFO]	[TRAIN] epoch: 2845, iter: 224730/250000, loss: 0.1893, lr: 0.001271, batch_cost: 0.5887, reader_cost: 0.02390, ips: 10.1923 samples/sec | ETA 04:07:55
2023-02-05 03:52:37 [INFO]	[TRAIN] epoch: 2845, iter: 224740/250000, loss: 0.1538, lr: 0.001271, batch_cost: 0.5662, reader_cost: 0.00011, ips: 10.5976 samples/sec | ETA 03:58:21
2023-02-05 03:52:43 [INFO]	[TRAIN] epoch: 2845, iter: 224750/250000, loss: 0.1995, lr: 0.001270, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6103 samples/sec | ETA 03:57:58
2023-02-05 03:52:49 [INFO]	[TRAIN] epoch: 2846, iter: 224760/250000, loss: 0.1723, lr: 0.001270, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6030 samples/sec | ETA 03:58:02
2023-02-05 03:52:54 [INFO]	[TRAIN] epoch: 2846, iter: 224770/250000, loss: 0.1734, lr: 0.001269, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6144 samples/sec | ETA 03:57:41
2023-02-05 03:53:00 [INFO]	[TRAIN] epoch: 2846, iter: 224780/250000, loss: 0.1711, lr: 0.001269, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6059 samples/sec | ETA 03:57:47
2023-02-05 03:53:06 [INFO]	[TRAIN] epoch: 2846, iter: 224790/250000, loss: 0.1333, lr: 0.001268, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6084 samples/sec | ETA 03:57:38
2023-02-05 03:53:11 [INFO]	[TRAIN] epoch: 2846, iter: 224800/250000, loss: 0.1610, lr: 0.001268, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6085 samples/sec | ETA 03:57:32
2023-02-05 03:53:17 [INFO]	[TRAIN] epoch: 2846, iter: 224810/250000, loss: 0.1698, lr: 0.001268, batch_cost: 0.5985, reader_cost: 0.03355, ips: 10.0249 samples/sec | ETA 04:11:16
2023-02-05 03:53:23 [INFO]	[TRAIN] epoch: 2846, iter: 224820/250000, loss: 0.1900, lr: 0.001267, batch_cost: 0.5637, reader_cost: 0.00013, ips: 10.6448 samples/sec | ETA 03:56:32
2023-02-05 03:53:29 [INFO]	[TRAIN] epoch: 2846, iter: 224830/250000, loss: 0.1903, lr: 0.001267, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6328 samples/sec | ETA 03:56:43
2023-02-05 03:53:34 [INFO]	[TRAIN] epoch: 2847, iter: 224840/250000, loss: 0.1944, lr: 0.001266, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6088 samples/sec | ETA 03:57:09
2023-02-05 03:53:40 [INFO]	[TRAIN] epoch: 2847, iter: 224850/250000, loss: 0.1715, lr: 0.001266, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6051 samples/sec | ETA 03:57:08
2023-02-05 03:53:46 [INFO]	[TRAIN] epoch: 2847, iter: 224860/250000, loss: 0.1397, lr: 0.001265, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6137 samples/sec | ETA 03:56:51
2023-02-05 03:53:51 [INFO]	[TRAIN] epoch: 2847, iter: 224870/250000, loss: 0.1300, lr: 0.001265, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6013 samples/sec | ETA 03:57:02
2023-02-05 03:53:57 [INFO]	[TRAIN] epoch: 2847, iter: 224880/250000, loss: 0.1842, lr: 0.001264, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5995 samples/sec | ETA 03:56:59
2023-02-05 03:54:03 [INFO]	[TRAIN] epoch: 2847, iter: 224890/250000, loss: 0.1559, lr: 0.001264, batch_cost: 0.5876, reader_cost: 0.02282, ips: 10.2111 samples/sec | ETA 04:05:54
2023-02-05 03:54:08 [INFO]	[TRAIN] epoch: 2847, iter: 224900/250000, loss: 0.1515, lr: 0.001264, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6233 samples/sec | ETA 03:56:16
2023-02-05 03:54:14 [INFO]	[TRAIN] epoch: 2847, iter: 224910/250000, loss: 0.1646, lr: 0.001263, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6258 samples/sec | ETA 03:56:07
2023-02-05 03:54:20 [INFO]	[TRAIN] epoch: 2848, iter: 224920/250000, loss: 0.1464, lr: 0.001263, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6336 samples/sec | ETA 03:55:51
2023-02-05 03:54:25 [INFO]	[TRAIN] epoch: 2848, iter: 224930/250000, loss: 0.1614, lr: 0.001262, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6330 samples/sec | ETA 03:55:46
2023-02-05 03:54:31 [INFO]	[TRAIN] epoch: 2848, iter: 224940/250000, loss: 0.1450, lr: 0.001262, batch_cost: 0.5649, reader_cost: 0.00008, ips: 10.6210 samples/sec | ETA 03:55:56
2023-02-05 03:54:37 [INFO]	[TRAIN] epoch: 2848, iter: 224950/250000, loss: 0.1601, lr: 0.001261, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5968 samples/sec | ETA 03:56:23
2023-02-05 03:54:42 [INFO]	[TRAIN] epoch: 2848, iter: 224960/250000, loss: 0.1400, lr: 0.001261, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5976 samples/sec | ETA 03:56:16
2023-02-05 03:54:48 [INFO]	[TRAIN] epoch: 2848, iter: 224970/250000, loss: 0.1477, lr: 0.001260, batch_cost: 0.6019, reader_cost: 0.03511, ips: 9.9680 samples/sec | ETA 04:11:06
2023-02-05 03:54:54 [INFO]	[TRAIN] epoch: 2848, iter: 224980/250000, loss: 0.1651, lr: 0.001260, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6200 samples/sec | ETA 03:55:35
2023-02-05 03:55:00 [INFO]	[TRAIN] epoch: 2848, iter: 224990/250000, loss: 0.1411, lr: 0.001259, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6127 samples/sec | ETA 03:55:39
2023-02-05 03:55:05 [INFO]	[TRAIN] epoch: 2849, iter: 225000/250000, loss: 0.1435, lr: 0.001259, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6113 samples/sec | ETA 03:55:35
2023-02-05 03:55:11 [INFO]	[TRAIN] epoch: 2849, iter: 225010/250000, loss: 0.1593, lr: 0.001259, batch_cost: 0.5658, reader_cost: 0.00008, ips: 10.6052 samples/sec | ETA 03:55:38
2023-02-05 03:55:17 [INFO]	[TRAIN] epoch: 2849, iter: 225020/250000, loss: 0.1346, lr: 0.001258, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6039 samples/sec | ETA 03:55:34
2023-02-05 03:55:22 [INFO]	[TRAIN] epoch: 2849, iter: 225030/250000, loss: 0.1437, lr: 0.001258, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6079 samples/sec | ETA 03:55:23
2023-02-05 03:55:28 [INFO]	[TRAIN] epoch: 2849, iter: 225040/250000, loss: 0.1683, lr: 0.001257, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6128 samples/sec | ETA 03:55:11
2023-02-05 03:55:34 [INFO]	[TRAIN] epoch: 2849, iter: 225050/250000, loss: 0.1500, lr: 0.001257, batch_cost: 0.5980, reader_cost: 0.03116, ips: 10.0335 samples/sec | ETA 04:08:40
2023-02-05 03:55:40 [INFO]	[TRAIN] epoch: 2849, iter: 225060/250000, loss: 0.1639, lr: 0.001256, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6149 samples/sec | ETA 03:54:57
2023-02-05 03:55:45 [INFO]	[TRAIN] epoch: 2849, iter: 225070/250000, loss: 0.1354, lr: 0.001256, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6165 samples/sec | ETA 03:54:49
2023-02-05 03:55:51 [INFO]	[TRAIN] epoch: 2850, iter: 225080/250000, loss: 0.1960, lr: 0.001255, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6010 samples/sec | ETA 03:55:04
2023-02-05 03:55:56 [INFO]	[TRAIN] epoch: 2850, iter: 225090/250000, loss: 0.1587, lr: 0.001255, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6105 samples/sec | ETA 03:54:46
2023-02-05 03:56:02 [INFO]	[TRAIN] epoch: 2850, iter: 225100/250000, loss: 0.1873, lr: 0.001254, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6140 samples/sec | ETA 03:54:35
2023-02-05 03:56:08 [INFO]	[TRAIN] epoch: 2850, iter: 225110/250000, loss: 0.1619, lr: 0.001254, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6022 samples/sec | ETA 03:54:45
2023-02-05 03:56:13 [INFO]	[TRAIN] epoch: 2850, iter: 225120/250000, loss: 0.2988, lr: 0.001254, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6077 samples/sec | ETA 03:54:32
2023-02-05 03:56:19 [INFO]	[TRAIN] epoch: 2850, iter: 225130/250000, loss: 0.2903, lr: 0.001253, batch_cost: 0.5911, reader_cost: 0.02595, ips: 10.1509 samples/sec | ETA 04:05:00
2023-02-05 03:56:25 [INFO]	[TRAIN] epoch: 2850, iter: 225140/250000, loss: 0.2706, lr: 0.001253, batch_cost: 0.5652, reader_cost: 0.00008, ips: 10.6162 samples/sec | ETA 03:54:10
2023-02-05 03:56:31 [INFO]	[TRAIN] epoch: 2850, iter: 225150/250000, loss: 0.2017, lr: 0.001252, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6124 samples/sec | ETA 03:54:09
2023-02-05 03:56:36 [INFO]	[TRAIN] epoch: 2851, iter: 225160/250000, loss: 0.2005, lr: 0.001252, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6115 samples/sec | ETA 03:54:05
2023-02-05 03:56:42 [INFO]	[TRAIN] epoch: 2851, iter: 225170/250000, loss: 0.1855, lr: 0.001251, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 03:54:06
2023-02-05 03:56:48 [INFO]	[TRAIN] epoch: 2851, iter: 225180/250000, loss: 0.2107, lr: 0.001251, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6072 samples/sec | ETA 03:53:59
2023-02-05 03:56:53 [INFO]	[TRAIN] epoch: 2851, iter: 225190/250000, loss: 0.1803, lr: 0.001250, batch_cost: 0.5647, reader_cost: 0.00008, ips: 10.6244 samples/sec | ETA 03:53:31
2023-02-05 03:56:59 [INFO]	[TRAIN] epoch: 2851, iter: 225200/250000, loss: 0.2045, lr: 0.001250, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6000 samples/sec | ETA 03:53:57
2023-02-05 03:57:05 [INFO]	[TRAIN] epoch: 2851, iter: 225210/250000, loss: 0.2073, lr: 0.001249, batch_cost: 0.5969, reader_cost: 0.03172, ips: 10.0522 samples/sec | ETA 04:06:36
2023-02-05 03:57:11 [INFO]	[TRAIN] epoch: 2851, iter: 225220/250000, loss: 0.1693, lr: 0.001249, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6037 samples/sec | ETA 03:53:41
2023-02-05 03:57:16 [INFO]	[TRAIN] epoch: 2852, iter: 225230/250000, loss: 0.1993, lr: 0.001249, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6146 samples/sec | ETA 03:53:21
2023-02-05 03:57:22 [INFO]	[TRAIN] epoch: 2852, iter: 225240/250000, loss: 0.1961, lr: 0.001248, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6110 samples/sec | ETA 03:53:20
2023-02-05 03:57:28 [INFO]	[TRAIN] epoch: 2852, iter: 225250/250000, loss: 0.1776, lr: 0.001248, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6061 samples/sec | ETA 03:53:21
2023-02-05 03:57:33 [INFO]	[TRAIN] epoch: 2852, iter: 225260/250000, loss: 0.1545, lr: 0.001247, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6184 samples/sec | ETA 03:52:59
2023-02-05 03:57:39 [INFO]	[TRAIN] epoch: 2852, iter: 225270/250000, loss: 0.1690, lr: 0.001247, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6091 samples/sec | ETA 03:53:06
2023-02-05 03:57:45 [INFO]	[TRAIN] epoch: 2852, iter: 225280/250000, loss: 0.2172, lr: 0.001246, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6112 samples/sec | ETA 03:52:57
2023-02-05 03:57:51 [INFO]	[TRAIN] epoch: 2852, iter: 225290/250000, loss: 0.1590, lr: 0.001246, batch_cost: 0.6012, reader_cost: 0.03682, ips: 9.9804 samples/sec | ETA 04:07:35
2023-02-05 03:57:56 [INFO]	[TRAIN] epoch: 2852, iter: 225300/250000, loss: 0.1636, lr: 0.001245, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6326 samples/sec | ETA 03:52:18
2023-02-05 03:58:02 [INFO]	[TRAIN] epoch: 2853, iter: 225310/250000, loss: 0.1688, lr: 0.001245, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5998 samples/sec | ETA 03:52:55
2023-02-05 03:58:07 [INFO]	[TRAIN] epoch: 2853, iter: 225320/250000, loss: 0.1942, lr: 0.001244, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6019 samples/sec | ETA 03:52:47
2023-02-05 03:58:13 [INFO]	[TRAIN] epoch: 2853, iter: 225330/250000, loss: 0.1508, lr: 0.001244, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6130 samples/sec | ETA 03:52:27
2023-02-05 03:58:19 [INFO]	[TRAIN] epoch: 2853, iter: 225340/250000, loss: 0.1892, lr: 0.001244, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6101 samples/sec | ETA 03:52:25
2023-02-05 03:58:24 [INFO]	[TRAIN] epoch: 2853, iter: 225350/250000, loss: 0.1591, lr: 0.001243, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6034 samples/sec | ETA 03:52:28
2023-02-05 03:58:30 [INFO]	[TRAIN] epoch: 2853, iter: 225360/250000, loss: 0.1506, lr: 0.001243, batch_cost: 0.5948, reader_cost: 0.02984, ips: 10.0870 samples/sec | ETA 04:04:16
2023-02-05 03:58:36 [INFO]	[TRAIN] epoch: 2853, iter: 225370/250000, loss: 0.2220, lr: 0.001242, batch_cost: 0.5650, reader_cost: 0.00019, ips: 10.6190 samples/sec | ETA 03:51:56
2023-02-05 03:58:42 [INFO]	[TRAIN] epoch: 2853, iter: 225380/250000, loss: 0.1846, lr: 0.001242, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6076 samples/sec | ETA 03:52:05
2023-02-05 03:58:47 [INFO]	[TRAIN] epoch: 2854, iter: 225390/250000, loss: 0.1874, lr: 0.001241, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6029 samples/sec | ETA 03:52:06
2023-02-05 03:58:53 [INFO]	[TRAIN] epoch: 2854, iter: 225400/250000, loss: 0.1417, lr: 0.001241, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6234 samples/sec | ETA 03:51:33
2023-02-05 03:58:59 [INFO]	[TRAIN] epoch: 2854, iter: 225410/250000, loss: 0.1579, lr: 0.001240, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6015 samples/sec | ETA 03:51:56
2023-02-05 03:59:04 [INFO]	[TRAIN] epoch: 2854, iter: 225420/250000, loss: 0.1671, lr: 0.001240, batch_cost: 0.5662, reader_cost: 0.00008, ips: 10.5963 samples/sec | ETA 03:51:58
2023-02-05 03:59:10 [INFO]	[TRAIN] epoch: 2854, iter: 225430/250000, loss: 0.2107, lr: 0.001239, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6111 samples/sec | ETA 03:51:33
2023-02-05 03:59:16 [INFO]	[TRAIN] epoch: 2854, iter: 225440/250000, loss: 0.1546, lr: 0.001239, batch_cost: 0.5911, reader_cost: 0.02578, ips: 10.1499 samples/sec | ETA 04:01:58
2023-02-05 03:59:22 [INFO]	[TRAIN] epoch: 2854, iter: 225450/250000, loss: 0.1365, lr: 0.001239, batch_cost: 0.5643, reader_cost: 0.00014, ips: 10.6318 samples/sec | ETA 03:50:54
2023-02-05 03:59:27 [INFO]	[TRAIN] epoch: 2854, iter: 225460/250000, loss: 0.1913, lr: 0.001238, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6240 samples/sec | ETA 03:50:59
2023-02-05 03:59:33 [INFO]	[TRAIN] epoch: 2855, iter: 225470/250000, loss: 0.1533, lr: 0.001238, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6033 samples/sec | ETA 03:51:20
2023-02-05 03:59:39 [INFO]	[TRAIN] epoch: 2855, iter: 225480/250000, loss: 0.1717, lr: 0.001237, batch_cost: 0.5663, reader_cost: 0.00010, ips: 10.5952 samples/sec | ETA 03:51:25
2023-02-05 03:59:44 [INFO]	[TRAIN] epoch: 2855, iter: 225490/250000, loss: 0.1606, lr: 0.001237, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6150 samples/sec | ETA 03:50:54
2023-02-05 03:59:50 [INFO]	[TRAIN] epoch: 2855, iter: 225500/250000, loss: 0.1424, lr: 0.001236, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6102 samples/sec | ETA 03:50:54
2023-02-05 03:59:55 [INFO]	[TRAIN] epoch: 2855, iter: 225510/250000, loss: 0.2293, lr: 0.001236, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6005 samples/sec | ETA 03:51:01
2023-02-05 04:00:01 [INFO]	[TRAIN] epoch: 2855, iter: 225520/250000, loss: 0.1714, lr: 0.001235, batch_cost: 0.5910, reader_cost: 0.02547, ips: 10.1519 samples/sec | ETA 04:01:08
2023-02-05 04:00:07 [INFO]	[TRAIN] epoch: 2855, iter: 225530/250000, loss: 0.2185, lr: 0.001235, batch_cost: 0.5648, reader_cost: 0.00015, ips: 10.6231 samples/sec | ETA 03:50:20
2023-02-05 04:00:13 [INFO]	[TRAIN] epoch: 2855, iter: 225540/250000, loss: 0.1655, lr: 0.001234, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6349 samples/sec | ETA 03:49:59
2023-02-05 04:00:18 [INFO]	[TRAIN] epoch: 2856, iter: 225550/250000, loss: 0.1537, lr: 0.001234, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6291 samples/sec | ETA 03:50:01
2023-02-05 04:00:24 [INFO]	[TRAIN] epoch: 2856, iter: 225560/250000, loss: 0.2048, lr: 0.001234, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6377 samples/sec | ETA 03:49:44
2023-02-05 04:00:30 [INFO]	[TRAIN] epoch: 2856, iter: 225570/250000, loss: 0.1704, lr: 0.001233, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6298 samples/sec | ETA 03:49:49
2023-02-05 04:00:35 [INFO]	[TRAIN] epoch: 2856, iter: 225580/250000, loss: 0.1851, lr: 0.001233, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6252 samples/sec | ETA 03:49:49
2023-02-05 04:00:41 [INFO]	[TRAIN] epoch: 2856, iter: 225590/250000, loss: 0.2439, lr: 0.001232, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6151 samples/sec | ETA 03:49:57
2023-02-05 04:00:47 [INFO]	[TRAIN] epoch: 2856, iter: 225600/250000, loss: 0.1603, lr: 0.001232, batch_cost: 0.5887, reader_cost: 0.02295, ips: 10.1925 samples/sec | ETA 03:59:23
2023-02-05 04:00:52 [INFO]	[TRAIN] epoch: 2856, iter: 225610/250000, loss: 0.1739, lr: 0.001231, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6317 samples/sec | ETA 03:49:24
2023-02-05 04:00:58 [INFO]	[TRAIN] epoch: 2856, iter: 225620/250000, loss: 0.1663, lr: 0.001231, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6219 samples/sec | ETA 03:49:31
2023-02-05 04:01:04 [INFO]	[TRAIN] epoch: 2857, iter: 225630/250000, loss: 0.1814, lr: 0.001230, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6241 samples/sec | ETA 03:49:23
2023-02-05 04:01:09 [INFO]	[TRAIN] epoch: 2857, iter: 225640/250000, loss: 0.1473, lr: 0.001230, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6241 samples/sec | ETA 03:49:17
2023-02-05 04:01:15 [INFO]	[TRAIN] epoch: 2857, iter: 225650/250000, loss: 0.1995, lr: 0.001229, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6280 samples/sec | ETA 03:49:06
2023-02-05 04:01:21 [INFO]	[TRAIN] epoch: 2857, iter: 225660/250000, loss: 0.1538, lr: 0.001229, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6266 samples/sec | ETA 03:49:02
2023-02-05 04:01:26 [INFO]	[TRAIN] epoch: 2857, iter: 225670/250000, loss: 0.1528, lr: 0.001229, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6307 samples/sec | ETA 03:48:51
2023-02-05 04:01:32 [INFO]	[TRAIN] epoch: 2857, iter: 225680/250000, loss: 0.1918, lr: 0.001228, batch_cost: 0.5879, reader_cost: 0.02371, ips: 10.2060 samples/sec | ETA 03:58:17
2023-02-05 04:01:38 [INFO]	[TRAIN] epoch: 2857, iter: 225690/250000, loss: 0.1697, lr: 0.001228, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6340 samples/sec | ETA 03:48:36
2023-02-05 04:01:44 [INFO]	[TRAIN] epoch: 2857, iter: 225700/250000, loss: 0.1707, lr: 0.001227, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6332 samples/sec | ETA 03:48:31
2023-02-05 04:01:49 [INFO]	[TRAIN] epoch: 2858, iter: 225710/250000, loss: 0.1752, lr: 0.001227, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6271 samples/sec | ETA 03:48:34
2023-02-05 04:01:55 [INFO]	[TRAIN] epoch: 2858, iter: 225720/250000, loss: 0.1733, lr: 0.001226, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6306 samples/sec | ETA 03:48:23
2023-02-05 04:02:00 [INFO]	[TRAIN] epoch: 2858, iter: 225730/250000, loss: 0.1594, lr: 0.001226, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6289 samples/sec | ETA 03:48:20
2023-02-05 04:02:06 [INFO]	[TRAIN] epoch: 2858, iter: 225740/250000, loss: 0.1776, lr: 0.001225, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6257 samples/sec | ETA 03:48:18
2023-02-05 04:02:12 [INFO]	[TRAIN] epoch: 2858, iter: 225750/250000, loss: 0.1639, lr: 0.001225, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6330 samples/sec | ETA 03:48:03
2023-02-05 04:02:18 [INFO]	[TRAIN] epoch: 2858, iter: 225760/250000, loss: 0.2010, lr: 0.001224, batch_cost: 0.5891, reader_cost: 0.02413, ips: 10.1848 samples/sec | ETA 03:58:00
2023-02-05 04:02:23 [INFO]	[TRAIN] epoch: 2858, iter: 225770/250000, loss: 0.2297, lr: 0.001224, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6396 samples/sec | ETA 03:47:44
2023-02-05 04:02:29 [INFO]	[TRAIN] epoch: 2858, iter: 225780/250000, loss: 0.1793, lr: 0.001224, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6320 samples/sec | ETA 03:47:48
2023-02-05 04:02:35 [INFO]	[TRAIN] epoch: 2859, iter: 225790/250000, loss: 0.1866, lr: 0.001223, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6263 samples/sec | ETA 03:47:49
2023-02-05 04:02:40 [INFO]	[TRAIN] epoch: 2859, iter: 225800/250000, loss: 0.1863, lr: 0.001223, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6244 samples/sec | ETA 03:47:46
2023-02-05 04:02:46 [INFO]	[TRAIN] epoch: 2859, iter: 225810/250000, loss: 0.1750, lr: 0.001222, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6283 samples/sec | ETA 03:47:35
2023-02-05 04:02:51 [INFO]	[TRAIN] epoch: 2859, iter: 225820/250000, loss: 0.1569, lr: 0.001222, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6267 samples/sec | ETA 03:47:32
2023-02-05 04:02:57 [INFO]	[TRAIN] epoch: 2859, iter: 225830/250000, loss: 0.1939, lr: 0.001221, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6229 samples/sec | ETA 03:47:31
2023-02-05 04:03:03 [INFO]	[TRAIN] epoch: 2859, iter: 225840/250000, loss: 0.1597, lr: 0.001221, batch_cost: 0.5887, reader_cost: 0.02336, ips: 10.1916 samples/sec | ETA 03:57:03
2023-02-05 04:03:09 [INFO]	[TRAIN] epoch: 2859, iter: 225850/250000, loss: 0.1456, lr: 0.001220, batch_cost: 0.5647, reader_cost: 0.00026, ips: 10.6253 samples/sec | ETA 03:47:17
2023-02-05 04:03:14 [INFO]	[TRAIN] epoch: 2859, iter: 225860/250000, loss: 0.1571, lr: 0.001220, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6372 samples/sec | ETA 03:46:56
2023-02-05 04:03:20 [INFO]	[TRAIN] epoch: 2860, iter: 225870/250000, loss: 0.1565, lr: 0.001219, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6282 samples/sec | ETA 03:47:02
2023-02-05 04:03:26 [INFO]	[TRAIN] epoch: 2860, iter: 225880/250000, loss: 0.1484, lr: 0.001219, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6269 samples/sec | ETA 03:46:58
2023-02-05 04:03:31 [INFO]	[TRAIN] epoch: 2860, iter: 225890/250000, loss: 0.1864, lr: 0.001219, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6206 samples/sec | ETA 03:47:00
2023-02-05 04:03:37 [INFO]	[TRAIN] epoch: 2860, iter: 225900/250000, loss: 0.1430, lr: 0.001218, batch_cost: 0.5652, reader_cost: 0.00008, ips: 10.6165 samples/sec | ETA 03:47:00
2023-02-05 04:03:43 [INFO]	[TRAIN] epoch: 2860, iter: 225910/250000, loss: 0.1467, lr: 0.001218, batch_cost: 0.5663, reader_cost: 0.00010, ips: 10.5956 samples/sec | ETA 03:47:21
2023-02-05 04:03:48 [INFO]	[TRAIN] epoch: 2860, iter: 225920/250000, loss: 0.1664, lr: 0.001217, batch_cost: 0.5921, reader_cost: 0.02755, ips: 10.1339 samples/sec | ETA 03:57:37
2023-02-05 04:03:54 [INFO]	[TRAIN] epoch: 2860, iter: 225930/250000, loss: 0.1299, lr: 0.001217, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6225 samples/sec | ETA 03:46:35
2023-02-05 04:04:00 [INFO]	[TRAIN] epoch: 2860, iter: 225940/250000, loss: 0.1732, lr: 0.001216, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6286 samples/sec | ETA 03:46:22
2023-02-05 04:04:05 [INFO]	[TRAIN] epoch: 2861, iter: 225950/250000, loss: 0.1545, lr: 0.001216, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6338 samples/sec | ETA 03:46:09
2023-02-05 04:04:11 [INFO]	[TRAIN] epoch: 2861, iter: 225960/250000, loss: 0.1500, lr: 0.001215, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6376 samples/sec | ETA 03:45:59
2023-02-05 04:04:17 [INFO]	[TRAIN] epoch: 2861, iter: 225970/250000, loss: 0.1696, lr: 0.001215, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6291 samples/sec | ETA 03:46:04
2023-02-05 04:04:22 [INFO]	[TRAIN] epoch: 2861, iter: 225980/250000, loss: 0.1483, lr: 0.001214, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6304 samples/sec | ETA 03:45:57
2023-02-05 04:04:28 [INFO]	[TRAIN] epoch: 2861, iter: 225990/250000, loss: 0.1834, lr: 0.001214, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6323 samples/sec | ETA 03:45:49
2023-02-05 04:04:34 [INFO]	[TRAIN] epoch: 2861, iter: 226000/250000, loss: 0.1736, lr: 0.001214, batch_cost: 0.5964, reader_cost: 0.03166, ips: 10.0606 samples/sec | ETA 03:58:33
2023-02-05 04:04:34 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1249 - reader cost: 0.0235 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1490 - reader cost: 0.0118 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1563 - reader cost: 0.0079 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1571 - reader cost: 0.0059 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1587 - reader cost: 0.0048 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1606 - reader cost: 0.0040 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1602 - reader cost: 0.0034 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1607 - reader cost: 0.0030 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1610 - reader cost: 0.002710/36 [=======>......................] - ETA: 4s - batch_cost: 0.1611 - reader cost: 0.002411/36 [========>.....................] - ETA: 4s - batch_cost: 0.1620 - reader cost: 0.002212/36 [=========>....................] - ETA: 3s - batch_cost: 0.1617 - reader cost: 0.002013/36 [=========>....................] - ETA: 3s - batch_cost: 0.1623 - reader cost: 0.001914/36 [==========>...................] - ETA: 3s - batch_cost: 0.1631 - reader cost: 0.001715/36 [===========>..................] - ETA: 3s - batch_cost: 0.1634 - reader cost: 0.001616/36 [============>.................] - ETA: 3s - batch_cost: 0.1642 - reader cost: 0.001517/36 [=============>................] - ETA: 3s - batch_cost: 0.1646 - reader cost: 0.001518/36 [==============>...............] - ETA: 2s - batch_cost: 0.1647 - reader cost: 0.001419/36 [==============>...............] - ETA: 2s - batch_cost: 0.1645 - reader cost: 0.001320/36 [===============>..............] - ETA: 2s - batch_cost: 0.1643 - reader cost: 0.001221/36 [================>.............] - ETA: 2s - batch_cost: 0.1643 - reader cost: 0.001222/36 [=================>............] - ETA: 2s - batch_cost: 0.1646 - reader cost: 0.001123/36 [==================>...........] - ETA: 2s - batch_cost: 0.1653 - reader cost: 0.001124/36 [===================>..........] - ETA: 1s - batch_cost: 0.1652 - reader cost: 0.001125/36 [===================>..........] - ETA: 1s - batch_cost: 0.1653 - reader cost: 0.001026/36 [====================>.........] - ETA: 1s - batch_cost: 0.1654 - reader cost: 9.7501e-0427/36 [=====================>........] - ETA: 1s - batch_cost: 0.1655 - reader cost: 9.4201e-0428/36 [======================>.......] - ETA: 1s - batch_cost: 0.1657 - reader cost: 9.1150e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1657 - reader cost: 8.8244e-0430/36 [========================>.....] - ETA: 0s - batch_cost: 0.1656 - reader cost: 8.5572e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1656 - reader cost: 8.3084e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1655 - reader cost: 8.0749e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1654 - reader cost: 7.8494e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1652 - reader cost: 7.6374e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1653 - reader cost: 7.4369e-0436/36 [==============================] - 6s 165ms/step - batch_cost: 0.1654 - reader cost: 7.2536e-04
2023-02-05 04:04:40 [INFO]	[EVAL] #Images: 36 mIoU: 0.8652 Acc: 0.9867 Kappa: 0.9518 Dice: 0.9239
2023-02-05 04:04:40 [INFO]	[EVAL] Class IoU: 
[0.9861 0.9273 0.8901 0.7053 0.7041 0.9724 0.8708]
2023-02-05 04:04:40 [INFO]	[EVAL] Class Precision: 
[0.9933 0.9652 0.9444 0.8316 0.8538 0.9805 0.9084]
2023-02-05 04:04:40 [INFO]	[EVAL] Class Recall: 
[0.9927 0.9594 0.9393 0.8228 0.8006 0.9917 0.9546]
2023-02-05 04:04:40 [INFO]	[EVAL] The model with the best validation mIoU (0.8682) was saved at iter 222000.
2023-02-05 04:04:46 [INFO]	[TRAIN] epoch: 2861, iter: 226010/250000, loss: 0.1953, lr: 0.001213, batch_cost: 0.5637, reader_cost: 0.00009, ips: 10.6441 samples/sec | ETA 03:45:23
2023-02-05 04:04:51 [INFO]	[TRAIN] epoch: 2862, iter: 226020/250000, loss: 0.1740, lr: 0.001213, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6313 samples/sec | ETA 03:45:33
2023-02-05 04:04:57 [INFO]	[TRAIN] epoch: 2862, iter: 226030/250000, loss: 0.1653, lr: 0.001212, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6333 samples/sec | ETA 03:45:25
2023-02-05 04:05:03 [INFO]	[TRAIN] epoch: 2862, iter: 226040/250000, loss: 0.1584, lr: 0.001212, batch_cost: 0.5641, reader_cost: 0.00008, ips: 10.6368 samples/sec | ETA 03:45:15
2023-02-05 04:05:08 [INFO]	[TRAIN] epoch: 2862, iter: 226050/250000, loss: 0.1597, lr: 0.001211, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6400 samples/sec | ETA 03:45:05
2023-02-05 04:05:14 [INFO]	[TRAIN] epoch: 2862, iter: 226060/250000, loss: 0.1430, lr: 0.001211, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6363 samples/sec | ETA 03:45:04
2023-02-05 04:05:20 [INFO]	[TRAIN] epoch: 2862, iter: 226070/250000, loss: 0.1549, lr: 0.001210, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6328 samples/sec | ETA 03:45:03
2023-02-05 04:05:26 [INFO]	[TRAIN] epoch: 2862, iter: 226080/250000, loss: 0.1705, lr: 0.001210, batch_cost: 0.5989, reader_cost: 0.03458, ips: 10.0179 samples/sec | ETA 03:58:46
2023-02-05 04:05:31 [INFO]	[TRAIN] epoch: 2862, iter: 226090/250000, loss: 0.1675, lr: 0.001209, batch_cost: 0.5647, reader_cost: 0.00008, ips: 10.6260 samples/sec | ETA 03:45:00
2023-02-05 04:05:37 [INFO]	[TRAIN] epoch: 2863, iter: 226100/250000, loss: 0.1543, lr: 0.001209, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6310 samples/sec | ETA 03:44:48
2023-02-05 04:05:43 [INFO]	[TRAIN] epoch: 2863, iter: 226110/250000, loss: 0.1442, lr: 0.001209, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6343 samples/sec | ETA 03:44:39
2023-02-05 04:05:48 [INFO]	[TRAIN] epoch: 2863, iter: 226120/250000, loss: 0.1519, lr: 0.001208, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6321 samples/sec | ETA 03:44:36
2023-02-05 04:05:54 [INFO]	[TRAIN] epoch: 2863, iter: 226130/250000, loss: 0.1642, lr: 0.001208, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6274 samples/sec | ETA 03:44:36
2023-02-05 04:06:00 [INFO]	[TRAIN] epoch: 2863, iter: 226140/250000, loss: 0.1497, lr: 0.001207, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6276 samples/sec | ETA 03:44:30
2023-02-05 04:06:05 [INFO]	[TRAIN] epoch: 2863, iter: 226150/250000, loss: 0.1851, lr: 0.001207, batch_cost: 0.5916, reader_cost: 0.02716, ips: 10.1428 samples/sec | ETA 03:55:08
2023-02-05 04:06:11 [INFO]	[TRAIN] epoch: 2863, iter: 226160/250000, loss: 0.1465, lr: 0.001206, batch_cost: 0.5648, reader_cost: 0.00023, ips: 10.6239 samples/sec | ETA 03:44:23
2023-02-05 04:06:17 [INFO]	[TRAIN] epoch: 2863, iter: 226170/250000, loss: 0.1518, lr: 0.001206, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6251 samples/sec | ETA 03:44:16
2023-02-05 04:06:22 [INFO]	[TRAIN] epoch: 2864, iter: 226180/250000, loss: 0.1362, lr: 0.001205, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6327 samples/sec | ETA 03:44:01
2023-02-05 04:06:28 [INFO]	[TRAIN] epoch: 2864, iter: 226190/250000, loss: 0.1306, lr: 0.001205, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6383 samples/sec | ETA 03:43:48
2023-02-05 04:06:34 [INFO]	[TRAIN] epoch: 2864, iter: 226200/250000, loss: 0.1432, lr: 0.001204, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6292 samples/sec | ETA 03:43:54
2023-02-05 04:06:39 [INFO]	[TRAIN] epoch: 2864, iter: 226210/250000, loss: 0.1496, lr: 0.001204, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6261 samples/sec | ETA 03:43:52
2023-02-05 04:06:45 [INFO]	[TRAIN] epoch: 2864, iter: 226220/250000, loss: 0.1597, lr: 0.001204, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6238 samples/sec | ETA 03:43:50
2023-02-05 04:06:51 [INFO]	[TRAIN] epoch: 2864, iter: 226230/250000, loss: 0.1618, lr: 0.001203, batch_cost: 0.5888, reader_cost: 0.02446, ips: 10.1903 samples/sec | ETA 03:53:15
2023-02-05 04:06:56 [INFO]	[TRAIN] epoch: 2864, iter: 226240/250000, loss: 0.1759, lr: 0.001203, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6260 samples/sec | ETA 03:43:36
2023-02-05 04:07:02 [INFO]	[TRAIN] epoch: 2864, iter: 226250/250000, loss: 0.1670, lr: 0.001202, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6245 samples/sec | ETA 03:43:32
2023-02-05 04:07:08 [INFO]	[TRAIN] epoch: 2865, iter: 226260/250000, loss: 0.1714, lr: 0.001202, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6231 samples/sec | ETA 03:43:28
2023-02-05 04:07:13 [INFO]	[TRAIN] epoch: 2865, iter: 226270/250000, loss: 0.1370, lr: 0.001201, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6353 samples/sec | ETA 03:43:07
2023-02-05 04:07:19 [INFO]	[TRAIN] epoch: 2865, iter: 226280/250000, loss: 0.1407, lr: 0.001201, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6269 samples/sec | ETA 03:43:12
2023-02-05 04:07:25 [INFO]	[TRAIN] epoch: 2865, iter: 226290/250000, loss: 0.1603, lr: 0.001200, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6269 samples/sec | ETA 03:43:06
2023-02-05 04:07:30 [INFO]	[TRAIN] epoch: 2865, iter: 226300/250000, loss: 0.1432, lr: 0.001200, batch_cost: 0.5649, reader_cost: 0.00008, ips: 10.6209 samples/sec | ETA 03:43:08
2023-02-05 04:07:36 [INFO]	[TRAIN] epoch: 2865, iter: 226310/250000, loss: 0.1382, lr: 0.001199, batch_cost: 0.5917, reader_cost: 0.02643, ips: 10.1404 samples/sec | ETA 03:53:37
2023-02-05 04:07:42 [INFO]	[TRAIN] epoch: 2865, iter: 226320/250000, loss: 0.1495, lr: 0.001199, batch_cost: 0.5647, reader_cost: 0.00019, ips: 10.6247 samples/sec | ETA 03:42:52
2023-02-05 04:07:48 [INFO]	[TRAIN] epoch: 2865, iter: 226330/250000, loss: 0.1486, lr: 0.001199, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6238 samples/sec | ETA 03:42:48
2023-02-05 04:07:53 [INFO]	[TRAIN] epoch: 2866, iter: 226340/250000, loss: 0.1577, lr: 0.001198, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6291 samples/sec | ETA 03:42:35
2023-02-05 04:07:59 [INFO]	[TRAIN] epoch: 2866, iter: 226350/250000, loss: 0.1665, lr: 0.001198, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6338 samples/sec | ETA 03:42:24
2023-02-05 04:08:05 [INFO]	[TRAIN] epoch: 2866, iter: 226360/250000, loss: 0.1606, lr: 0.001197, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6270 samples/sec | ETA 03:42:27
2023-02-05 04:08:10 [INFO]	[TRAIN] epoch: 2866, iter: 226370/250000, loss: 0.1712, lr: 0.001197, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6286 samples/sec | ETA 03:42:19
2023-02-05 04:08:16 [INFO]	[TRAIN] epoch: 2866, iter: 226380/250000, loss: 0.1496, lr: 0.001196, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6242 samples/sec | ETA 03:42:19
2023-02-05 04:08:22 [INFO]	[TRAIN] epoch: 2866, iter: 226390/250000, loss: 0.1486, lr: 0.001196, batch_cost: 0.6001, reader_cost: 0.03567, ips: 9.9990 samples/sec | ETA 03:56:07
2023-02-05 04:08:27 [INFO]	[TRAIN] epoch: 2866, iter: 226400/250000, loss: 0.1729, lr: 0.001195, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6315 samples/sec | ETA 03:41:58
2023-02-05 04:08:33 [INFO]	[TRAIN] epoch: 2866, iter: 226410/250000, loss: 0.1172, lr: 0.001195, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6239 samples/sec | ETA 03:42:02
2023-02-05 04:08:39 [INFO]	[TRAIN] epoch: 2867, iter: 226420/250000, loss: 0.1636, lr: 0.001194, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6239 samples/sec | ETA 03:41:57
2023-02-05 04:08:44 [INFO]	[TRAIN] epoch: 2867, iter: 226430/250000, loss: 0.1934, lr: 0.001194, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6402 samples/sec | ETA 03:41:31
2023-02-05 04:08:50 [INFO]	[TRAIN] epoch: 2867, iter: 226440/250000, loss: 0.1886, lr: 0.001194, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6246 samples/sec | ETA 03:41:44
2023-02-05 04:08:56 [INFO]	[TRAIN] epoch: 2867, iter: 226450/250000, loss: 0.1410, lr: 0.001193, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6312 samples/sec | ETA 03:41:31
2023-02-05 04:09:01 [INFO]	[TRAIN] epoch: 2867, iter: 226460/250000, loss: 0.1341, lr: 0.001193, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6225 samples/sec | ETA 03:41:36
2023-02-05 04:09:07 [INFO]	[TRAIN] epoch: 2867, iter: 226470/250000, loss: 0.1603, lr: 0.001192, batch_cost: 0.5930, reader_cost: 0.02861, ips: 10.1180 samples/sec | ETA 03:52:33
2023-02-05 04:09:13 [INFO]	[TRAIN] epoch: 2867, iter: 226480/250000, loss: 0.1387, lr: 0.001192, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6263 samples/sec | ETA 03:41:20
2023-02-05 04:09:19 [INFO]	[TRAIN] epoch: 2867, iter: 226490/250000, loss: 0.1561, lr: 0.001191, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6276 samples/sec | ETA 03:41:12
2023-02-05 04:09:24 [INFO]	[TRAIN] epoch: 2868, iter: 226500/250000, loss: 0.1270, lr: 0.001191, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6345 samples/sec | ETA 03:40:58
2023-02-05 04:09:30 [INFO]	[TRAIN] epoch: 2868, iter: 226510/250000, loss: 0.1343, lr: 0.001190, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6271 samples/sec | ETA 03:41:02
2023-02-05 04:09:36 [INFO]	[TRAIN] epoch: 2868, iter: 226520/250000, loss: 0.1336, lr: 0.001190, batch_cost: 0.5650, reader_cost: 0.00008, ips: 10.6190 samples/sec | ETA 03:41:06
2023-02-05 04:09:41 [INFO]	[TRAIN] epoch: 2868, iter: 226530/250000, loss: 0.1526, lr: 0.001189, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6295 samples/sec | ETA 03:40:48
2023-02-05 04:09:47 [INFO]	[TRAIN] epoch: 2868, iter: 226540/250000, loss: 0.1280, lr: 0.001189, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6281 samples/sec | ETA 03:40:44
2023-02-05 04:09:53 [INFO]	[TRAIN] epoch: 2868, iter: 226550/250000, loss: 0.1285, lr: 0.001189, batch_cost: 0.6028, reader_cost: 0.03794, ips: 9.9528 samples/sec | ETA 03:55:36
2023-02-05 04:09:58 [INFO]	[TRAIN] epoch: 2868, iter: 226560/250000, loss: 0.1919, lr: 0.001188, batch_cost: 0.5647, reader_cost: 0.00013, ips: 10.6259 samples/sec | ETA 03:40:35
2023-02-05 04:10:04 [INFO]	[TRAIN] epoch: 2868, iter: 226570/250000, loss: 0.1419, lr: 0.001188, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6298 samples/sec | ETA 03:40:25
2023-02-05 04:10:10 [INFO]	[TRAIN] epoch: 2869, iter: 226580/250000, loss: 0.1509, lr: 0.001187, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6267 samples/sec | ETA 03:40:23
2023-02-05 04:10:15 [INFO]	[TRAIN] epoch: 2869, iter: 226590/250000, loss: 0.1957, lr: 0.001187, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6226 samples/sec | ETA 03:40:22
2023-02-05 04:10:21 [INFO]	[TRAIN] epoch: 2869, iter: 226600/250000, loss: 0.1448, lr: 0.001186, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6279 samples/sec | ETA 03:40:10
2023-02-05 04:10:27 [INFO]	[TRAIN] epoch: 2869, iter: 226610/250000, loss: 0.1429, lr: 0.001186, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6350 samples/sec | ETA 03:39:56
2023-02-05 04:10:32 [INFO]	[TRAIN] epoch: 2869, iter: 226620/250000, loss: 0.1824, lr: 0.001185, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6334 samples/sec | ETA 03:39:52
2023-02-05 04:10:38 [INFO]	[TRAIN] epoch: 2869, iter: 226630/250000, loss: 0.1897, lr: 0.001185, batch_cost: 0.5920, reader_cost: 0.02714, ips: 10.1345 samples/sec | ETA 03:50:35
2023-02-05 04:10:44 [INFO]	[TRAIN] epoch: 2869, iter: 226640/250000, loss: 0.1689, lr: 0.001184, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6314 samples/sec | ETA 03:39:43
2023-02-05 04:10:50 [INFO]	[TRAIN] epoch: 2869, iter: 226650/250000, loss: 0.1805, lr: 0.001184, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6299 samples/sec | ETA 03:39:39
2023-02-05 04:10:55 [INFO]	[TRAIN] epoch: 2870, iter: 226660/250000, loss: 0.1564, lr: 0.001183, batch_cost: 0.5646, reader_cost: 0.00008, ips: 10.6266 samples/sec | ETA 03:39:38
2023-02-05 04:11:01 [INFO]	[TRAIN] epoch: 2870, iter: 226670/250000, loss: 0.1755, lr: 0.001183, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6255 samples/sec | ETA 03:39:33
2023-02-05 04:11:06 [INFO]	[TRAIN] epoch: 2870, iter: 226680/250000, loss: 0.1649, lr: 0.001183, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6289 samples/sec | ETA 03:39:24
2023-02-05 04:11:12 [INFO]	[TRAIN] epoch: 2870, iter: 226690/250000, loss: 0.1961, lr: 0.001182, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6209 samples/sec | ETA 03:39:28
2023-02-05 04:11:18 [INFO]	[TRAIN] epoch: 2870, iter: 226700/250000, loss: 0.1513, lr: 0.001182, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6092 samples/sec | ETA 03:39:37
2023-02-05 04:11:24 [INFO]	[TRAIN] epoch: 2870, iter: 226710/250000, loss: 0.1687, lr: 0.001181, batch_cost: 0.5888, reader_cost: 0.02418, ips: 10.1896 samples/sec | ETA 03:48:33
2023-02-05 04:11:29 [INFO]	[TRAIN] epoch: 2870, iter: 226720/250000, loss: 0.2373, lr: 0.001181, batch_cost: 0.5642, reader_cost: 0.00012, ips: 10.6344 samples/sec | ETA 03:38:54
2023-02-05 04:11:35 [INFO]	[TRAIN] epoch: 2870, iter: 226730/250000, loss: 0.1772, lr: 0.001180, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6323 samples/sec | ETA 03:38:51
2023-02-05 04:11:41 [INFO]	[TRAIN] epoch: 2871, iter: 226740/250000, loss: 0.1518, lr: 0.001180, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6034 samples/sec | ETA 03:39:21
2023-02-05 04:11:46 [INFO]	[TRAIN] epoch: 2871, iter: 226750/250000, loss: 0.1420, lr: 0.001179, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5988 samples/sec | ETA 03:39:21
2023-02-05 04:11:52 [INFO]	[TRAIN] epoch: 2871, iter: 226760/250000, loss: 0.1634, lr: 0.001179, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6022 samples/sec | ETA 03:39:11
2023-02-05 04:11:58 [INFO]	[TRAIN] epoch: 2871, iter: 226770/250000, loss: 0.1655, lr: 0.001178, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6078 samples/sec | ETA 03:38:59
2023-02-05 04:12:03 [INFO]	[TRAIN] epoch: 2871, iter: 226780/250000, loss: 0.1787, lr: 0.001178, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6136 samples/sec | ETA 03:38:46
2023-02-05 04:12:09 [INFO]	[TRAIN] epoch: 2871, iter: 226790/250000, loss: 0.1584, lr: 0.001178, batch_cost: 0.5908, reader_cost: 0.02545, ips: 10.1558 samples/sec | ETA 03:48:32
2023-02-05 04:12:15 [INFO]	[TRAIN] epoch: 2871, iter: 226800/250000, loss: 0.1546, lr: 0.001177, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6210 samples/sec | ETA 03:38:26
2023-02-05 04:12:20 [INFO]	[TRAIN] epoch: 2872, iter: 226810/250000, loss: 0.1539, lr: 0.001177, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6329 samples/sec | ETA 03:38:05
2023-02-05 04:12:26 [INFO]	[TRAIN] epoch: 2872, iter: 226820/250000, loss: 0.1905, lr: 0.001176, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6327 samples/sec | ETA 03:38:00
2023-02-05 04:12:32 [INFO]	[TRAIN] epoch: 2872, iter: 226830/250000, loss: 0.1776, lr: 0.001176, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6371 samples/sec | ETA 03:37:49
2023-02-05 04:12:37 [INFO]	[TRAIN] epoch: 2872, iter: 226840/250000, loss: 0.1390, lr: 0.001175, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6035 samples/sec | ETA 03:38:25
2023-02-05 04:12:43 [INFO]	[TRAIN] epoch: 2872, iter: 226850/250000, loss: 0.1365, lr: 0.001175, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6034 samples/sec | ETA 03:38:19
2023-02-05 04:12:49 [INFO]	[TRAIN] epoch: 2872, iter: 226860/250000, loss: 0.1827, lr: 0.001174, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6112 samples/sec | ETA 03:38:04
2023-02-05 04:12:55 [INFO]	[TRAIN] epoch: 2872, iter: 226870/250000, loss: 0.1705, lr: 0.001174, batch_cost: 0.5931, reader_cost: 0.02906, ips: 10.1161 samples/sec | ETA 03:48:38
2023-02-05 04:13:00 [INFO]	[TRAIN] epoch: 2872, iter: 226880/250000, loss: 0.1714, lr: 0.001173, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6359 samples/sec | ETA 03:37:22
2023-02-05 04:13:06 [INFO]	[TRAIN] epoch: 2873, iter: 226890/250000, loss: 0.1370, lr: 0.001173, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6292 samples/sec | ETA 03:37:25
2023-02-05 04:13:12 [INFO]	[TRAIN] epoch: 2873, iter: 226900/250000, loss: 0.1991, lr: 0.001173, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6298 samples/sec | ETA 03:37:18
2023-02-05 04:13:17 [INFO]	[TRAIN] epoch: 2873, iter: 226910/250000, loss: 0.1784, lr: 0.001172, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6285 samples/sec | ETA 03:37:14
2023-02-05 04:13:23 [INFO]	[TRAIN] epoch: 2873, iter: 226920/250000, loss: 0.1658, lr: 0.001172, batch_cost: 0.5640, reader_cost: 0.00008, ips: 10.6376 samples/sec | ETA 03:36:57
2023-02-05 04:13:29 [INFO]	[TRAIN] epoch: 2873, iter: 226930/250000, loss: 0.1666, lr: 0.001171, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5983 samples/sec | ETA 03:37:40
2023-02-05 04:13:34 [INFO]	[TRAIN] epoch: 2873, iter: 226940/250000, loss: 0.1274, lr: 0.001171, batch_cost: 0.5957, reader_cost: 0.03028, ips: 10.0716 samples/sec | ETA 03:48:57
2023-02-05 04:13:40 [INFO]	[TRAIN] epoch: 2873, iter: 226950/250000, loss: 0.1579, lr: 0.001170, batch_cost: 0.5649, reader_cost: 0.00014, ips: 10.6209 samples/sec | ETA 03:37:01
2023-02-05 04:13:46 [INFO]	[TRAIN] epoch: 2873, iter: 226960/250000, loss: 0.1501, lr: 0.001170, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6225 samples/sec | ETA 03:36:53
2023-02-05 04:13:51 [INFO]	[TRAIN] epoch: 2874, iter: 226970/250000, loss: 0.1327, lr: 0.001169, batch_cost: 0.5646, reader_cost: 0.00008, ips: 10.6272 samples/sec | ETA 03:36:42
2023-02-05 04:13:57 [INFO]	[TRAIN] epoch: 2874, iter: 226980/250000, loss: 0.1605, lr: 0.001169, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6285 samples/sec | ETA 03:36:35
2023-02-05 04:14:03 [INFO]	[TRAIN] epoch: 2874, iter: 226990/250000, loss: 0.1860, lr: 0.001168, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6349 samples/sec | ETA 03:36:21
2023-02-05 04:14:08 [INFO]	[TRAIN] epoch: 2874, iter: 227000/250000, loss: 0.1489, lr: 0.001168, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6007 samples/sec | ETA 03:36:57
2023-02-05 04:14:14 [INFO]	[TRAIN] epoch: 2874, iter: 227010/250000, loss: 0.1548, lr: 0.001167, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6157 samples/sec | ETA 03:36:33
2023-02-05 04:14:20 [INFO]	[TRAIN] epoch: 2874, iter: 227020/250000, loss: 0.1838, lr: 0.001167, batch_cost: 0.5937, reader_cost: 0.02923, ips: 10.1058 samples/sec | ETA 03:47:23
2023-02-05 04:14:26 [INFO]	[TRAIN] epoch: 2874, iter: 227030/250000, loss: 0.1741, lr: 0.001167, batch_cost: 0.5651, reader_cost: 0.00019, ips: 10.6183 samples/sec | ETA 03:36:19
2023-02-05 04:14:31 [INFO]	[TRAIN] epoch: 2874, iter: 227040/250000, loss: 0.1700, lr: 0.001166, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6363 samples/sec | ETA 03:35:51
2023-02-05 04:14:37 [INFO]	[TRAIN] epoch: 2875, iter: 227050/250000, loss: 0.1323, lr: 0.001166, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6364 samples/sec | ETA 03:35:46
2023-02-05 04:14:43 [INFO]	[TRAIN] epoch: 2875, iter: 227060/250000, loss: 0.1902, lr: 0.001165, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6262 samples/sec | ETA 03:35:52
2023-02-05 04:14:48 [INFO]	[TRAIN] epoch: 2875, iter: 227070/250000, loss: 0.2732, lr: 0.001165, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6322 samples/sec | ETA 03:35:39
2023-02-05 04:14:54 [INFO]	[TRAIN] epoch: 2875, iter: 227080/250000, loss: 0.1567, lr: 0.001164, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6347 samples/sec | ETA 03:35:31
2023-02-05 04:14:59 [INFO]	[TRAIN] epoch: 2875, iter: 227090/250000, loss: 0.1205, lr: 0.001164, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6375 samples/sec | ETA 03:35:22
2023-02-05 04:15:05 [INFO]	[TRAIN] epoch: 2875, iter: 227100/250000, loss: 0.1653, lr: 0.001163, batch_cost: 0.5860, reader_cost: 0.02193, ips: 10.2384 samples/sec | ETA 03:43:40
2023-02-05 04:15:11 [INFO]	[TRAIN] epoch: 2875, iter: 227110/250000, loss: 0.1498, lr: 0.001163, batch_cost: 0.5643, reader_cost: 0.00015, ips: 10.6332 samples/sec | ETA 03:35:16
2023-02-05 04:15:17 [INFO]	[TRAIN] epoch: 2875, iter: 227120/250000, loss: 0.1426, lr: 0.001162, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6352 samples/sec | ETA 03:35:08
2023-02-05 04:15:22 [INFO]	[TRAIN] epoch: 2876, iter: 227130/250000, loss: 0.1542, lr: 0.001162, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6318 samples/sec | ETA 03:35:06
2023-02-05 04:15:28 [INFO]	[TRAIN] epoch: 2876, iter: 227140/250000, loss: 0.1444, lr: 0.001162, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6334 samples/sec | ETA 03:34:58
2023-02-05 04:15:34 [INFO]	[TRAIN] epoch: 2876, iter: 227150/250000, loss: 0.1501, lr: 0.001161, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6316 samples/sec | ETA 03:34:55
2023-02-05 04:15:39 [INFO]	[TRAIN] epoch: 2876, iter: 227160/250000, loss: 0.1848, lr: 0.001161, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6282 samples/sec | ETA 03:34:53
2023-02-05 04:15:45 [INFO]	[TRAIN] epoch: 2876, iter: 227170/250000, loss: 0.1643, lr: 0.001160, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6323 samples/sec | ETA 03:34:43
2023-02-05 04:15:51 [INFO]	[TRAIN] epoch: 2876, iter: 227180/250000, loss: 0.1860, lr: 0.001160, batch_cost: 0.5890, reader_cost: 0.02477, ips: 10.1865 samples/sec | ETA 03:44:01
2023-02-05 04:15:56 [INFO]	[TRAIN] epoch: 2876, iter: 227190/250000, loss: 0.1446, lr: 0.001159, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6349 samples/sec | ETA 03:34:28
2023-02-05 04:16:02 [INFO]	[TRAIN] epoch: 2876, iter: 227200/250000, loss: 0.1721, lr: 0.001159, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6312 samples/sec | ETA 03:34:27
2023-02-05 04:16:08 [INFO]	[TRAIN] epoch: 2877, iter: 227210/250000, loss: 0.1346, lr: 0.001158, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6323 samples/sec | ETA 03:34:20
2023-02-05 04:16:13 [INFO]	[TRAIN] epoch: 2877, iter: 227220/250000, loss: 0.1569, lr: 0.001158, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6318 samples/sec | ETA 03:34:15
2023-02-05 04:16:19 [INFO]	[TRAIN] epoch: 2877, iter: 227230/250000, loss: 0.1580, lr: 0.001157, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6377 samples/sec | ETA 03:34:02
2023-02-05 04:16:25 [INFO]	[TRAIN] epoch: 2877, iter: 227240/250000, loss: 0.1913, lr: 0.001157, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6332 samples/sec | ETA 03:34:02
2023-02-05 04:16:30 [INFO]	[TRAIN] epoch: 2877, iter: 227250/250000, loss: 0.1806, lr: 0.001157, batch_cost: 0.5651, reader_cost: 0.00017, ips: 10.6184 samples/sec | ETA 03:34:15
2023-02-05 04:16:36 [INFO]	[TRAIN] epoch: 2877, iter: 227260/250000, loss: 0.2046, lr: 0.001156, batch_cost: 0.5941, reader_cost: 0.02876, ips: 10.0993 samples/sec | ETA 03:45:09
2023-02-05 04:16:42 [INFO]	[TRAIN] epoch: 2877, iter: 227270/250000, loss: 0.1469, lr: 0.001156, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6160 samples/sec | ETA 03:34:06
2023-02-05 04:16:47 [INFO]	[TRAIN] epoch: 2877, iter: 227280/250000, loss: 0.1445, lr: 0.001155, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6126 samples/sec | ETA 03:34:05
2023-02-05 04:16:53 [INFO]	[TRAIN] epoch: 2878, iter: 227290/250000, loss: 0.1348, lr: 0.001155, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6096 samples/sec | ETA 03:34:03
2023-02-05 04:16:59 [INFO]	[TRAIN] epoch: 2878, iter: 227300/250000, loss: 0.1870, lr: 0.001154, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6142 samples/sec | ETA 03:33:51
2023-02-05 04:17:04 [INFO]	[TRAIN] epoch: 2878, iter: 227310/250000, loss: 0.1904, lr: 0.001154, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6071 samples/sec | ETA 03:33:54
2023-02-05 04:17:10 [INFO]	[TRAIN] epoch: 2878, iter: 227320/250000, loss: 0.1479, lr: 0.001153, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6169 samples/sec | ETA 03:33:37
2023-02-05 04:17:16 [INFO]	[TRAIN] epoch: 2878, iter: 227330/250000, loss: 0.1281, lr: 0.001153, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5974 samples/sec | ETA 03:33:55
2023-02-05 04:17:22 [INFO]	[TRAIN] epoch: 2878, iter: 227340/250000, loss: 0.1750, lr: 0.001152, batch_cost: 0.5961, reader_cost: 0.03126, ips: 10.0660 samples/sec | ETA 03:45:06
2023-02-05 04:17:27 [INFO]	[TRAIN] epoch: 2878, iter: 227350/250000, loss: 0.1833, lr: 0.001152, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6269 samples/sec | ETA 03:33:08
2023-02-05 04:17:33 [INFO]	[TRAIN] epoch: 2878, iter: 227360/250000, loss: 0.1442, lr: 0.001151, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6335 samples/sec | ETA 03:32:54
2023-02-05 04:17:39 [INFO]	[TRAIN] epoch: 2879, iter: 227370/250000, loss: 0.1583, lr: 0.001151, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6066 samples/sec | ETA 03:33:21
2023-02-05 04:17:44 [INFO]	[TRAIN] epoch: 2879, iter: 227380/250000, loss: 0.1530, lr: 0.001151, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6088 samples/sec | ETA 03:33:13
2023-02-05 04:17:50 [INFO]	[TRAIN] epoch: 2879, iter: 227390/250000, loss: 0.1297, lr: 0.001150, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6113 samples/sec | ETA 03:33:04
2023-02-05 04:17:56 [INFO]	[TRAIN] epoch: 2879, iter: 227400/250000, loss: 0.2040, lr: 0.001150, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6062 samples/sec | ETA 03:33:05
2023-02-05 04:18:01 [INFO]	[TRAIN] epoch: 2879, iter: 227410/250000, loss: 0.1585, lr: 0.001149, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6047 samples/sec | ETA 03:33:01
2023-02-05 04:18:07 [INFO]	[TRAIN] epoch: 2879, iter: 227420/250000, loss: 0.1408, lr: 0.001149, batch_cost: 0.5968, reader_cost: 0.03190, ips: 10.0533 samples/sec | ETA 03:44:36
2023-02-05 04:18:13 [INFO]	[TRAIN] epoch: 2879, iter: 227430/250000, loss: 0.1499, lr: 0.001148, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6283 samples/sec | ETA 03:32:21
2023-02-05 04:18:19 [INFO]	[TRAIN] epoch: 2879, iter: 227440/250000, loss: 0.1256, lr: 0.001148, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6409 samples/sec | ETA 03:32:00
2023-02-05 04:18:24 [INFO]	[TRAIN] epoch: 2880, iter: 227450/250000, loss: 0.1947, lr: 0.001147, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6325 samples/sec | ETA 03:32:05
2023-02-05 04:18:30 [INFO]	[TRAIN] epoch: 2880, iter: 227460/250000, loss: 0.1708, lr: 0.001147, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6324 samples/sec | ETA 03:31:59
2023-02-05 04:18:35 [INFO]	[TRAIN] epoch: 2880, iter: 227470/250000, loss: 0.1724, lr: 0.001146, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6334 samples/sec | ETA 03:31:52
2023-02-05 04:18:41 [INFO]	[TRAIN] epoch: 2880, iter: 227480/250000, loss: 0.1518, lr: 0.001146, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6283 samples/sec | ETA 03:31:53
2023-02-05 04:18:47 [INFO]	[TRAIN] epoch: 2880, iter: 227490/250000, loss: 0.2149, lr: 0.001146, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6346 samples/sec | ETA 03:31:40
2023-02-05 04:18:53 [INFO]	[TRAIN] epoch: 2880, iter: 227500/250000, loss: 0.1670, lr: 0.001145, batch_cost: 0.6026, reader_cost: 0.03835, ips: 9.9572 samples/sec | ETA 03:45:58
2023-02-05 04:18:58 [INFO]	[TRAIN] epoch: 2880, iter: 227510/250000, loss: 0.1470, lr: 0.001145, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6307 samples/sec | ETA 03:31:33
2023-02-05 04:19:04 [INFO]	[TRAIN] epoch: 2880, iter: 227520/250000, loss: 0.1494, lr: 0.001144, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6323 samples/sec | ETA 03:31:25
2023-02-05 04:19:10 [INFO]	[TRAIN] epoch: 2881, iter: 227530/250000, loss: 0.1543, lr: 0.001144, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6411 samples/sec | ETA 03:31:09
2023-02-05 04:19:15 [INFO]	[TRAIN] epoch: 2881, iter: 227540/250000, loss: 0.1324, lr: 0.001143, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6279 samples/sec | ETA 03:31:19
2023-02-05 04:19:21 [INFO]	[TRAIN] epoch: 2881, iter: 227550/250000, loss: 0.1589, lr: 0.001143, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6294 samples/sec | ETA 03:31:12
2023-02-05 04:19:27 [INFO]	[TRAIN] epoch: 2881, iter: 227560/250000, loss: 0.1867, lr: 0.001142, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6263 samples/sec | ETA 03:31:10
2023-02-05 04:19:32 [INFO]	[TRAIN] epoch: 2881, iter: 227570/250000, loss: 0.1492, lr: 0.001142, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6334 samples/sec | ETA 03:30:56
2023-02-05 04:19:38 [INFO]	[TRAIN] epoch: 2881, iter: 227580/250000, loss: 0.1382, lr: 0.001141, batch_cost: 0.5879, reader_cost: 0.02361, ips: 10.2063 samples/sec | ETA 03:39:40
2023-02-05 04:19:44 [INFO]	[TRAIN] epoch: 2881, iter: 227590/250000, loss: 0.1490, lr: 0.001141, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6346 samples/sec | ETA 03:30:43
2023-02-05 04:19:49 [INFO]	[TRAIN] epoch: 2882, iter: 227600/250000, loss: 0.1430, lr: 0.001140, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6136 samples/sec | ETA 03:31:03
2023-02-05 04:19:55 [INFO]	[TRAIN] epoch: 2882, iter: 227610/250000, loss: 0.1443, lr: 0.001140, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6064 samples/sec | ETA 03:31:05
2023-02-05 04:20:01 [INFO]	[TRAIN] epoch: 2882, iter: 227620/250000, loss: 0.1576, lr: 0.001140, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6060 samples/sec | ETA 03:31:00
2023-02-05 04:20:06 [INFO]	[TRAIN] epoch: 2882, iter: 227630/250000, loss: 0.1387, lr: 0.001139, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6107 samples/sec | ETA 03:30:49
2023-02-05 04:20:12 [INFO]	[TRAIN] epoch: 2882, iter: 227640/250000, loss: 0.1450, lr: 0.001139, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6073 samples/sec | ETA 03:30:47
2023-02-05 04:20:18 [INFO]	[TRAIN] epoch: 2882, iter: 227650/250000, loss: 0.1539, lr: 0.001138, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6128 samples/sec | ETA 03:30:35
2023-02-05 04:20:24 [INFO]	[TRAIN] epoch: 2882, iter: 227660/250000, loss: 0.1241, lr: 0.001138, batch_cost: 0.5941, reader_cost: 0.02931, ips: 10.0996 samples/sec | ETA 03:41:11
2023-02-05 04:20:29 [INFO]	[TRAIN] epoch: 2882, iter: 227670/250000, loss: 0.1494, lr: 0.001137, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6343 samples/sec | ETA 03:29:58
2023-02-05 04:20:35 [INFO]	[TRAIN] epoch: 2883, iter: 227680/250000, loss: 0.1348, lr: 0.001137, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6080 samples/sec | ETA 03:30:24
2023-02-05 04:20:41 [INFO]	[TRAIN] epoch: 2883, iter: 227690/250000, loss: 0.1688, lr: 0.001136, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6080 samples/sec | ETA 03:30:18
2023-02-05 04:20:46 [INFO]	[TRAIN] epoch: 2883, iter: 227700/250000, loss: 0.1923, lr: 0.001136, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6163 samples/sec | ETA 03:30:03
2023-02-05 04:20:52 [INFO]	[TRAIN] epoch: 2883, iter: 227710/250000, loss: 0.1885, lr: 0.001135, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6014 samples/sec | ETA 03:30:15
2023-02-05 04:20:58 [INFO]	[TRAIN] epoch: 2883, iter: 227720/250000, loss: 0.1568, lr: 0.001135, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6017 samples/sec | ETA 03:30:09
2023-02-05 04:21:03 [INFO]	[TRAIN] epoch: 2883, iter: 227730/250000, loss: 0.1516, lr: 0.001135, batch_cost: 0.5867, reader_cost: 0.02193, ips: 10.2271 samples/sec | ETA 03:37:45
2023-02-05 04:21:09 [INFO]	[TRAIN] epoch: 2883, iter: 227740/250000, loss: 0.1508, lr: 0.001134, batch_cost: 0.5653, reader_cost: 0.00012, ips: 10.6139 samples/sec | ETA 03:29:43
2023-02-05 04:21:15 [INFO]	[TRAIN] epoch: 2883, iter: 227750/250000, loss: 0.1640, lr: 0.001134, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6058 samples/sec | ETA 03:29:47
2023-02-05 04:21:20 [INFO]	[TRAIN] epoch: 2884, iter: 227760/250000, loss: 0.1337, lr: 0.001133, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6097 samples/sec | ETA 03:29:37
2023-02-05 04:21:26 [INFO]	[TRAIN] epoch: 2884, iter: 227770/250000, loss: 0.1461, lr: 0.001133, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6147 samples/sec | ETA 03:29:25
2023-02-05 04:21:32 [INFO]	[TRAIN] epoch: 2884, iter: 227780/250000, loss: 0.1526, lr: 0.001132, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5943 samples/sec | ETA 03:29:44
2023-02-05 04:21:37 [INFO]	[TRAIN] epoch: 2884, iter: 227790/250000, loss: 0.1502, lr: 0.001132, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6042 samples/sec | ETA 03:29:26
2023-02-05 04:21:43 [INFO]	[TRAIN] epoch: 2884, iter: 227800/250000, loss: 0.1358, lr: 0.001131, batch_cost: 0.5652, reader_cost: 0.00008, ips: 10.6154 samples/sec | ETA 03:29:07
2023-02-05 04:21:49 [INFO]	[TRAIN] epoch: 2884, iter: 227810/250000, loss: 0.1420, lr: 0.001131, batch_cost: 0.5930, reader_cost: 0.02796, ips: 10.1174 samples/sec | ETA 03:39:19
2023-02-05 04:21:55 [INFO]	[TRAIN] epoch: 2884, iter: 227820/250000, loss: 0.1312, lr: 0.001130, batch_cost: 0.5643, reader_cost: 0.00014, ips: 10.6335 samples/sec | ETA 03:28:35
2023-02-05 04:22:00 [INFO]	[TRAIN] epoch: 2884, iter: 227830/250000, loss: 0.1574, lr: 0.001130, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6221 samples/sec | ETA 03:28:42
2023-02-05 04:22:06 [INFO]	[TRAIN] epoch: 2885, iter: 227840/250000, loss: 0.1675, lr: 0.001129, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6283 samples/sec | ETA 03:28:30
2023-02-05 04:22:12 [INFO]	[TRAIN] epoch: 2885, iter: 227850/250000, loss: 0.1427, lr: 0.001129, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5986 samples/sec | ETA 03:28:59
2023-02-05 04:22:17 [INFO]	[TRAIN] epoch: 2885, iter: 227860/250000, loss: 0.1518, lr: 0.001129, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6151 samples/sec | ETA 03:28:34
2023-02-05 04:22:23 [INFO]	[TRAIN] epoch: 2885, iter: 227870/250000, loss: 0.1470, lr: 0.001128, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6116 samples/sec | ETA 03:28:32
2023-02-05 04:22:29 [INFO]	[TRAIN] epoch: 2885, iter: 227880/250000, loss: 0.1451, lr: 0.001128, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6040 samples/sec | ETA 03:28:36
2023-02-05 04:22:35 [INFO]	[TRAIN] epoch: 2885, iter: 227890/250000, loss: 0.2025, lr: 0.001127, batch_cost: 0.5915, reader_cost: 0.02609, ips: 10.1433 samples/sec | ETA 03:37:58
2023-02-05 04:22:40 [INFO]	[TRAIN] epoch: 2885, iter: 227900/250000, loss: 0.1584, lr: 0.001127, batch_cost: 0.5654, reader_cost: 0.00013, ips: 10.6112 samples/sec | ETA 03:28:16
2023-02-05 04:22:46 [INFO]	[TRAIN] epoch: 2885, iter: 227910/250000, loss: 0.1552, lr: 0.001126, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6176 samples/sec | ETA 03:28:03
2023-02-05 04:22:51 [INFO]	[TRAIN] epoch: 2886, iter: 227920/250000, loss: 0.1762, lr: 0.001126, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6065 samples/sec | ETA 03:28:10
2023-02-05 04:22:57 [INFO]	[TRAIN] epoch: 2886, iter: 227930/250000, loss: 0.1205, lr: 0.001125, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5951 samples/sec | ETA 03:28:18
2023-02-05 04:23:03 [INFO]	[TRAIN] epoch: 2886, iter: 227940/250000, loss: 0.1465, lr: 0.001125, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6069 samples/sec | ETA 03:27:58
2023-02-05 04:23:08 [INFO]	[TRAIN] epoch: 2886, iter: 227950/250000, loss: 0.1997, lr: 0.001124, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6183 samples/sec | ETA 03:27:39
2023-02-05 04:23:14 [INFO]	[TRAIN] epoch: 2886, iter: 227960/250000, loss: 0.1751, lr: 0.001124, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6015 samples/sec | ETA 03:27:53
2023-02-05 04:23:20 [INFO]	[TRAIN] epoch: 2886, iter: 227970/250000, loss: 0.2080, lr: 0.001124, batch_cost: 0.5925, reader_cost: 0.02723, ips: 10.1266 samples/sec | ETA 03:37:32
2023-02-05 04:23:26 [INFO]	[TRAIN] epoch: 2886, iter: 227980/250000, loss: 0.1842, lr: 0.001123, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6281 samples/sec | ETA 03:27:11
2023-02-05 04:23:31 [INFO]	[TRAIN] epoch: 2886, iter: 227990/250000, loss: 0.1748, lr: 0.001123, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6240 samples/sec | ETA 03:27:10
2023-02-05 04:23:37 [INFO]	[TRAIN] epoch: 2887, iter: 228000/250000, loss: 0.2079, lr: 0.001122, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6351 samples/sec | ETA 03:26:51
2023-02-05 04:23:37 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1233 - reader cost: 0.0225 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1487 - reader cost: 0.0113 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1556 - reader cost: 0.0075 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1569 - reader cost: 0.0057 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1583 - reader cost: 0.0046 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1615 - reader cost: 0.0038 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1613 - reader cost: 0.0033 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1612 - reader cost: 0.0029 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1620 - reader cost: 0.002610/36 [=======>......................] - ETA: 4s - batch_cost: 0.1618 - reader cost: 0.002311/36 [========>.....................] - ETA: 4s - batch_cost: 0.1624 - reader cost: 0.002112/36 [=========>....................] - ETA: 3s - batch_cost: 0.1620 - reader cost: 0.001913/36 [=========>....................] - ETA: 3s - batch_cost: 0.1622 - reader cost: 0.001814/36 [==========>...................] - ETA: 3s - batch_cost: 0.1627 - reader cost: 0.001715/36 [===========>..................] - ETA: 3s - batch_cost: 0.1626 - reader cost: 0.001616/36 [============>.................] - ETA: 3s - batch_cost: 0.1631 - reader cost: 0.001517/36 [=============>................] - ETA: 3s - batch_cost: 0.1633 - reader cost: 0.001418/36 [==============>...............] - ETA: 2s - batch_cost: 0.1634 - reader cost: 0.001319/36 [==============>...............] - ETA: 2s - batch_cost: 0.1631 - reader cost: 0.001320/36 [===============>..............] - ETA: 2s - batch_cost: 0.1632 - reader cost: 0.001221/36 [================>.............] - ETA: 2s - batch_cost: 0.1633 - reader cost: 0.001122/36 [=================>............] - ETA: 2s - batch_cost: 0.1635 - reader cost: 0.001123/36 [==================>...........] - ETA: 2s - batch_cost: 0.1641 - reader cost: 0.001024/36 [===================>..........] - ETA: 1s - batch_cost: 0.1641 - reader cost: 0.001025/36 [===================>..........] - ETA: 1s - batch_cost: 0.1642 - reader cost: 9.7169e-0426/36 [====================>.........] - ETA: 1s - batch_cost: 0.1644 - reader cost: 9.3704e-0427/36 [=====================>........] - ETA: 1s - batch_cost: 0.1646 - reader cost: 9.0639e-0428/36 [======================>.......] - ETA: 1s - batch_cost: 0.1649 - reader cost: 8.7655e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1651 - reader cost: 8.4883e-0430/36 [========================>.....] - ETA: 0s - batch_cost: 0.1650 - reader cost: 8.2333e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1649 - reader cost: 7.9902e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1649 - reader cost: 7.7662e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1647 - reader cost: 7.5503e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1645 - reader cost: 7.3460e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1645 - reader cost: 7.1538e-0436/36 [==============================] - 6s 165ms/step - batch_cost: 0.1647 - reader cost: 6.9754e-04
2023-02-05 04:23:43 [INFO]	[EVAL] #Images: 36 mIoU: 0.8680 Acc: 0.9867 Kappa: 0.9520 Dice: 0.9260
2023-02-05 04:23:43 [INFO]	[EVAL] Class IoU: 
[0.986  0.9235 0.9006 0.7215 0.7169 0.9718 0.8556]
2023-02-05 04:23:43 [INFO]	[EVAL] Class Precision: 
[0.994  0.9611 0.9425 0.8235 0.8219 0.9814 0.9006]
2023-02-05 04:23:43 [INFO]	[EVAL] Class Recall: 
[0.9919 0.9593 0.9529 0.8535 0.8488 0.99   0.9448]
2023-02-05 04:23:43 [INFO]	[EVAL] The model with the best validation mIoU (0.8682) was saved at iter 222000.
2023-02-05 04:23:49 [INFO]	[TRAIN] epoch: 2887, iter: 228010/250000, loss: 0.1488, lr: 0.001122, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6297 samples/sec | ETA 03:26:52
2023-02-05 04:23:54 [INFO]	[TRAIN] epoch: 2887, iter: 228020/250000, loss: 0.2008, lr: 0.001121, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6302 samples/sec | ETA 03:26:46
2023-02-05 04:24:00 [INFO]	[TRAIN] epoch: 2887, iter: 228030/250000, loss: 0.1640, lr: 0.001121, batch_cost: 0.5642, reader_cost: 0.00008, ips: 10.6354 samples/sec | ETA 03:26:34
2023-02-05 04:24:06 [INFO]	[TRAIN] epoch: 2887, iter: 228040/250000, loss: 0.1743, lr: 0.001120, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6330 samples/sec | ETA 03:26:31
2023-02-05 04:24:12 [INFO]	[TRAIN] epoch: 2887, iter: 228050/250000, loss: 0.1666, lr: 0.001120, batch_cost: 0.5937, reader_cost: 0.02940, ips: 10.1069 samples/sec | ETA 03:37:10
2023-02-05 04:24:17 [INFO]	[TRAIN] epoch: 2887, iter: 228060/250000, loss: 0.1966, lr: 0.001119, batch_cost: 0.5640, reader_cost: 0.00014, ips: 10.6383 samples/sec | ETA 03:26:14
2023-02-05 04:24:23 [INFO]	[TRAIN] epoch: 2887, iter: 228070/250000, loss: 0.1773, lr: 0.001119, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6376 samples/sec | ETA 03:26:09
2023-02-05 04:24:29 [INFO]	[TRAIN] epoch: 2888, iter: 228080/250000, loss: 0.1345, lr: 0.001118, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6386 samples/sec | ETA 03:26:02
2023-02-05 04:24:34 [INFO]	[TRAIN] epoch: 2888, iter: 228090/250000, loss: 0.1561, lr: 0.001118, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6328 samples/sec | ETA 03:26:03
2023-02-05 04:24:40 [INFO]	[TRAIN] epoch: 2888, iter: 228100/250000, loss: 0.1772, lr: 0.001118, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6318 samples/sec | ETA 03:25:59
2023-02-05 04:24:46 [INFO]	[TRAIN] epoch: 2888, iter: 228110/250000, loss: 0.1637, lr: 0.001117, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6296 samples/sec | ETA 03:25:56
2023-02-05 04:24:51 [INFO]	[TRAIN] epoch: 2888, iter: 228120/250000, loss: 0.2368, lr: 0.001117, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6258 samples/sec | ETA 03:25:54
2023-02-05 04:24:57 [INFO]	[TRAIN] epoch: 2888, iter: 228130/250000, loss: 0.1509, lr: 0.001116, batch_cost: 0.5876, reader_cost: 0.02247, ips: 10.2110 samples/sec | ETA 03:34:10
2023-02-05 04:25:03 [INFO]	[TRAIN] epoch: 2888, iter: 228140/250000, loss: 0.1587, lr: 0.001116, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6366 samples/sec | ETA 03:25:31
2023-02-05 04:25:08 [INFO]	[TRAIN] epoch: 2888, iter: 228150/250000, loss: 0.2009, lr: 0.001115, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6325 samples/sec | ETA 03:25:30
2023-02-05 04:25:14 [INFO]	[TRAIN] epoch: 2889, iter: 228160/250000, loss: 0.1883, lr: 0.001115, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6307 samples/sec | ETA 03:25:26
2023-02-05 04:25:20 [INFO]	[TRAIN] epoch: 2889, iter: 228170/250000, loss: 0.1400, lr: 0.001114, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6394 samples/sec | ETA 03:25:10
2023-02-05 04:25:25 [INFO]	[TRAIN] epoch: 2889, iter: 228180/250000, loss: 0.1295, lr: 0.001114, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6345 samples/sec | ETA 03:25:10
2023-02-05 04:25:31 [INFO]	[TRAIN] epoch: 2889, iter: 228190/250000, loss: 0.1518, lr: 0.001113, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6396 samples/sec | ETA 03:24:59
2023-02-05 04:25:37 [INFO]	[TRAIN] epoch: 2889, iter: 228200/250000, loss: 0.1564, lr: 0.001113, batch_cost: 0.5646, reader_cost: 0.00008, ips: 10.6261 samples/sec | ETA 03:25:09
2023-02-05 04:25:42 [INFO]	[TRAIN] epoch: 2889, iter: 228210/250000, loss: 0.1507, lr: 0.001113, batch_cost: 0.5944, reader_cost: 0.02816, ips: 10.0941 samples/sec | ETA 03:35:52
2023-02-05 04:25:48 [INFO]	[TRAIN] epoch: 2889, iter: 228220/250000, loss: 0.1601, lr: 0.001112, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6354 samples/sec | ETA 03:24:47
2023-02-05 04:25:54 [INFO]	[TRAIN] epoch: 2889, iter: 228230/250000, loss: 0.1540, lr: 0.001112, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6365 samples/sec | ETA 03:24:40
2023-02-05 04:25:59 [INFO]	[TRAIN] epoch: 2890, iter: 228240/250000, loss: 0.1660, lr: 0.001111, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6393 samples/sec | ETA 03:24:31
2023-02-05 04:26:05 [INFO]	[TRAIN] epoch: 2890, iter: 228250/250000, loss: 0.1516, lr: 0.001111, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6387 samples/sec | ETA 03:24:26
2023-02-05 04:26:11 [INFO]	[TRAIN] epoch: 2890, iter: 228260/250000, loss: 0.1423, lr: 0.001110, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6370 samples/sec | ETA 03:24:22
2023-02-05 04:26:16 [INFO]	[TRAIN] epoch: 2890, iter: 228270/250000, loss: 0.1630, lr: 0.001110, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6050 samples/sec | ETA 03:24:54
2023-02-05 04:26:22 [INFO]	[TRAIN] epoch: 2890, iter: 228280/250000, loss: 0.1469, lr: 0.001109, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6062 samples/sec | ETA 03:24:47
2023-02-05 04:26:28 [INFO]	[TRAIN] epoch: 2890, iter: 228290/250000, loss: 0.1313, lr: 0.001109, batch_cost: 0.6000, reader_cost: 0.03499, ips: 10.0000 samples/sec | ETA 03:37:06
2023-02-05 04:26:34 [INFO]	[TRAIN] epoch: 2890, iter: 228300/250000, loss: 0.1760, lr: 0.001108, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6354 samples/sec | ETA 03:24:02
2023-02-05 04:26:39 [INFO]	[TRAIN] epoch: 2890, iter: 228310/250000, loss: 0.1404, lr: 0.001108, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6221 samples/sec | ETA 03:24:11
2023-02-05 04:26:45 [INFO]	[TRAIN] epoch: 2891, iter: 228320/250000, loss: 0.1584, lr: 0.001107, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6056 samples/sec | ETA 03:24:25
2023-02-05 04:26:51 [INFO]	[TRAIN] epoch: 2891, iter: 228330/250000, loss: 0.1626, lr: 0.001107, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6005 samples/sec | ETA 03:24:25
2023-02-05 04:26:56 [INFO]	[TRAIN] epoch: 2891, iter: 228340/250000, loss: 0.1517, lr: 0.001107, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6075 samples/sec | ETA 03:24:11
2023-02-05 04:27:02 [INFO]	[TRAIN] epoch: 2891, iter: 228350/250000, loss: 0.1785, lr: 0.001106, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6135 samples/sec | ETA 03:23:59
2023-02-05 04:27:08 [INFO]	[TRAIN] epoch: 2891, iter: 228360/250000, loss: 0.1435, lr: 0.001106, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6056 samples/sec | ETA 03:24:02
2023-02-05 04:27:14 [INFO]	[TRAIN] epoch: 2891, iter: 228370/250000, loss: 0.1437, lr: 0.001105, batch_cost: 0.6019, reader_cost: 0.03648, ips: 9.9688 samples/sec | ETA 03:36:58
2023-02-05 04:27:19 [INFO]	[TRAIN] epoch: 2891, iter: 228380/250000, loss: 0.1638, lr: 0.001105, batch_cost: 0.5636, reader_cost: 0.00009, ips: 10.6454 samples/sec | ETA 03:23:05
2023-02-05 04:27:25 [INFO]	[TRAIN] epoch: 2892, iter: 228390/250000, loss: 0.1274, lr: 0.001104, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6373 samples/sec | ETA 03:23:09
2023-02-05 04:27:31 [INFO]	[TRAIN] epoch: 2892, iter: 228400/250000, loss: 0.1427, lr: 0.001104, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6326 samples/sec | ETA 03:23:08
2023-02-05 04:27:36 [INFO]	[TRAIN] epoch: 2892, iter: 228410/250000, loss: 0.1640, lr: 0.001103, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6192 samples/sec | ETA 03:23:18
2023-02-05 04:27:42 [INFO]	[TRAIN] epoch: 2892, iter: 228420/250000, loss: 0.1374, lr: 0.001103, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6333 samples/sec | ETA 03:22:56
2023-02-05 04:27:47 [INFO]	[TRAIN] epoch: 2892, iter: 228430/250000, loss: 0.1560, lr: 0.001102, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6374 samples/sec | ETA 03:22:46
2023-02-05 04:27:53 [INFO]	[TRAIN] epoch: 2892, iter: 228440/250000, loss: 0.1475, lr: 0.001102, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6285 samples/sec | ETA 03:22:51
2023-02-05 04:27:59 [INFO]	[TRAIN] epoch: 2892, iter: 228450/250000, loss: 0.1405, lr: 0.001101, batch_cost: 0.5929, reader_cost: 0.02854, ips: 10.1206 samples/sec | ETA 03:32:55
2023-02-05 04:28:05 [INFO]	[TRAIN] epoch: 2892, iter: 228460/250000, loss: 0.1587, lr: 0.001101, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6361 samples/sec | ETA 03:22:31
2023-02-05 04:28:10 [INFO]	[TRAIN] epoch: 2893, iter: 228470/250000, loss: 0.1330, lr: 0.001101, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6313 samples/sec | ETA 03:22:30
2023-02-05 04:28:16 [INFO]	[TRAIN] epoch: 2893, iter: 228480/250000, loss: 0.2279, lr: 0.001100, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6290 samples/sec | ETA 03:22:27
2023-02-05 04:28:22 [INFO]	[TRAIN] epoch: 2893, iter: 228490/250000, loss: 0.1731, lr: 0.001100, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6321 samples/sec | ETA 03:22:18
2023-02-05 04:28:27 [INFO]	[TRAIN] epoch: 2893, iter: 228500/250000, loss: 0.2163, lr: 0.001099, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6338 samples/sec | ETA 03:22:11
2023-02-05 04:28:33 [INFO]	[TRAIN] epoch: 2893, iter: 228510/250000, loss: 0.2831, lr: 0.001099, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6361 samples/sec | ETA 03:22:02
2023-02-05 04:28:39 [INFO]	[TRAIN] epoch: 2893, iter: 228520/250000, loss: 0.2044, lr: 0.001098, batch_cost: 0.5853, reader_cost: 0.02141, ips: 10.2504 samples/sec | ETA 03:29:33
2023-02-05 04:28:44 [INFO]	[TRAIN] epoch: 2893, iter: 228530/250000, loss: 0.1594, lr: 0.001098, batch_cost: 0.5656, reader_cost: 0.00059, ips: 10.6089 samples/sec | ETA 03:22:22
2023-02-05 04:28:50 [INFO]	[TRAIN] epoch: 2893, iter: 228540/250000, loss: 0.1358, lr: 0.001097, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6033 samples/sec | ETA 03:22:23
2023-02-05 04:28:56 [INFO]	[TRAIN] epoch: 2894, iter: 228550/250000, loss: 0.1276, lr: 0.001097, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6145 samples/sec | ETA 03:22:04
2023-02-05 04:29:01 [INFO]	[TRAIN] epoch: 2894, iter: 228560/250000, loss: 0.1789, lr: 0.001096, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6139 samples/sec | ETA 03:21:59
2023-02-05 04:29:07 [INFO]	[TRAIN] epoch: 2894, iter: 228570/250000, loss: 0.1641, lr: 0.001096, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6048 samples/sec | ETA 03:22:04
2023-02-05 04:29:13 [INFO]	[TRAIN] epoch: 2894, iter: 228580/250000, loss: 0.1488, lr: 0.001095, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6137 samples/sec | ETA 03:21:48
2023-02-05 04:29:18 [INFO]	[TRAIN] epoch: 2894, iter: 228590/250000, loss: 0.2067, lr: 0.001095, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6122 samples/sec | ETA 03:21:44
2023-02-05 04:29:24 [INFO]	[TRAIN] epoch: 2894, iter: 228600/250000, loss: 0.1919, lr: 0.001095, batch_cost: 0.5964, reader_cost: 0.03063, ips: 10.0610 samples/sec | ETA 03:32:42
2023-02-05 04:29:30 [INFO]	[TRAIN] epoch: 2894, iter: 228610/250000, loss: 0.1404, lr: 0.001094, batch_cost: 0.5647, reader_cost: 0.00016, ips: 10.6248 samples/sec | ETA 03:21:19
2023-02-05 04:29:36 [INFO]	[TRAIN] epoch: 2894, iter: 228620/250000, loss: 0.1298, lr: 0.001094, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6271 samples/sec | ETA 03:21:11
2023-02-05 04:29:41 [INFO]	[TRAIN] epoch: 2895, iter: 228630/250000, loss: 0.1957, lr: 0.001093, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6336 samples/sec | ETA 03:20:57
2023-02-05 04:29:47 [INFO]	[TRAIN] epoch: 2895, iter: 228640/250000, loss: 0.1834, lr: 0.001093, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6360 samples/sec | ETA 03:20:49
2023-02-05 04:29:53 [INFO]	[TRAIN] epoch: 2895, iter: 228650/250000, loss: 0.1839, lr: 0.001092, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6210 samples/sec | ETA 03:21:00
2023-02-05 04:29:58 [INFO]	[TRAIN] epoch: 2895, iter: 228660/250000, loss: 0.1813, lr: 0.001092, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6242 samples/sec | ETA 03:20:51
2023-02-05 04:30:04 [INFO]	[TRAIN] epoch: 2895, iter: 228670/250000, loss: 0.1493, lr: 0.001091, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6207 samples/sec | ETA 03:20:50
2023-02-05 04:30:10 [INFO]	[TRAIN] epoch: 2895, iter: 228680/250000, loss: 0.1786, lr: 0.001091, batch_cost: 0.5973, reader_cost: 0.03302, ips: 10.0446 samples/sec | ETA 03:32:15
2023-02-05 04:30:15 [INFO]	[TRAIN] epoch: 2895, iter: 228690/250000, loss: 0.1605, lr: 0.001090, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6283 samples/sec | ETA 03:20:30
2023-02-05 04:30:21 [INFO]	[TRAIN] epoch: 2895, iter: 228700/250000, loss: 0.1935, lr: 0.001090, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6000 samples/sec | ETA 03:20:56
2023-02-05 04:30:27 [INFO]	[TRAIN] epoch: 2896, iter: 228710/250000, loss: 0.1265, lr: 0.001090, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6108 samples/sec | ETA 03:20:38
2023-02-05 04:30:32 [INFO]	[TRAIN] epoch: 2896, iter: 228720/250000, loss: 0.1484, lr: 0.001089, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6070 samples/sec | ETA 03:20:37
2023-02-05 04:30:38 [INFO]	[TRAIN] epoch: 2896, iter: 228730/250000, loss: 0.1434, lr: 0.001089, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6066 samples/sec | ETA 03:20:32
2023-02-05 04:30:44 [INFO]	[TRAIN] epoch: 2896, iter: 228740/250000, loss: 0.1431, lr: 0.001088, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6066 samples/sec | ETA 03:20:26
2023-02-05 04:30:49 [INFO]	[TRAIN] epoch: 2896, iter: 228750/250000, loss: 0.1777, lr: 0.001088, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6115 samples/sec | ETA 03:20:15
2023-02-05 04:30:55 [INFO]	[TRAIN] epoch: 2896, iter: 228760/250000, loss: 0.2104, lr: 0.001087, batch_cost: 0.5888, reader_cost: 0.02319, ips: 10.1895 samples/sec | ETA 03:28:27
2023-02-05 04:31:01 [INFO]	[TRAIN] epoch: 2896, iter: 228770/250000, loss: 0.1979, lr: 0.001087, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6206 samples/sec | ETA 03:19:53
2023-02-05 04:31:07 [INFO]	[TRAIN] epoch: 2896, iter: 228780/250000, loss: 0.1404, lr: 0.001086, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6358 samples/sec | ETA 03:19:30
2023-02-05 04:31:12 [INFO]	[TRAIN] epoch: 2897, iter: 228790/250000, loss: 0.1561, lr: 0.001086, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6088 samples/sec | ETA 03:19:55
2023-02-05 04:31:18 [INFO]	[TRAIN] epoch: 2897, iter: 228800/250000, loss: 0.1603, lr: 0.001085, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6047 samples/sec | ETA 03:19:54
2023-02-05 04:31:24 [INFO]	[TRAIN] epoch: 2897, iter: 228810/250000, loss: 0.1357, lr: 0.001085, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6138 samples/sec | ETA 03:19:38
2023-02-05 04:31:29 [INFO]	[TRAIN] epoch: 2897, iter: 228820/250000, loss: 0.1455, lr: 0.001084, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6115 samples/sec | ETA 03:19:35
2023-02-05 04:31:35 [INFO]	[TRAIN] epoch: 2897, iter: 228830/250000, loss: 0.1693, lr: 0.001084, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5973 samples/sec | ETA 03:19:46
2023-02-05 04:31:41 [INFO]	[TRAIN] epoch: 2897, iter: 228840/250000, loss: 0.1372, lr: 0.001084, batch_cost: 0.5974, reader_cost: 0.03164, ips: 10.0437 samples/sec | ETA 03:30:40
2023-02-05 04:31:46 [INFO]	[TRAIN] epoch: 2897, iter: 228850/250000, loss: 0.1374, lr: 0.001083, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6145 samples/sec | ETA 03:19:15
2023-02-05 04:31:52 [INFO]	[TRAIN] epoch: 2897, iter: 228860/250000, loss: 0.1743, lr: 0.001083, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6135 samples/sec | ETA 03:19:10
2023-02-05 04:31:58 [INFO]	[TRAIN] epoch: 2898, iter: 228870/250000, loss: 0.1740, lr: 0.001082, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6059 samples/sec | ETA 03:19:13
2023-02-05 04:32:03 [INFO]	[TRAIN] epoch: 2898, iter: 228880/250000, loss: 0.1867, lr: 0.001082, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.5999 samples/sec | ETA 03:19:14
2023-02-05 04:32:09 [INFO]	[TRAIN] epoch: 2898, iter: 228890/250000, loss: 0.1546, lr: 0.001081, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6135 samples/sec | ETA 03:18:53
2023-02-05 04:32:15 [INFO]	[TRAIN] epoch: 2898, iter: 228900/250000, loss: 0.1513, lr: 0.001081, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6141 samples/sec | ETA 03:18:47
2023-02-05 04:32:20 [INFO]	[TRAIN] epoch: 2898, iter: 228910/250000, loss: 0.1452, lr: 0.001080, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6020 samples/sec | ETA 03:18:55
2023-02-05 04:32:26 [INFO]	[TRAIN] epoch: 2898, iter: 228920/250000, loss: 0.1663, lr: 0.001080, batch_cost: 0.5927, reader_cost: 0.02770, ips: 10.1228 samples/sec | ETA 03:28:14
2023-02-05 04:32:32 [INFO]	[TRAIN] epoch: 2898, iter: 228930/250000, loss: 0.1440, lr: 0.001079, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6264 samples/sec | ETA 03:18:16
2023-02-05 04:32:38 [INFO]	[TRAIN] epoch: 2898, iter: 228940/250000, loss: 0.1663, lr: 0.001079, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6292 samples/sec | ETA 03:18:08
2023-02-05 04:32:43 [INFO]	[TRAIN] epoch: 2899, iter: 228950/250000, loss: 0.1452, lr: 0.001078, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6356 samples/sec | ETA 03:17:55
2023-02-05 04:32:49 [INFO]	[TRAIN] epoch: 2899, iter: 228960/250000, loss: 0.1722, lr: 0.001078, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6119 samples/sec | ETA 03:18:16
2023-02-05 04:32:55 [INFO]	[TRAIN] epoch: 2899, iter: 228970/250000, loss: 0.1875, lr: 0.001078, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6010 samples/sec | ETA 03:18:22
2023-02-05 04:33:00 [INFO]	[TRAIN] epoch: 2899, iter: 228980/250000, loss: 0.1386, lr: 0.001077, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6125 samples/sec | ETA 03:18:04
2023-02-05 04:33:06 [INFO]	[TRAIN] epoch: 2899, iter: 228990/250000, loss: 0.1666, lr: 0.001077, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6036 samples/sec | ETA 03:18:08
2023-02-05 04:33:12 [INFO]	[TRAIN] epoch: 2899, iter: 229000/250000, loss: 0.1830, lr: 0.001076, batch_cost: 0.5911, reader_cost: 0.02613, ips: 10.1505 samples/sec | ETA 03:26:53
2023-02-05 04:33:17 [INFO]	[TRAIN] epoch: 2899, iter: 229010/250000, loss: 0.1420, lr: 0.001076, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6298 samples/sec | ETA 03:17:27
2023-02-05 04:33:23 [INFO]	[TRAIN] epoch: 2899, iter: 229020/250000, loss: 0.1868, lr: 0.001075, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6066 samples/sec | ETA 03:17:48
2023-02-05 04:33:29 [INFO]	[TRAIN] epoch: 2900, iter: 229030/250000, loss: 0.1466, lr: 0.001075, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5969 samples/sec | ETA 03:17:53
2023-02-05 04:33:34 [INFO]	[TRAIN] epoch: 2900, iter: 229040/250000, loss: 0.1431, lr: 0.001074, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6117 samples/sec | ETA 03:17:31
2023-02-05 04:33:40 [INFO]	[TRAIN] epoch: 2900, iter: 229050/250000, loss: 0.1543, lr: 0.001074, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6096 samples/sec | ETA 03:17:27
2023-02-05 04:33:46 [INFO]	[TRAIN] epoch: 2900, iter: 229060/250000, loss: 0.1475, lr: 0.001073, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5978 samples/sec | ETA 03:17:35
2023-02-05 04:33:51 [INFO]	[TRAIN] epoch: 2900, iter: 229070/250000, loss: 0.1914, lr: 0.001073, batch_cost: 0.5658, reader_cost: 0.00008, ips: 10.6047 samples/sec | ETA 03:17:21
2023-02-05 04:33:57 [INFO]	[TRAIN] epoch: 2900, iter: 229080/250000, loss: 0.1549, lr: 0.001072, batch_cost: 0.5871, reader_cost: 0.02274, ips: 10.2191 samples/sec | ETA 03:24:42
2023-02-05 04:34:03 [INFO]	[TRAIN] epoch: 2900, iter: 229090/250000, loss: 0.1623, lr: 0.001072, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6284 samples/sec | ETA 03:16:44
2023-02-05 04:34:09 [INFO]	[TRAIN] epoch: 2900, iter: 229100/250000, loss: 0.1225, lr: 0.001072, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6294 samples/sec | ETA 03:16:37
2023-02-05 04:34:14 [INFO]	[TRAIN] epoch: 2901, iter: 229110/250000, loss: 0.2296, lr: 0.001071, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6412 samples/sec | ETA 03:16:18
2023-02-05 04:34:20 [INFO]	[TRAIN] epoch: 2901, iter: 229120/250000, loss: 0.1522, lr: 0.001071, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6335 samples/sec | ETA 03:16:21
2023-02-05 04:34:25 [INFO]	[TRAIN] epoch: 2901, iter: 229130/250000, loss: 0.1294, lr: 0.001070, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6281 samples/sec | ETA 03:16:21
2023-02-05 04:34:31 [INFO]	[TRAIN] epoch: 2901, iter: 229140/250000, loss: 0.1474, lr: 0.001070, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6310 samples/sec | ETA 03:16:13
2023-02-05 04:34:37 [INFO]	[TRAIN] epoch: 2901, iter: 229150/250000, loss: 0.1596, lr: 0.001069, batch_cost: 0.5649, reader_cost: 0.00008, ips: 10.6222 samples/sec | ETA 03:16:17
2023-02-05 04:34:43 [INFO]	[TRAIN] epoch: 2901, iter: 229160/250000, loss: 0.1601, lr: 0.001069, batch_cost: 0.5897, reader_cost: 0.02286, ips: 10.1746 samples/sec | ETA 03:24:49
2023-02-05 04:34:48 [INFO]	[TRAIN] epoch: 2901, iter: 229170/250000, loss: 0.2034, lr: 0.001068, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6014 samples/sec | ETA 03:16:28
2023-02-05 04:34:54 [INFO]	[TRAIN] epoch: 2902, iter: 229180/250000, loss: 0.1411, lr: 0.001068, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6081 samples/sec | ETA 03:16:15
2023-02-05 04:35:00 [INFO]	[TRAIN] epoch: 2902, iter: 229190/250000, loss: 0.1626, lr: 0.001067, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6122 samples/sec | ETA 03:16:05
2023-02-05 04:35:05 [INFO]	[TRAIN] epoch: 2902, iter: 229200/250000, loss: 0.1510, lr: 0.001067, batch_cost: 0.5663, reader_cost: 0.00008, ips: 10.5951 samples/sec | ETA 03:16:19
2023-02-05 04:35:11 [INFO]	[TRAIN] epoch: 2902, iter: 229210/250000, loss: 0.1289, lr: 0.001066, batch_cost: 0.5660, reader_cost: 0.00008, ips: 10.6004 samples/sec | ETA 03:16:07
2023-02-05 04:35:17 [INFO]	[TRAIN] epoch: 2902, iter: 229220/250000, loss: 0.1331, lr: 0.001066, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6066 samples/sec | ETA 03:15:54
2023-02-05 04:35:22 [INFO]	[TRAIN] epoch: 2902, iter: 229230/250000, loss: 0.2167, lr: 0.001066, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6143 samples/sec | ETA 03:15:40
2023-02-05 04:35:28 [INFO]	[TRAIN] epoch: 2902, iter: 229240/250000, loss: 0.1465, lr: 0.001065, batch_cost: 0.5860, reader_cost: 0.02084, ips: 10.2395 samples/sec | ETA 03:22:44
2023-02-05 04:35:34 [INFO]	[TRAIN] epoch: 2902, iter: 229250/250000, loss: 0.1830, lr: 0.001065, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6235 samples/sec | ETA 03:15:19
2023-02-05 04:35:39 [INFO]	[TRAIN] epoch: 2903, iter: 229260/250000, loss: 0.1484, lr: 0.001064, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6278 samples/sec | ETA 03:15:08
2023-02-05 04:35:45 [INFO]	[TRAIN] epoch: 2903, iter: 229270/250000, loss: 0.1791, lr: 0.001064, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6208 samples/sec | ETA 03:15:11
2023-02-05 04:35:51 [INFO]	[TRAIN] epoch: 2903, iter: 229280/250000, loss: 0.1332, lr: 0.001063, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6093 samples/sec | ETA 03:15:18
2023-02-05 04:35:56 [INFO]	[TRAIN] epoch: 2903, iter: 229290/250000, loss: 0.1707, lr: 0.001063, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6042 samples/sec | ETA 03:15:18
2023-02-05 04:36:02 [INFO]	[TRAIN] epoch: 2903, iter: 229300/250000, loss: 0.1278, lr: 0.001062, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6061 samples/sec | ETA 03:15:10
2023-02-05 04:36:08 [INFO]	[TRAIN] epoch: 2903, iter: 229310/250000, loss: 0.1723, lr: 0.001062, batch_cost: 0.5921, reader_cost: 0.02659, ips: 10.1335 samples/sec | ETA 03:24:10
2023-02-05 04:36:14 [INFO]	[TRAIN] epoch: 2903, iter: 229320/250000, loss: 0.1217, lr: 0.001061, batch_cost: 0.5656, reader_cost: 0.00017, ips: 10.6088 samples/sec | ETA 03:14:55
2023-02-05 04:36:19 [INFO]	[TRAIN] epoch: 2903, iter: 229330/250000, loss: 0.1801, lr: 0.001061, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6225 samples/sec | ETA 03:14:35
2023-02-05 04:36:25 [INFO]	[TRAIN] epoch: 2904, iter: 229340/250000, loss: 0.1466, lr: 0.001060, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6220 samples/sec | ETA 03:14:30
2023-02-05 04:36:31 [INFO]	[TRAIN] epoch: 2904, iter: 229350/250000, loss: 0.1801, lr: 0.001060, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6276 samples/sec | ETA 03:14:18
2023-02-05 04:36:36 [INFO]	[TRAIN] epoch: 2904, iter: 229360/250000, loss: 0.1511, lr: 0.001060, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6314 samples/sec | ETA 03:14:08
2023-02-05 04:36:42 [INFO]	[TRAIN] epoch: 2904, iter: 229370/250000, loss: 0.1707, lr: 0.001059, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6223 samples/sec | ETA 03:14:12
2023-02-05 04:36:48 [INFO]	[TRAIN] epoch: 2904, iter: 229380/250000, loss: 0.1577, lr: 0.001059, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6266 samples/sec | ETA 03:14:02
2023-02-05 04:36:53 [INFO]	[TRAIN] epoch: 2904, iter: 229390/250000, loss: 0.1568, lr: 0.001058, batch_cost: 0.5958, reader_cost: 0.03071, ips: 10.0702 samples/sec | ETA 03:24:39
2023-02-05 04:36:59 [INFO]	[TRAIN] epoch: 2904, iter: 229400/250000, loss: 0.1524, lr: 0.001058, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6217 samples/sec | ETA 03:13:56
2023-02-05 04:37:05 [INFO]	[TRAIN] epoch: 2904, iter: 229410/250000, loss: 0.1449, lr: 0.001057, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6314 samples/sec | ETA 03:13:40
2023-02-05 04:37:10 [INFO]	[TRAIN] epoch: 2905, iter: 229420/250000, loss: 0.1752, lr: 0.001057, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6281 samples/sec | ETA 03:13:38
2023-02-05 04:37:16 [INFO]	[TRAIN] epoch: 2905, iter: 229430/250000, loss: 0.1407, lr: 0.001056, batch_cost: 0.5651, reader_cost: 0.00008, ips: 10.6185 samples/sec | ETA 03:13:43
2023-02-05 04:37:22 [INFO]	[TRAIN] epoch: 2905, iter: 229440/250000, loss: 0.1442, lr: 0.001056, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6305 samples/sec | ETA 03:13:24
2023-02-05 04:37:27 [INFO]	[TRAIN] epoch: 2905, iter: 229450/250000, loss: 0.1209, lr: 0.001055, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6389 samples/sec | ETA 03:13:09
2023-02-05 04:37:33 [INFO]	[TRAIN] epoch: 2905, iter: 229460/250000, loss: 0.1480, lr: 0.001055, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6310 samples/sec | ETA 03:13:12
2023-02-05 04:37:39 [INFO]	[TRAIN] epoch: 2905, iter: 229470/250000, loss: 0.1722, lr: 0.001054, batch_cost: 0.5910, reader_cost: 0.02634, ips: 10.1523 samples/sec | ETA 03:22:13
2023-02-05 04:37:45 [INFO]	[TRAIN] epoch: 2905, iter: 229480/250000, loss: 0.1311, lr: 0.001054, batch_cost: 0.5642, reader_cost: 0.00014, ips: 10.6350 samples/sec | ETA 03:12:56
2023-02-05 04:37:50 [INFO]	[TRAIN] epoch: 2905, iter: 229490/250000, loss: 0.1347, lr: 0.001054, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6301 samples/sec | ETA 03:12:56
2023-02-05 04:37:56 [INFO]	[TRAIN] epoch: 2906, iter: 229500/250000, loss: 0.1470, lr: 0.001053, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6327 samples/sec | ETA 03:12:48
2023-02-05 04:38:01 [INFO]	[TRAIN] epoch: 2906, iter: 229510/250000, loss: 0.1667, lr: 0.001053, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6255 samples/sec | ETA 03:12:50
2023-02-05 04:38:07 [INFO]	[TRAIN] epoch: 2906, iter: 229520/250000, loss: 0.1451, lr: 0.001052, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6206 samples/sec | ETA 03:12:49
2023-02-05 04:38:13 [INFO]	[TRAIN] epoch: 2906, iter: 229530/250000, loss: 0.1366, lr: 0.001052, batch_cost: 0.5642, reader_cost: 0.00008, ips: 10.6337 samples/sec | ETA 03:12:30
2023-02-05 04:38:18 [INFO]	[TRAIN] epoch: 2906, iter: 229540/250000, loss: 0.1569, lr: 0.001051, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6078 samples/sec | ETA 03:12:52
2023-02-05 04:38:24 [INFO]	[TRAIN] epoch: 2906, iter: 229550/250000, loss: 0.1461, lr: 0.001051, batch_cost: 0.5990, reader_cost: 0.03338, ips: 10.0166 samples/sec | ETA 03:24:09
2023-02-05 04:38:30 [INFO]	[TRAIN] epoch: 2906, iter: 229560/250000, loss: 0.1507, lr: 0.001050, batch_cost: 0.5646, reader_cost: 0.00014, ips: 10.6269 samples/sec | ETA 03:12:20
2023-02-05 04:38:36 [INFO]	[TRAIN] epoch: 2906, iter: 229570/250000, loss: 0.1216, lr: 0.001050, batch_cost: 0.5639, reader_cost: 0.00008, ips: 10.6393 samples/sec | ETA 03:12:01
2023-02-05 04:38:41 [INFO]	[TRAIN] epoch: 2907, iter: 229580/250000, loss: 0.1221, lr: 0.001049, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6251 samples/sec | ETA 03:12:11
2023-02-05 04:38:47 [INFO]	[TRAIN] epoch: 2907, iter: 229590/250000, loss: 0.1564, lr: 0.001049, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6155 samples/sec | ETA 03:12:15
2023-02-05 04:38:53 [INFO]	[TRAIN] epoch: 2907, iter: 229600/250000, loss: 0.1577, lr: 0.001048, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5987 samples/sec | ETA 03:12:28
2023-02-05 04:38:58 [INFO]	[TRAIN] epoch: 2907, iter: 229610/250000, loss: 0.1786, lr: 0.001048, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6086 samples/sec | ETA 03:12:12
2023-02-05 04:39:04 [INFO]	[TRAIN] epoch: 2907, iter: 229620/250000, loss: 0.1677, lr: 0.001048, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6108 samples/sec | ETA 03:12:04
2023-02-05 04:39:10 [INFO]	[TRAIN] epoch: 2907, iter: 229630/250000, loss: 0.1570, lr: 0.001047, batch_cost: 0.5913, reader_cost: 0.02613, ips: 10.1473 samples/sec | ETA 03:20:44
2023-02-05 04:39:16 [INFO]	[TRAIN] epoch: 2907, iter: 229640/250000, loss: 0.1225, lr: 0.001047, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6301 samples/sec | ETA 03:11:31
2023-02-05 04:39:21 [INFO]	[TRAIN] epoch: 2907, iter: 229650/250000, loss: 0.1547, lr: 0.001046, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6149 samples/sec | ETA 03:11:42
2023-02-05 04:39:27 [INFO]	[TRAIN] epoch: 2908, iter: 229660/250000, loss: 0.1514, lr: 0.001046, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6024 samples/sec | ETA 03:11:50
2023-02-05 04:39:32 [INFO]	[TRAIN] epoch: 2908, iter: 229670/250000, loss: 0.1425, lr: 0.001045, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6104 samples/sec | ETA 03:11:36
2023-02-05 04:39:38 [INFO]	[TRAIN] epoch: 2908, iter: 229680/250000, loss: 0.1908, lr: 0.001045, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6096 samples/sec | ETA 03:11:31
2023-02-05 04:39:44 [INFO]	[TRAIN] epoch: 2908, iter: 229690/250000, loss: 0.1548, lr: 0.001044, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6036 samples/sec | ETA 03:11:32
2023-02-05 04:39:49 [INFO]	[TRAIN] epoch: 2908, iter: 229700/250000, loss: 0.1909, lr: 0.001044, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6024 samples/sec | ETA 03:11:27
2023-02-05 04:39:55 [INFO]	[TRAIN] epoch: 2908, iter: 229710/250000, loss: 0.2010, lr: 0.001043, batch_cost: 0.5958, reader_cost: 0.02859, ips: 10.0700 samples/sec | ETA 03:21:29
2023-02-05 04:40:01 [INFO]	[TRAIN] epoch: 2908, iter: 229720/250000, loss: 0.2103, lr: 0.001043, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6308 samples/sec | ETA 03:10:45
2023-02-05 04:40:07 [INFO]	[TRAIN] epoch: 2908, iter: 229730/250000, loss: 0.1503, lr: 0.001042, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6296 samples/sec | ETA 03:10:41
2023-02-05 04:40:12 [INFO]	[TRAIN] epoch: 2909, iter: 229740/250000, loss: 0.1535, lr: 0.001042, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6325 samples/sec | ETA 03:10:32
2023-02-05 04:40:18 [INFO]	[TRAIN] epoch: 2909, iter: 229750/250000, loss: 0.1653, lr: 0.001041, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6099 samples/sec | ETA 03:10:51
2023-02-05 04:40:24 [INFO]	[TRAIN] epoch: 2909, iter: 229760/250000, loss: 0.1734, lr: 0.001041, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6061 samples/sec | ETA 03:10:49
2023-02-05 04:40:29 [INFO]	[TRAIN] epoch: 2909, iter: 229770/250000, loss: 0.1826, lr: 0.001041, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5993 samples/sec | ETA 03:10:51
2023-02-05 04:40:35 [INFO]	[TRAIN] epoch: 2909, iter: 229780/250000, loss: 0.1354, lr: 0.001040, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6070 samples/sec | ETA 03:10:37
2023-02-05 04:40:41 [INFO]	[TRAIN] epoch: 2909, iter: 229790/250000, loss: 0.1735, lr: 0.001040, batch_cost: 0.5902, reader_cost: 0.02531, ips: 10.1665 samples/sec | ETA 03:18:47
2023-02-05 04:40:47 [INFO]	[TRAIN] epoch: 2909, iter: 229800/250000, loss: 0.1650, lr: 0.001039, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6397 samples/sec | ETA 03:09:51
2023-02-05 04:40:52 [INFO]	[TRAIN] epoch: 2909, iter: 229810/250000, loss: 0.1388, lr: 0.001039, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6318 samples/sec | ETA 03:09:54
2023-02-05 04:40:58 [INFO]	[TRAIN] epoch: 2910, iter: 229820/250000, loss: 0.1643, lr: 0.001038, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6051 samples/sec | ETA 03:10:17
2023-02-05 04:41:04 [INFO]	[TRAIN] epoch: 2910, iter: 229830/250000, loss: 0.1714, lr: 0.001038, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5992 samples/sec | ETA 03:10:17
2023-02-05 04:41:09 [INFO]	[TRAIN] epoch: 2910, iter: 229840/250000, loss: 0.1705, lr: 0.001037, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5991 samples/sec | ETA 03:10:12
2023-02-05 04:41:15 [INFO]	[TRAIN] epoch: 2910, iter: 229850/250000, loss: 0.1327, lr: 0.001037, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6113 samples/sec | ETA 03:09:53
2023-02-05 04:41:20 [INFO]	[TRAIN] epoch: 2910, iter: 229860/250000, loss: 0.1592, lr: 0.001036, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6098 samples/sec | ETA 03:09:49
2023-02-05 04:41:26 [INFO]	[TRAIN] epoch: 2910, iter: 229870/250000, loss: 0.1298, lr: 0.001036, batch_cost: 0.5904, reader_cost: 0.02578, ips: 10.1627 samples/sec | ETA 03:18:04
2023-02-05 04:41:32 [INFO]	[TRAIN] epoch: 2910, iter: 229880/250000, loss: 0.1480, lr: 0.001035, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6390 samples/sec | ETA 03:09:06
2023-02-05 04:41:38 [INFO]	[TRAIN] epoch: 2910, iter: 229890/250000, loss: 0.1599, lr: 0.001035, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6304 samples/sec | ETA 03:09:10
2023-02-05 04:41:43 [INFO]	[TRAIN] epoch: 2911, iter: 229900/250000, loss: 0.1405, lr: 0.001035, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6326 samples/sec | ETA 03:09:02
2023-02-05 04:41:49 [INFO]	[TRAIN] epoch: 2911, iter: 229910/250000, loss: 0.1716, lr: 0.001034, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6176 samples/sec | ETA 03:09:12
2023-02-05 04:41:55 [INFO]	[TRAIN] epoch: 2911, iter: 229920/250000, loss: 0.1641, lr: 0.001034, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6077 samples/sec | ETA 03:09:17
2023-02-05 04:42:00 [INFO]	[TRAIN] epoch: 2911, iter: 229930/250000, loss: 0.1543, lr: 0.001033, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6068 samples/sec | ETA 03:09:13
2023-02-05 04:42:06 [INFO]	[TRAIN] epoch: 2911, iter: 229940/250000, loss: 0.1669, lr: 0.001033, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6134 samples/sec | ETA 03:09:00
2023-02-05 04:42:12 [INFO]	[TRAIN] epoch: 2911, iter: 229950/250000, loss: 0.1447, lr: 0.001032, batch_cost: 0.6054, reader_cost: 0.04093, ips: 9.9104 samples/sec | ETA 03:22:18
2023-02-05 04:42:18 [INFO]	[TRAIN] epoch: 2911, iter: 229960/250000, loss: 0.1253, lr: 0.001032, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6243 samples/sec | ETA 03:08:37
2023-02-05 04:42:23 [INFO]	[TRAIN] epoch: 2912, iter: 229970/250000, loss: 0.1906, lr: 0.001031, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6355 samples/sec | ETA 03:08:19
2023-02-05 04:42:29 [INFO]	[TRAIN] epoch: 2912, iter: 229980/250000, loss: 0.1582, lr: 0.001031, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6054 samples/sec | ETA 03:08:46
2023-02-05 04:42:35 [INFO]	[TRAIN] epoch: 2912, iter: 229990/250000, loss: 0.1656, lr: 0.001030, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6015 samples/sec | ETA 03:08:44
2023-02-05 04:42:40 [INFO]	[TRAIN] epoch: 2912, iter: 230000/250000, loss: 0.1915, lr: 0.001030, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6191 samples/sec | ETA 03:08:20
2023-02-05 04:42:40 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1227 - reader cost: 0.0230 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1492 - reader cost: 0.0116 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1569 - reader cost: 0.0077 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1575 - reader cost: 0.0058 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1582 - reader cost: 0.0047 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1603 - reader cost: 0.0039 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1605 - reader cost: 0.0034 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1614 - reader cost: 0.0029 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1625 - reader cost: 0.002610/36 [=======>......................] - ETA: 4s - batch_cost: 0.1622 - reader cost: 0.002411/36 [========>.....................] - ETA: 4s - batch_cost: 0.1629 - reader cost: 0.002212/36 [=========>....................] - ETA: 3s - batch_cost: 0.1627 - reader cost: 0.002013/36 [=========>....................] - ETA: 3s - batch_cost: 0.1631 - reader cost: 0.001814/36 [==========>...................] - ETA: 3s - batch_cost: 0.1638 - reader cost: 0.001715/36 [===========>..................] - ETA: 3s - batch_cost: 0.1637 - reader cost: 0.001616/36 [============>.................] - ETA: 3s - batch_cost: 0.1648 - reader cost: 0.001517/36 [=============>................] - ETA: 3s - batch_cost: 0.1651 - reader cost: 0.001418/36 [==============>...............] - ETA: 2s - batch_cost: 0.1650 - reader cost: 0.001419/36 [==============>...............] - ETA: 2s - batch_cost: 0.1647 - reader cost: 0.001320/36 [===============>..............] - ETA: 2s - batch_cost: 0.1647 - reader cost: 0.001221/36 [================>.............] - ETA: 2s - batch_cost: 0.1649 - reader cost: 0.001222/36 [=================>............] - ETA: 2s - batch_cost: 0.1653 - reader cost: 0.001123/36 [==================>...........] - ETA: 2s - batch_cost: 0.1660 - reader cost: 0.001124/36 [===================>..........] - ETA: 1s - batch_cost: 0.1661 - reader cost: 0.001025/36 [===================>..........] - ETA: 1s - batch_cost: 0.1662 - reader cost: 9.9694e-0426/36 [====================>.........] - ETA: 1s - batch_cost: 0.1665 - reader cost: 9.6130e-0427/36 [=====================>........] - ETA: 1s - batch_cost: 0.1668 - reader cost: 9.2876e-0428/36 [======================>.......] - ETA: 1s - batch_cost: 0.1669 - reader cost: 8.9829e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1671 - reader cost: 8.6976e-0430/36 [========================>.....] - ETA: 1s - batch_cost: 0.1670 - reader cost: 8.4321e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1669 - reader cost: 8.1843e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1669 - reader cost: 7.9516e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1667 - reader cost: 7.7352e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1665 - reader cost: 7.5309e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1665 - reader cost: 7.3396e-0436/36 [==============================] - 6s 167ms/step - batch_cost: 0.1667 - reader cost: 7.1532e-04
2023-02-05 04:42:46 [INFO]	[EVAL] #Images: 36 mIoU: 0.8619 Acc: 0.9861 Kappa: 0.9497 Dice: 0.9222
2023-02-05 04:42:46 [INFO]	[EVAL] Class IoU: 
[0.9854 0.9187 0.8966 0.7056 0.7122 0.9734 0.8412]
2023-02-05 04:42:46 [INFO]	[EVAL] Class Precision: 
[0.9928 0.9625 0.9432 0.8341 0.878  0.9833 0.8987]
2023-02-05 04:42:46 [INFO]	[EVAL] Class Recall: 
[0.9925 0.9528 0.9478 0.8208 0.7904 0.9897 0.9294]
2023-02-05 04:42:46 [INFO]	[EVAL] The model with the best validation mIoU (0.8682) was saved at iter 222000.
2023-02-05 04:42:52 [INFO]	[TRAIN] epoch: 2912, iter: 230010/250000, loss: 0.1621, lr: 0.001029, batch_cost: 0.5638, reader_cost: 0.00010, ips: 10.6422 samples/sec | ETA 03:07:50
2023-02-05 04:42:58 [INFO]	[TRAIN] epoch: 2912, iter: 230020/250000, loss: 0.1669, lr: 0.001029, batch_cost: 0.5639, reader_cost: 0.00008, ips: 10.6394 samples/sec | ETA 03:07:47
2023-02-05 04:43:04 [INFO]	[TRAIN] epoch: 2912, iter: 230030/250000, loss: 0.1516, lr: 0.001029, batch_cost: 0.5996, reader_cost: 0.03468, ips: 10.0070 samples/sec | ETA 03:19:33
2023-02-05 04:43:09 [INFO]	[TRAIN] epoch: 2912, iter: 230040/250000, loss: 0.1404, lr: 0.001028, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6323 samples/sec | ETA 03:07:43
2023-02-05 04:43:15 [INFO]	[TRAIN] epoch: 2913, iter: 230050/250000, loss: 0.1353, lr: 0.001028, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6350 samples/sec | ETA 03:07:35
2023-02-05 04:43:21 [INFO]	[TRAIN] epoch: 2913, iter: 230060/250000, loss: 0.1703, lr: 0.001027, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6300 samples/sec | ETA 03:07:34
2023-02-05 04:43:26 [INFO]	[TRAIN] epoch: 2913, iter: 230070/250000, loss: 0.1435, lr: 0.001027, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6418 samples/sec | ETA 03:07:16
2023-02-05 04:43:32 [INFO]	[TRAIN] epoch: 2913, iter: 230080/250000, loss: 0.2146, lr: 0.001026, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6347 samples/sec | ETA 03:07:18
2023-02-05 04:43:38 [INFO]	[TRAIN] epoch: 2913, iter: 230090/250000, loss: 0.1726, lr: 0.001026, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6320 samples/sec | ETA 03:07:15
2023-02-05 04:43:44 [INFO]	[TRAIN] epoch: 2913, iter: 230100/250000, loss: 0.1626, lr: 0.001025, batch_cost: 0.5880, reader_cost: 0.02345, ips: 10.2036 samples/sec | ETA 03:15:01
2023-02-05 04:43:49 [INFO]	[TRAIN] epoch: 2913, iter: 230110/250000, loss: 0.1597, lr: 0.001025, batch_cost: 0.5645, reader_cost: 0.00015, ips: 10.6292 samples/sec | ETA 03:07:07
2023-02-05 04:43:55 [INFO]	[TRAIN] epoch: 2913, iter: 230120/250000, loss: 0.2714, lr: 0.001024, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6327 samples/sec | ETA 03:06:58
2023-02-05 04:44:00 [INFO]	[TRAIN] epoch: 2914, iter: 230130/250000, loss: 0.1394, lr: 0.001024, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6328 samples/sec | ETA 03:06:52
2023-02-05 04:44:06 [INFO]	[TRAIN] epoch: 2914, iter: 230140/250000, loss: 0.1896, lr: 0.001023, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6243 samples/sec | ETA 03:06:55
2023-02-05 04:44:12 [INFO]	[TRAIN] epoch: 2914, iter: 230150/250000, loss: 0.1382, lr: 0.001023, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6346 samples/sec | ETA 03:06:39
2023-02-05 04:44:17 [INFO]	[TRAIN] epoch: 2914, iter: 230160/250000, loss: 0.1325, lr: 0.001022, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6248 samples/sec | ETA 03:06:43
2023-02-05 04:44:23 [INFO]	[TRAIN] epoch: 2914, iter: 230170/250000, loss: 0.1362, lr: 0.001022, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6169 samples/sec | ETA 03:06:46
2023-02-05 04:44:29 [INFO]	[TRAIN] epoch: 2914, iter: 230180/250000, loss: 0.1823, lr: 0.001022, batch_cost: 0.5917, reader_cost: 0.02582, ips: 10.1411 samples/sec | ETA 03:15:26
2023-02-05 04:44:35 [INFO]	[TRAIN] epoch: 2914, iter: 230190/250000, loss: 0.1589, lr: 0.001021, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6285 samples/sec | ETA 03:06:23
2023-02-05 04:44:40 [INFO]	[TRAIN] epoch: 2914, iter: 230200/250000, loss: 0.1405, lr: 0.001021, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6251 samples/sec | ETA 03:06:21
2023-02-05 04:44:46 [INFO]	[TRAIN] epoch: 2915, iter: 230210/250000, loss: 0.1355, lr: 0.001020, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6303 samples/sec | ETA 03:06:09
2023-02-05 04:44:52 [INFO]	[TRAIN] epoch: 2915, iter: 230220/250000, loss: 0.1347, lr: 0.001020, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6275 samples/sec | ETA 03:06:07
2023-02-05 04:44:57 [INFO]	[TRAIN] epoch: 2915, iter: 230230/250000, loss: 0.1450, lr: 0.001019, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6316 samples/sec | ETA 03:05:57
2023-02-05 04:45:03 [INFO]	[TRAIN] epoch: 2915, iter: 230240/250000, loss: 0.1495, lr: 0.001019, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6386 samples/sec | ETA 03:05:44
2023-02-05 04:45:08 [INFO]	[TRAIN] epoch: 2915, iter: 230250/250000, loss: 0.1899, lr: 0.001018, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6276 samples/sec | ETA 03:05:50
2023-02-05 04:45:14 [INFO]	[TRAIN] epoch: 2915, iter: 230260/250000, loss: 0.1416, lr: 0.001018, batch_cost: 0.5850, reader_cost: 0.02045, ips: 10.2565 samples/sec | ETA 03:12:27
2023-02-05 04:45:20 [INFO]	[TRAIN] epoch: 2915, iter: 230270/250000, loss: 0.1561, lr: 0.001017, batch_cost: 0.5646, reader_cost: 0.00013, ips: 10.6273 samples/sec | ETA 03:05:39
2023-02-05 04:45:26 [INFO]	[TRAIN] epoch: 2915, iter: 230280/250000, loss: 0.1485, lr: 0.001017, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6289 samples/sec | ETA 03:05:31
2023-02-05 04:45:31 [INFO]	[TRAIN] epoch: 2916, iter: 230290/250000, loss: 0.1542, lr: 0.001016, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6360 samples/sec | ETA 03:05:18
2023-02-05 04:45:37 [INFO]	[TRAIN] epoch: 2916, iter: 230300/250000, loss: 0.1764, lr: 0.001016, batch_cost: 0.5640, reader_cost: 0.00011, ips: 10.6383 samples/sec | ETA 03:05:10
2023-02-05 04:45:43 [INFO]	[TRAIN] epoch: 2916, iter: 230310/250000, loss: 0.1217, lr: 0.001016, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6286 samples/sec | ETA 03:05:15
2023-02-05 04:45:48 [INFO]	[TRAIN] epoch: 2916, iter: 230320/250000, loss: 0.1381, lr: 0.001015, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6280 samples/sec | ETA 03:05:10
2023-02-05 04:45:54 [INFO]	[TRAIN] epoch: 2916, iter: 230330/250000, loss: 0.1627, lr: 0.001015, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6392 samples/sec | ETA 03:04:52
2023-02-05 04:46:00 [INFO]	[TRAIN] epoch: 2916, iter: 230340/250000, loss: 0.1421, lr: 0.001014, batch_cost: 0.5968, reader_cost: 0.03181, ips: 10.0528 samples/sec | ETA 03:15:34
2023-02-05 04:46:05 [INFO]	[TRAIN] epoch: 2916, iter: 230350/250000, loss: 0.1479, lr: 0.001014, batch_cost: 0.5643, reader_cost: 0.00011, ips: 10.6329 samples/sec | ETA 03:04:48
2023-02-05 04:46:11 [INFO]	[TRAIN] epoch: 2916, iter: 230360/250000, loss: 0.1483, lr: 0.001013, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6389 samples/sec | ETA 03:04:36
2023-02-05 04:46:17 [INFO]	[TRAIN] epoch: 2917, iter: 230370/250000, loss: 0.1424, lr: 0.001013, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6260 samples/sec | ETA 03:04:44
2023-02-05 04:46:22 [INFO]	[TRAIN] epoch: 2917, iter: 230380/250000, loss: 0.1382, lr: 0.001012, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6244 samples/sec | ETA 03:04:40
2023-02-05 04:46:28 [INFO]	[TRAIN] epoch: 2917, iter: 230390/250000, loss: 0.1241, lr: 0.001012, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6328 samples/sec | ETA 03:04:25
2023-02-05 04:46:34 [INFO]	[TRAIN] epoch: 2917, iter: 230400/250000, loss: 0.1306, lr: 0.001011, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6378 samples/sec | ETA 03:04:14
2023-02-05 04:46:39 [INFO]	[TRAIN] epoch: 2917, iter: 230410/250000, loss: 0.1543, lr: 0.001011, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6371 samples/sec | ETA 03:04:10
2023-02-05 04:46:45 [INFO]	[TRAIN] epoch: 2917, iter: 230420/250000, loss: 0.1482, lr: 0.001010, batch_cost: 0.5919, reader_cost: 0.02721, ips: 10.1368 samples/sec | ETA 03:13:09
2023-02-05 04:46:51 [INFO]	[TRAIN] epoch: 2917, iter: 230430/250000, loss: 0.1538, lr: 0.001010, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6224 samples/sec | ETA 03:04:14
2023-02-05 04:46:57 [INFO]	[TRAIN] epoch: 2917, iter: 230440/250000, loss: 0.1244, lr: 0.001009, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6075 samples/sec | ETA 03:04:23
2023-02-05 04:47:02 [INFO]	[TRAIN] epoch: 2918, iter: 230450/250000, loss: 0.1509, lr: 0.001009, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6001 samples/sec | ETA 03:04:25
2023-02-05 04:47:08 [INFO]	[TRAIN] epoch: 2918, iter: 230460/250000, loss: 0.1378, lr: 0.001009, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6161 samples/sec | ETA 03:04:03
2023-02-05 04:47:13 [INFO]	[TRAIN] epoch: 2918, iter: 230470/250000, loss: 0.1357, lr: 0.001008, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6026 samples/sec | ETA 03:04:12
2023-02-05 04:47:19 [INFO]	[TRAIN] epoch: 2918, iter: 230480/250000, loss: 0.1428, lr: 0.001008, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6017 samples/sec | ETA 03:04:07
2023-02-05 04:47:25 [INFO]	[TRAIN] epoch: 2918, iter: 230490/250000, loss: 0.1266, lr: 0.001007, batch_cost: 0.5652, reader_cost: 0.00008, ips: 10.6156 samples/sec | ETA 03:03:47
2023-02-05 04:47:31 [INFO]	[TRAIN] epoch: 2918, iter: 230500/250000, loss: 0.1363, lr: 0.001007, batch_cost: 0.5982, reader_cost: 0.03357, ips: 10.0303 samples/sec | ETA 03:14:24
2023-02-05 04:47:36 [INFO]	[TRAIN] epoch: 2918, iter: 230510/250000, loss: 0.1422, lr: 0.001006, batch_cost: 0.5643, reader_cost: 0.00014, ips: 10.6318 samples/sec | ETA 03:03:19
2023-02-05 04:47:42 [INFO]	[TRAIN] epoch: 2918, iter: 230520/250000, loss: 0.1287, lr: 0.001006, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6221 samples/sec | ETA 03:03:23
2023-02-05 04:47:48 [INFO]	[TRAIN] epoch: 2919, iter: 230530/250000, loss: 0.2114, lr: 0.001005, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6368 samples/sec | ETA 03:03:02
2023-02-05 04:47:53 [INFO]	[TRAIN] epoch: 2919, iter: 230540/250000, loss: 0.1383, lr: 0.001005, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6152 samples/sec | ETA 03:03:19
2023-02-05 04:47:59 [INFO]	[TRAIN] epoch: 2919, iter: 230550/250000, loss: 0.1652, lr: 0.001004, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6044 samples/sec | ETA 03:03:24
2023-02-05 04:48:05 [INFO]	[TRAIN] epoch: 2919, iter: 230560/250000, loss: 0.2371, lr: 0.001004, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5992 samples/sec | ETA 03:03:24
2023-02-05 04:48:10 [INFO]	[TRAIN] epoch: 2919, iter: 230570/250000, loss: 0.1726, lr: 0.001003, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6225 samples/sec | ETA 03:02:54
2023-02-05 04:48:16 [INFO]	[TRAIN] epoch: 2919, iter: 230580/250000, loss: 0.1425, lr: 0.001003, batch_cost: 0.5912, reader_cost: 0.02655, ips: 10.1489 samples/sec | ETA 03:11:21
2023-02-05 04:48:22 [INFO]	[TRAIN] epoch: 2919, iter: 230590/250000, loss: 0.1768, lr: 0.001003, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6367 samples/sec | ETA 03:02:28
2023-02-05 04:48:28 [INFO]	[TRAIN] epoch: 2919, iter: 230600/250000, loss: 0.1587, lr: 0.001002, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6361 samples/sec | ETA 03:02:23
2023-02-05 04:48:33 [INFO]	[TRAIN] epoch: 2920, iter: 230610/250000, loss: 0.1469, lr: 0.001002, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6282 samples/sec | ETA 03:02:26
2023-02-05 04:48:39 [INFO]	[TRAIN] epoch: 2920, iter: 230620/250000, loss: 0.1433, lr: 0.001001, batch_cost: 0.5647, reader_cost: 0.00008, ips: 10.6249 samples/sec | ETA 03:02:24
2023-02-05 04:48:44 [INFO]	[TRAIN] epoch: 2920, iter: 230630/250000, loss: 0.1354, lr: 0.001001, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6081 samples/sec | ETA 03:02:35
2023-02-05 04:48:50 [INFO]	[TRAIN] epoch: 2920, iter: 230640/250000, loss: 0.1632, lr: 0.001000, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6097 samples/sec | ETA 03:02:28
2023-02-05 04:48:56 [INFO]	[TRAIN] epoch: 2920, iter: 230650/250000, loss: 0.2003, lr: 0.001000, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6183 samples/sec | ETA 03:02:13
2023-02-05 04:49:02 [INFO]	[TRAIN] epoch: 2920, iter: 230660/250000, loss: 0.1315, lr: 0.000999, batch_cost: 0.5925, reader_cost: 0.02732, ips: 10.1259 samples/sec | ETA 03:10:59
2023-02-05 04:49:07 [INFO]	[TRAIN] epoch: 2920, iter: 230670/250000, loss: 0.1178, lr: 0.000999, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6087 samples/sec | ETA 03:02:12
2023-02-05 04:49:13 [INFO]	[TRAIN] epoch: 2920, iter: 230680/250000, loss: 0.1498, lr: 0.000998, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6116 samples/sec | ETA 03:02:03
2023-02-05 04:49:19 [INFO]	[TRAIN] epoch: 2921, iter: 230690/250000, loss: 0.1347, lr: 0.000998, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6127 samples/sec | ETA 03:01:57
2023-02-05 04:49:24 [INFO]	[TRAIN] epoch: 2921, iter: 230700/250000, loss: 0.1459, lr: 0.000997, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6177 samples/sec | ETA 03:01:46
2023-02-05 04:49:30 [INFO]	[TRAIN] epoch: 2921, iter: 230710/250000, loss: 0.1352, lr: 0.000997, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 03:01:52
2023-02-05 04:49:36 [INFO]	[TRAIN] epoch: 2921, iter: 230720/250000, loss: 0.1359, lr: 0.000996, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6059 samples/sec | ETA 03:01:47
2023-02-05 04:49:41 [INFO]	[TRAIN] epoch: 2921, iter: 230730/250000, loss: 0.1540, lr: 0.000996, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6095 samples/sec | ETA 03:01:37
2023-02-05 04:49:47 [INFO]	[TRAIN] epoch: 2921, iter: 230740/250000, loss: 0.1400, lr: 0.000996, batch_cost: 0.5944, reader_cost: 0.02987, ips: 10.0948 samples/sec | ETA 03:10:47
2023-02-05 04:49:53 [INFO]	[TRAIN] epoch: 2921, iter: 230750/250000, loss: 0.1388, lr: 0.000995, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6127 samples/sec | ETA 03:01:23
2023-02-05 04:49:59 [INFO]	[TRAIN] epoch: 2922, iter: 230760/250000, loss: 0.1838, lr: 0.000995, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6074 samples/sec | ETA 03:01:22
2023-02-05 04:50:04 [INFO]	[TRAIN] epoch: 2922, iter: 230770/250000, loss: 0.1404, lr: 0.000994, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6123 samples/sec | ETA 03:01:12
2023-02-05 04:50:10 [INFO]	[TRAIN] epoch: 2922, iter: 230780/250000, loss: 0.1265, lr: 0.000994, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6100 samples/sec | ETA 03:01:08
2023-02-05 04:50:16 [INFO]	[TRAIN] epoch: 2922, iter: 230790/250000, loss: 0.1200, lr: 0.000993, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6104 samples/sec | ETA 03:01:02
2023-02-05 04:50:21 [INFO]	[TRAIN] epoch: 2922, iter: 230800/250000, loss: 0.1512, lr: 0.000993, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6092 samples/sec | ETA 03:00:58
2023-02-05 04:50:27 [INFO]	[TRAIN] epoch: 2922, iter: 230810/250000, loss: 0.1584, lr: 0.000992, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6101 samples/sec | ETA 03:00:51
2023-02-05 04:50:33 [INFO]	[TRAIN] epoch: 2922, iter: 230820/250000, loss: 0.1599, lr: 0.000992, batch_cost: 0.5894, reader_cost: 0.02483, ips: 10.1797 samples/sec | ETA 03:08:24
2023-02-05 04:50:38 [INFO]	[TRAIN] epoch: 2922, iter: 230830/250000, loss: 0.1333, lr: 0.000991, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6202 samples/sec | ETA 03:00:30
2023-02-05 04:50:44 [INFO]	[TRAIN] epoch: 2923, iter: 230840/250000, loss: 0.1809, lr: 0.000991, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6119 samples/sec | ETA 03:00:33
2023-02-05 04:50:50 [INFO]	[TRAIN] epoch: 2923, iter: 230850/250000, loss: 0.1424, lr: 0.000990, batch_cost: 0.5658, reader_cost: 0.00008, ips: 10.6042 samples/sec | ETA 03:00:35
2023-02-05 04:50:55 [INFO]	[TRAIN] epoch: 2923, iter: 230860/250000, loss: 0.1311, lr: 0.000990, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6182 samples/sec | ETA 03:00:15
2023-02-05 04:51:01 [INFO]	[TRAIN] epoch: 2923, iter: 230870/250000, loss: 0.1654, lr: 0.000990, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6083 samples/sec | ETA 03:00:19
2023-02-05 04:51:07 [INFO]	[TRAIN] epoch: 2923, iter: 230880/250000, loss: 0.2334, lr: 0.000989, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6121 samples/sec | ETA 03:00:10
2023-02-05 04:51:13 [INFO]	[TRAIN] epoch: 2923, iter: 230890/250000, loss: 0.1551, lr: 0.000989, batch_cost: 0.5897, reader_cost: 0.02427, ips: 10.1743 samples/sec | ETA 03:07:49
2023-02-05 04:51:18 [INFO]	[TRAIN] epoch: 2923, iter: 230900/250000, loss: 0.1913, lr: 0.000988, batch_cost: 0.5655, reader_cost: 0.00014, ips: 10.6095 samples/sec | ETA 03:00:01
2023-02-05 04:51:24 [INFO]	[TRAIN] epoch: 2923, iter: 230910/250000, loss: 0.1445, lr: 0.000988, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6122 samples/sec | ETA 02:59:53
2023-02-05 04:51:30 [INFO]	[TRAIN] epoch: 2924, iter: 230920/250000, loss: 0.1373, lr: 0.000987, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6028 samples/sec | ETA 02:59:57
2023-02-05 04:51:35 [INFO]	[TRAIN] epoch: 2924, iter: 230930/250000, loss: 0.1412, lr: 0.000987, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6137 samples/sec | ETA 02:59:40
2023-02-05 04:51:41 [INFO]	[TRAIN] epoch: 2924, iter: 230940/250000, loss: 0.1738, lr: 0.000986, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6126 samples/sec | ETA 02:59:35
2023-02-05 04:51:46 [INFO]	[TRAIN] epoch: 2924, iter: 230950/250000, loss: 0.1528, lr: 0.000986, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5970 samples/sec | ETA 02:59:46
2023-02-05 04:51:52 [INFO]	[TRAIN] epoch: 2924, iter: 230960/250000, loss: 0.1420, lr: 0.000985, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6028 samples/sec | ETA 02:59:34
2023-02-05 04:51:58 [INFO]	[TRAIN] epoch: 2924, iter: 230970/250000, loss: 0.1480, lr: 0.000985, batch_cost: 0.5945, reader_cost: 0.02936, ips: 10.0926 samples/sec | ETA 03:08:33
2023-02-05 04:52:04 [INFO]	[TRAIN] epoch: 2924, iter: 230980/250000, loss: 0.1333, lr: 0.000984, batch_cost: 0.5647, reader_cost: 0.00014, ips: 10.6242 samples/sec | ETA 02:59:01
2023-02-05 04:52:09 [INFO]	[TRAIN] epoch: 2924, iter: 230990/250000, loss: 0.1419, lr: 0.000984, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6313 samples/sec | ETA 02:58:48
2023-02-05 04:52:15 [INFO]	[TRAIN] epoch: 2925, iter: 231000/250000, loss: 0.1550, lr: 0.000983, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6283 samples/sec | ETA 02:58:46
2023-02-05 04:52:21 [INFO]	[TRAIN] epoch: 2925, iter: 231010/250000, loss: 0.1432, lr: 0.000983, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6313 samples/sec | ETA 02:58:37
2023-02-05 04:52:26 [INFO]	[TRAIN] epoch: 2925, iter: 231020/250000, loss: 0.1376, lr: 0.000983, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6225 samples/sec | ETA 02:58:40
2023-02-05 04:52:32 [INFO]	[TRAIN] epoch: 2925, iter: 231030/250000, loss: 0.1482, lr: 0.000982, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6150 samples/sec | ETA 02:58:42
2023-02-05 04:52:38 [INFO]	[TRAIN] epoch: 2925, iter: 231040/250000, loss: 0.1362, lr: 0.000982, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6003 samples/sec | ETA 02:58:51
2023-02-05 04:52:44 [INFO]	[TRAIN] epoch: 2925, iter: 231050/250000, loss: 0.1535, lr: 0.000981, batch_cost: 0.5908, reader_cost: 0.02541, ips: 10.1560 samples/sec | ETA 03:06:35
2023-02-05 04:52:49 [INFO]	[TRAIN] epoch: 2925, iter: 231060/250000, loss: 0.1489, lr: 0.000981, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6181 samples/sec | ETA 02:58:22
2023-02-05 04:52:55 [INFO]	[TRAIN] epoch: 2925, iter: 231070/250000, loss: 0.1939, lr: 0.000980, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6319 samples/sec | ETA 02:58:02
2023-02-05 04:53:00 [INFO]	[TRAIN] epoch: 2926, iter: 231080/250000, loss: 0.1450, lr: 0.000980, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6366 samples/sec | ETA 02:57:52
2023-02-05 04:53:06 [INFO]	[TRAIN] epoch: 2926, iter: 231090/250000, loss: 0.1485, lr: 0.000979, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6309 samples/sec | ETA 02:57:52
2023-02-05 04:53:12 [INFO]	[TRAIN] epoch: 2926, iter: 231100/250000, loss: 0.1480, lr: 0.000979, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6311 samples/sec | ETA 02:57:46
2023-02-05 04:53:17 [INFO]	[TRAIN] epoch: 2926, iter: 231110/250000, loss: 0.1436, lr: 0.000978, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6280 samples/sec | ETA 02:57:44
2023-02-05 04:53:23 [INFO]	[TRAIN] epoch: 2926, iter: 231120/250000, loss: 0.1280, lr: 0.000978, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6166 samples/sec | ETA 02:57:50
2023-02-05 04:53:29 [INFO]	[TRAIN] epoch: 2926, iter: 231130/250000, loss: 0.1782, lr: 0.000977, batch_cost: 0.5994, reader_cost: 0.03281, ips: 10.0102 samples/sec | ETA 03:08:30
2023-02-05 04:53:35 [INFO]	[TRAIN] epoch: 2926, iter: 231140/250000, loss: 0.1568, lr: 0.000977, batch_cost: 0.5647, reader_cost: 0.00014, ips: 10.6252 samples/sec | ETA 02:57:30
2023-02-05 04:53:40 [INFO]	[TRAIN] epoch: 2926, iter: 231150/250000, loss: 0.1249, lr: 0.000976, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6245 samples/sec | ETA 02:57:25
2023-02-05 04:53:46 [INFO]	[TRAIN] epoch: 2927, iter: 231160/250000, loss: 0.1753, lr: 0.000976, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6269 samples/sec | ETA 02:57:17
2023-02-05 04:53:52 [INFO]	[TRAIN] epoch: 2927, iter: 231170/250000, loss: 0.1572, lr: 0.000976, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6175 samples/sec | ETA 02:57:20
2023-02-05 04:53:57 [INFO]	[TRAIN] epoch: 2927, iter: 231180/250000, loss: 0.1301, lr: 0.000975, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6145 samples/sec | ETA 02:57:18
2023-02-05 04:54:03 [INFO]	[TRAIN] epoch: 2927, iter: 231190/250000, loss: 0.1460, lr: 0.000975, batch_cost: 0.5663, reader_cost: 0.00008, ips: 10.5952 samples/sec | ETA 02:57:31
2023-02-05 04:54:09 [INFO]	[TRAIN] epoch: 2927, iter: 231200/250000, loss: 0.1319, lr: 0.000974, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 02:57:15
2023-02-05 04:54:15 [INFO]	[TRAIN] epoch: 2927, iter: 231210/250000, loss: 0.1305, lr: 0.000974, batch_cost: 0.5972, reader_cost: 0.03204, ips: 10.0466 samples/sec | ETA 03:07:01
2023-02-05 04:54:20 [INFO]	[TRAIN] epoch: 2927, iter: 231220/250000, loss: 0.1629, lr: 0.000973, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6062 samples/sec | ETA 02:57:03
2023-02-05 04:54:26 [INFO]	[TRAIN] epoch: 2927, iter: 231230/250000, loss: 0.1450, lr: 0.000973, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5964 samples/sec | ETA 02:57:08
2023-02-05 04:54:32 [INFO]	[TRAIN] epoch: 2928, iter: 231240/250000, loss: 0.1123, lr: 0.000972, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6203 samples/sec | ETA 02:56:38
2023-02-05 04:54:37 [INFO]	[TRAIN] epoch: 2928, iter: 231250/250000, loss: 0.1416, lr: 0.000972, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6110 samples/sec | ETA 02:56:42
2023-02-05 04:54:43 [INFO]	[TRAIN] epoch: 2928, iter: 231260/250000, loss: 0.1343, lr: 0.000971, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6011 samples/sec | ETA 02:56:46
2023-02-05 04:54:49 [INFO]	[TRAIN] epoch: 2928, iter: 231270/250000, loss: 0.1365, lr: 0.000971, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6121 samples/sec | ETA 02:56:29
2023-02-05 04:54:54 [INFO]	[TRAIN] epoch: 2928, iter: 231280/250000, loss: 0.1624, lr: 0.000970, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6083 samples/sec | ETA 02:56:27
2023-02-05 04:55:00 [INFO]	[TRAIN] epoch: 2928, iter: 231290/250000, loss: 0.1815, lr: 0.000970, batch_cost: 0.6040, reader_cost: 0.03863, ips: 9.9340 samples/sec | ETA 03:08:20
2023-02-05 04:55:06 [INFO]	[TRAIN] epoch: 2928, iter: 231300/250000, loss: 0.1185, lr: 0.000969, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6312 samples/sec | ETA 02:55:53
2023-02-05 04:55:12 [INFO]	[TRAIN] epoch: 2928, iter: 231310/250000, loss: 0.1448, lr: 0.000969, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6311 samples/sec | ETA 02:55:48
2023-02-05 04:55:17 [INFO]	[TRAIN] epoch: 2929, iter: 231320/250000, loss: 0.1286, lr: 0.000969, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6240 samples/sec | ETA 02:55:49
2023-02-05 04:55:23 [INFO]	[TRAIN] epoch: 2929, iter: 231330/250000, loss: 0.1593, lr: 0.000968, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6317 samples/sec | ETA 02:55:36
2023-02-05 04:55:28 [INFO]	[TRAIN] epoch: 2929, iter: 231340/250000, loss: 0.1484, lr: 0.000968, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6205 samples/sec | ETA 02:55:41
2023-02-05 04:55:34 [INFO]	[TRAIN] epoch: 2929, iter: 231350/250000, loss: 0.1431, lr: 0.000967, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6096 samples/sec | ETA 02:55:47
2023-02-05 04:55:40 [INFO]	[TRAIN] epoch: 2929, iter: 231360/250000, loss: 0.1715, lr: 0.000967, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6008 samples/sec | ETA 02:55:50
2023-02-05 04:55:46 [INFO]	[TRAIN] epoch: 2929, iter: 231370/250000, loss: 0.1472, lr: 0.000966, batch_cost: 0.5914, reader_cost: 0.02665, ips: 10.1462 samples/sec | ETA 03:03:36
2023-02-05 04:55:51 [INFO]	[TRAIN] epoch: 2929, iter: 231380/250000, loss: 0.1318, lr: 0.000966, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6283 samples/sec | ETA 02:55:11
2023-02-05 04:55:57 [INFO]	[TRAIN] epoch: 2929, iter: 231390/250000, loss: 0.1430, lr: 0.000965, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6301 samples/sec | ETA 02:55:04
2023-02-05 04:56:03 [INFO]	[TRAIN] epoch: 2930, iter: 231400/250000, loss: 0.1210, lr: 0.000965, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6285 samples/sec | ETA 02:55:00
2023-02-05 04:56:08 [INFO]	[TRAIN] epoch: 2930, iter: 231410/250000, loss: 0.1394, lr: 0.000964, batch_cost: 0.5637, reader_cost: 0.00009, ips: 10.6435 samples/sec | ETA 02:54:39
2023-02-05 04:56:14 [INFO]	[TRAIN] epoch: 2930, iter: 231420/250000, loss: 0.1485, lr: 0.000964, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6365 samples/sec | ETA 02:54:40
2023-02-05 04:56:20 [INFO]	[TRAIN] epoch: 2930, iter: 231430/250000, loss: 0.1328, lr: 0.000963, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6306 samples/sec | ETA 02:54:41
2023-02-05 04:56:25 [INFO]	[TRAIN] epoch: 2930, iter: 231440/250000, loss: 0.1325, lr: 0.000963, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6219 samples/sec | ETA 02:54:43
2023-02-05 04:56:31 [INFO]	[TRAIN] epoch: 2930, iter: 231450/250000, loss: 0.1842, lr: 0.000962, batch_cost: 0.5971, reader_cost: 0.03090, ips: 10.0485 samples/sec | ETA 03:04:36
2023-02-05 04:56:37 [INFO]	[TRAIN] epoch: 2930, iter: 231460/250000, loss: 0.1266, lr: 0.000962, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6324 samples/sec | ETA 02:54:22
2023-02-05 04:56:42 [INFO]	[TRAIN] epoch: 2930, iter: 231470/250000, loss: 0.1552, lr: 0.000962, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6385 samples/sec | ETA 02:54:10
2023-02-05 04:56:48 [INFO]	[TRAIN] epoch: 2931, iter: 231480/250000, loss: 0.1386, lr: 0.000961, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6329 samples/sec | ETA 02:54:10
2023-02-05 04:56:54 [INFO]	[TRAIN] epoch: 2931, iter: 231490/250000, loss: 0.1364, lr: 0.000961, batch_cost: 0.5647, reader_cost: 0.00008, ips: 10.6251 samples/sec | ETA 02:54:12
2023-02-05 04:56:59 [INFO]	[TRAIN] epoch: 2931, iter: 231500/250000, loss: 0.1445, lr: 0.000960, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6301 samples/sec | ETA 02:54:02
2023-02-05 04:57:05 [INFO]	[TRAIN] epoch: 2931, iter: 231510/250000, loss: 0.1228, lr: 0.000960, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6365 samples/sec | ETA 02:53:50
2023-02-05 04:57:11 [INFO]	[TRAIN] epoch: 2931, iter: 231520/250000, loss: 0.1402, lr: 0.000959, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6312 samples/sec | ETA 02:53:49
2023-02-05 04:57:17 [INFO]	[TRAIN] epoch: 2931, iter: 231530/250000, loss: 0.1269, lr: 0.000959, batch_cost: 0.5883, reader_cost: 0.02308, ips: 10.1985 samples/sec | ETA 03:01:06
2023-02-05 04:57:22 [INFO]	[TRAIN] epoch: 2931, iter: 231540/250000, loss: 0.1391, lr: 0.000958, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6294 samples/sec | ETA 02:53:40
2023-02-05 04:57:28 [INFO]	[TRAIN] epoch: 2932, iter: 231550/250000, loss: 0.1375, lr: 0.000958, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6387 samples/sec | ETA 02:53:25
2023-02-05 04:57:33 [INFO]	[TRAIN] epoch: 2932, iter: 231560/250000, loss: 0.1681, lr: 0.000957, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6393 samples/sec | ETA 02:53:19
2023-02-05 04:57:39 [INFO]	[TRAIN] epoch: 2932, iter: 231570/250000, loss: 0.1221, lr: 0.000957, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6282 samples/sec | ETA 02:53:24
2023-02-05 04:57:45 [INFO]	[TRAIN] epoch: 2932, iter: 231580/250000, loss: 0.1294, lr: 0.000956, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6286 samples/sec | ETA 02:53:18
2023-02-05 04:57:50 [INFO]	[TRAIN] epoch: 2932, iter: 231590/250000, loss: 0.1393, lr: 0.000956, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6281 samples/sec | ETA 02:53:13
2023-02-05 04:57:56 [INFO]	[TRAIN] epoch: 2932, iter: 231600/250000, loss: 0.1431, lr: 0.000955, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6287 samples/sec | ETA 02:53:06
2023-02-05 04:58:02 [INFO]	[TRAIN] epoch: 2932, iter: 231610/250000, loss: 0.1192, lr: 0.000955, batch_cost: 0.5926, reader_cost: 0.02789, ips: 10.1253 samples/sec | ETA 03:01:37
2023-02-05 04:58:08 [INFO]	[TRAIN] epoch: 2932, iter: 231620/250000, loss: 0.1567, lr: 0.000955, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6321 samples/sec | ETA 02:52:52
2023-02-05 04:58:13 [INFO]	[TRAIN] epoch: 2933, iter: 231630/250000, loss: 0.1293, lr: 0.000954, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6340 samples/sec | ETA 02:52:44
2023-02-05 04:58:19 [INFO]	[TRAIN] epoch: 2933, iter: 231640/250000, loss: 0.1255, lr: 0.000954, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6328 samples/sec | ETA 02:52:40
2023-02-05 04:58:25 [INFO]	[TRAIN] epoch: 2933, iter: 231650/250000, loss: 0.1565, lr: 0.000953, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6322 samples/sec | ETA 02:52:35
2023-02-05 04:58:30 [INFO]	[TRAIN] epoch: 2933, iter: 231660/250000, loss: 0.1595, lr: 0.000953, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6226 samples/sec | ETA 02:52:39
2023-02-05 04:58:36 [INFO]	[TRAIN] epoch: 2933, iter: 231670/250000, loss: 0.1399, lr: 0.000952, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6316 samples/sec | ETA 02:52:24
2023-02-05 04:58:42 [INFO]	[TRAIN] epoch: 2933, iter: 231680/250000, loss: 0.1413, lr: 0.000952, batch_cost: 0.5978, reader_cost: 0.03345, ips: 10.0376 samples/sec | ETA 03:02:30
2023-02-05 04:58:47 [INFO]	[TRAIN] epoch: 2933, iter: 231690/250000, loss: 0.1346, lr: 0.000951, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6084 samples/sec | ETA 02:52:35
2023-02-05 04:58:53 [INFO]	[TRAIN] epoch: 2933, iter: 231700/250000, loss: 0.1194, lr: 0.000951, batch_cost: 0.5642, reader_cost: 0.00008, ips: 10.6351 samples/sec | ETA 02:52:04
2023-02-05 04:58:59 [INFO]	[TRAIN] epoch: 2934, iter: 231710/250000, loss: 0.1243, lr: 0.000950, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6352 samples/sec | ETA 02:51:58
2023-02-05 04:59:04 [INFO]	[TRAIN] epoch: 2934, iter: 231720/250000, loss: 0.1296, lr: 0.000950, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6252 samples/sec | ETA 02:52:02
2023-02-05 04:59:10 [INFO]	[TRAIN] epoch: 2934, iter: 231730/250000, loss: 0.2138, lr: 0.000949, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6373 samples/sec | ETA 02:51:45
2023-02-05 04:59:16 [INFO]	[TRAIN] epoch: 2934, iter: 231740/250000, loss: 0.1362, lr: 0.000949, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6335 samples/sec | ETA 02:51:43
2023-02-05 04:59:21 [INFO]	[TRAIN] epoch: 2934, iter: 231750/250000, loss: 0.1691, lr: 0.000948, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6327 samples/sec | ETA 02:51:38
2023-02-05 04:59:27 [INFO]	[TRAIN] epoch: 2934, iter: 231760/250000, loss: 0.1667, lr: 0.000948, batch_cost: 0.5960, reader_cost: 0.03177, ips: 10.0678 samples/sec | ETA 03:01:10
2023-02-05 04:59:33 [INFO]	[TRAIN] epoch: 2934, iter: 231770/250000, loss: 0.1310, lr: 0.000948, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6273 samples/sec | ETA 02:51:32
2023-02-05 04:59:39 [INFO]	[TRAIN] epoch: 2934, iter: 231780/250000, loss: 0.1433, lr: 0.000947, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6339 samples/sec | ETA 02:51:20
2023-02-05 04:59:44 [INFO]	[TRAIN] epoch: 2935, iter: 231790/250000, loss: 0.1601, lr: 0.000947, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6372 samples/sec | ETA 02:51:11
2023-02-05 04:59:50 [INFO]	[TRAIN] epoch: 2935, iter: 231800/250000, loss: 0.1149, lr: 0.000946, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6308 samples/sec | ETA 02:51:12
2023-02-05 04:59:56 [INFO]	[TRAIN] epoch: 2935, iter: 231810/250000, loss: 0.1286, lr: 0.000946, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6303 samples/sec | ETA 02:51:06
2023-02-05 05:00:01 [INFO]	[TRAIN] epoch: 2935, iter: 231820/250000, loss: 0.1620, lr: 0.000945, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6309 samples/sec | ETA 02:51:00
2023-02-05 05:00:07 [INFO]	[TRAIN] epoch: 2935, iter: 231830/250000, loss: 0.1478, lr: 0.000945, batch_cost: 0.5647, reader_cost: 0.00008, ips: 10.6244 samples/sec | ETA 02:51:01
2023-02-05 05:00:13 [INFO]	[TRAIN] epoch: 2935, iter: 231840/250000, loss: 0.1506, lr: 0.000944, batch_cost: 0.5957, reader_cost: 0.03197, ips: 10.0721 samples/sec | ETA 03:00:18
2023-02-05 05:00:18 [INFO]	[TRAIN] epoch: 2935, iter: 231850/250000, loss: 0.1131, lr: 0.000944, batch_cost: 0.5650, reader_cost: 0.00014, ips: 10.6188 samples/sec | ETA 02:50:55
2023-02-05 05:00:24 [INFO]	[TRAIN] epoch: 2935, iter: 231860/250000, loss: 0.1511, lr: 0.000943, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6314 samples/sec | ETA 02:50:37
2023-02-05 05:00:30 [INFO]	[TRAIN] epoch: 2936, iter: 231870/250000, loss: 0.1344, lr: 0.000943, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6297 samples/sec | ETA 02:50:33
2023-02-05 05:00:35 [INFO]	[TRAIN] epoch: 2936, iter: 231880/250000, loss: 0.1880, lr: 0.000942, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6261 samples/sec | ETA 02:50:31
2023-02-05 05:00:41 [INFO]	[TRAIN] epoch: 2936, iter: 231890/250000, loss: 0.1210, lr: 0.000942, batch_cost: 0.5642, reader_cost: 0.00008, ips: 10.6354 samples/sec | ETA 02:50:16
2023-02-05 05:00:47 [INFO]	[TRAIN] epoch: 2936, iter: 231900/250000, loss: 0.1470, lr: 0.000941, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6293 samples/sec | ETA 02:50:17
2023-02-05 05:00:52 [INFO]	[TRAIN] epoch: 2936, iter: 231910/250000, loss: 0.1500, lr: 0.000941, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6379 samples/sec | ETA 02:50:03
2023-02-05 05:00:58 [INFO]	[TRAIN] epoch: 2936, iter: 231920/250000, loss: 0.1424, lr: 0.000940, batch_cost: 0.5930, reader_cost: 0.02834, ips: 10.1181 samples/sec | ETA 02:58:41
2023-02-05 05:01:04 [INFO]	[TRAIN] epoch: 2936, iter: 231930/250000, loss: 0.1495, lr: 0.000940, batch_cost: 0.5667, reader_cost: 0.00010, ips: 10.5870 samples/sec | ETA 02:50:40
2023-02-05 05:01:10 [INFO]	[TRAIN] epoch: 2936, iter: 231940/250000, loss: 0.1353, lr: 0.000940, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6373 samples/sec | ETA 02:49:46
2023-02-05 05:01:15 [INFO]	[TRAIN] epoch: 2937, iter: 231950/250000, loss: 0.1478, lr: 0.000939, batch_cost: 0.5642, reader_cost: 0.00008, ips: 10.6337 samples/sec | ETA 02:49:44
2023-02-05 05:01:21 [INFO]	[TRAIN] epoch: 2937, iter: 231960/250000, loss: 0.1196, lr: 0.000939, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6328 samples/sec | ETA 02:49:39
2023-02-05 05:01:26 [INFO]	[TRAIN] epoch: 2937, iter: 231970/250000, loss: 0.1383, lr: 0.000938, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6355 samples/sec | ETA 02:49:31
2023-02-05 05:01:32 [INFO]	[TRAIN] epoch: 2937, iter: 231980/250000, loss: 0.1460, lr: 0.000938, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6349 samples/sec | ETA 02:49:26
2023-02-05 05:01:38 [INFO]	[TRAIN] epoch: 2937, iter: 231990/250000, loss: 0.1379, lr: 0.000937, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6247 samples/sec | ETA 02:49:30
2023-02-05 05:01:44 [INFO]	[TRAIN] epoch: 2937, iter: 232000/250000, loss: 0.1538, lr: 0.000937, batch_cost: 0.5961, reader_cost: 0.03181, ips: 10.0660 samples/sec | ETA 02:58:49
2023-02-05 05:01:44 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1328 - reader cost: 0.0327 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1540 - reader cost: 0.0164 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1590 - reader cost: 0.0109 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1586 - reader cost: 0.0082 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1596 - reader cost: 0.0066 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1610 - reader cost: 0.0055 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1608 - reader cost: 0.0047 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1612 - reader cost: 0.0041 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1623 - reader cost: 0.003710/36 [=======>......................] - ETA: 4s - batch_cost: 0.1619 - reader cost: 0.003311/36 [========>.....................] - ETA: 4s - batch_cost: 0.1626 - reader cost: 0.003012/36 [=========>....................] - ETA: 3s - batch_cost: 0.1623 - reader cost: 0.002813/36 [=========>....................] - ETA: 3s - batch_cost: 0.1625 - reader cost: 0.002614/36 [==========>...................] - ETA: 3s - batch_cost: 0.1631 - reader cost: 0.002415/36 [===========>..................] - ETA: 3s - batch_cost: 0.1632 - reader cost: 0.002216/36 [============>.................] - ETA: 3s - batch_cost: 0.1640 - reader cost: 0.002117/36 [=============>................] - ETA: 3s - batch_cost: 0.1644 - reader cost: 0.002018/36 [==============>...............] - ETA: 2s - batch_cost: 0.1645 - reader cost: 0.001919/36 [==============>...............] - ETA: 2s - batch_cost: 0.1643 - reader cost: 0.001820/36 [===============>..............] - ETA: 2s - batch_cost: 0.1642 - reader cost: 0.001721/36 [================>.............] - ETA: 2s - batch_cost: 0.1643 - reader cost: 0.001622/36 [=================>............] - ETA: 2s - batch_cost: 0.1646 - reader cost: 0.001623/36 [==================>...........] - ETA: 2s - batch_cost: 0.1653 - reader cost: 0.001524/36 [===================>..........] - ETA: 1s - batch_cost: 0.1653 - reader cost: 0.001425/36 [===================>..........] - ETA: 1s - batch_cost: 0.1654 - reader cost: 0.001426/36 [====================>.........] - ETA: 1s - batch_cost: 0.1655 - reader cost: 0.001327/36 [=====================>........] - ETA: 1s - batch_cost: 0.1657 - reader cost: 0.001328/36 [======================>.......] - ETA: 1s - batch_cost: 0.1660 - reader cost: 0.001229/36 [=======================>......] - ETA: 1s - batch_cost: 0.1661 - reader cost: 0.001230/36 [========================>.....] - ETA: 0s - batch_cost: 0.1660 - reader cost: 0.001231/36 [========================>.....] - ETA: 0s - batch_cost: 0.1660 - reader cost: 0.001132/36 [=========================>....] - ETA: 0s - batch_cost: 0.1659 - reader cost: 0.001133/36 [==========================>...] - ETA: 0s - batch_cost: 0.1658 - reader cost: 0.001134/36 [===========================>..] - ETA: 0s - batch_cost: 0.1656 - reader cost: 0.001035/36 [============================>.] - ETA: 0s - batch_cost: 0.1656 - reader cost: 0.001036/36 [==============================] - 6s 166ms/step - batch_cost: 0.1657 - reader cost: 9.7989e-04
2023-02-05 05:01:50 [INFO]	[EVAL] #Images: 36 mIoU: 0.8648 Acc: 0.9862 Kappa: 0.9498 Dice: 0.9241
2023-02-05 05:01:50 [INFO]	[EVAL] Class IoU: 
[0.9856 0.9114 0.896  0.7112 0.7197 0.9715 0.858 ]
2023-02-05 05:01:50 [INFO]	[EVAL] Class Precision: 
[0.9923 0.9662 0.9448 0.8351 0.8629 0.9812 0.9161]
2023-02-05 05:01:50 [INFO]	[EVAL] Class Recall: 
[0.9932 0.9414 0.9455 0.8274 0.8126 0.9899 0.9311]
2023-02-05 05:01:50 [INFO]	[EVAL] The model with the best validation mIoU (0.8682) was saved at iter 222000.
2023-02-05 05:01:56 [INFO]	[TRAIN] epoch: 2937, iter: 232010/250000, loss: 0.1298, lr: 0.000936, batch_cost: 0.5638, reader_cost: 0.00010, ips: 10.6412 samples/sec | ETA 02:49:03
2023-02-05 05:02:01 [INFO]	[TRAIN] epoch: 2937, iter: 232020/250000, loss: 0.1587, lr: 0.000936, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6387 samples/sec | ETA 02:49:00
2023-02-05 05:02:07 [INFO]	[TRAIN] epoch: 2938, iter: 232030/250000, loss: 0.1430, lr: 0.000935, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6392 samples/sec | ETA 02:48:54
2023-02-05 05:02:12 [INFO]	[TRAIN] epoch: 2938, iter: 232040/250000, loss: 0.1367, lr: 0.000935, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6307 samples/sec | ETA 02:48:56
2023-02-05 05:02:18 [INFO]	[TRAIN] epoch: 2938, iter: 232050/250000, loss: 0.1432, lr: 0.000934, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6410 samples/sec | ETA 02:48:41
2023-02-05 05:02:24 [INFO]	[TRAIN] epoch: 2938, iter: 232060/250000, loss: 0.1500, lr: 0.000934, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6417 samples/sec | ETA 02:48:34
2023-02-05 05:02:29 [INFO]	[TRAIN] epoch: 2938, iter: 232070/250000, loss: 0.1471, lr: 0.000933, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6360 samples/sec | ETA 02:48:34
2023-02-05 05:02:35 [INFO]	[TRAIN] epoch: 2938, iter: 232080/250000, loss: 0.1749, lr: 0.000933, batch_cost: 0.5933, reader_cost: 0.02907, ips: 10.1138 samples/sec | ETA 02:57:11
2023-02-05 05:02:41 [INFO]	[TRAIN] epoch: 2938, iter: 232090/250000, loss: 0.1601, lr: 0.000933, batch_cost: 0.5640, reader_cost: 0.00008, ips: 10.6384 samples/sec | ETA 02:48:21
2023-02-05 05:02:47 [INFO]	[TRAIN] epoch: 2938, iter: 232100/250000, loss: 0.1501, lr: 0.000932, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6388 samples/sec | ETA 02:48:15
2023-02-05 05:02:52 [INFO]	[TRAIN] epoch: 2939, iter: 232110/250000, loss: 0.2642, lr: 0.000932, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6268 samples/sec | ETA 02:48:20
2023-02-05 05:02:58 [INFO]	[TRAIN] epoch: 2939, iter: 232120/250000, loss: 0.2063, lr: 0.000931, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6329 samples/sec | ETA 02:48:09
2023-02-05 05:03:04 [INFO]	[TRAIN] epoch: 2939, iter: 232130/250000, loss: 0.1574, lr: 0.000931, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6375 samples/sec | ETA 02:47:59
2023-02-05 05:03:09 [INFO]	[TRAIN] epoch: 2939, iter: 232140/250000, loss: 0.1899, lr: 0.000930, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6303 samples/sec | ETA 02:48:00
2023-02-05 05:03:15 [INFO]	[TRAIN] epoch: 2939, iter: 232150/250000, loss: 0.1402, lr: 0.000930, batch_cost: 0.5637, reader_cost: 0.00009, ips: 10.6432 samples/sec | ETA 02:47:42
2023-02-05 05:03:21 [INFO]	[TRAIN] epoch: 2939, iter: 232160/250000, loss: 0.1335, lr: 0.000929, batch_cost: 0.5930, reader_cost: 0.02898, ips: 10.1189 samples/sec | ETA 02:56:18
2023-02-05 05:03:26 [INFO]	[TRAIN] epoch: 2939, iter: 232170/250000, loss: 0.1779, lr: 0.000929, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6398 samples/sec | ETA 02:47:34
2023-02-05 05:03:32 [INFO]	[TRAIN] epoch: 2939, iter: 232180/250000, loss: 0.2030, lr: 0.000928, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6332 samples/sec | ETA 02:47:35
2023-02-05 05:03:38 [INFO]	[TRAIN] epoch: 2940, iter: 232190/250000, loss: 0.2158, lr: 0.000928, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6339 samples/sec | ETA 02:47:28
2023-02-05 05:03:43 [INFO]	[TRAIN] epoch: 2940, iter: 232200/250000, loss: 0.1751, lr: 0.000927, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6365 samples/sec | ETA 02:47:20
2023-02-05 05:03:49 [INFO]	[TRAIN] epoch: 2940, iter: 232210/250000, loss: 0.1325, lr: 0.000927, batch_cost: 0.5640, reader_cost: 0.00008, ips: 10.6380 samples/sec | ETA 02:47:13
2023-02-05 05:03:55 [INFO]	[TRAIN] epoch: 2940, iter: 232220/250000, loss: 0.1412, lr: 0.000926, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6364 samples/sec | ETA 02:47:09
2023-02-05 05:04:00 [INFO]	[TRAIN] epoch: 2940, iter: 232230/250000, loss: 0.1977, lr: 0.000926, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6300 samples/sec | ETA 02:47:10
2023-02-05 05:04:06 [INFO]	[TRAIN] epoch: 2940, iter: 232240/250000, loss: 0.1608, lr: 0.000925, batch_cost: 0.5933, reader_cost: 0.02905, ips: 10.1133 samples/sec | ETA 02:55:36
2023-02-05 05:04:12 [INFO]	[TRAIN] epoch: 2940, iter: 232250/250000, loss: 0.1595, lr: 0.000925, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6372 samples/sec | ETA 02:46:52
2023-02-05 05:04:17 [INFO]	[TRAIN] epoch: 2940, iter: 232260/250000, loss: 0.1342, lr: 0.000925, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6379 samples/sec | ETA 02:46:45
2023-02-05 05:04:23 [INFO]	[TRAIN] epoch: 2941, iter: 232270/250000, loss: 0.1513, lr: 0.000924, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6339 samples/sec | ETA 02:46:43
2023-02-05 05:04:29 [INFO]	[TRAIN] epoch: 2941, iter: 232280/250000, loss: 0.1253, lr: 0.000924, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6345 samples/sec | ETA 02:46:37
2023-02-05 05:04:34 [INFO]	[TRAIN] epoch: 2941, iter: 232290/250000, loss: 0.1425, lr: 0.000923, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6372 samples/sec | ETA 02:46:29
2023-02-05 05:04:40 [INFO]	[TRAIN] epoch: 2941, iter: 232300/250000, loss: 0.1446, lr: 0.000923, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6387 samples/sec | ETA 02:46:22
2023-02-05 05:04:46 [INFO]	[TRAIN] epoch: 2941, iter: 232310/250000, loss: 0.1583, lr: 0.000922, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6323 samples/sec | ETA 02:46:22
2023-02-05 05:04:52 [INFO]	[TRAIN] epoch: 2941, iter: 232320/250000, loss: 0.1531, lr: 0.000922, batch_cost: 0.5927, reader_cost: 0.02683, ips: 10.1226 samples/sec | ETA 02:54:39
2023-02-05 05:04:57 [INFO]	[TRAIN] epoch: 2941, iter: 232330/250000, loss: 0.1524, lr: 0.000921, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6419 samples/sec | ETA 02:46:02
2023-02-05 05:05:03 [INFO]	[TRAIN] epoch: 2942, iter: 232340/250000, loss: 0.1592, lr: 0.000921, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6401 samples/sec | ETA 02:45:58
2023-02-05 05:05:09 [INFO]	[TRAIN] epoch: 2942, iter: 232350/250000, loss: 0.2098, lr: 0.000920, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6275 samples/sec | ETA 02:46:04
2023-02-05 05:05:14 [INFO]	[TRAIN] epoch: 2942, iter: 232360/250000, loss: 0.1953, lr: 0.000920, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6298 samples/sec | ETA 02:45:56
2023-02-05 05:05:20 [INFO]	[TRAIN] epoch: 2942, iter: 232370/250000, loss: 0.1514, lr: 0.000919, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6320 samples/sec | ETA 02:45:49
2023-02-05 05:05:25 [INFO]	[TRAIN] epoch: 2942, iter: 232380/250000, loss: 0.1489, lr: 0.000919, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6378 samples/sec | ETA 02:45:38
2023-02-05 05:05:31 [INFO]	[TRAIN] epoch: 2942, iter: 232390/250000, loss: 0.1787, lr: 0.000918, batch_cost: 0.5641, reader_cost: 0.00008, ips: 10.6362 samples/sec | ETA 02:45:33
2023-02-05 05:05:37 [INFO]	[TRAIN] epoch: 2942, iter: 232400/250000, loss: 0.1823, lr: 0.000918, batch_cost: 0.5919, reader_cost: 0.02758, ips: 10.1373 samples/sec | ETA 02:53:37
2023-02-05 05:05:43 [INFO]	[TRAIN] epoch: 2942, iter: 232410/250000, loss: 0.1301, lr: 0.000918, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6423 samples/sec | ETA 02:45:17
2023-02-05 05:05:48 [INFO]	[TRAIN] epoch: 2943, iter: 232420/250000, loss: 0.1181, lr: 0.000917, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6283 samples/sec | ETA 02:45:24
2023-02-05 05:05:54 [INFO]	[TRAIN] epoch: 2943, iter: 232430/250000, loss: 0.1755, lr: 0.000917, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6321 samples/sec | ETA 02:45:15
2023-02-05 05:06:00 [INFO]	[TRAIN] epoch: 2943, iter: 232440/250000, loss: 0.1351, lr: 0.000916, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6320 samples/sec | ETA 02:45:09
2023-02-05 05:06:05 [INFO]	[TRAIN] epoch: 2943, iter: 232450/250000, loss: 0.1514, lr: 0.000916, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6379 samples/sec | ETA 02:44:58
2023-02-05 05:06:11 [INFO]	[TRAIN] epoch: 2943, iter: 232460/250000, loss: 0.1558, lr: 0.000915, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6391 samples/sec | ETA 02:44:51
2023-02-05 05:06:17 [INFO]	[TRAIN] epoch: 2943, iter: 232470/250000, loss: 0.1294, lr: 0.000915, batch_cost: 0.5882, reader_cost: 0.02449, ips: 10.2004 samples/sec | ETA 02:51:51
2023-02-05 05:06:22 [INFO]	[TRAIN] epoch: 2943, iter: 232480/250000, loss: 0.1430, lr: 0.000914, batch_cost: 0.5647, reader_cost: 0.00021, ips: 10.6259 samples/sec | ETA 02:44:52
2023-02-05 05:06:28 [INFO]	[TRAIN] epoch: 2943, iter: 232490/250000, loss: 0.1556, lr: 0.000914, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6304 samples/sec | ETA 02:44:42
2023-02-05 05:06:34 [INFO]	[TRAIN] epoch: 2944, iter: 232500/250000, loss: 0.1509, lr: 0.000913, batch_cost: 0.5636, reader_cost: 0.00010, ips: 10.6454 samples/sec | ETA 02:44:23
2023-02-05 05:06:39 [INFO]	[TRAIN] epoch: 2944, iter: 232510/250000, loss: 0.1311, lr: 0.000913, batch_cost: 0.5632, reader_cost: 0.00009, ips: 10.6529 samples/sec | ETA 02:44:10
2023-02-05 05:06:45 [INFO]	[TRAIN] epoch: 2944, iter: 232520/250000, loss: 0.1239, lr: 0.000912, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6340 samples/sec | ETA 02:44:22
2023-02-05 05:06:51 [INFO]	[TRAIN] epoch: 2944, iter: 232530/250000, loss: 0.1823, lr: 0.000912, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6300 samples/sec | ETA 02:44:20
2023-02-05 05:06:56 [INFO]	[TRAIN] epoch: 2944, iter: 232540/250000, loss: 0.1295, lr: 0.000911, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6322 samples/sec | ETA 02:44:13
2023-02-05 05:07:02 [INFO]	[TRAIN] epoch: 2944, iter: 232550/250000, loss: 0.1492, lr: 0.000911, batch_cost: 0.6000, reader_cost: 0.03599, ips: 10.0001 samples/sec | ETA 02:54:29
2023-02-05 05:07:08 [INFO]	[TRAIN] epoch: 2944, iter: 232560/250000, loss: 0.1229, lr: 0.000910, batch_cost: 0.5644, reader_cost: 0.00013, ips: 10.6302 samples/sec | ETA 02:44:03
2023-02-05 05:07:14 [INFO]	[TRAIN] epoch: 2944, iter: 232570/250000, loss: 0.1354, lr: 0.000910, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6312 samples/sec | ETA 02:43:57
2023-02-05 05:07:19 [INFO]	[TRAIN] epoch: 2945, iter: 232580/250000, loss: 0.1609, lr: 0.000910, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6370 samples/sec | ETA 02:43:46
2023-02-05 05:07:25 [INFO]	[TRAIN] epoch: 2945, iter: 232590/250000, loss: 0.1201, lr: 0.000909, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6337 samples/sec | ETA 02:43:43
2023-02-05 05:07:30 [INFO]	[TRAIN] epoch: 2945, iter: 232600/250000, loss: 0.2033, lr: 0.000909, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6343 samples/sec | ETA 02:43:37
2023-02-05 05:07:36 [INFO]	[TRAIN] epoch: 2945, iter: 232610/250000, loss: 0.1520, lr: 0.000908, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6378 samples/sec | ETA 02:43:28
2023-02-05 05:07:42 [INFO]	[TRAIN] epoch: 2945, iter: 232620/250000, loss: 0.1411, lr: 0.000908, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6366 samples/sec | ETA 02:43:23
2023-02-05 05:07:48 [INFO]	[TRAIN] epoch: 2945, iter: 232630/250000, loss: 0.1400, lr: 0.000907, batch_cost: 0.5994, reader_cost: 0.03455, ips: 10.0108 samples/sec | ETA 02:53:30
2023-02-05 05:07:53 [INFO]	[TRAIN] epoch: 2945, iter: 232640/250000, loss: 0.1509, lr: 0.000907, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6243 samples/sec | ETA 02:43:23
2023-02-05 05:07:59 [INFO]	[TRAIN] epoch: 2945, iter: 232650/250000, loss: 0.1166, lr: 0.000906, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6359 samples/sec | ETA 02:43:07
2023-02-05 05:08:05 [INFO]	[TRAIN] epoch: 2946, iter: 232660/250000, loss: 0.1679, lr: 0.000906, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6351 samples/sec | ETA 02:43:02
2023-02-05 05:08:10 [INFO]	[TRAIN] epoch: 2946, iter: 232670/250000, loss: 0.1642, lr: 0.000905, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6282 samples/sec | ETA 02:43:03
2023-02-05 05:08:16 [INFO]	[TRAIN] epoch: 2946, iter: 232680/250000, loss: 0.1464, lr: 0.000905, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6311 samples/sec | ETA 02:42:55
2023-02-05 05:08:22 [INFO]	[TRAIN] epoch: 2946, iter: 232690/250000, loss: 0.1152, lr: 0.000904, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6305 samples/sec | ETA 02:42:50
2023-02-05 05:08:27 [INFO]	[TRAIN] epoch: 2946, iter: 232700/250000, loss: 0.1395, lr: 0.000904, batch_cost: 0.5635, reader_cost: 0.00008, ips: 10.6469 samples/sec | ETA 02:42:29
2023-02-05 05:08:33 [INFO]	[TRAIN] epoch: 2946, iter: 232710/250000, loss: 0.1562, lr: 0.000903, batch_cost: 0.5950, reader_cost: 0.03066, ips: 10.0842 samples/sec | ETA 02:51:27
2023-02-05 05:08:39 [INFO]	[TRAIN] epoch: 2946, iter: 232720/250000, loss: 0.1612, lr: 0.000903, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6092 samples/sec | ETA 02:42:52
2023-02-05 05:08:44 [INFO]	[TRAIN] epoch: 2946, iter: 232730/250000, loss: 0.1308, lr: 0.000902, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6334 samples/sec | ETA 02:42:24
2023-02-05 05:08:50 [INFO]	[TRAIN] epoch: 2947, iter: 232740/250000, loss: 0.1437, lr: 0.000902, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6301 samples/sec | ETA 02:42:22
2023-02-05 05:08:56 [INFO]	[TRAIN] epoch: 2947, iter: 232750/250000, loss: 0.1365, lr: 0.000902, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6319 samples/sec | ETA 02:42:14
2023-02-05 05:09:01 [INFO]	[TRAIN] epoch: 2947, iter: 232760/250000, loss: 0.1383, lr: 0.000901, batch_cost: 0.5640, reader_cost: 0.00008, ips: 10.6391 samples/sec | ETA 02:42:02
2023-02-05 05:09:07 [INFO]	[TRAIN] epoch: 2947, iter: 232770/250000, loss: 0.1374, lr: 0.000901, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6412 samples/sec | ETA 02:41:55
2023-02-05 05:09:13 [INFO]	[TRAIN] epoch: 2947, iter: 232780/250000, loss: 0.1455, lr: 0.000900, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6325 samples/sec | ETA 02:41:57
2023-02-05 05:09:19 [INFO]	[TRAIN] epoch: 2947, iter: 232790/250000, loss: 0.1426, lr: 0.000900, batch_cost: 0.5944, reader_cost: 0.02988, ips: 10.0945 samples/sec | ETA 02:50:29
2023-02-05 05:09:24 [INFO]	[TRAIN] epoch: 2947, iter: 232800/250000, loss: 0.1562, lr: 0.000899, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6301 samples/sec | ETA 02:41:48
2023-02-05 05:09:30 [INFO]	[TRAIN] epoch: 2947, iter: 232810/250000, loss: 0.1421, lr: 0.000899, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6300 samples/sec | ETA 02:41:42
2023-02-05 05:09:36 [INFO]	[TRAIN] epoch: 2948, iter: 232820/250000, loss: 0.1256, lr: 0.000898, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6355 samples/sec | ETA 02:41:32
2023-02-05 05:09:41 [INFO]	[TRAIN] epoch: 2948, iter: 232830/250000, loss: 0.1417, lr: 0.000898, batch_cost: 0.5639, reader_cost: 0.00008, ips: 10.6404 samples/sec | ETA 02:41:21
2023-02-05 05:09:47 [INFO]	[TRAIN] epoch: 2948, iter: 232840/250000, loss: 0.1617, lr: 0.000897, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6394 samples/sec | ETA 02:41:17
2023-02-05 05:09:52 [INFO]	[TRAIN] epoch: 2948, iter: 232850/250000, loss: 0.1232, lr: 0.000897, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6330 samples/sec | ETA 02:41:17
2023-02-05 05:09:58 [INFO]	[TRAIN] epoch: 2948, iter: 232860/250000, loss: 0.1761, lr: 0.000896, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6293 samples/sec | ETA 02:41:15
2023-02-05 05:10:04 [INFO]	[TRAIN] epoch: 2948, iter: 232870/250000, loss: 0.1716, lr: 0.000896, batch_cost: 0.5899, reader_cost: 0.02552, ips: 10.1711 samples/sec | ETA 02:48:25
2023-02-05 05:10:10 [INFO]	[TRAIN] epoch: 2948, iter: 232880/250000, loss: 0.1148, lr: 0.000895, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6375 samples/sec | ETA 02:40:56
2023-02-05 05:10:15 [INFO]	[TRAIN] epoch: 2948, iter: 232890/250000, loss: 0.1362, lr: 0.000895, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6315 samples/sec | ETA 02:40:56
2023-02-05 05:10:21 [INFO]	[TRAIN] epoch: 2949, iter: 232900/250000, loss: 0.1273, lr: 0.000894, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6331 samples/sec | ETA 02:40:49
2023-02-05 05:10:27 [INFO]	[TRAIN] epoch: 2949, iter: 232910/250000, loss: 0.1641, lr: 0.000894, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6322 samples/sec | ETA 02:40:44
2023-02-05 05:10:32 [INFO]	[TRAIN] epoch: 2949, iter: 232920/250000, loss: 0.1291, lr: 0.000894, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6372 samples/sec | ETA 02:40:34
2023-02-05 05:10:38 [INFO]	[TRAIN] epoch: 2949, iter: 232930/250000, loss: 0.1385, lr: 0.000893, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6415 samples/sec | ETA 02:40:24
2023-02-05 05:10:44 [INFO]	[TRAIN] epoch: 2949, iter: 232940/250000, loss: 0.1404, lr: 0.000893, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6314 samples/sec | ETA 02:40:28
2023-02-05 05:10:50 [INFO]	[TRAIN] epoch: 2949, iter: 232950/250000, loss: 0.1633, lr: 0.000892, batch_cost: 0.6003, reader_cost: 0.03281, ips: 9.9950 samples/sec | ETA 02:50:35
2023-02-05 05:10:55 [INFO]	[TRAIN] epoch: 2949, iter: 232960/250000, loss: 0.1618, lr: 0.000892, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6323 samples/sec | ETA 02:40:16
2023-02-05 05:11:01 [INFO]	[TRAIN] epoch: 2949, iter: 232970/250000, loss: 0.1393, lr: 0.000891, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6400 samples/sec | ETA 02:40:03
2023-02-05 05:11:06 [INFO]	[TRAIN] epoch: 2950, iter: 232980/250000, loss: 0.1543, lr: 0.000891, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6330 samples/sec | ETA 02:40:04
2023-02-05 05:11:12 [INFO]	[TRAIN] epoch: 2950, iter: 232990/250000, loss: 0.1642, lr: 0.000890, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6312 samples/sec | ETA 02:40:00
2023-02-05 05:11:18 [INFO]	[TRAIN] epoch: 2950, iter: 233000/250000, loss: 0.1957, lr: 0.000890, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6259 samples/sec | ETA 02:39:59
2023-02-05 05:11:23 [INFO]	[TRAIN] epoch: 2950, iter: 233010/250000, loss: 0.1483, lr: 0.000889, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6357 samples/sec | ETA 02:39:44
2023-02-05 05:11:29 [INFO]	[TRAIN] epoch: 2950, iter: 233020/250000, loss: 0.1901, lr: 0.000889, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6267 samples/sec | ETA 02:39:47
2023-02-05 05:11:35 [INFO]	[TRAIN] epoch: 2950, iter: 233030/250000, loss: 0.1732, lr: 0.000888, batch_cost: 0.5848, reader_cost: 0.02056, ips: 10.2595 samples/sec | ETA 02:45:24
2023-02-05 05:11:41 [INFO]	[TRAIN] epoch: 2950, iter: 233040/250000, loss: 0.1701, lr: 0.000888, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6351 samples/sec | ETA 02:39:28
2023-02-05 05:11:46 [INFO]	[TRAIN] epoch: 2950, iter: 233050/250000, loss: 0.1501, lr: 0.000887, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6305 samples/sec | ETA 02:39:26
2023-02-05 05:11:52 [INFO]	[TRAIN] epoch: 2951, iter: 233060/250000, loss: 0.1295, lr: 0.000887, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6289 samples/sec | ETA 02:39:22
2023-02-05 05:11:57 [INFO]	[TRAIN] epoch: 2951, iter: 233070/250000, loss: 0.1264, lr: 0.000886, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6350 samples/sec | ETA 02:39:11
2023-02-05 05:12:03 [INFO]	[TRAIN] epoch: 2951, iter: 233080/250000, loss: 0.1361, lr: 0.000886, batch_cost: 0.5642, reader_cost: 0.00008, ips: 10.6353 samples/sec | ETA 02:39:05
2023-02-05 05:12:09 [INFO]	[TRAIN] epoch: 2951, iter: 233090/250000, loss: 0.1419, lr: 0.000886, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6352 samples/sec | ETA 02:39:00
2023-02-05 05:12:14 [INFO]	[TRAIN] epoch: 2951, iter: 233100/250000, loss: 0.1601, lr: 0.000885, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6288 samples/sec | ETA 02:39:00
2023-02-05 05:12:20 [INFO]	[TRAIN] epoch: 2951, iter: 233110/250000, loss: 0.1639, lr: 0.000885, batch_cost: 0.5903, reader_cost: 0.02526, ips: 10.1648 samples/sec | ETA 02:46:09
2023-02-05 05:12:26 [INFO]	[TRAIN] epoch: 2951, iter: 233120/250000, loss: 0.1586, lr: 0.000884, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6328 samples/sec | ETA 02:38:45
2023-02-05 05:12:32 [INFO]	[TRAIN] epoch: 2952, iter: 233130/250000, loss: 0.1569, lr: 0.000884, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6289 samples/sec | ETA 02:38:43
2023-02-05 05:12:37 [INFO]	[TRAIN] epoch: 2952, iter: 233140/250000, loss: 0.1445, lr: 0.000883, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6343 samples/sec | ETA 02:38:32
2023-02-05 05:12:43 [INFO]	[TRAIN] epoch: 2952, iter: 233150/250000, loss: 0.1660, lr: 0.000883, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6312 samples/sec | ETA 02:38:29
2023-02-05 05:12:49 [INFO]	[TRAIN] epoch: 2952, iter: 233160/250000, loss: 0.2214, lr: 0.000882, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6299 samples/sec | ETA 02:38:25
2023-02-05 05:12:54 [INFO]	[TRAIN] epoch: 2952, iter: 233170/250000, loss: 0.1463, lr: 0.000882, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6373 samples/sec | ETA 02:38:13
2023-02-05 05:13:00 [INFO]	[TRAIN] epoch: 2952, iter: 233180/250000, loss: 0.1395, lr: 0.000881, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6350 samples/sec | ETA 02:38:09
2023-02-05 05:13:06 [INFO]	[TRAIN] epoch: 2952, iter: 233190/250000, loss: 0.1356, lr: 0.000881, batch_cost: 0.5919, reader_cost: 0.02779, ips: 10.1375 samples/sec | ETA 02:45:49
2023-02-05 05:13:11 [INFO]	[TRAIN] epoch: 2952, iter: 233200/250000, loss: 0.1250, lr: 0.000880, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6385 samples/sec | ETA 02:37:55
2023-02-05 05:13:17 [INFO]	[TRAIN] epoch: 2953, iter: 233210/250000, loss: 0.1129, lr: 0.000880, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6398 samples/sec | ETA 02:37:48
2023-02-05 05:13:23 [INFO]	[TRAIN] epoch: 2953, iter: 233220/250000, loss: 0.1560, lr: 0.000879, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6235 samples/sec | ETA 02:37:57
2023-02-05 05:13:28 [INFO]	[TRAIN] epoch: 2953, iter: 233230/250000, loss: 0.1336, lr: 0.000879, batch_cost: 0.5646, reader_cost: 0.00008, ips: 10.6276 samples/sec | ETA 02:37:47
2023-02-05 05:13:34 [INFO]	[TRAIN] epoch: 2953, iter: 233240/250000, loss: 0.1431, lr: 0.000878, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6396 samples/sec | ETA 02:37:31
2023-02-05 05:13:40 [INFO]	[TRAIN] epoch: 2953, iter: 233250/250000, loss: 0.1270, lr: 0.000878, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6335 samples/sec | ETA 02:37:31
2023-02-05 05:13:45 [INFO]	[TRAIN] epoch: 2953, iter: 233260/250000, loss: 0.1443, lr: 0.000878, batch_cost: 0.5850, reader_cost: 0.02131, ips: 10.2568 samples/sec | ETA 02:43:12
2023-02-05 05:13:51 [INFO]	[TRAIN] epoch: 2953, iter: 233270/250000, loss: 0.1399, lr: 0.000877, batch_cost: 0.5641, reader_cost: 0.00017, ips: 10.6364 samples/sec | ETA 02:37:17
2023-02-05 05:13:57 [INFO]	[TRAIN] epoch: 2953, iter: 233280/250000, loss: 0.1341, lr: 0.000877, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6293 samples/sec | ETA 02:37:18
2023-02-05 05:14:02 [INFO]	[TRAIN] epoch: 2954, iter: 233290/250000, loss: 0.1186, lr: 0.000876, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6317 samples/sec | ETA 02:37:10
2023-02-05 05:14:08 [INFO]	[TRAIN] epoch: 2954, iter: 233300/250000, loss: 0.1371, lr: 0.000876, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6320 samples/sec | ETA 02:37:04
2023-02-05 05:14:14 [INFO]	[TRAIN] epoch: 2954, iter: 233310/250000, loss: 0.1264, lr: 0.000875, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6401 samples/sec | ETA 02:36:51
2023-02-05 05:14:19 [INFO]	[TRAIN] epoch: 2954, iter: 233320/250000, loss: 0.1522, lr: 0.000875, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6321 samples/sec | ETA 02:36:53
2023-02-05 05:14:25 [INFO]	[TRAIN] epoch: 2954, iter: 233330/250000, loss: 0.1221, lr: 0.000874, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6276 samples/sec | ETA 02:36:51
2023-02-05 05:14:31 [INFO]	[TRAIN] epoch: 2954, iter: 233340/250000, loss: 0.1272, lr: 0.000874, batch_cost: 0.5940, reader_cost: 0.03018, ips: 10.1004 samples/sec | ETA 02:44:56
2023-02-05 05:14:37 [INFO]	[TRAIN] epoch: 2954, iter: 233350/250000, loss: 0.1253, lr: 0.000873, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6306 samples/sec | ETA 02:36:37
2023-02-05 05:14:42 [INFO]	[TRAIN] epoch: 2954, iter: 233360/250000, loss: 0.1804, lr: 0.000873, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6277 samples/sec | ETA 02:36:34
2023-02-05 05:14:48 [INFO]	[TRAIN] epoch: 2955, iter: 233370/250000, loss: 0.1421, lr: 0.000872, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6266 samples/sec | ETA 02:36:29
2023-02-05 05:14:53 [INFO]	[TRAIN] epoch: 2955, iter: 233380/250000, loss: 0.1457, lr: 0.000872, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6339 samples/sec | ETA 02:36:17
2023-02-05 05:14:59 [INFO]	[TRAIN] epoch: 2955, iter: 233390/250000, loss: 0.1867, lr: 0.000871, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6254 samples/sec | ETA 02:36:19
2023-02-05 05:15:05 [INFO]	[TRAIN] epoch: 2955, iter: 233400/250000, loss: 0.1482, lr: 0.000871, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6301 samples/sec | ETA 02:36:09
2023-02-05 05:15:10 [INFO]	[TRAIN] epoch: 2955, iter: 233410/250000, loss: 0.1423, lr: 0.000870, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6401 samples/sec | ETA 02:35:55
2023-02-05 05:15:16 [INFO]	[TRAIN] epoch: 2955, iter: 233420/250000, loss: 0.1708, lr: 0.000870, batch_cost: 0.5954, reader_cost: 0.03069, ips: 10.0780 samples/sec | ETA 02:44:30
2023-02-05 05:15:22 [INFO]	[TRAIN] epoch: 2955, iter: 233430/250000, loss: 0.1262, lr: 0.000869, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6361 samples/sec | ETA 02:35:47
2023-02-05 05:15:28 [INFO]	[TRAIN] epoch: 2955, iter: 233440/250000, loss: 0.1424, lr: 0.000869, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6406 samples/sec | ETA 02:35:37
2023-02-05 05:15:33 [INFO]	[TRAIN] epoch: 2956, iter: 233450/250000, loss: 0.1260, lr: 0.000869, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6375 samples/sec | ETA 02:35:34
2023-02-05 05:15:39 [INFO]	[TRAIN] epoch: 2956, iter: 233460/250000, loss: 0.1773, lr: 0.000868, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6297 samples/sec | ETA 02:35:36
2023-02-05 05:15:45 [INFO]	[TRAIN] epoch: 2956, iter: 233470/250000, loss: 0.1522, lr: 0.000868, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6300 samples/sec | ETA 02:35:30
2023-02-05 05:15:50 [INFO]	[TRAIN] epoch: 2956, iter: 233480/250000, loss: 0.1527, lr: 0.000867, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6346 samples/sec | ETA 02:35:20
2023-02-05 05:15:56 [INFO]	[TRAIN] epoch: 2956, iter: 233490/250000, loss: 0.1208, lr: 0.000867, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6340 samples/sec | ETA 02:35:15
2023-02-05 05:16:02 [INFO]	[TRAIN] epoch: 2956, iter: 233500/250000, loss: 0.1246, lr: 0.000866, batch_cost: 0.6009, reader_cost: 0.03609, ips: 9.9852 samples/sec | ETA 02:45:14
2023-02-05 05:16:07 [INFO]	[TRAIN] epoch: 2956, iter: 233510/250000, loss: 0.1443, lr: 0.000866, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6260 samples/sec | ETA 02:35:11
2023-02-05 05:16:13 [INFO]	[TRAIN] epoch: 2956, iter: 233520/250000, loss: 0.1316, lr: 0.000865, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6318 samples/sec | ETA 02:35:00
2023-02-05 05:16:19 [INFO]	[TRAIN] epoch: 2957, iter: 233530/250000, loss: 0.1656, lr: 0.000865, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6385 samples/sec | ETA 02:34:48
2023-02-05 05:16:24 [INFO]	[TRAIN] epoch: 2957, iter: 233540/250000, loss: 0.1150, lr: 0.000864, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6289 samples/sec | ETA 02:34:51
2023-02-05 05:16:30 [INFO]	[TRAIN] epoch: 2957, iter: 233550/250000, loss: 0.1164, lr: 0.000864, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6280 samples/sec | ETA 02:34:46
2023-02-05 05:16:36 [INFO]	[TRAIN] epoch: 2957, iter: 233560/250000, loss: 0.1466, lr: 0.000863, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6300 samples/sec | ETA 02:34:39
2023-02-05 05:16:41 [INFO]	[TRAIN] epoch: 2957, iter: 233570/250000, loss: 0.1384, lr: 0.000863, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6341 samples/sec | ETA 02:34:30
2023-02-05 05:16:47 [INFO]	[TRAIN] epoch: 2957, iter: 233580/250000, loss: 0.1597, lr: 0.000862, batch_cost: 0.5900, reader_cost: 0.02595, ips: 10.1697 samples/sec | ETA 02:41:27
2023-02-05 05:16:53 [INFO]	[TRAIN] epoch: 2957, iter: 233590/250000, loss: 0.1676, lr: 0.000862, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6167 samples/sec | ETA 02:34:34
2023-02-05 05:16:59 [INFO]	[TRAIN] epoch: 2957, iter: 233600/250000, loss: 0.1350, lr: 0.000861, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6286 samples/sec | ETA 02:34:18
2023-02-05 05:17:04 [INFO]	[TRAIN] epoch: 2958, iter: 233610/250000, loss: 0.1457, lr: 0.000861, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6278 samples/sec | ETA 02:34:13
2023-02-05 05:17:10 [INFO]	[TRAIN] epoch: 2958, iter: 233620/250000, loss: 0.1217, lr: 0.000861, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6354 samples/sec | ETA 02:34:00
2023-02-05 05:17:15 [INFO]	[TRAIN] epoch: 2958, iter: 233630/250000, loss: 0.1378, lr: 0.000860, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6358 samples/sec | ETA 02:33:54
2023-02-05 05:17:21 [INFO]	[TRAIN] epoch: 2958, iter: 233640/250000, loss: 0.1243, lr: 0.000860, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6228 samples/sec | ETA 02:34:00
2023-02-05 05:17:27 [INFO]	[TRAIN] epoch: 2958, iter: 233650/250000, loss: 0.1420, lr: 0.000859, batch_cost: 0.5647, reader_cost: 0.00014, ips: 10.6247 samples/sec | ETA 02:33:53
2023-02-05 05:17:33 [INFO]	[TRAIN] epoch: 2958, iter: 233660/250000, loss: 0.1257, lr: 0.000859, batch_cost: 0.5890, reader_cost: 0.02463, ips: 10.1863 samples/sec | ETA 02:40:24
2023-02-05 05:17:38 [INFO]	[TRAIN] epoch: 2958, iter: 233670/250000, loss: 0.1664, lr: 0.000858, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6286 samples/sec | ETA 02:33:38
2023-02-05 05:17:44 [INFO]	[TRAIN] epoch: 2958, iter: 233680/250000, loss: 0.1346, lr: 0.000858, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6289 samples/sec | ETA 02:33:32
2023-02-05 05:17:50 [INFO]	[TRAIN] epoch: 2959, iter: 233690/250000, loss: 0.1678, lr: 0.000857, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6332 samples/sec | ETA 02:33:23
2023-02-05 05:17:55 [INFO]	[TRAIN] epoch: 2959, iter: 233700/250000, loss: 0.1338, lr: 0.000857, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6370 samples/sec | ETA 02:33:14
2023-02-05 05:18:01 [INFO]	[TRAIN] epoch: 2959, iter: 233710/250000, loss: 0.1489, lr: 0.000856, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6319 samples/sec | ETA 02:33:13
2023-02-05 05:18:07 [INFO]	[TRAIN] epoch: 2959, iter: 233720/250000, loss: 0.1907, lr: 0.000856, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6334 samples/sec | ETA 02:33:06
2023-02-05 05:18:12 [INFO]	[TRAIN] epoch: 2959, iter: 233730/250000, loss: 0.1371, lr: 0.000855, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6366 samples/sec | ETA 02:32:57
2023-02-05 05:18:18 [INFO]	[TRAIN] epoch: 2959, iter: 233740/250000, loss: 0.1685, lr: 0.000855, batch_cost: 0.5934, reader_cost: 0.02954, ips: 10.1115 samples/sec | ETA 02:40:48
2023-02-05 05:18:24 [INFO]	[TRAIN] epoch: 2959, iter: 233750/250000, loss: 0.1560, lr: 0.000854, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6273 samples/sec | ETA 02:32:54
2023-02-05 05:18:29 [INFO]	[TRAIN] epoch: 2959, iter: 233760/250000, loss: 0.1713, lr: 0.000854, batch_cost: 0.5642, reader_cost: 0.00008, ips: 10.6340 samples/sec | ETA 02:32:43
2023-02-05 05:18:35 [INFO]	[TRAIN] epoch: 2960, iter: 233770/250000, loss: 0.1962, lr: 0.000853, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6366 samples/sec | ETA 02:32:35
2023-02-05 05:18:41 [INFO]	[TRAIN] epoch: 2960, iter: 233780/250000, loss: 0.1280, lr: 0.000853, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6356 samples/sec | ETA 02:32:30
2023-02-05 05:18:46 [INFO]	[TRAIN] epoch: 2960, iter: 233790/250000, loss: 0.2241, lr: 0.000852, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6275 samples/sec | ETA 02:32:31
2023-02-05 05:18:52 [INFO]	[TRAIN] epoch: 2960, iter: 233800/250000, loss: 0.2531, lr: 0.000852, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6321 samples/sec | ETA 02:32:22
2023-02-05 05:18:58 [INFO]	[TRAIN] epoch: 2960, iter: 233810/250000, loss: 0.1876, lr: 0.000852, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6282 samples/sec | ETA 02:32:19
2023-02-05 05:19:04 [INFO]	[TRAIN] epoch: 2960, iter: 233820/250000, loss: 0.1488, lr: 0.000851, batch_cost: 0.5907, reader_cost: 0.02587, ips: 10.1570 samples/sec | ETA 02:39:17
2023-02-05 05:19:09 [INFO]	[TRAIN] epoch: 2960, iter: 233830/250000, loss: 0.1337, lr: 0.000851, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6363 samples/sec | ETA 02:32:01
2023-02-05 05:19:15 [INFO]	[TRAIN] epoch: 2960, iter: 233840/250000, loss: 0.2064, lr: 0.000850, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6357 samples/sec | ETA 02:31:56
2023-02-05 05:19:20 [INFO]	[TRAIN] epoch: 2961, iter: 233850/250000, loss: 0.1752, lr: 0.000850, batch_cost: 0.5640, reader_cost: 0.00008, ips: 10.6374 samples/sec | ETA 02:31:49
2023-02-05 05:19:26 [INFO]	[TRAIN] epoch: 2961, iter: 233860/250000, loss: 0.1346, lr: 0.000849, batch_cost: 0.5642, reader_cost: 0.00008, ips: 10.6354 samples/sec | ETA 02:31:45
2023-02-05 05:19:32 [INFO]	[TRAIN] epoch: 2961, iter: 233870/250000, loss: 0.1565, lr: 0.000849, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6286 samples/sec | ETA 02:31:45
2023-02-05 05:19:37 [INFO]	[TRAIN] epoch: 2961, iter: 233880/250000, loss: 0.1399, lr: 0.000848, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6311 samples/sec | ETA 02:31:37
2023-02-05 05:19:43 [INFO]	[TRAIN] epoch: 2961, iter: 233890/250000, loss: 0.1507, lr: 0.000848, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6321 samples/sec | ETA 02:31:31
2023-02-05 05:19:49 [INFO]	[TRAIN] epoch: 2961, iter: 233900/250000, loss: 0.1518, lr: 0.000847, batch_cost: 0.6008, reader_cost: 0.03653, ips: 9.9875 samples/sec | ETA 02:41:12
2023-02-05 05:19:55 [INFO]	[TRAIN] epoch: 2961, iter: 233910/250000, loss: 0.1284, lr: 0.000847, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6333 samples/sec | ETA 02:31:19
2023-02-05 05:20:00 [INFO]	[TRAIN] epoch: 2962, iter: 233920/250000, loss: 0.1548, lr: 0.000846, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6264 samples/sec | ETA 02:31:19
2023-02-05 05:20:06 [INFO]	[TRAIN] epoch: 2962, iter: 233930/250000, loss: 0.1557, lr: 0.000846, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6312 samples/sec | ETA 02:31:09
2023-02-05 05:20:12 [INFO]	[TRAIN] epoch: 2962, iter: 233940/250000, loss: 0.1312, lr: 0.000845, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6073 samples/sec | ETA 02:31:24
2023-02-05 05:20:17 [INFO]	[TRAIN] epoch: 2962, iter: 233950/250000, loss: 0.1278, lr: 0.000845, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6073 samples/sec | ETA 02:31:18
2023-02-05 05:20:23 [INFO]	[TRAIN] epoch: 2962, iter: 233960/250000, loss: 0.1432, lr: 0.000844, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6086 samples/sec | ETA 02:31:11
2023-02-05 05:20:29 [INFO]	[TRAIN] epoch: 2962, iter: 233970/250000, loss: 0.1289, lr: 0.000844, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6169 samples/sec | ETA 02:30:59
2023-02-05 05:20:35 [INFO]	[TRAIN] epoch: 2962, iter: 233980/250000, loss: 0.1897, lr: 0.000843, batch_cost: 0.5954, reader_cost: 0.03145, ips: 10.0779 samples/sec | ETA 02:38:57
2023-02-05 05:20:40 [INFO]	[TRAIN] epoch: 2962, iter: 233990/250000, loss: 0.1466, lr: 0.000843, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6260 samples/sec | ETA 02:30:40
2023-02-05 05:20:46 [INFO]	[TRAIN] epoch: 2963, iter: 234000/250000, loss: 0.1285, lr: 0.000843, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6217 samples/sec | ETA 02:30:38
2023-02-05 05:20:46 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1338 - reader cost: 0.0357 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1536 - reader cost: 0.0179 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1589 - reader cost: 0.0119 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1592 - reader cost: 0.0090 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1596 - reader cost: 0.0072 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1612 - reader cost: 0.0060 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1609 - reader cost: 0.0052 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1615 - reader cost: 0.0045 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1620 - reader cost: 0.004010/36 [=======>......................] - ETA: 4s - batch_cost: 0.1617 - reader cost: 0.003611/36 [========>.....................] - ETA: 4s - batch_cost: 0.1623 - reader cost: 0.003312/36 [=========>....................] - ETA: 3s - batch_cost: 0.1621 - reader cost: 0.003013/36 [=========>....................] - ETA: 3s - batch_cost: 0.1621 - reader cost: 0.002814/36 [==========>...................] - ETA: 3s - batch_cost: 0.1624 - reader cost: 0.002615/36 [===========>..................] - ETA: 3s - batch_cost: 0.1625 - reader cost: 0.002416/36 [============>.................] - ETA: 3s - batch_cost: 0.1633 - reader cost: 0.002317/36 [=============>................] - ETA: 3s - batch_cost: 0.1635 - reader cost: 0.002218/36 [==============>...............] - ETA: 2s - batch_cost: 0.1635 - reader cost: 0.002119/36 [==============>...............] - ETA: 2s - batch_cost: 0.1631 - reader cost: 0.001920/36 [===============>..............] - ETA: 2s - batch_cost: 0.1631 - reader cost: 0.001921/36 [================>.............] - ETA: 2s - batch_cost: 0.1631 - reader cost: 0.001822/36 [=================>............] - ETA: 2s - batch_cost: 0.1633 - reader cost: 0.001723/36 [==================>...........] - ETA: 2s - batch_cost: 0.1638 - reader cost: 0.001624/36 [===================>..........] - ETA: 1s - batch_cost: 0.1638 - reader cost: 0.001625/36 [===================>..........] - ETA: 1s - batch_cost: 0.1640 - reader cost: 0.001526/36 [====================>.........] - ETA: 1s - batch_cost: 0.1642 - reader cost: 0.001427/36 [=====================>........] - ETA: 1s - batch_cost: 0.1645 - reader cost: 0.001428/36 [======================>.......] - ETA: 1s - batch_cost: 0.1647 - reader cost: 0.001329/36 [=======================>......] - ETA: 1s - batch_cost: 0.1649 - reader cost: 0.001330/36 [========================>.....] - ETA: 0s - batch_cost: 0.1649 - reader cost: 0.001331/36 [========================>.....] - ETA: 0s - batch_cost: 0.1650 - reader cost: 0.001232/36 [=========================>....] - ETA: 0s - batch_cost: 0.1649 - reader cost: 0.001233/36 [==========================>...] - ETA: 0s - batch_cost: 0.1647 - reader cost: 0.001234/36 [===========================>..] - ETA: 0s - batch_cost: 0.1645 - reader cost: 0.001135/36 [============================>.] - ETA: 0s - batch_cost: 0.1647 - reader cost: 0.001136/36 [==============================] - 6s 165ms/step - batch_cost: 0.1649 - reader cost: 0.0011
2023-02-05 05:20:52 [INFO]	[EVAL] #Images: 36 mIoU: 0.8656 Acc: 0.9867 Kappa: 0.9520 Dice: 0.9242
2023-02-05 05:20:52 [INFO]	[EVAL] Class IoU: 
[0.9861 0.922  0.8966 0.7062 0.7019 0.9673 0.8791]
2023-02-05 05:20:52 [INFO]	[EVAL] Class Precision: 
[0.9935 0.9643 0.9462 0.8267 0.8268 0.9763 0.9145]
2023-02-05 05:20:52 [INFO]	[EVAL] Class Recall: 
[0.9925 0.9546 0.9448 0.8289 0.8229 0.9905 0.9578]
2023-02-05 05:20:52 [INFO]	[EVAL] The model with the best validation mIoU (0.8682) was saved at iter 222000.
2023-02-05 05:20:58 [INFO]	[TRAIN] epoch: 2963, iter: 234010/250000, loss: 0.1610, lr: 0.000842, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6179 samples/sec | ETA 02:30:35
2023-02-05 05:21:03 [INFO]	[TRAIN] epoch: 2963, iter: 234020/250000, loss: 0.1296, lr: 0.000842, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6304 samples/sec | ETA 02:30:19
2023-02-05 05:21:09 [INFO]	[TRAIN] epoch: 2963, iter: 234030/250000, loss: 0.1752, lr: 0.000841, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6374 samples/sec | ETA 02:30:07
2023-02-05 05:21:15 [INFO]	[TRAIN] epoch: 2963, iter: 234040/250000, loss: 0.1385, lr: 0.000841, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6289 samples/sec | ETA 02:30:09
2023-02-05 05:21:21 [INFO]	[TRAIN] epoch: 2963, iter: 234050/250000, loss: 0.1466, lr: 0.000840, batch_cost: 0.5944, reader_cost: 0.03013, ips: 10.0946 samples/sec | ETA 02:38:00
2023-02-05 05:21:26 [INFO]	[TRAIN] epoch: 2963, iter: 234060/250000, loss: 0.1286, lr: 0.000840, batch_cost: 0.5660, reader_cost: 0.00022, ips: 10.6006 samples/sec | ETA 02:30:22
2023-02-05 05:21:32 [INFO]	[TRAIN] epoch: 2963, iter: 234070/250000, loss: 0.1611, lr: 0.000839, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6245 samples/sec | ETA 02:29:56
2023-02-05 05:21:37 [INFO]	[TRAIN] epoch: 2964, iter: 234080/250000, loss: 0.1383, lr: 0.000839, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6255 samples/sec | ETA 02:29:49
2023-02-05 05:21:43 [INFO]	[TRAIN] epoch: 2964, iter: 234090/250000, loss: 0.1532, lr: 0.000838, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6112 samples/sec | ETA 02:29:56
2023-02-05 05:21:49 [INFO]	[TRAIN] epoch: 2964, iter: 234100/250000, loss: 0.1446, lr: 0.000838, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6113 samples/sec | ETA 02:29:50
2023-02-05 05:21:54 [INFO]	[TRAIN] epoch: 2964, iter: 234110/250000, loss: 0.1395, lr: 0.000837, batch_cost: 0.5657, reader_cost: 0.00011, ips: 10.6061 samples/sec | ETA 02:29:49
2023-02-05 05:22:00 [INFO]	[TRAIN] epoch: 2964, iter: 234120/250000, loss: 0.1365, lr: 0.000837, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6158 samples/sec | ETA 02:29:35
2023-02-05 05:22:06 [INFO]	[TRAIN] epoch: 2964, iter: 234130/250000, loss: 0.1262, lr: 0.000836, batch_cost: 0.5877, reader_cost: 0.02240, ips: 10.2101 samples/sec | ETA 02:35:26
2023-02-05 05:22:12 [INFO]	[TRAIN] epoch: 2964, iter: 234140/250000, loss: 0.1564, lr: 0.000836, batch_cost: 0.5646, reader_cost: 0.00018, ips: 10.6264 samples/sec | ETA 02:29:15
2023-02-05 05:22:17 [INFO]	[TRAIN] epoch: 2964, iter: 234150/250000, loss: 0.1176, lr: 0.000835, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6258 samples/sec | ETA 02:29:09
2023-02-05 05:22:23 [INFO]	[TRAIN] epoch: 2965, iter: 234160/250000, loss: 0.1321, lr: 0.000835, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6288 samples/sec | ETA 02:29:01
2023-02-05 05:22:29 [INFO]	[TRAIN] epoch: 2965, iter: 234170/250000, loss: 0.1268, lr: 0.000834, batch_cost: 0.5648, reader_cost: 0.00008, ips: 10.6240 samples/sec | ETA 02:29:00
2023-02-05 05:22:34 [INFO]	[TRAIN] epoch: 2965, iter: 234180/250000, loss: 0.1375, lr: 0.000834, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6130 samples/sec | ETA 02:29:03
2023-02-05 05:22:40 [INFO]	[TRAIN] epoch: 2965, iter: 234190/250000, loss: 0.1416, lr: 0.000834, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6081 samples/sec | ETA 02:29:02
2023-02-05 05:22:46 [INFO]	[TRAIN] epoch: 2965, iter: 234200/250000, loss: 0.1290, lr: 0.000833, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6044 samples/sec | ETA 02:28:59
2023-02-05 05:22:52 [INFO]	[TRAIN] epoch: 2965, iter: 234210/250000, loss: 0.1402, lr: 0.000833, batch_cost: 0.5964, reader_cost: 0.03167, ips: 10.0604 samples/sec | ETA 02:36:57
2023-02-05 05:22:57 [INFO]	[TRAIN] epoch: 2965, iter: 234220/250000, loss: 0.1258, lr: 0.000832, batch_cost: 0.5649, reader_cost: 0.00016, ips: 10.6208 samples/sec | ETA 02:28:34
2023-02-05 05:23:03 [INFO]	[TRAIN] epoch: 2965, iter: 234230/250000, loss: 0.1927, lr: 0.000832, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6356 samples/sec | ETA 02:28:16
2023-02-05 05:23:08 [INFO]	[TRAIN] epoch: 2966, iter: 234240/250000, loss: 0.1269, lr: 0.000831, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6207 samples/sec | ETA 02:28:23
2023-02-05 05:23:14 [INFO]	[TRAIN] epoch: 2966, iter: 234250/250000, loss: 0.1435, lr: 0.000831, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6094 samples/sec | ETA 02:28:27
2023-02-05 05:23:20 [INFO]	[TRAIN] epoch: 2966, iter: 234260/250000, loss: 0.1787, lr: 0.000830, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6035 samples/sec | ETA 02:28:26
2023-02-05 05:23:25 [INFO]	[TRAIN] epoch: 2966, iter: 234270/250000, loss: 0.1368, lr: 0.000830, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6222 samples/sec | ETA 02:28:05
2023-02-05 05:23:31 [INFO]	[TRAIN] epoch: 2966, iter: 234280/250000, loss: 0.1390, lr: 0.000829, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6031 samples/sec | ETA 02:28:15
2023-02-05 05:23:37 [INFO]	[TRAIN] epoch: 2966, iter: 234290/250000, loss: 0.2050, lr: 0.000829, batch_cost: 0.5898, reader_cost: 0.02434, ips: 10.1737 samples/sec | ETA 02:34:25
2023-02-05 05:23:43 [INFO]	[TRAIN] epoch: 2966, iter: 234300/250000, loss: 0.1571, lr: 0.000828, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6289 samples/sec | ETA 02:27:42
2023-02-05 05:23:48 [INFO]	[TRAIN] epoch: 2966, iter: 234310/250000, loss: 0.1671, lr: 0.000828, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6410 samples/sec | ETA 02:27:26
2023-02-05 05:23:54 [INFO]	[TRAIN] epoch: 2967, iter: 234320/250000, loss: 0.1465, lr: 0.000827, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6350 samples/sec | ETA 02:27:26
2023-02-05 05:24:00 [INFO]	[TRAIN] epoch: 2967, iter: 234330/250000, loss: 0.1674, lr: 0.000827, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6337 samples/sec | ETA 02:27:21
2023-02-05 05:24:05 [INFO]	[TRAIN] epoch: 2967, iter: 234340/250000, loss: 0.1439, lr: 0.000826, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6266 samples/sec | ETA 02:27:21
2023-02-05 05:24:11 [INFO]	[TRAIN] epoch: 2967, iter: 234350/250000, loss: 0.1319, lr: 0.000826, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6061 samples/sec | ETA 02:27:33
2023-02-05 05:24:16 [INFO]	[TRAIN] epoch: 2967, iter: 234360/250000, loss: 0.1502, lr: 0.000825, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6125 samples/sec | ETA 02:27:22
2023-02-05 05:24:22 [INFO]	[TRAIN] epoch: 2967, iter: 234370/250000, loss: 0.1139, lr: 0.000825, batch_cost: 0.5932, reader_cost: 0.02808, ips: 10.1151 samples/sec | ETA 02:34:31
2023-02-05 05:24:28 [INFO]	[TRAIN] epoch: 2967, iter: 234380/250000, loss: 0.1490, lr: 0.000825, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6303 samples/sec | ETA 02:26:56
2023-02-05 05:24:34 [INFO]	[TRAIN] epoch: 2967, iter: 234390/250000, loss: 0.1362, lr: 0.000824, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6204 samples/sec | ETA 02:26:58
2023-02-05 05:24:39 [INFO]	[TRAIN] epoch: 2968, iter: 234400/250000, loss: 0.1356, lr: 0.000824, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6023 samples/sec | ETA 02:27:08
2023-02-05 05:24:45 [INFO]	[TRAIN] epoch: 2968, iter: 234410/250000, loss: 0.1294, lr: 0.000823, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6073 samples/sec | ETA 02:26:58
2023-02-05 05:24:51 [INFO]	[TRAIN] epoch: 2968, iter: 234420/250000, loss: 0.2633, lr: 0.000823, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6065 samples/sec | ETA 02:26:53
2023-02-05 05:24:56 [INFO]	[TRAIN] epoch: 2968, iter: 234430/250000, loss: 0.1570, lr: 0.000822, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6049 samples/sec | ETA 02:26:49
2023-02-05 05:25:02 [INFO]	[TRAIN] epoch: 2968, iter: 234440/250000, loss: 0.1551, lr: 0.000822, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6100 samples/sec | ETA 02:26:39
2023-02-05 05:25:08 [INFO]	[TRAIN] epoch: 2968, iter: 234450/250000, loss: 0.1715, lr: 0.000821, batch_cost: 0.5986, reader_cost: 0.03049, ips: 10.0240 samples/sec | ETA 02:35:07
2023-02-05 05:25:14 [INFO]	[TRAIN] epoch: 2968, iter: 234460/250000, loss: 0.1519, lr: 0.000821, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6294 samples/sec | ETA 02:26:11
2023-02-05 05:25:19 [INFO]	[TRAIN] epoch: 2968, iter: 234470/250000, loss: 0.1625, lr: 0.000820, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6283 samples/sec | ETA 02:26:07
2023-02-05 05:25:25 [INFO]	[TRAIN] epoch: 2969, iter: 234480/250000, loss: 0.1421, lr: 0.000820, batch_cost: 0.5642, reader_cost: 0.00008, ips: 10.6354 samples/sec | ETA 02:25:55
2023-02-05 05:25:31 [INFO]	[TRAIN] epoch: 2969, iter: 234490/250000, loss: 0.1588, lr: 0.000819, batch_cost: 0.5640, reader_cost: 0.00008, ips: 10.6378 samples/sec | ETA 02:25:48
2023-02-05 05:25:36 [INFO]	[TRAIN] epoch: 2969, iter: 234500/250000, loss: 0.1140, lr: 0.000819, batch_cost: 0.5648, reader_cost: 0.00008, ips: 10.6235 samples/sec | ETA 02:25:54
2023-02-05 05:25:42 [INFO]	[TRAIN] epoch: 2969, iter: 234510/250000, loss: 0.1543, lr: 0.000818, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6050 samples/sec | ETA 02:26:03
2023-02-05 05:25:48 [INFO]	[TRAIN] epoch: 2969, iter: 234520/250000, loss: 0.1361, lr: 0.000818, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5991 samples/sec | ETA 02:26:03
2023-02-05 05:25:53 [INFO]	[TRAIN] epoch: 2969, iter: 234530/250000, loss: 0.1693, lr: 0.000817, batch_cost: 0.5866, reader_cost: 0.02251, ips: 10.2278 samples/sec | ETA 02:31:15
2023-02-05 05:25:59 [INFO]	[TRAIN] epoch: 2969, iter: 234540/250000, loss: 0.1389, lr: 0.000817, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6133 samples/sec | ETA 02:25:39
2023-02-05 05:26:05 [INFO]	[TRAIN] epoch: 2969, iter: 234550/250000, loss: 0.1542, lr: 0.000816, batch_cost: 0.5657, reader_cost: 0.00011, ips: 10.6065 samples/sec | ETA 02:25:39
2023-02-05 05:26:10 [INFO]	[TRAIN] epoch: 2970, iter: 234560/250000, loss: 0.1851, lr: 0.000816, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6094 samples/sec | ETA 02:25:31
2023-02-05 05:26:16 [INFO]	[TRAIN] epoch: 2970, iter: 234570/250000, loss: 0.1786, lr: 0.000815, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6120 samples/sec | ETA 02:25:24
2023-02-05 05:26:22 [INFO]	[TRAIN] epoch: 2970, iter: 234580/250000, loss: 0.1731, lr: 0.000815, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6045 samples/sec | ETA 02:25:24
2023-02-05 05:26:27 [INFO]	[TRAIN] epoch: 2970, iter: 234590/250000, loss: 0.1317, lr: 0.000815, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6073 samples/sec | ETA 02:25:16
2023-02-05 05:26:33 [INFO]	[TRAIN] epoch: 2970, iter: 234600/250000, loss: 0.1460, lr: 0.000814, batch_cost: 0.5652, reader_cost: 0.00008, ips: 10.6153 samples/sec | ETA 02:25:04
2023-02-05 05:26:39 [INFO]	[TRAIN] epoch: 2970, iter: 234610/250000, loss: 0.1534, lr: 0.000814, batch_cost: 0.5906, reader_cost: 0.02584, ips: 10.1590 samples/sec | ETA 02:31:29
2023-02-05 05:26:45 [INFO]	[TRAIN] epoch: 2970, iter: 234620/250000, loss: 0.1344, lr: 0.000813, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6288 samples/sec | ETA 02:24:42
2023-02-05 05:26:50 [INFO]	[TRAIN] epoch: 2970, iter: 234630/250000, loss: 0.1638, lr: 0.000813, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6092 samples/sec | ETA 02:24:52
2023-02-05 05:26:56 [INFO]	[TRAIN] epoch: 2971, iter: 234640/250000, loss: 0.1402, lr: 0.000812, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6015 samples/sec | ETA 02:24:53
2023-02-05 05:27:02 [INFO]	[TRAIN] epoch: 2971, iter: 234650/250000, loss: 0.1550, lr: 0.000812, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6131 samples/sec | ETA 02:24:37
2023-02-05 05:27:07 [INFO]	[TRAIN] epoch: 2971, iter: 234660/250000, loss: 0.1564, lr: 0.000811, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6094 samples/sec | ETA 02:24:35
2023-02-05 05:27:13 [INFO]	[TRAIN] epoch: 2971, iter: 234670/250000, loss: 0.1972, lr: 0.000811, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6066 samples/sec | ETA 02:24:31
2023-02-05 05:27:18 [INFO]	[TRAIN] epoch: 2971, iter: 234680/250000, loss: 0.1518, lr: 0.000810, batch_cost: 0.5650, reader_cost: 0.00008, ips: 10.6193 samples/sec | ETA 02:24:15
2023-02-05 05:27:24 [INFO]	[TRAIN] epoch: 2971, iter: 234690/250000, loss: 0.1711, lr: 0.000810, batch_cost: 0.5933, reader_cost: 0.02845, ips: 10.1133 samples/sec | ETA 02:31:23
2023-02-05 05:27:30 [INFO]	[TRAIN] epoch: 2971, iter: 234700/250000, loss: 0.1483, lr: 0.000809, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6119 samples/sec | ETA 02:24:10
2023-02-05 05:27:36 [INFO]	[TRAIN] epoch: 2972, iter: 234710/250000, loss: 0.1904, lr: 0.000809, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6116 samples/sec | ETA 02:24:05
2023-02-05 05:27:41 [INFO]	[TRAIN] epoch: 2972, iter: 234720/250000, loss: 0.1629, lr: 0.000808, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6143 samples/sec | ETA 02:23:57
2023-02-05 05:27:47 [INFO]	[TRAIN] epoch: 2972, iter: 234730/250000, loss: 0.1704, lr: 0.000808, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6067 samples/sec | ETA 02:23:57
2023-02-05 05:27:53 [INFO]	[TRAIN] epoch: 2972, iter: 234740/250000, loss: 0.1614, lr: 0.000807, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6183 samples/sec | ETA 02:23:42
2023-02-05 05:27:58 [INFO]	[TRAIN] epoch: 2972, iter: 234750/250000, loss: 0.1527, lr: 0.000807, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6078 samples/sec | ETA 02:23:45
2023-02-05 05:28:04 [INFO]	[TRAIN] epoch: 2972, iter: 234760/250000, loss: 0.1578, lr: 0.000806, batch_cost: 0.5660, reader_cost: 0.00008, ips: 10.6011 samples/sec | ETA 02:23:45
2023-02-05 05:28:10 [INFO]	[TRAIN] epoch: 2972, iter: 234770/250000, loss: 0.1406, lr: 0.000806, batch_cost: 0.5958, reader_cost: 0.03136, ips: 10.0699 samples/sec | ETA 02:31:14
2023-02-05 05:28:16 [INFO]	[TRAIN] epoch: 2972, iter: 234780/250000, loss: 0.1877, lr: 0.000805, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6137 samples/sec | ETA 02:23:23
2023-02-05 05:28:21 [INFO]	[TRAIN] epoch: 2973, iter: 234790/250000, loss: 0.1726, lr: 0.000805, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 02:23:25
2023-02-05 05:28:27 [INFO]	[TRAIN] epoch: 2973, iter: 234800/250000, loss: 0.1746, lr: 0.000805, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6083 samples/sec | ETA 02:23:17
2023-02-05 05:28:33 [INFO]	[TRAIN] epoch: 2973, iter: 234810/250000, loss: 0.1365, lr: 0.000804, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6148 samples/sec | ETA 02:23:06
2023-02-05 05:28:38 [INFO]	[TRAIN] epoch: 2973, iter: 234820/250000, loss: 0.1433, lr: 0.000804, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6110 samples/sec | ETA 02:23:03
2023-02-05 05:28:44 [INFO]	[TRAIN] epoch: 2973, iter: 234830/250000, loss: 0.1784, lr: 0.000803, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6165 samples/sec | ETA 02:22:53
2023-02-05 05:28:50 [INFO]	[TRAIN] epoch: 2973, iter: 234840/250000, loss: 0.1301, lr: 0.000803, batch_cost: 0.5899, reader_cost: 0.02419, ips: 10.1717 samples/sec | ETA 02:29:02
2023-02-05 05:28:55 [INFO]	[TRAIN] epoch: 2973, iter: 234850/250000, loss: 0.1414, lr: 0.000802, batch_cost: 0.5648, reader_cost: 0.00014, ips: 10.6233 samples/sec | ETA 02:22:36
2023-02-05 05:29:01 [INFO]	[TRAIN] epoch: 2973, iter: 234860/250000, loss: 0.1411, lr: 0.000802, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6276 samples/sec | ETA 02:22:27
2023-02-05 05:29:07 [INFO]	[TRAIN] epoch: 2974, iter: 234870/250000, loss: 0.1388, lr: 0.000801, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 02:22:38
2023-02-05 05:29:12 [INFO]	[TRAIN] epoch: 2974, iter: 234880/250000, loss: 0.2452, lr: 0.000801, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6149 samples/sec | ETA 02:22:26
2023-02-05 05:29:18 [INFO]	[TRAIN] epoch: 2974, iter: 234890/250000, loss: 0.1989, lr: 0.000800, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6059 samples/sec | ETA 02:22:28
2023-02-05 05:29:24 [INFO]	[TRAIN] epoch: 2974, iter: 234900/250000, loss: 0.1560, lr: 0.000800, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6016 samples/sec | ETA 02:22:25
2023-02-05 05:29:29 [INFO]	[TRAIN] epoch: 2974, iter: 234910/250000, loss: 0.1551, lr: 0.000799, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6130 samples/sec | ETA 02:22:11
2023-02-05 05:29:35 [INFO]	[TRAIN] epoch: 2974, iter: 234920/250000, loss: 0.1414, lr: 0.000799, batch_cost: 0.5925, reader_cost: 0.02701, ips: 10.1267 samples/sec | ETA 02:28:54
2023-02-05 05:29:41 [INFO]	[TRAIN] epoch: 2974, iter: 234930/250000, loss: 0.1276, lr: 0.000798, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6387 samples/sec | ETA 02:21:39
2023-02-05 05:29:47 [INFO]	[TRAIN] epoch: 2974, iter: 234940/250000, loss: 0.1441, lr: 0.000798, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6387 samples/sec | ETA 02:21:33
2023-02-05 05:29:52 [INFO]	[TRAIN] epoch: 2975, iter: 234950/250000, loss: 0.1329, lr: 0.000797, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6296 samples/sec | ETA 02:21:35
2023-02-05 05:29:58 [INFO]	[TRAIN] epoch: 2975, iter: 234960/250000, loss: 0.1767, lr: 0.000797, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6287 samples/sec | ETA 02:21:30
2023-02-05 05:30:04 [INFO]	[TRAIN] epoch: 2975, iter: 234970/250000, loss: 0.1276, lr: 0.000796, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6028 samples/sec | ETA 02:21:45
2023-02-05 05:30:09 [INFO]	[TRAIN] epoch: 2975, iter: 234980/250000, loss: 0.1708, lr: 0.000796, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6076 samples/sec | ETA 02:21:35
2023-02-05 05:30:15 [INFO]	[TRAIN] epoch: 2975, iter: 234990/250000, loss: 0.1488, lr: 0.000795, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6099 samples/sec | ETA 02:21:28
2023-02-05 05:30:21 [INFO]	[TRAIN] epoch: 2975, iter: 235000/250000, loss: 0.1256, lr: 0.000795, batch_cost: 0.5990, reader_cost: 0.03398, ips: 10.0173 samples/sec | ETA 02:29:44
2023-02-05 05:30:26 [INFO]	[TRAIN] epoch: 2975, iter: 235010/250000, loss: 0.1481, lr: 0.000795, batch_cost: 0.5650, reader_cost: 0.00013, ips: 10.6202 samples/sec | ETA 02:21:08
2023-02-05 05:30:32 [INFO]	[TRAIN] epoch: 2975, iter: 235020/250000, loss: 0.1405, lr: 0.000794, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6391 samples/sec | ETA 02:20:48
2023-02-05 05:30:38 [INFO]	[TRAIN] epoch: 2976, iter: 235030/250000, loss: 0.1404, lr: 0.000794, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6001 samples/sec | ETA 02:21:13
2023-02-05 05:30:43 [INFO]	[TRAIN] epoch: 2976, iter: 235040/250000, loss: 0.2186, lr: 0.000793, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6107 samples/sec | ETA 02:20:59
2023-02-05 05:30:49 [INFO]	[TRAIN] epoch: 2976, iter: 235050/250000, loss: 0.1960, lr: 0.000793, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6134 samples/sec | ETA 02:20:51
2023-02-05 05:30:55 [INFO]	[TRAIN] epoch: 2976, iter: 235060/250000, loss: 0.2007, lr: 0.000792, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6058 samples/sec | ETA 02:20:51
2023-02-05 05:31:00 [INFO]	[TRAIN] epoch: 2976, iter: 235070/250000, loss: 0.1477, lr: 0.000792, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6088 samples/sec | ETA 02:20:43
2023-02-05 05:31:06 [INFO]	[TRAIN] epoch: 2976, iter: 235080/250000, loss: 0.1377, lr: 0.000791, batch_cost: 0.5916, reader_cost: 0.02704, ips: 10.1420 samples/sec | ETA 02:27:06
2023-02-05 05:31:12 [INFO]	[TRAIN] epoch: 2976, iter: 235090/250000, loss: 0.1786, lr: 0.000791, batch_cost: 0.5646, reader_cost: 0.00011, ips: 10.6276 samples/sec | ETA 02:20:17
2023-02-05 05:31:18 [INFO]	[TRAIN] epoch: 2976, iter: 235100/250000, loss: 0.1435, lr: 0.000790, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6268 samples/sec | ETA 02:20:12
2023-02-05 05:31:23 [INFO]	[TRAIN] epoch: 2977, iter: 235110/250000, loss: 0.1513, lr: 0.000790, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6323 samples/sec | ETA 02:20:02
2023-02-05 05:31:29 [INFO]	[TRAIN] epoch: 2977, iter: 235120/250000, loss: 0.1420, lr: 0.000789, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6333 samples/sec | ETA 02:19:56
2023-02-05 05:31:35 [INFO]	[TRAIN] epoch: 2977, iter: 235130/250000, loss: 0.1476, lr: 0.000789, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6309 samples/sec | ETA 02:19:52
2023-02-05 05:31:40 [INFO]	[TRAIN] epoch: 2977, iter: 235140/250000, loss: 0.1504, lr: 0.000788, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6210 samples/sec | ETA 02:19:54
2023-02-05 05:31:46 [INFO]	[TRAIN] epoch: 2977, iter: 235150/250000, loss: 0.1489, lr: 0.000788, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6308 samples/sec | ETA 02:19:41
2023-02-05 05:31:52 [INFO]	[TRAIN] epoch: 2977, iter: 235160/250000, loss: 0.1198, lr: 0.000787, batch_cost: 0.5897, reader_cost: 0.02530, ips: 10.1744 samples/sec | ETA 02:25:51
2023-02-05 05:31:57 [INFO]	[TRAIN] epoch: 2977, iter: 235170/250000, loss: 0.1331, lr: 0.000787, batch_cost: 0.5644, reader_cost: 0.00012, ips: 10.6300 samples/sec | ETA 02:19:30
2023-02-05 05:32:03 [INFO]	[TRAIN] epoch: 2977, iter: 235180/250000, loss: 0.1306, lr: 0.000786, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6268 samples/sec | ETA 02:19:27
2023-02-05 05:32:09 [INFO]	[TRAIN] epoch: 2978, iter: 235190/250000, loss: 0.1872, lr: 0.000786, batch_cost: 0.5648, reader_cost: 0.00016, ips: 10.6232 samples/sec | ETA 02:19:24
2023-02-05 05:32:14 [INFO]	[TRAIN] epoch: 2978, iter: 235200/250000, loss: 0.1562, lr: 0.000785, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6427 samples/sec | ETA 02:19:03
2023-02-05 05:32:20 [INFO]	[TRAIN] epoch: 2978, iter: 235210/250000, loss: 0.1517, lr: 0.000785, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6315 samples/sec | ETA 02:19:06
2023-02-05 05:32:26 [INFO]	[TRAIN] epoch: 2978, iter: 235220/250000, loss: 0.1588, lr: 0.000784, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6263 samples/sec | ETA 02:19:05
2023-02-05 05:32:31 [INFO]	[TRAIN] epoch: 2978, iter: 235230/250000, loss: 0.1455, lr: 0.000784, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6320 samples/sec | ETA 02:18:55
2023-02-05 05:32:37 [INFO]	[TRAIN] epoch: 2978, iter: 235240/250000, loss: 0.1576, lr: 0.000784, batch_cost: 0.5896, reader_cost: 0.02431, ips: 10.1768 samples/sec | ETA 02:25:02
2023-02-05 05:32:43 [INFO]	[TRAIN] epoch: 2978, iter: 235250/250000, loss: 0.1402, lr: 0.000783, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6284 samples/sec | ETA 02:18:46
2023-02-05 05:32:48 [INFO]	[TRAIN] epoch: 2978, iter: 235260/250000, loss: 0.1448, lr: 0.000783, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6261 samples/sec | ETA 02:18:42
2023-02-05 05:32:54 [INFO]	[TRAIN] epoch: 2979, iter: 235270/250000, loss: 0.1594, lr: 0.000782, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6217 samples/sec | ETA 02:18:40
2023-02-05 05:33:00 [INFO]	[TRAIN] epoch: 2979, iter: 235280/250000, loss: 0.1344, lr: 0.000782, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6332 samples/sec | ETA 02:18:26
2023-02-05 05:33:05 [INFO]	[TRAIN] epoch: 2979, iter: 235290/250000, loss: 0.1540, lr: 0.000781, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6283 samples/sec | ETA 02:18:24
2023-02-05 05:33:11 [INFO]	[TRAIN] epoch: 2979, iter: 235300/250000, loss: 0.1496, lr: 0.000781, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6242 samples/sec | ETA 02:18:21
2023-02-05 05:33:17 [INFO]	[TRAIN] epoch: 2979, iter: 235310/250000, loss: 0.1400, lr: 0.000780, batch_cost: 0.5647, reader_cost: 0.00008, ips: 10.6257 samples/sec | ETA 02:18:14
2023-02-05 05:33:23 [INFO]	[TRAIN] epoch: 2979, iter: 235320/250000, loss: 0.1424, lr: 0.000780, batch_cost: 0.5903, reader_cost: 0.02560, ips: 10.1651 samples/sec | ETA 02:24:24
2023-02-05 05:33:28 [INFO]	[TRAIN] epoch: 2979, iter: 235330/250000, loss: 0.1157, lr: 0.000779, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6258 samples/sec | ETA 02:18:03
2023-02-05 05:33:34 [INFO]	[TRAIN] epoch: 2979, iter: 235340/250000, loss: 0.1319, lr: 0.000779, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6312 samples/sec | ETA 02:17:53
2023-02-05 05:33:39 [INFO]	[TRAIN] epoch: 2980, iter: 235350/250000, loss: 0.1850, lr: 0.000778, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6280 samples/sec | ETA 02:17:50
2023-02-05 05:33:45 [INFO]	[TRAIN] epoch: 2980, iter: 235360/250000, loss: 0.1277, lr: 0.000778, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6333 samples/sec | ETA 02:17:40
2023-02-05 05:33:51 [INFO]	[TRAIN] epoch: 2980, iter: 235370/250000, loss: 0.1371, lr: 0.000777, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6301 samples/sec | ETA 02:17:37
2023-02-05 05:33:56 [INFO]	[TRAIN] epoch: 2980, iter: 235380/250000, loss: 0.1520, lr: 0.000777, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6217 samples/sec | ETA 02:17:38
2023-02-05 05:34:02 [INFO]	[TRAIN] epoch: 2980, iter: 235390/250000, loss: 0.1330, lr: 0.000776, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6151 samples/sec | ETA 02:17:38
2023-02-05 05:34:08 [INFO]	[TRAIN] epoch: 2980, iter: 235400/250000, loss: 0.1208, lr: 0.000776, batch_cost: 0.5874, reader_cost: 0.02230, ips: 10.2140 samples/sec | ETA 02:22:56
2023-02-05 05:34:14 [INFO]	[TRAIN] epoch: 2980, iter: 235410/250000, loss: 0.1355, lr: 0.000775, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6056 samples/sec | ETA 02:17:34
2023-02-05 05:34:19 [INFO]	[TRAIN] epoch: 2980, iter: 235420/250000, loss: 0.1834, lr: 0.000775, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6122 samples/sec | ETA 02:17:23
2023-02-05 05:34:25 [INFO]	[TRAIN] epoch: 2981, iter: 235430/250000, loss: 0.1468, lr: 0.000774, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6123 samples/sec | ETA 02:17:17
2023-02-05 05:34:31 [INFO]	[TRAIN] epoch: 2981, iter: 235440/250000, loss: 0.1559, lr: 0.000774, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6118 samples/sec | ETA 02:17:12
2023-02-05 05:34:36 [INFO]	[TRAIN] epoch: 2981, iter: 235450/250000, loss: 0.1633, lr: 0.000773, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6095 samples/sec | ETA 02:17:08
2023-02-05 05:34:42 [INFO]	[TRAIN] epoch: 2981, iter: 235460/250000, loss: 0.1956, lr: 0.000773, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6050 samples/sec | ETA 02:17:06
2023-02-05 05:34:48 [INFO]	[TRAIN] epoch: 2981, iter: 235470/250000, loss: 0.1377, lr: 0.000773, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6146 samples/sec | ETA 02:16:53
2023-02-05 05:34:53 [INFO]	[TRAIN] epoch: 2981, iter: 235480/250000, loss: 0.1267, lr: 0.000772, batch_cost: 0.5934, reader_cost: 0.02855, ips: 10.1109 samples/sec | ETA 02:23:36
2023-02-05 05:34:59 [INFO]	[TRAIN] epoch: 2981, iter: 235490/250000, loss: 0.1391, lr: 0.000772, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6304 samples/sec | ETA 02:16:29
2023-02-05 05:35:05 [INFO]	[TRAIN] epoch: 2982, iter: 235500/250000, loss: 0.1634, lr: 0.000771, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6135 samples/sec | ETA 02:16:37
2023-02-05 05:35:10 [INFO]	[TRAIN] epoch: 2982, iter: 235510/250000, loss: 0.1327, lr: 0.000771, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6122 samples/sec | ETA 02:16:32
2023-02-05 05:35:16 [INFO]	[TRAIN] epoch: 2982, iter: 235520/250000, loss: 0.1290, lr: 0.000770, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6096 samples/sec | ETA 02:16:28
2023-02-05 05:35:22 [INFO]	[TRAIN] epoch: 2982, iter: 235530/250000, loss: 0.1281, lr: 0.000770, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6140 samples/sec | ETA 02:16:19
2023-02-05 05:35:27 [INFO]	[TRAIN] epoch: 2982, iter: 235540/250000, loss: 0.1193, lr: 0.000769, batch_cost: 0.5660, reader_cost: 0.00008, ips: 10.6013 samples/sec | ETA 02:16:23
2023-02-05 05:35:33 [INFO]	[TRAIN] epoch: 2982, iter: 235550/250000, loss: 0.1476, lr: 0.000769, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6060 samples/sec | ETA 02:16:14
2023-02-05 05:35:39 [INFO]	[TRAIN] epoch: 2982, iter: 235560/250000, loss: 0.1576, lr: 0.000768, batch_cost: 0.5965, reader_cost: 0.03106, ips: 10.0591 samples/sec | ETA 02:23:33
2023-02-05 05:35:45 [INFO]	[TRAIN] epoch: 2982, iter: 235570/250000, loss: 0.1483, lr: 0.000768, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6321 samples/sec | ETA 02:15:43
2023-02-05 05:35:50 [INFO]	[TRAIN] epoch: 2983, iter: 235580/250000, loss: 0.1440, lr: 0.000767, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6220 samples/sec | ETA 02:15:45
2023-02-05 05:35:56 [INFO]	[TRAIN] epoch: 2983, iter: 235590/250000, loss: 0.1386, lr: 0.000767, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6278 samples/sec | ETA 02:15:35
2023-02-05 05:36:02 [INFO]	[TRAIN] epoch: 2983, iter: 235600/250000, loss: 0.1419, lr: 0.000766, batch_cost: 0.5646, reader_cost: 0.00008, ips: 10.6269 samples/sec | ETA 02:15:30
2023-02-05 05:36:07 [INFO]	[TRAIN] epoch: 2983, iter: 235610/250000, loss: 0.2325, lr: 0.000766, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6177 samples/sec | ETA 02:15:31
2023-02-05 05:36:13 [INFO]	[TRAIN] epoch: 2983, iter: 235620/250000, loss: 0.1118, lr: 0.000765, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6103 samples/sec | ETA 02:15:31
2023-02-05 05:36:19 [INFO]	[TRAIN] epoch: 2983, iter: 235630/250000, loss: 0.1615, lr: 0.000765, batch_cost: 0.5910, reader_cost: 0.02579, ips: 10.1524 samples/sec | ETA 02:21:32
2023-02-05 05:36:24 [INFO]	[TRAIN] epoch: 2983, iter: 235640/250000, loss: 0.1450, lr: 0.000764, batch_cost: 0.5650, reader_cost: 0.00018, ips: 10.6201 samples/sec | ETA 02:15:12
2023-02-05 05:36:30 [INFO]	[TRAIN] epoch: 2983, iter: 235650/250000, loss: 0.1272, lr: 0.000764, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6248 samples/sec | ETA 02:15:03
2023-02-05 05:36:36 [INFO]	[TRAIN] epoch: 2984, iter: 235660/250000, loss: 0.1645, lr: 0.000763, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6056 samples/sec | ETA 02:15:12
2023-02-05 05:36:41 [INFO]	[TRAIN] epoch: 2984, iter: 235670/250000, loss: 0.1379, lr: 0.000763, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6249 samples/sec | ETA 02:14:52
2023-02-05 05:36:47 [INFO]	[TRAIN] epoch: 2984, iter: 235680/250000, loss: 0.1323, lr: 0.000762, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6100 samples/sec | ETA 02:14:58
2023-02-05 05:36:53 [INFO]	[TRAIN] epoch: 2984, iter: 235690/250000, loss: 0.1553, lr: 0.000762, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6141 samples/sec | ETA 02:14:49
2023-02-05 05:36:58 [INFO]	[TRAIN] epoch: 2984, iter: 235700/250000, loss: 0.1668, lr: 0.000762, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6126 samples/sec | ETA 02:14:44
2023-02-05 05:37:04 [INFO]	[TRAIN] epoch: 2984, iter: 235710/250000, loss: 0.1098, lr: 0.000761, batch_cost: 0.5904, reader_cost: 0.02567, ips: 10.1622 samples/sec | ETA 02:20:37
2023-02-05 05:37:10 [INFO]	[TRAIN] epoch: 2984, iter: 235720/250000, loss: 0.1214, lr: 0.000761, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6144 samples/sec | ETA 02:14:32
2023-02-05 05:37:16 [INFO]	[TRAIN] epoch: 2984, iter: 235730/250000, loss: 0.1190, lr: 0.000760, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6104 samples/sec | ETA 02:14:29
2023-02-05 05:37:21 [INFO]	[TRAIN] epoch: 2985, iter: 235740/250000, loss: 0.1263, lr: 0.000760, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6049 samples/sec | ETA 02:14:27
2023-02-05 05:37:27 [INFO]	[TRAIN] epoch: 2985, iter: 235750/250000, loss: 0.1574, lr: 0.000759, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6111 samples/sec | ETA 02:14:17
2023-02-05 05:37:33 [INFO]	[TRAIN] epoch: 2985, iter: 235760/250000, loss: 0.1414, lr: 0.000759, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6098 samples/sec | ETA 02:14:12
2023-02-05 05:37:38 [INFO]	[TRAIN] epoch: 2985, iter: 235770/250000, loss: 0.1350, lr: 0.000758, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 02:14:11
2023-02-05 05:37:44 [INFO]	[TRAIN] epoch: 2985, iter: 235780/250000, loss: 0.1197, lr: 0.000758, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6105 samples/sec | ETA 02:14:01
2023-02-05 05:37:50 [INFO]	[TRAIN] epoch: 2985, iter: 235790/250000, loss: 0.1282, lr: 0.000757, batch_cost: 0.5896, reader_cost: 0.02421, ips: 10.1762 samples/sec | ETA 02:19:38
2023-02-05 05:37:55 [INFO]	[TRAIN] epoch: 2985, iter: 235800/250000, loss: 0.1466, lr: 0.000757, batch_cost: 0.5647, reader_cost: 0.00016, ips: 10.6260 samples/sec | ETA 02:13:38
2023-02-05 05:38:01 [INFO]	[TRAIN] epoch: 2985, iter: 235810/250000, loss: 0.1385, lr: 0.000756, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6249 samples/sec | ETA 02:13:33
2023-02-05 05:38:07 [INFO]	[TRAIN] epoch: 2986, iter: 235820/250000, loss: 0.1563, lr: 0.000756, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6346 samples/sec | ETA 02:13:20
2023-02-05 05:38:12 [INFO]	[TRAIN] epoch: 2986, iter: 235830/250000, loss: 0.1324, lr: 0.000755, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5989 samples/sec | ETA 02:13:41
2023-02-05 05:38:18 [INFO]	[TRAIN] epoch: 2986, iter: 235840/250000, loss: 0.1496, lr: 0.000755, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5994 samples/sec | ETA 02:13:35
2023-02-05 05:38:24 [INFO]	[TRAIN] epoch: 2986, iter: 235850/250000, loss: 0.1397, lr: 0.000754, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6130 samples/sec | ETA 02:13:19
2023-02-05 05:38:29 [INFO]	[TRAIN] epoch: 2986, iter: 235860/250000, loss: 0.1301, lr: 0.000754, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6152 samples/sec | ETA 02:13:12
2023-02-05 05:38:35 [INFO]	[TRAIN] epoch: 2986, iter: 235870/250000, loss: 0.1731, lr: 0.000753, batch_cost: 0.5891, reader_cost: 0.02350, ips: 10.1851 samples/sec | ETA 02:18:43
2023-02-05 05:38:41 [INFO]	[TRAIN] epoch: 2986, iter: 235880/250000, loss: 0.1878, lr: 0.000753, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6285 samples/sec | ETA 02:12:51
2023-02-05 05:38:47 [INFO]	[TRAIN] epoch: 2986, iter: 235890/250000, loss: 0.1524, lr: 0.000752, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6300 samples/sec | ETA 02:12:44
2023-02-05 05:38:52 [INFO]	[TRAIN] epoch: 2987, iter: 235900/250000, loss: 0.1208, lr: 0.000752, batch_cost: 0.5639, reader_cost: 0.00008, ips: 10.6395 samples/sec | ETA 02:12:31
2023-02-05 05:38:58 [INFO]	[TRAIN] epoch: 2987, iter: 235910/250000, loss: 0.1351, lr: 0.000751, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6275 samples/sec | ETA 02:12:34
2023-02-05 05:39:03 [INFO]	[TRAIN] epoch: 2987, iter: 235920/250000, loss: 0.1286, lr: 0.000751, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6370 samples/sec | ETA 02:12:22
2023-02-05 05:39:09 [INFO]	[TRAIN] epoch: 2987, iter: 235930/250000, loss: 0.1326, lr: 0.000750, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6297 samples/sec | ETA 02:12:21
2023-02-05 05:39:15 [INFO]	[TRAIN] epoch: 2987, iter: 235940/250000, loss: 0.1450, lr: 0.000750, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6285 samples/sec | ETA 02:12:17
2023-02-05 05:39:21 [INFO]	[TRAIN] epoch: 2987, iter: 235950/250000, loss: 0.1674, lr: 0.000750, batch_cost: 0.5899, reader_cost: 0.02552, ips: 10.1719 samples/sec | ETA 02:18:07
2023-02-05 05:39:26 [INFO]	[TRAIN] epoch: 2987, iter: 235960/250000, loss: 0.1350, lr: 0.000749, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6280 samples/sec | ETA 02:12:06
2023-02-05 05:39:32 [INFO]	[TRAIN] epoch: 2987, iter: 235970/250000, loss: 0.1204, lr: 0.000749, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6338 samples/sec | ETA 02:11:56
2023-02-05 05:39:38 [INFO]	[TRAIN] epoch: 2988, iter: 235980/250000, loss: 0.1421, lr: 0.000748, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6301 samples/sec | ETA 02:11:53
2023-02-05 05:39:43 [INFO]	[TRAIN] epoch: 2988, iter: 235990/250000, loss: 0.1460, lr: 0.000748, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6430 samples/sec | ETA 02:11:38
2023-02-05 05:39:49 [INFO]	[TRAIN] epoch: 2988, iter: 236000/250000, loss: 0.1268, lr: 0.000747, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6321 samples/sec | ETA 02:11:40
2023-02-05 05:39:49 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1233 - reader cost: 0.0233 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1487 - reader cost: 0.0117 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1560 - reader cost: 0.0078 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1572 - reader cost: 0.0059 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1582 - reader cost: 0.0047 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1612 - reader cost: 0.0040 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1607 - reader cost: 0.0034 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1611 - reader cost: 0.0030 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1621 - reader cost: 0.002710/36 [=======>......................] - ETA: 4s - batch_cost: 0.1620 - reader cost: 0.002411/36 [========>.....................] - ETA: 4s - batch_cost: 0.1629 - reader cost: 0.002212/36 [=========>....................] - ETA: 3s - batch_cost: 0.1625 - reader cost: 0.002013/36 [=========>....................] - ETA: 3s - batch_cost: 0.1627 - reader cost: 0.001914/36 [==========>...................] - ETA: 3s - batch_cost: 0.1633 - reader cost: 0.001715/36 [===========>..................] - ETA: 3s - batch_cost: 0.1633 - reader cost: 0.001616/36 [============>.................] - ETA: 3s - batch_cost: 0.1643 - reader cost: 0.001517/36 [=============>................] - ETA: 3s - batch_cost: 0.1646 - reader cost: 0.001418/36 [==============>...............] - ETA: 2s - batch_cost: 0.1647 - reader cost: 0.001419/36 [==============>...............] - ETA: 2s - batch_cost: 0.1644 - reader cost: 0.001320/36 [===============>..............] - ETA: 2s - batch_cost: 0.1643 - reader cost: 0.001221/36 [================>.............] - ETA: 2s - batch_cost: 0.1643 - reader cost: 0.001222/36 [=================>............] - ETA: 2s - batch_cost: 0.1643 - reader cost: 0.001123/36 [==================>...........] - ETA: 2s - batch_cost: 0.1649 - reader cost: 0.001124/36 [===================>..........] - ETA: 1s - batch_cost: 0.1648 - reader cost: 0.001025/36 [===================>..........] - ETA: 1s - batch_cost: 0.1650 - reader cost: 0.001026/36 [====================>.........] - ETA: 1s - batch_cost: 0.1651 - reader cost: 9.7224e-0427/36 [=====================>........] - ETA: 1s - batch_cost: 0.1653 - reader cost: 9.3879e-0428/36 [======================>.......] - ETA: 1s - batch_cost: 0.1656 - reader cost: 9.0774e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1657 - reader cost: 8.7880e-0430/36 [========================>.....] - ETA: 0s - batch_cost: 0.1656 - reader cost: 8.5242e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1655 - reader cost: 8.2717e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1654 - reader cost: 8.0352e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1654 - reader cost: 7.8112e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1652 - reader cost: 7.6030e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1652 - reader cost: 7.4043e-0436/36 [==============================] - 6s 165ms/step - batch_cost: 0.1652 - reader cost: 7.2162e-04
2023-02-05 05:39:55 [INFO]	[EVAL] #Images: 36 mIoU: 0.8631 Acc: 0.9857 Kappa: 0.9483 Dice: 0.9232
2023-02-05 05:39:55 [INFO]	[EVAL] Class IoU: 
[0.9851 0.911  0.8916 0.7094 0.7182 0.9679 0.8587]
2023-02-05 05:39:55 [INFO]	[EVAL] Class Precision: 
[0.9924 0.9654 0.9444 0.8301 0.8521 0.9775 0.9039]
2023-02-05 05:39:55 [INFO]	[EVAL] Class Recall: 
[0.9926 0.9417 0.9411 0.8299 0.8205 0.9899 0.9449]
2023-02-05 05:39:55 [INFO]	[EVAL] The model with the best validation mIoU (0.8682) was saved at iter 222000.
2023-02-05 05:40:01 [INFO]	[TRAIN] epoch: 2988, iter: 236010/250000, loss: 0.1227, lr: 0.000747, batch_cost: 0.5641, reader_cost: 0.00010, ips: 10.6364 samples/sec | ETA 02:11:31
2023-02-05 05:40:06 [INFO]	[TRAIN] epoch: 2988, iter: 236020/250000, loss: 0.1665, lr: 0.000746, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6324 samples/sec | ETA 02:11:29
2023-02-05 05:40:12 [INFO]	[TRAIN] epoch: 2988, iter: 236030/250000, loss: 0.1143, lr: 0.000746, batch_cost: 0.5982, reader_cost: 0.03415, ips: 10.0295 samples/sec | ETA 02:19:17
2023-02-05 05:40:18 [INFO]	[TRAIN] epoch: 2988, iter: 236040/250000, loss: 0.1350, lr: 0.000745, batch_cost: 0.5638, reader_cost: 0.00009, ips: 10.6425 samples/sec | ETA 02:11:10
2023-02-05 05:40:24 [INFO]	[TRAIN] epoch: 2988, iter: 236050/250000, loss: 0.1437, lr: 0.000745, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6296 samples/sec | ETA 02:11:14
2023-02-05 05:40:29 [INFO]	[TRAIN] epoch: 2989, iter: 236060/250000, loss: 0.1383, lr: 0.000744, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6225 samples/sec | ETA 02:11:13
2023-02-05 05:40:35 [INFO]	[TRAIN] epoch: 2989, iter: 236070/250000, loss: 0.1390, lr: 0.000744, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6409 samples/sec | ETA 02:10:54
2023-02-05 05:40:41 [INFO]	[TRAIN] epoch: 2989, iter: 236080/250000, loss: 0.1477, lr: 0.000743, batch_cost: 0.5640, reader_cost: 0.00008, ips: 10.6389 samples/sec | ETA 02:10:50
2023-02-05 05:40:46 [INFO]	[TRAIN] epoch: 2989, iter: 236090/250000, loss: 0.1492, lr: 0.000743, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6313 samples/sec | ETA 02:10:50
2023-02-05 05:40:52 [INFO]	[TRAIN] epoch: 2989, iter: 236100/250000, loss: 0.1501, lr: 0.000742, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6327 samples/sec | ETA 02:10:43
2023-02-05 05:40:58 [INFO]	[TRAIN] epoch: 2989, iter: 236110/250000, loss: 0.1277, lr: 0.000742, batch_cost: 0.5922, reader_cost: 0.02802, ips: 10.1316 samples/sec | ETA 02:17:05
2023-02-05 05:41:03 [INFO]	[TRAIN] epoch: 2989, iter: 236120/250000, loss: 0.1249, lr: 0.000741, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6342 samples/sec | ETA 02:10:31
2023-02-05 05:41:09 [INFO]	[TRAIN] epoch: 2989, iter: 236130/250000, loss: 0.1445, lr: 0.000741, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6322 samples/sec | ETA 02:10:27
2023-02-05 05:41:15 [INFO]	[TRAIN] epoch: 2990, iter: 236140/250000, loss: 0.1531, lr: 0.000740, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6233 samples/sec | ETA 02:10:28
2023-02-05 05:41:20 [INFO]	[TRAIN] epoch: 2990, iter: 236150/250000, loss: 0.1340, lr: 0.000740, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6320 samples/sec | ETA 02:10:16
2023-02-05 05:41:26 [INFO]	[TRAIN] epoch: 2990, iter: 236160/250000, loss: 0.1439, lr: 0.000739, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6375 samples/sec | ETA 02:10:06
2023-02-05 05:41:32 [INFO]	[TRAIN] epoch: 2990, iter: 236170/250000, loss: 0.1420, lr: 0.000739, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6411 samples/sec | ETA 02:09:58
2023-02-05 05:41:37 [INFO]	[TRAIN] epoch: 2990, iter: 236180/250000, loss: 0.1691, lr: 0.000738, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6295 samples/sec | ETA 02:10:00
2023-02-05 05:41:43 [INFO]	[TRAIN] epoch: 2990, iter: 236190/250000, loss: 0.1342, lr: 0.000738, batch_cost: 0.5874, reader_cost: 0.02299, ips: 10.2152 samples/sec | ETA 02:15:11
2023-02-05 05:41:49 [INFO]	[TRAIN] epoch: 2990, iter: 236200/250000, loss: 0.1343, lr: 0.000738, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6314 samples/sec | ETA 02:09:48
2023-02-05 05:41:54 [INFO]	[TRAIN] epoch: 2990, iter: 236210/250000, loss: 0.1739, lr: 0.000737, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6386 samples/sec | ETA 02:09:37
2023-02-05 05:42:00 [INFO]	[TRAIN] epoch: 2991, iter: 236220/250000, loss: 0.1627, lr: 0.000737, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6347 samples/sec | ETA 02:09:34
2023-02-05 05:42:06 [INFO]	[TRAIN] epoch: 2991, iter: 236230/250000, loss: 0.1477, lr: 0.000736, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6293 samples/sec | ETA 02:09:32
2023-02-05 05:42:11 [INFO]	[TRAIN] epoch: 2991, iter: 236240/250000, loss: 0.1367, lr: 0.000736, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6257 samples/sec | ETA 02:09:29
2023-02-05 05:42:17 [INFO]	[TRAIN] epoch: 2991, iter: 236250/250000, loss: 0.1379, lr: 0.000735, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6295 samples/sec | ETA 02:09:21
2023-02-05 05:42:23 [INFO]	[TRAIN] epoch: 2991, iter: 236260/250000, loss: 0.1306, lr: 0.000735, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6384 samples/sec | ETA 02:09:09
2023-02-05 05:42:28 [INFO]	[TRAIN] epoch: 2991, iter: 236270/250000, loss: 0.1510, lr: 0.000734, batch_cost: 0.5833, reader_cost: 0.01886, ips: 10.2866 samples/sec | ETA 02:13:28
2023-02-05 05:42:34 [INFO]	[TRAIN] epoch: 2991, iter: 236280/250000, loss: 0.1301, lr: 0.000734, batch_cost: 0.5641, reader_cost: 0.00008, ips: 10.6358 samples/sec | ETA 02:08:59
2023-02-05 05:42:40 [INFO]	[TRAIN] epoch: 2992, iter: 236290/250000, loss: 0.1121, lr: 0.000733, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6359 samples/sec | ETA 02:08:54
2023-02-05 05:42:45 [INFO]	[TRAIN] epoch: 2992, iter: 236300/250000, loss: 0.1567, lr: 0.000733, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6270 samples/sec | ETA 02:08:54
2023-02-05 05:42:51 [INFO]	[TRAIN] epoch: 2992, iter: 236310/250000, loss: 0.1686, lr: 0.000732, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6286 samples/sec | ETA 02:08:48
2023-02-05 05:42:57 [INFO]	[TRAIN] epoch: 2992, iter: 236320/250000, loss: 0.1286, lr: 0.000732, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6303 samples/sec | ETA 02:08:41
2023-02-05 05:43:02 [INFO]	[TRAIN] epoch: 2992, iter: 236330/250000, loss: 0.1693, lr: 0.000731, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6363 samples/sec | ETA 02:08:31
2023-02-05 05:43:08 [INFO]	[TRAIN] epoch: 2992, iter: 236340/250000, loss: 0.1632, lr: 0.000731, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6337 samples/sec | ETA 02:08:27
2023-02-05 05:43:14 [INFO]	[TRAIN] epoch: 2992, iter: 236350/250000, loss: 0.1478, lr: 0.000730, batch_cost: 0.5991, reader_cost: 0.03433, ips: 10.0147 samples/sec | ETA 02:16:17
2023-02-05 05:43:20 [INFO]	[TRAIN] epoch: 2992, iter: 236360/250000, loss: 0.1434, lr: 0.000730, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6306 samples/sec | ETA 02:08:18
2023-02-05 05:43:25 [INFO]	[TRAIN] epoch: 2993, iter: 236370/250000, loss: 0.1489, lr: 0.000729, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6364 samples/sec | ETA 02:08:08
2023-02-05 05:43:31 [INFO]	[TRAIN] epoch: 2993, iter: 236380/250000, loss: 0.1470, lr: 0.000729, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6290 samples/sec | ETA 02:08:08
2023-02-05 05:43:37 [INFO]	[TRAIN] epoch: 2993, iter: 236390/250000, loss: 0.1535, lr: 0.000728, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6272 samples/sec | ETA 02:08:04
2023-02-05 05:43:42 [INFO]	[TRAIN] epoch: 2993, iter: 236400/250000, loss: 0.1278, lr: 0.000728, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6283 samples/sec | ETA 02:07:57
2023-02-05 05:43:48 [INFO]	[TRAIN] epoch: 2993, iter: 236410/250000, loss: 0.1441, lr: 0.000727, batch_cost: 0.5647, reader_cost: 0.00008, ips: 10.6251 samples/sec | ETA 02:07:54
2023-02-05 05:43:54 [INFO]	[TRAIN] epoch: 2993, iter: 236420/250000, loss: 0.1388, lr: 0.000727, batch_cost: 0.5881, reader_cost: 0.02365, ips: 10.2030 samples/sec | ETA 02:13:05
2023-02-05 05:43:59 [INFO]	[TRAIN] epoch: 2993, iter: 236430/250000, loss: 0.1248, lr: 0.000726, batch_cost: 0.5642, reader_cost: 0.00017, ips: 10.6344 samples/sec | ETA 02:07:36
2023-02-05 05:44:05 [INFO]	[TRAIN] epoch: 2993, iter: 236440/250000, loss: 0.1321, lr: 0.000726, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6310 samples/sec | ETA 02:07:33
2023-02-05 05:44:11 [INFO]	[TRAIN] epoch: 2994, iter: 236450/250000, loss: 0.1570, lr: 0.000725, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6024 samples/sec | ETA 02:07:48
2023-02-05 05:44:16 [INFO]	[TRAIN] epoch: 2994, iter: 236460/250000, loss: 0.1258, lr: 0.000725, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6121 samples/sec | ETA 02:07:35
2023-02-05 05:44:22 [INFO]	[TRAIN] epoch: 2994, iter: 236470/250000, loss: 0.1589, lr: 0.000725, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6073 samples/sec | ETA 02:07:33
2023-02-05 05:44:28 [INFO]	[TRAIN] epoch: 2994, iter: 236480/250000, loss: 0.1449, lr: 0.000724, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6101 samples/sec | ETA 02:07:25
2023-02-05 05:44:33 [INFO]	[TRAIN] epoch: 2994, iter: 236490/250000, loss: 0.1682, lr: 0.000724, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6098 samples/sec | ETA 02:07:20
2023-02-05 05:44:39 [INFO]	[TRAIN] epoch: 2994, iter: 236500/250000, loss: 0.1343, lr: 0.000723, batch_cost: 0.5945, reader_cost: 0.02934, ips: 10.0918 samples/sec | ETA 02:13:46
2023-02-05 05:44:45 [INFO]	[TRAIN] epoch: 2994, iter: 236510/250000, loss: 0.1786, lr: 0.000723, batch_cost: 0.5642, reader_cost: 0.00014, ips: 10.6346 samples/sec | ETA 02:06:50
2023-02-05 05:44:51 [INFO]	[TRAIN] epoch: 2994, iter: 236520/250000, loss: 0.1603, lr: 0.000722, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6053 samples/sec | ETA 02:07:06
2023-02-05 05:44:56 [INFO]	[TRAIN] epoch: 2995, iter: 236530/250000, loss: 0.1562, lr: 0.000722, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6072 samples/sec | ETA 02:06:59
2023-02-05 05:45:02 [INFO]	[TRAIN] epoch: 2995, iter: 236540/250000, loss: 0.1373, lr: 0.000721, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6025 samples/sec | ETA 02:06:57
2023-02-05 05:45:08 [INFO]	[TRAIN] epoch: 2995, iter: 236550/250000, loss: 0.1528, lr: 0.000721, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5955 samples/sec | ETA 02:06:56
2023-02-05 05:45:13 [INFO]	[TRAIN] epoch: 2995, iter: 236560/250000, loss: 0.1361, lr: 0.000720, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6032 samples/sec | ETA 02:06:45
2023-02-05 05:45:19 [INFO]	[TRAIN] epoch: 2995, iter: 236570/250000, loss: 0.1466, lr: 0.000720, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6043 samples/sec | ETA 02:06:38
2023-02-05 05:45:25 [INFO]	[TRAIN] epoch: 2995, iter: 236580/250000, loss: 0.1405, lr: 0.000719, batch_cost: 0.5988, reader_cost: 0.03339, ips: 10.0206 samples/sec | ETA 02:13:55
2023-02-05 05:45:30 [INFO]	[TRAIN] epoch: 2995, iter: 236590/250000, loss: 0.1243, lr: 0.000719, batch_cost: 0.5646, reader_cost: 0.00012, ips: 10.6274 samples/sec | ETA 02:06:10
2023-02-05 05:45:36 [INFO]	[TRAIN] epoch: 2995, iter: 236600/250000, loss: 0.1744, lr: 0.000718, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6338 samples/sec | ETA 02:06:00
2023-02-05 05:45:42 [INFO]	[TRAIN] epoch: 2996, iter: 236610/250000, loss: 0.1462, lr: 0.000718, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6298 samples/sec | ETA 02:05:57
2023-02-05 05:45:47 [INFO]	[TRAIN] epoch: 2996, iter: 236620/250000, loss: 0.1192, lr: 0.000717, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6331 samples/sec | ETA 02:05:50
2023-02-05 05:45:53 [INFO]	[TRAIN] epoch: 2996, iter: 236630/250000, loss: 0.1221, lr: 0.000717, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6286 samples/sec | ETA 02:05:47
2023-02-05 05:45:59 [INFO]	[TRAIN] epoch: 2996, iter: 236640/250000, loss: 0.1569, lr: 0.000716, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6312 samples/sec | ETA 02:05:40
2023-02-05 05:46:04 [INFO]	[TRAIN] epoch: 2996, iter: 236650/250000, loss: 0.1410, lr: 0.000716, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6246 samples/sec | ETA 02:05:39
2023-02-05 05:46:10 [INFO]	[TRAIN] epoch: 2996, iter: 236660/250000, loss: 0.1106, lr: 0.000715, batch_cost: 0.5988, reader_cost: 0.03459, ips: 10.0208 samples/sec | ETA 02:13:07
2023-02-05 05:46:16 [INFO]	[TRAIN] epoch: 2996, iter: 236670/250000, loss: 0.1244, lr: 0.000715, batch_cost: 0.5651, reader_cost: 0.00015, ips: 10.6177 samples/sec | ETA 02:05:32
2023-02-05 05:46:22 [INFO]	[TRAIN] epoch: 2996, iter: 236680/250000, loss: 0.1324, lr: 0.000714, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6223 samples/sec | ETA 02:05:23
2023-02-05 05:46:27 [INFO]	[TRAIN] epoch: 2997, iter: 236690/250000, loss: 0.1412, lr: 0.000714, batch_cost: 0.5646, reader_cost: 0.00008, ips: 10.6277 samples/sec | ETA 02:05:14
2023-02-05 05:46:33 [INFO]	[TRAIN] epoch: 2997, iter: 236700/250000, loss: 0.1609, lr: 0.000713, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6373 samples/sec | ETA 02:05:01
2023-02-05 05:46:39 [INFO]	[TRAIN] epoch: 2997, iter: 236710/250000, loss: 0.1261, lr: 0.000713, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6318 samples/sec | ETA 02:05:00
2023-02-05 05:46:44 [INFO]	[TRAIN] epoch: 2997, iter: 236720/250000, loss: 0.1508, lr: 0.000712, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6009 samples/sec | ETA 02:05:16
2023-02-05 05:46:50 [INFO]	[TRAIN] epoch: 2997, iter: 236730/250000, loss: 0.1739, lr: 0.000712, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6082 samples/sec | ETA 02:05:05
2023-02-05 05:46:56 [INFO]	[TRAIN] epoch: 2997, iter: 236740/250000, loss: 0.1351, lr: 0.000711, batch_cost: 0.5926, reader_cost: 0.02723, ips: 10.1248 samples/sec | ETA 02:10:57
2023-02-05 05:47:01 [INFO]	[TRAIN] epoch: 2997, iter: 236750/250000, loss: 0.1367, lr: 0.000711, batch_cost: 0.5652, reader_cost: 0.00014, ips: 10.6166 samples/sec | ETA 02:04:48
2023-02-05 05:47:07 [INFO]	[TRAIN] epoch: 2997, iter: 236760/250000, loss: 0.1540, lr: 0.000711, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6281 samples/sec | ETA 02:04:34
2023-02-05 05:47:13 [INFO]	[TRAIN] epoch: 2998, iter: 236770/250000, loss: 0.1340, lr: 0.000710, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6136 samples/sec | ETA 02:04:39
2023-02-05 05:47:18 [INFO]	[TRAIN] epoch: 2998, iter: 236780/250000, loss: 0.1447, lr: 0.000710, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5983 samples/sec | ETA 02:04:44
2023-02-05 05:47:24 [INFO]	[TRAIN] epoch: 2998, iter: 236790/250000, loss: 0.1361, lr: 0.000709, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6138 samples/sec | ETA 02:04:27
2023-02-05 05:47:30 [INFO]	[TRAIN] epoch: 2998, iter: 236800/250000, loss: 0.1306, lr: 0.000709, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6147 samples/sec | ETA 02:04:21
2023-02-05 05:47:35 [INFO]	[TRAIN] epoch: 2998, iter: 236810/250000, loss: 0.2096, lr: 0.000708, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5977 samples/sec | ETA 02:04:27
2023-02-05 05:47:41 [INFO]	[TRAIN] epoch: 2998, iter: 236820/250000, loss: 0.1194, lr: 0.000708, batch_cost: 0.5973, reader_cost: 0.02975, ips: 10.0452 samples/sec | ETA 02:11:12
2023-02-05 05:47:47 [INFO]	[TRAIN] epoch: 2998, iter: 236830/250000, loss: 0.1403, lr: 0.000707, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6155 samples/sec | ETA 02:04:03
2023-02-05 05:47:53 [INFO]	[TRAIN] epoch: 2998, iter: 236840/250000, loss: 0.1701, lr: 0.000707, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6048 samples/sec | ETA 02:04:05
2023-02-05 05:47:58 [INFO]	[TRAIN] epoch: 2999, iter: 236850/250000, loss: 0.1409, lr: 0.000706, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6143 samples/sec | ETA 02:03:53
2023-02-05 05:48:04 [INFO]	[TRAIN] epoch: 2999, iter: 236860/250000, loss: 0.1669, lr: 0.000706, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6070 samples/sec | ETA 02:03:52
2023-02-05 05:48:10 [INFO]	[TRAIN] epoch: 2999, iter: 236870/250000, loss: 0.1270, lr: 0.000705, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6000 samples/sec | ETA 02:03:52
2023-02-05 05:48:15 [INFO]	[TRAIN] epoch: 2999, iter: 236880/250000, loss: 0.1339, lr: 0.000705, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6125 samples/sec | ETA 02:03:37
2023-02-05 05:48:21 [INFO]	[TRAIN] epoch: 2999, iter: 236890/250000, loss: 0.1812, lr: 0.000704, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6088 samples/sec | ETA 02:03:34
2023-02-05 05:48:27 [INFO]	[TRAIN] epoch: 2999, iter: 236900/250000, loss: 0.1336, lr: 0.000704, batch_cost: 0.5862, reader_cost: 0.02140, ips: 10.2354 samples/sec | ETA 02:07:59
2023-02-05 05:48:32 [INFO]	[TRAIN] epoch: 2999, iter: 236910/250000, loss: 0.1352, lr: 0.000703, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6275 samples/sec | ETA 02:03:10
2023-02-05 05:48:38 [INFO]	[TRAIN] epoch: 2999, iter: 236920/250000, loss: 0.1337, lr: 0.000703, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6241 samples/sec | ETA 02:03:06
2023-02-05 05:48:44 [INFO]	[TRAIN] epoch: 3000, iter: 236930/250000, loss: 0.1470, lr: 0.000702, batch_cost: 0.5646, reader_cost: 0.00008, ips: 10.6261 samples/sec | ETA 02:02:59
2023-02-05 05:48:49 [INFO]	[TRAIN] epoch: 3000, iter: 236940/250000, loss: 0.1224, lr: 0.000702, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6330 samples/sec | ETA 02:02:49
2023-02-05 05:48:55 [INFO]	[TRAIN] epoch: 3000, iter: 236950/250000, loss: 0.1422, lr: 0.000701, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6252 samples/sec | ETA 02:02:49
2023-02-05 05:49:01 [INFO]	[TRAIN] epoch: 3000, iter: 236960/250000, loss: 0.1533, lr: 0.000701, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6204 samples/sec | ETA 02:02:46
2023-02-05 05:49:06 [INFO]	[TRAIN] epoch: 3000, iter: 236970/250000, loss: 0.1356, lr: 0.000700, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6153 samples/sec | ETA 02:02:44
2023-02-05 05:49:12 [INFO]	[TRAIN] epoch: 3000, iter: 236980/250000, loss: 0.1334, lr: 0.000700, batch_cost: 0.5881, reader_cost: 0.02360, ips: 10.2022 samples/sec | ETA 02:07:37
2023-02-05 05:49:18 [INFO]	[TRAIN] epoch: 3000, iter: 236990/250000, loss: 0.1707, lr: 0.000699, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6169 samples/sec | ETA 02:02:32
2023-02-05 05:49:24 [INFO]	[TRAIN] epoch: 3000, iter: 237000/250000, loss: 0.1057, lr: 0.000699, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 02:02:35
2023-02-05 05:49:29 [INFO]	[TRAIN] epoch: 3001, iter: 237010/250000, loss: 0.1529, lr: 0.000698, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6049 samples/sec | ETA 02:02:29
2023-02-05 05:49:35 [INFO]	[TRAIN] epoch: 3001, iter: 237020/250000, loss: 0.1268, lr: 0.000698, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6129 samples/sec | ETA 02:02:18
2023-02-05 05:49:40 [INFO]	[TRAIN] epoch: 3001, iter: 237030/250000, loss: 0.1427, lr: 0.000697, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6084 samples/sec | ETA 02:02:15
2023-02-05 05:49:46 [INFO]	[TRAIN] epoch: 3001, iter: 237040/250000, loss: 0.1170, lr: 0.000697, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6027 samples/sec | ETA 02:02:13
2023-02-05 05:49:52 [INFO]	[TRAIN] epoch: 3001, iter: 237050/250000, loss: 0.1427, lr: 0.000697, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6063 samples/sec | ETA 02:02:05
2023-02-05 05:49:58 [INFO]	[TRAIN] epoch: 3001, iter: 237060/250000, loss: 0.1353, lr: 0.000696, batch_cost: 0.5904, reader_cost: 0.02576, ips: 10.1634 samples/sec | ETA 02:07:19
2023-02-05 05:50:03 [INFO]	[TRAIN] epoch: 3001, iter: 237070/250000, loss: 0.1364, lr: 0.000696, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6338 samples/sec | ETA 02:01:35
2023-02-05 05:50:09 [INFO]	[TRAIN] epoch: 3002, iter: 237080/250000, loss: 0.1417, lr: 0.000695, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6262 samples/sec | ETA 02:01:35
2023-02-05 05:50:15 [INFO]	[TRAIN] epoch: 3002, iter: 237090/250000, loss: 0.1267, lr: 0.000695, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6178 samples/sec | ETA 02:01:35
2023-02-05 05:50:20 [INFO]	[TRAIN] epoch: 3002, iter: 237100/250000, loss: 0.1373, lr: 0.000694, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6006 samples/sec | ETA 02:01:41
2023-02-05 05:50:26 [INFO]	[TRAIN] epoch: 3002, iter: 237110/250000, loss: 0.1518, lr: 0.000694, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6096 samples/sec | ETA 02:01:29
2023-02-05 05:50:32 [INFO]	[TRAIN] epoch: 3002, iter: 237120/250000, loss: 0.1287, lr: 0.000693, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6099 samples/sec | ETA 02:01:23
2023-02-05 05:50:37 [INFO]	[TRAIN] epoch: 3002, iter: 237130/250000, loss: 0.1306, lr: 0.000693, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6008 samples/sec | ETA 02:01:24
2023-02-05 05:50:43 [INFO]	[TRAIN] epoch: 3002, iter: 237140/250000, loss: 0.1547, lr: 0.000692, batch_cost: 0.5977, reader_cost: 0.03300, ips: 10.0380 samples/sec | ETA 02:08:06
2023-02-05 05:50:49 [INFO]	[TRAIN] epoch: 3002, iter: 237150/250000, loss: 0.1147, lr: 0.000692, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6032 samples/sec | ETA 02:01:11
2023-02-05 05:50:55 [INFO]	[TRAIN] epoch: 3003, iter: 237160/250000, loss: 0.1401, lr: 0.000691, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6083 samples/sec | ETA 02:01:02
2023-02-05 05:51:00 [INFO]	[TRAIN] epoch: 3003, iter: 237170/250000, loss: 0.1448, lr: 0.000691, batch_cost: 0.5658, reader_cost: 0.00008, ips: 10.6051 samples/sec | ETA 02:00:58
2023-02-05 05:51:06 [INFO]	[TRAIN] epoch: 3003, iter: 237180/250000, loss: 0.1309, lr: 0.000690, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6090 samples/sec | ETA 02:00:50
2023-02-05 05:51:12 [INFO]	[TRAIN] epoch: 3003, iter: 237190/250000, loss: 0.1307, lr: 0.000690, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6086 samples/sec | ETA 02:00:45
2023-02-05 05:51:17 [INFO]	[TRAIN] epoch: 3003, iter: 237200/250000, loss: 0.1388, lr: 0.000689, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6067 samples/sec | ETA 02:00:40
2023-02-05 05:51:23 [INFO]	[TRAIN] epoch: 3003, iter: 237210/250000, loss: 0.1444, lr: 0.000689, batch_cost: 0.5965, reader_cost: 0.03152, ips: 10.0590 samples/sec | ETA 02:07:08
2023-02-05 05:51:29 [INFO]	[TRAIN] epoch: 3003, iter: 237220/250000, loss: 0.1270, lr: 0.000688, batch_cost: 0.5654, reader_cost: 0.00021, ips: 10.6111 samples/sec | ETA 02:00:26
2023-02-05 05:51:34 [INFO]	[TRAIN] epoch: 3003, iter: 237230/250000, loss: 0.1187, lr: 0.000688, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6112 samples/sec | ETA 02:00:20
2023-02-05 05:51:40 [INFO]	[TRAIN] epoch: 3004, iter: 237240/250000, loss: 0.1188, lr: 0.000687, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 02:00:18
2023-02-05 05:51:46 [INFO]	[TRAIN] epoch: 3004, iter: 237250/250000, loss: 0.1387, lr: 0.000687, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6134 samples/sec | ETA 02:00:07
2023-02-05 05:51:51 [INFO]	[TRAIN] epoch: 3004, iter: 237260/250000, loss: 0.1685, lr: 0.000686, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6158 samples/sec | ETA 02:00:00
2023-02-05 05:51:57 [INFO]	[TRAIN] epoch: 3004, iter: 237270/250000, loss: 0.1396, lr: 0.000686, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5971 samples/sec | ETA 02:00:07
2023-02-05 05:52:03 [INFO]	[TRAIN] epoch: 3004, iter: 237280/250000, loss: 0.1193, lr: 0.000685, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6067 samples/sec | ETA 01:59:55
2023-02-05 05:52:09 [INFO]	[TRAIN] epoch: 3004, iter: 237290/250000, loss: 0.1534, lr: 0.000685, batch_cost: 0.5962, reader_cost: 0.03080, ips: 10.0639 samples/sec | ETA 02:06:17
2023-02-05 05:52:14 [INFO]	[TRAIN] epoch: 3004, iter: 237300/250000, loss: 0.1461, lr: 0.000684, batch_cost: 0.5647, reader_cost: 0.00014, ips: 10.6253 samples/sec | ETA 01:59:31
2023-02-05 05:52:20 [INFO]	[TRAIN] epoch: 3004, iter: 237310/250000, loss: 0.1325, lr: 0.000684, batch_cost: 0.5663, reader_cost: 0.00010, ips: 10.5952 samples/sec | ETA 01:59:46
2023-02-05 05:52:26 [INFO]	[TRAIN] epoch: 3005, iter: 237320/250000, loss: 0.1310, lr: 0.000683, batch_cost: 0.5659, reader_cost: 0.00008, ips: 10.6025 samples/sec | ETA 01:59:35
2023-02-05 05:52:31 [INFO]	[TRAIN] epoch: 3005, iter: 237330/250000, loss: 0.1626, lr: 0.000683, batch_cost: 0.5652, reader_cost: 0.00008, ips: 10.6162 samples/sec | ETA 01:59:20
2023-02-05 05:52:37 [INFO]	[TRAIN] epoch: 3005, iter: 237340/250000, loss: 0.1759, lr: 0.000682, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6060 samples/sec | ETA 01:59:21
2023-02-05 05:52:43 [INFO]	[TRAIN] epoch: 3005, iter: 237350/250000, loss: 0.1341, lr: 0.000682, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6078 samples/sec | ETA 01:59:15
2023-02-05 05:52:48 [INFO]	[TRAIN] epoch: 3005, iter: 237360/250000, loss: 0.1263, lr: 0.000681, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6120 samples/sec | ETA 01:59:06
2023-02-05 05:52:54 [INFO]	[TRAIN] epoch: 3005, iter: 237370/250000, loss: 0.1118, lr: 0.000681, batch_cost: 0.5961, reader_cost: 0.03032, ips: 10.0658 samples/sec | ETA 02:05:28
2023-02-05 05:53:00 [INFO]	[TRAIN] epoch: 3005, iter: 237380/250000, loss: 0.1272, lr: 0.000681, batch_cost: 0.5658, reader_cost: 0.00014, ips: 10.6041 samples/sec | ETA 01:59:00
2023-02-05 05:53:06 [INFO]	[TRAIN] epoch: 3005, iter: 237390/250000, loss: 0.1553, lr: 0.000680, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6273 samples/sec | ETA 01:58:39
2023-02-05 05:53:11 [INFO]	[TRAIN] epoch: 3006, iter: 237400/250000, loss: 0.1258, lr: 0.000680, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6239 samples/sec | ETA 01:58:36
2023-02-05 05:53:17 [INFO]	[TRAIN] epoch: 3006, iter: 237410/250000, loss: 0.1427, lr: 0.000679, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6190 samples/sec | ETA 01:58:33
2023-02-05 05:53:23 [INFO]	[TRAIN] epoch: 3006, iter: 237420/250000, loss: 0.1176, lr: 0.000679, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6126 samples/sec | ETA 01:58:32
2023-02-05 05:53:28 [INFO]	[TRAIN] epoch: 3006, iter: 237430/250000, loss: 0.1588, lr: 0.000678, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6061 samples/sec | ETA 01:58:30
2023-02-05 05:53:34 [INFO]	[TRAIN] epoch: 3006, iter: 237440/250000, loss: 0.1529, lr: 0.000678, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6168 samples/sec | ETA 01:58:18
2023-02-05 05:53:40 [INFO]	[TRAIN] epoch: 3006, iter: 237450/250000, loss: 0.1689, lr: 0.000677, batch_cost: 0.5960, reader_cost: 0.03134, ips: 10.0668 samples/sec | ETA 02:04:40
2023-02-05 05:53:45 [INFO]	[TRAIN] epoch: 3006, iter: 237460/250000, loss: 0.1518, lr: 0.000677, batch_cost: 0.5650, reader_cost: 0.00013, ips: 10.6191 samples/sec | ETA 01:58:05
2023-02-05 05:53:51 [INFO]	[TRAIN] epoch: 3006, iter: 237470/250000, loss: 0.1515, lr: 0.000676, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6102 samples/sec | ETA 01:58:05
2023-02-05 05:53:57 [INFO]	[TRAIN] epoch: 3007, iter: 237480/250000, loss: 0.1313, lr: 0.000676, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6059 samples/sec | ETA 01:58:02
2023-02-05 05:54:02 [INFO]	[TRAIN] epoch: 3007, iter: 237490/250000, loss: 0.1195, lr: 0.000675, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6067 samples/sec | ETA 01:57:56
2023-02-05 05:54:08 [INFO]	[TRAIN] epoch: 3007, iter: 237500/250000, loss: 0.1356, lr: 0.000675, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6102 samples/sec | ETA 01:57:48
2023-02-05 05:54:14 [INFO]	[TRAIN] epoch: 3007, iter: 237510/250000, loss: 0.1392, lr: 0.000674, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6092 samples/sec | ETA 01:57:43
2023-02-05 05:54:19 [INFO]	[TRAIN] epoch: 3007, iter: 237520/250000, loss: 0.1265, lr: 0.000674, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6110 samples/sec | ETA 01:57:36
2023-02-05 05:54:25 [INFO]	[TRAIN] epoch: 3007, iter: 237530/250000, loss: 0.1334, lr: 0.000673, batch_cost: 0.5953, reader_cost: 0.03072, ips: 10.0788 samples/sec | ETA 02:03:43
2023-02-05 05:54:31 [INFO]	[TRAIN] epoch: 3007, iter: 237540/250000, loss: 0.1592, lr: 0.000673, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6352 samples/sec | ETA 01:57:09
2023-02-05 05:54:37 [INFO]	[TRAIN] epoch: 3007, iter: 237550/250000, loss: 0.1301, lr: 0.000672, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6214 samples/sec | ETA 01:57:13
2023-02-05 05:54:42 [INFO]	[TRAIN] epoch: 3008, iter: 237560/250000, loss: 0.1776, lr: 0.000672, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6150 samples/sec | ETA 01:57:11
2023-02-05 05:54:48 [INFO]	[TRAIN] epoch: 3008, iter: 237570/250000, loss: 0.1350, lr: 0.000671, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6133 samples/sec | ETA 01:57:07
2023-02-05 05:54:54 [INFO]	[TRAIN] epoch: 3008, iter: 237580/250000, loss: 0.1272, lr: 0.000671, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6060 samples/sec | ETA 01:57:06
2023-02-05 05:54:59 [INFO]	[TRAIN] epoch: 3008, iter: 237590/250000, loss: 0.1323, lr: 0.000670, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5979 samples/sec | ETA 01:57:05
2023-02-05 05:55:05 [INFO]	[TRAIN] epoch: 3008, iter: 237600/250000, loss: 0.1110, lr: 0.000670, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6063 samples/sec | ETA 01:56:54
2023-02-05 05:55:11 [INFO]	[TRAIN] epoch: 3008, iter: 237610/250000, loss: 0.1217, lr: 0.000669, batch_cost: 0.5936, reader_cost: 0.02883, ips: 10.1080 samples/sec | ETA 02:02:34
2023-02-05 05:55:17 [INFO]	[TRAIN] epoch: 3008, iter: 237620/250000, loss: 0.1719, lr: 0.000669, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6104 samples/sec | ETA 01:56:40
2023-02-05 05:55:22 [INFO]	[TRAIN] epoch: 3008, iter: 237630/250000, loss: 0.1438, lr: 0.000668, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6017 samples/sec | ETA 01:56:40
2023-02-05 05:55:28 [INFO]	[TRAIN] epoch: 3009, iter: 237640/250000, loss: 0.1288, lr: 0.000668, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6145 samples/sec | ETA 01:56:26
2023-02-05 05:55:33 [INFO]	[TRAIN] epoch: 3009, iter: 237650/250000, loss: 0.1368, lr: 0.000667, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6074 samples/sec | ETA 01:56:25
2023-02-05 05:55:39 [INFO]	[TRAIN] epoch: 3009, iter: 237660/250000, loss: 0.1546, lr: 0.000667, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6059 samples/sec | ETA 01:56:21
2023-02-05 05:55:45 [INFO]	[TRAIN] epoch: 3009, iter: 237670/250000, loss: 0.1188, lr: 0.000666, batch_cost: 0.5654, reader_cost: 0.00011, ips: 10.6127 samples/sec | ETA 01:56:10
2023-02-05 05:55:50 [INFO]	[TRAIN] epoch: 3009, iter: 237680/250000, loss: 0.1325, lr: 0.000666, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6093 samples/sec | ETA 01:56:07
2023-02-05 05:55:56 [INFO]	[TRAIN] epoch: 3009, iter: 237690/250000, loss: 0.1332, lr: 0.000665, batch_cost: 0.5830, reader_cost: 0.01808, ips: 10.2909 samples/sec | ETA 01:59:37
2023-02-05 05:56:02 [INFO]	[TRAIN] epoch: 3009, iter: 237700/250000, loss: 0.1641, lr: 0.000665, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6312 samples/sec | ETA 01:55:41
2023-02-05 05:56:08 [INFO]	[TRAIN] epoch: 3009, iter: 237710/250000, loss: 0.1247, lr: 0.000664, batch_cost: 0.5648, reader_cost: 0.00008, ips: 10.6224 samples/sec | ETA 01:55:41
2023-02-05 05:56:13 [INFO]	[TRAIN] epoch: 3010, iter: 237720/250000, loss: 0.1245, lr: 0.000664, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6236 samples/sec | ETA 01:55:35
2023-02-05 05:56:19 [INFO]	[TRAIN] epoch: 3010, iter: 237730/250000, loss: 0.1669, lr: 0.000664, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6237 samples/sec | ETA 01:55:29
2023-02-05 05:56:25 [INFO]	[TRAIN] epoch: 3010, iter: 237740/250000, loss: 0.1325, lr: 0.000663, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6194 samples/sec | ETA 01:55:26
2023-02-05 05:56:30 [INFO]	[TRAIN] epoch: 3010, iter: 237750/250000, loss: 0.1424, lr: 0.000663, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5971 samples/sec | ETA 01:55:35
2023-02-05 05:56:36 [INFO]	[TRAIN] epoch: 3010, iter: 237760/250000, loss: 0.1334, lr: 0.000662, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6063 samples/sec | ETA 01:55:24
2023-02-05 05:56:42 [INFO]	[TRAIN] epoch: 3010, iter: 237770/250000, loss: 0.1398, lr: 0.000662, batch_cost: 0.5955, reader_cost: 0.03146, ips: 10.0760 samples/sec | ETA 02:01:22
2023-02-05 05:56:47 [INFO]	[TRAIN] epoch: 3010, iter: 237780/250000, loss: 0.1415, lr: 0.000661, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6311 samples/sec | ETA 01:54:56
2023-02-05 05:56:53 [INFO]	[TRAIN] epoch: 3010, iter: 237790/250000, loss: 0.1206, lr: 0.000661, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6221 samples/sec | ETA 01:54:56
2023-02-05 05:56:59 [INFO]	[TRAIN] epoch: 3011, iter: 237800/250000, loss: 0.1177, lr: 0.000660, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6079 samples/sec | ETA 01:55:00
2023-02-05 05:57:04 [INFO]	[TRAIN] epoch: 3011, iter: 237810/250000, loss: 0.1282, lr: 0.000660, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6075 samples/sec | ETA 01:54:55
2023-02-05 05:57:10 [INFO]	[TRAIN] epoch: 3011, iter: 237820/250000, loss: 0.1378, lr: 0.000659, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6049 samples/sec | ETA 01:54:51
2023-02-05 05:57:16 [INFO]	[TRAIN] epoch: 3011, iter: 237830/250000, loss: 0.1323, lr: 0.000659, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6072 samples/sec | ETA 01:54:44
2023-02-05 05:57:21 [INFO]	[TRAIN] epoch: 3011, iter: 237840/250000, loss: 0.1290, lr: 0.000658, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6094 samples/sec | ETA 01:54:36
2023-02-05 05:57:27 [INFO]	[TRAIN] epoch: 3011, iter: 237850/250000, loss: 0.1347, lr: 0.000658, batch_cost: 0.5925, reader_cost: 0.02655, ips: 10.1258 samples/sec | ETA 01:59:59
2023-02-05 05:57:33 [INFO]	[TRAIN] epoch: 3011, iter: 237860/250000, loss: 0.1858, lr: 0.000657, batch_cost: 0.5647, reader_cost: 0.00008, ips: 10.6255 samples/sec | ETA 01:54:15
2023-02-05 05:57:39 [INFO]	[TRAIN] epoch: 3012, iter: 237870/250000, loss: 0.1392, lr: 0.000657, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6117 samples/sec | ETA 01:54:18
2023-02-05 05:57:44 [INFO]	[TRAIN] epoch: 3012, iter: 237880/250000, loss: 0.1547, lr: 0.000656, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6086 samples/sec | ETA 01:54:14
2023-02-05 05:57:50 [INFO]	[TRAIN] epoch: 3012, iter: 237890/250000, loss: 0.1149, lr: 0.000656, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6082 samples/sec | ETA 01:54:09
2023-02-05 05:57:56 [INFO]	[TRAIN] epoch: 3012, iter: 237900/250000, loss: 0.1303, lr: 0.000655, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6088 samples/sec | ETA 01:54:03
2023-02-05 05:58:01 [INFO]	[TRAIN] epoch: 3012, iter: 237910/250000, loss: 0.1313, lr: 0.000655, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 01:53:59
2023-02-05 05:58:07 [INFO]	[TRAIN] epoch: 3012, iter: 237920/250000, loss: 0.1382, lr: 0.000654, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6101 samples/sec | ETA 01:53:51
2023-02-05 05:58:13 [INFO]	[TRAIN] epoch: 3012, iter: 237930/250000, loss: 0.1156, lr: 0.000654, batch_cost: 0.5936, reader_cost: 0.02828, ips: 10.1071 samples/sec | ETA 01:59:25
2023-02-05 05:58:18 [INFO]	[TRAIN] epoch: 3012, iter: 237940/250000, loss: 0.1418, lr: 0.000653, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6246 samples/sec | ETA 01:53:30
2023-02-05 05:58:24 [INFO]	[TRAIN] epoch: 3013, iter: 237950/250000, loss: 0.1828, lr: 0.000653, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6235 samples/sec | ETA 01:53:25
2023-02-05 05:58:30 [INFO]	[TRAIN] epoch: 3013, iter: 237960/250000, loss: 0.1243, lr: 0.000652, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6114 samples/sec | ETA 01:53:27
2023-02-05 05:58:35 [INFO]	[TRAIN] epoch: 3013, iter: 237970/250000, loss: 0.1349, lr: 0.000652, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6052 samples/sec | ETA 01:53:26
2023-02-05 05:58:41 [INFO]	[TRAIN] epoch: 3013, iter: 237980/250000, loss: 0.1165, lr: 0.000651, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6100 samples/sec | ETA 01:53:17
2023-02-05 05:58:47 [INFO]	[TRAIN] epoch: 3013, iter: 237990/250000, loss: 0.1559, lr: 0.000651, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6089 samples/sec | ETA 01:53:12
2023-02-05 05:58:53 [INFO]	[TRAIN] epoch: 3013, iter: 238000/250000, loss: 0.1489, lr: 0.000650, batch_cost: 0.5996, reader_cost: 0.03374, ips: 10.0067 samples/sec | ETA 01:59:55
2023-02-05 05:58:53 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1253 - reader cost: 0.0257 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1504 - reader cost: 0.0129 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1579 - reader cost: 0.0086 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1588 - reader cost: 0.0065 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1596 - reader cost: 0.0052 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1618 - reader cost: 0.0044 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1619 - reader cost: 0.0038 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1625 - reader cost: 0.0033 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1637 - reader cost: 0.002910/36 [=======>......................] - ETA: 4s - batch_cost: 0.1632 - reader cost: 0.002711/36 [========>.....................] - ETA: 4s - batch_cost: 0.1637 - reader cost: 0.002412/36 [=========>....................] - ETA: 3s - batch_cost: 0.1630 - reader cost: 0.002213/36 [=========>....................] - ETA: 3s - batch_cost: 0.1630 - reader cost: 0.002114/36 [==========>...................] - ETA: 3s - batch_cost: 0.1631 - reader cost: 0.001915/36 [===========>..................] - ETA: 3s - batch_cost: 0.1632 - reader cost: 0.001816/36 [============>.................] - ETA: 3s - batch_cost: 0.1641 - reader cost: 0.001717/36 [=============>................] - ETA: 3s - batch_cost: 0.1643 - reader cost: 0.001618/36 [==============>...............] - ETA: 2s - batch_cost: 0.1643 - reader cost: 0.001519/36 [==============>...............] - ETA: 2s - batch_cost: 0.1640 - reader cost: 0.001420/36 [===============>..............] - ETA: 2s - batch_cost: 0.1638 - reader cost: 0.001421/36 [================>.............] - ETA: 2s - batch_cost: 0.1640 - reader cost: 0.001322/36 [=================>............] - ETA: 2s - batch_cost: 0.1644 - reader cost: 0.001223/36 [==================>...........] - ETA: 2s - batch_cost: 0.1650 - reader cost: 0.001224/36 [===================>..........] - ETA: 1s - batch_cost: 0.1648 - reader cost: 0.001125/36 [===================>..........] - ETA: 1s - batch_cost: 0.1650 - reader cost: 0.001126/36 [====================>.........] - ETA: 1s - batch_cost: 0.1654 - reader cost: 0.001127/36 [=====================>........] - ETA: 1s - batch_cost: 0.1657 - reader cost: 0.001028/36 [======================>.......] - ETA: 1s - batch_cost: 0.1660 - reader cost: 9.9265e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1661 - reader cost: 9.6084e-0430/36 [========================>.....] - ETA: 0s - batch_cost: 0.1660 - reader cost: 9.3118e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1660 - reader cost: 9.0337e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1659 - reader cost: 8.7724e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1657 - reader cost: 8.5257e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1655 - reader cost: 8.2935e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1655 - reader cost: 8.0741e-0436/36 [==============================] - 6s 166ms/step - batch_cost: 0.1656 - reader cost: 7.8719e-04
2023-02-05 05:58:59 [INFO]	[EVAL] #Images: 36 mIoU: 0.8665 Acc: 0.9860 Kappa: 0.9493 Dice: 0.9252
2023-02-05 05:58:59 [INFO]	[EVAL] Class IoU: 
[0.9854 0.9065 0.8926 0.7161 0.7189 0.9717 0.8747]
2023-02-05 05:58:59 [INFO]	[EVAL] Class Precision: 
[0.9924 0.968  0.9439 0.817  0.8717 0.9832 0.9044]
2023-02-05 05:58:59 [INFO]	[EVAL] Class Recall: 
[0.9929 0.9345 0.9426 0.8528 0.804  0.988  0.9638]
2023-02-05 05:58:59 [INFO]	[EVAL] The model with the best validation mIoU (0.8682) was saved at iter 222000.
2023-02-05 05:59:05 [INFO]	[TRAIN] epoch: 3013, iter: 238010/250000, loss: 0.1372, lr: 0.000650, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6354 samples/sec | ETA 01:52:44
2023-02-05 05:59:10 [INFO]	[TRAIN] epoch: 3013, iter: 238020/250000, loss: 0.1195, lr: 0.000649, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6385 samples/sec | ETA 01:52:36
2023-02-05 05:59:16 [INFO]	[TRAIN] epoch: 3014, iter: 238030/250000, loss: 0.1533, lr: 0.000649, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6290 samples/sec | ETA 01:52:36
2023-02-05 05:59:22 [INFO]	[TRAIN] epoch: 3014, iter: 238040/250000, loss: 0.1671, lr: 0.000648, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6306 samples/sec | ETA 01:52:30
2023-02-05 05:59:27 [INFO]	[TRAIN] epoch: 3014, iter: 238050/250000, loss: 0.1399, lr: 0.000648, batch_cost: 0.5645, reader_cost: 0.00018, ips: 10.6293 samples/sec | ETA 01:52:25
2023-02-05 05:59:33 [INFO]	[TRAIN] epoch: 3014, iter: 238060/250000, loss: 0.1604, lr: 0.000647, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6279 samples/sec | ETA 01:52:20
2023-02-05 05:59:38 [INFO]	[TRAIN] epoch: 3014, iter: 238070/250000, loss: 0.1622, lr: 0.000647, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6313 samples/sec | ETA 01:52:12
2023-02-05 05:59:44 [INFO]	[TRAIN] epoch: 3014, iter: 238080/250000, loss: 0.1427, lr: 0.000646, batch_cost: 0.5965, reader_cost: 0.03136, ips: 10.0580 samples/sec | ETA 01:58:30
2023-02-05 05:59:50 [INFO]	[TRAIN] epoch: 3014, iter: 238090/250000, loss: 0.1245, lr: 0.000646, batch_cost: 0.5646, reader_cost: 0.00017, ips: 10.6265 samples/sec | ETA 01:52:04
2023-02-05 05:59:56 [INFO]	[TRAIN] epoch: 3014, iter: 238100/250000, loss: 0.1512, lr: 0.000645, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6223 samples/sec | ETA 01:52:01
2023-02-05 06:00:01 [INFO]	[TRAIN] epoch: 3015, iter: 238110/250000, loss: 0.1185, lr: 0.000645, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6295 samples/sec | ETA 01:51:51
2023-02-05 06:00:07 [INFO]	[TRAIN] epoch: 3015, iter: 238120/250000, loss: 0.1318, lr: 0.000644, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6289 samples/sec | ETA 01:51:46
2023-02-05 06:00:13 [INFO]	[TRAIN] epoch: 3015, iter: 238130/250000, loss: 0.1480, lr: 0.000644, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6284 samples/sec | ETA 01:51:40
2023-02-05 06:00:18 [INFO]	[TRAIN] epoch: 3015, iter: 238140/250000, loss: 0.1847, lr: 0.000644, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6248 samples/sec | ETA 01:51:37
2023-02-05 06:00:24 [INFO]	[TRAIN] epoch: 3015, iter: 238150/250000, loss: 0.1431, lr: 0.000643, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6117 samples/sec | ETA 01:51:40
2023-02-05 06:00:30 [INFO]	[TRAIN] epoch: 3015, iter: 238160/250000, loss: 0.1430, lr: 0.000643, batch_cost: 0.5948, reader_cost: 0.02925, ips: 10.0879 samples/sec | ETA 01:57:22
2023-02-05 06:00:36 [INFO]	[TRAIN] epoch: 3015, iter: 238170/250000, loss: 0.1436, lr: 0.000642, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6341 samples/sec | ETA 01:51:14
2023-02-05 06:00:41 [INFO]	[TRAIN] epoch: 3015, iter: 238180/250000, loss: 0.1253, lr: 0.000642, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6129 samples/sec | ETA 01:51:22
2023-02-05 06:00:47 [INFO]	[TRAIN] epoch: 3016, iter: 238190/250000, loss: 0.0932, lr: 0.000641, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6091 samples/sec | ETA 01:51:19
2023-02-05 06:00:53 [INFO]	[TRAIN] epoch: 3016, iter: 238200/250000, loss: 0.1705, lr: 0.000641, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6040 samples/sec | ETA 01:51:16
2023-02-05 06:00:58 [INFO]	[TRAIN] epoch: 3016, iter: 238210/250000, loss: 0.1251, lr: 0.000640, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6238 samples/sec | ETA 01:50:58
2023-02-05 06:01:04 [INFO]	[TRAIN] epoch: 3016, iter: 238220/250000, loss: 0.1273, lr: 0.000640, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6022 samples/sec | ETA 01:51:06
2023-02-05 06:01:09 [INFO]	[TRAIN] epoch: 3016, iter: 238230/250000, loss: 0.1263, lr: 0.000639, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6099 samples/sec | ETA 01:50:56
2023-02-05 06:01:16 [INFO]	[TRAIN] epoch: 3016, iter: 238240/250000, loss: 0.1400, lr: 0.000639, batch_cost: 0.6065, reader_cost: 0.04071, ips: 9.8932 samples/sec | ETA 01:58:52
2023-02-05 06:01:21 [INFO]	[TRAIN] epoch: 3016, iter: 238250/250000, loss: 0.1531, lr: 0.000638, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6267 samples/sec | ETA 01:50:34
2023-02-05 06:01:27 [INFO]	[TRAIN] epoch: 3016, iter: 238260/250000, loss: 0.1201, lr: 0.000638, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6084 samples/sec | ETA 01:50:40
2023-02-05 06:01:32 [INFO]	[TRAIN] epoch: 3017, iter: 238270/250000, loss: 0.1209, lr: 0.000637, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6097 samples/sec | ETA 01:50:33
2023-02-05 06:01:38 [INFO]	[TRAIN] epoch: 3017, iter: 238280/250000, loss: 0.1291, lr: 0.000637, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6074 samples/sec | ETA 01:50:29
2023-02-05 06:01:44 [INFO]	[TRAIN] epoch: 3017, iter: 238290/250000, loss: 0.1398, lr: 0.000636, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6134 samples/sec | ETA 01:50:19
2023-02-05 06:01:49 [INFO]	[TRAIN] epoch: 3017, iter: 238300/250000, loss: 0.1288, lr: 0.000636, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6160 samples/sec | ETA 01:50:12
2023-02-05 06:01:55 [INFO]	[TRAIN] epoch: 3017, iter: 238310/250000, loss: 0.1621, lr: 0.000635, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6005 samples/sec | ETA 01:50:16
2023-02-05 06:02:01 [INFO]	[TRAIN] epoch: 3017, iter: 238320/250000, loss: 0.1125, lr: 0.000635, batch_cost: 0.5921, reader_cost: 0.02718, ips: 10.1328 samples/sec | ETA 01:55:16
2023-02-05 06:02:07 [INFO]	[TRAIN] epoch: 3017, iter: 238330/250000, loss: 0.1052, lr: 0.000634, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6169 samples/sec | ETA 01:49:55
2023-02-05 06:02:12 [INFO]	[TRAIN] epoch: 3017, iter: 238340/250000, loss: 0.1104, lr: 0.000634, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6083 samples/sec | ETA 01:49:54
2023-02-05 06:02:18 [INFO]	[TRAIN] epoch: 3018, iter: 238350/250000, loss: 0.1348, lr: 0.000633, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6125 samples/sec | ETA 01:49:46
2023-02-05 06:02:24 [INFO]	[TRAIN] epoch: 3018, iter: 238360/250000, loss: 0.1750, lr: 0.000633, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6065 samples/sec | ETA 01:49:44
2023-02-05 06:02:29 [INFO]	[TRAIN] epoch: 3018, iter: 238370/250000, loss: 0.1106, lr: 0.000632, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6154 samples/sec | ETA 01:49:33
2023-02-05 06:02:35 [INFO]	[TRAIN] epoch: 3018, iter: 238380/250000, loss: 0.1216, lr: 0.000632, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6202 samples/sec | ETA 01:49:24
2023-02-05 06:02:41 [INFO]	[TRAIN] epoch: 3018, iter: 238390/250000, loss: 0.1571, lr: 0.000631, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5948 samples/sec | ETA 01:49:34
2023-02-05 06:02:46 [INFO]	[TRAIN] epoch: 3018, iter: 238400/250000, loss: 0.1227, lr: 0.000631, batch_cost: 0.5871, reader_cost: 0.02152, ips: 10.2189 samples/sec | ETA 01:53:30
2023-02-05 06:02:52 [INFO]	[TRAIN] epoch: 3018, iter: 238410/250000, loss: 0.1329, lr: 0.000630, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6116 samples/sec | ETA 01:49:13
2023-02-05 06:02:58 [INFO]	[TRAIN] epoch: 3018, iter: 238420/250000, loss: 0.1423, lr: 0.000630, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6104 samples/sec | ETA 01:49:08
2023-02-05 06:03:03 [INFO]	[TRAIN] epoch: 3019, iter: 238430/250000, loss: 0.1194, lr: 0.000629, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6055 samples/sec | ETA 01:49:05
2023-02-05 06:03:09 [INFO]	[TRAIN] epoch: 3019, iter: 238440/250000, loss: 0.1183, lr: 0.000629, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6077 samples/sec | ETA 01:48:58
2023-02-05 06:03:15 [INFO]	[TRAIN] epoch: 3019, iter: 238450/250000, loss: 0.1316, lr: 0.000628, batch_cost: 0.5648, reader_cost: 0.00008, ips: 10.6223 samples/sec | ETA 01:48:44
2023-02-05 06:03:20 [INFO]	[TRAIN] epoch: 3019, iter: 238460/250000, loss: 0.1388, lr: 0.000628, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6036 samples/sec | ETA 01:48:49
2023-02-05 06:03:26 [INFO]	[TRAIN] epoch: 3019, iter: 238470/250000, loss: 0.1725, lr: 0.000627, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6012 samples/sec | ETA 01:48:45
2023-02-05 06:03:32 [INFO]	[TRAIN] epoch: 3019, iter: 238480/250000, loss: 0.1069, lr: 0.000627, batch_cost: 0.5997, reader_cost: 0.03504, ips: 10.0049 samples/sec | ETA 01:55:08
2023-02-05 06:03:38 [INFO]	[TRAIN] epoch: 3019, iter: 238490/250000, loss: 0.1162, lr: 0.000626, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6124 samples/sec | ETA 01:48:27
2023-02-05 06:03:43 [INFO]	[TRAIN] epoch: 3019, iter: 238500/250000, loss: 0.1302, lr: 0.000626, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6034 samples/sec | ETA 01:48:27
2023-02-05 06:03:49 [INFO]	[TRAIN] epoch: 3020, iter: 238510/250000, loss: 0.1669, lr: 0.000625, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6146 samples/sec | ETA 01:48:14
2023-02-05 06:03:55 [INFO]	[TRAIN] epoch: 3020, iter: 238520/250000, loss: 0.1280, lr: 0.000625, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6075 samples/sec | ETA 01:48:13
2023-02-05 06:04:00 [INFO]	[TRAIN] epoch: 3020, iter: 238530/250000, loss: 0.1306, lr: 0.000624, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6055 samples/sec | ETA 01:48:09
2023-02-05 06:04:06 [INFO]	[TRAIN] epoch: 3020, iter: 238540/250000, loss: 0.1473, lr: 0.000624, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6165 samples/sec | ETA 01:47:56
2023-02-05 06:04:12 [INFO]	[TRAIN] epoch: 3020, iter: 238550/250000, loss: 0.1171, lr: 0.000623, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6083 samples/sec | ETA 01:47:56
2023-02-05 06:04:18 [INFO]	[TRAIN] epoch: 3020, iter: 238560/250000, loss: 0.1380, lr: 0.000623, batch_cost: 0.6027, reader_cost: 0.03781, ips: 9.9545 samples/sec | ETA 01:54:55
2023-02-05 06:04:23 [INFO]	[TRAIN] epoch: 3020, iter: 238570/250000, loss: 0.1138, lr: 0.000622, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6095 samples/sec | ETA 01:47:44
2023-02-05 06:04:29 [INFO]	[TRAIN] epoch: 3020, iter: 238580/250000, loss: 0.1140, lr: 0.000622, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6107 samples/sec | ETA 01:47:37
2023-02-05 06:04:35 [INFO]	[TRAIN] epoch: 3021, iter: 238590/250000, loss: 0.1204, lr: 0.000622, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6142 samples/sec | ETA 01:47:29
2023-02-05 06:04:40 [INFO]	[TRAIN] epoch: 3021, iter: 238600/250000, loss: 0.1567, lr: 0.000621, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6114 samples/sec | ETA 01:47:25
2023-02-05 06:04:46 [INFO]	[TRAIN] epoch: 3021, iter: 238610/250000, loss: 0.1473, lr: 0.000621, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6113 samples/sec | ETA 01:47:20
2023-02-05 06:04:52 [INFO]	[TRAIN] epoch: 3021, iter: 238620/250000, loss: 0.1312, lr: 0.000620, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6082 samples/sec | ETA 01:47:16
2023-02-05 06:04:57 [INFO]	[TRAIN] epoch: 3021, iter: 238630/250000, loss: 0.1428, lr: 0.000620, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6021 samples/sec | ETA 01:47:14
2023-02-05 06:05:03 [INFO]	[TRAIN] epoch: 3021, iter: 238640/250000, loss: 0.1113, lr: 0.000619, batch_cost: 0.5983, reader_cost: 0.03197, ips: 10.0277 samples/sec | ETA 01:53:17
2023-02-05 06:05:09 [INFO]	[TRAIN] epoch: 3021, iter: 238650/250000, loss: 0.1369, lr: 0.000619, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6092 samples/sec | ETA 01:46:58
2023-02-05 06:05:15 [INFO]	[TRAIN] epoch: 3022, iter: 238660/250000, loss: 0.1233, lr: 0.000618, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6071 samples/sec | ETA 01:46:54
2023-02-05 06:05:20 [INFO]	[TRAIN] epoch: 3022, iter: 238670/250000, loss: 0.1164, lr: 0.000618, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6087 samples/sec | ETA 01:46:47
2023-02-05 06:05:26 [INFO]	[TRAIN] epoch: 3022, iter: 238680/250000, loss: 0.1616, lr: 0.000617, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5993 samples/sec | ETA 01:46:47
2023-02-05 06:05:32 [INFO]	[TRAIN] epoch: 3022, iter: 238690/250000, loss: 0.1407, lr: 0.000617, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6133 samples/sec | ETA 01:46:33
2023-02-05 06:05:37 [INFO]	[TRAIN] epoch: 3022, iter: 238700/250000, loss: 0.1262, lr: 0.000616, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6099 samples/sec | ETA 01:46:30
2023-02-05 06:05:43 [INFO]	[TRAIN] epoch: 3022, iter: 238710/250000, loss: 0.1267, lr: 0.000616, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6018 samples/sec | ETA 01:46:29
2023-02-05 06:05:49 [INFO]	[TRAIN] epoch: 3022, iter: 238720/250000, loss: 0.1577, lr: 0.000615, batch_cost: 0.5931, reader_cost: 0.02714, ips: 10.1159 samples/sec | ETA 01:51:30
2023-02-05 06:05:54 [INFO]	[TRAIN] epoch: 3022, iter: 238730/250000, loss: 0.1556, lr: 0.000615, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5973 samples/sec | ETA 01:46:20
2023-02-05 06:06:00 [INFO]	[TRAIN] epoch: 3023, iter: 238740/250000, loss: 0.1503, lr: 0.000614, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6124 samples/sec | ETA 01:46:06
2023-02-05 06:06:06 [INFO]	[TRAIN] epoch: 3023, iter: 238750/250000, loss: 0.1178, lr: 0.000614, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6137 samples/sec | ETA 01:45:59
2023-02-05 06:06:11 [INFO]	[TRAIN] epoch: 3023, iter: 238760/250000, loss: 0.1506, lr: 0.000613, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 01:45:59
2023-02-05 06:06:17 [INFO]	[TRAIN] epoch: 3023, iter: 238770/250000, loss: 0.1129, lr: 0.000613, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6060 samples/sec | ETA 01:45:52
2023-02-05 06:06:23 [INFO]	[TRAIN] epoch: 3023, iter: 238780/250000, loss: 0.1142, lr: 0.000612, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6182 samples/sec | ETA 01:45:40
2023-02-05 06:06:29 [INFO]	[TRAIN] epoch: 3023, iter: 238790/250000, loss: 0.1289, lr: 0.000612, batch_cost: 0.5991, reader_cost: 0.03321, ips: 10.0151 samples/sec | ETA 01:51:55
2023-02-05 06:06:34 [INFO]	[TRAIN] epoch: 3023, iter: 238800/250000, loss: 0.1206, lr: 0.000611, batch_cost: 0.5652, reader_cost: 0.00011, ips: 10.6150 samples/sec | ETA 01:45:30
2023-02-05 06:06:40 [INFO]	[TRAIN] epoch: 3023, iter: 238810/250000, loss: 0.1123, lr: 0.000611, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6071 samples/sec | ETA 01:45:29
2023-02-05 06:06:46 [INFO]	[TRAIN] epoch: 3024, iter: 238820/250000, loss: 0.1439, lr: 0.000610, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6129 samples/sec | ETA 01:45:20
2023-02-05 06:06:51 [INFO]	[TRAIN] epoch: 3024, iter: 238830/250000, loss: 0.1306, lr: 0.000610, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6082 samples/sec | ETA 01:45:17
2023-02-05 06:06:57 [INFO]	[TRAIN] epoch: 3024, iter: 238840/250000, loss: 0.1595, lr: 0.000609, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6087 samples/sec | ETA 01:45:11
2023-02-05 06:07:03 [INFO]	[TRAIN] epoch: 3024, iter: 238850/250000, loss: 0.1392, lr: 0.000609, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6123 samples/sec | ETA 01:45:04
2023-02-05 06:07:08 [INFO]	[TRAIN] epoch: 3024, iter: 238860/250000, loss: 0.1399, lr: 0.000608, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6014 samples/sec | ETA 01:45:04
2023-02-05 06:07:14 [INFO]	[TRAIN] epoch: 3024, iter: 238870/250000, loss: 0.1626, lr: 0.000608, batch_cost: 0.5909, reader_cost: 0.02569, ips: 10.1537 samples/sec | ETA 01:49:36
2023-02-05 06:07:20 [INFO]	[TRAIN] epoch: 3024, iter: 238880/250000, loss: 0.1230, lr: 0.000607, batch_cost: 0.5665, reader_cost: 0.00014, ips: 10.5909 samples/sec | ETA 01:44:59
2023-02-05 06:07:26 [INFO]	[TRAIN] epoch: 3024, iter: 238890/250000, loss: 0.1369, lr: 0.000607, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6058 samples/sec | ETA 01:44:45
2023-02-05 06:07:31 [INFO]	[TRAIN] epoch: 3025, iter: 238900/250000, loss: 0.1132, lr: 0.000606, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6164 samples/sec | ETA 01:44:33
2023-02-05 06:07:37 [INFO]	[TRAIN] epoch: 3025, iter: 238910/250000, loss: 0.1323, lr: 0.000606, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6147 samples/sec | ETA 01:44:28
2023-02-05 06:07:43 [INFO]	[TRAIN] epoch: 3025, iter: 238920/250000, loss: 0.1622, lr: 0.000605, batch_cost: 0.5660, reader_cost: 0.00008, ips: 10.6012 samples/sec | ETA 01:44:30
2023-02-05 06:07:48 [INFO]	[TRAIN] epoch: 3025, iter: 238930/250000, loss: 0.1076, lr: 0.000605, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6088 samples/sec | ETA 01:44:20
2023-02-05 06:07:54 [INFO]	[TRAIN] epoch: 3025, iter: 238940/250000, loss: 0.1179, lr: 0.000604, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6140 samples/sec | ETA 01:44:12
2023-02-05 06:08:00 [INFO]	[TRAIN] epoch: 3025, iter: 238950/250000, loss: 0.1204, lr: 0.000604, batch_cost: 0.5904, reader_cost: 0.02515, ips: 10.1622 samples/sec | ETA 01:48:44
2023-02-05 06:08:05 [INFO]	[TRAIN] epoch: 3025, iter: 238960/250000, loss: 0.1354, lr: 0.000603, batch_cost: 0.5658, reader_cost: 0.00018, ips: 10.6041 samples/sec | ETA 01:44:06
2023-02-05 06:08:11 [INFO]	[TRAIN] epoch: 3025, iter: 238970/250000, loss: 0.1275, lr: 0.000603, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6153 samples/sec | ETA 01:43:54
2023-02-05 06:08:17 [INFO]	[TRAIN] epoch: 3026, iter: 238980/250000, loss: 0.1512, lr: 0.000602, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6051 samples/sec | ETA 01:43:54
2023-02-05 06:08:22 [INFO]	[TRAIN] epoch: 3026, iter: 238990/250000, loss: 0.1160, lr: 0.000602, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6085 samples/sec | ETA 01:43:47
2023-02-05 06:08:28 [INFO]	[TRAIN] epoch: 3026, iter: 239000/250000, loss: 0.1411, lr: 0.000601, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6115 samples/sec | ETA 01:43:39
2023-02-05 06:08:34 [INFO]	[TRAIN] epoch: 3026, iter: 239010/250000, loss: 0.1319, lr: 0.000601, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6057 samples/sec | ETA 01:43:37
2023-02-05 06:08:39 [INFO]	[TRAIN] epoch: 3026, iter: 239020/250000, loss: 0.1559, lr: 0.000600, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6053 samples/sec | ETA 01:43:31
2023-02-05 06:08:45 [INFO]	[TRAIN] epoch: 3026, iter: 239030/250000, loss: 0.1523, lr: 0.000600, batch_cost: 0.5870, reader_cost: 0.02142, ips: 10.2218 samples/sec | ETA 01:47:19
2023-02-05 06:08:51 [INFO]	[TRAIN] epoch: 3026, iter: 239040/250000, loss: 0.1299, lr: 0.000599, batch_cost: 0.5669, reader_cost: 0.00009, ips: 10.5844 samples/sec | ETA 01:43:32
2023-02-05 06:08:57 [INFO]	[TRAIN] epoch: 3026, iter: 239050/250000, loss: 0.1408, lr: 0.000599, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6074 samples/sec | ETA 01:43:13
2023-02-05 06:09:02 [INFO]	[TRAIN] epoch: 3027, iter: 239060/250000, loss: 0.1149, lr: 0.000598, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6133 samples/sec | ETA 01:43:04
2023-02-05 06:09:08 [INFO]	[TRAIN] epoch: 3027, iter: 239070/250000, loss: 0.1546, lr: 0.000598, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6094 samples/sec | ETA 01:43:01
2023-02-05 06:09:13 [INFO]	[TRAIN] epoch: 3027, iter: 239080/250000, loss: 0.1336, lr: 0.000597, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6111 samples/sec | ETA 01:42:54
2023-02-05 06:09:19 [INFO]	[TRAIN] epoch: 3027, iter: 239090/250000, loss: 0.1285, lr: 0.000597, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6132 samples/sec | ETA 01:42:47
2023-02-05 06:09:25 [INFO]	[TRAIN] epoch: 3027, iter: 239100/250000, loss: 0.1497, lr: 0.000596, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6042 samples/sec | ETA 01:42:47
2023-02-05 06:09:31 [INFO]	[TRAIN] epoch: 3027, iter: 239110/250000, loss: 0.1156, lr: 0.000596, batch_cost: 0.5943, reader_cost: 0.02823, ips: 10.0958 samples/sec | ETA 01:47:52
2023-02-05 06:09:36 [INFO]	[TRAIN] epoch: 3027, iter: 239120/250000, loss: 0.1205, lr: 0.000595, batch_cost: 0.5662, reader_cost: 0.00013, ips: 10.5977 samples/sec | ETA 01:42:39
2023-02-05 06:09:42 [INFO]	[TRAIN] epoch: 3027, iter: 239130/250000, loss: 0.1305, lr: 0.000595, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6094 samples/sec | ETA 01:42:27
2023-02-05 06:09:48 [INFO]	[TRAIN] epoch: 3028, iter: 239140/250000, loss: 0.1482, lr: 0.000594, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6165 samples/sec | ETA 01:42:17
2023-02-05 06:09:53 [INFO]	[TRAIN] epoch: 3028, iter: 239150/250000, loss: 0.1254, lr: 0.000594, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6015 samples/sec | ETA 01:42:20
2023-02-05 06:09:59 [INFO]	[TRAIN] epoch: 3028, iter: 239160/250000, loss: 0.1330, lr: 0.000593, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6150 samples/sec | ETA 01:42:07
2023-02-05 06:10:05 [INFO]	[TRAIN] epoch: 3028, iter: 239170/250000, loss: 0.1348, lr: 0.000593, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6128 samples/sec | ETA 01:42:02
2023-02-05 06:10:10 [INFO]	[TRAIN] epoch: 3028, iter: 239180/250000, loss: 0.1362, lr: 0.000593, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6035 samples/sec | ETA 01:42:02
2023-02-05 06:10:16 [INFO]	[TRAIN] epoch: 3028, iter: 239190/250000, loss: 0.1509, lr: 0.000592, batch_cost: 0.5928, reader_cost: 0.02738, ips: 10.1210 samples/sec | ETA 01:46:48
2023-02-05 06:10:22 [INFO]	[TRAIN] epoch: 3028, iter: 239200/250000, loss: 0.1381, lr: 0.000592, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6097 samples/sec | ETA 01:41:47
2023-02-05 06:10:28 [INFO]	[TRAIN] epoch: 3028, iter: 239210/250000, loss: 0.1179, lr: 0.000591, batch_cost: 0.5655, reader_cost: 0.00015, ips: 10.6108 samples/sec | ETA 01:41:41
2023-02-05 06:10:33 [INFO]	[TRAIN] epoch: 3029, iter: 239220/250000, loss: 0.1316, lr: 0.000591, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6149 samples/sec | ETA 01:41:33
2023-02-05 06:10:39 [INFO]	[TRAIN] epoch: 3029, iter: 239230/250000, loss: 0.1528, lr: 0.000590, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6123 samples/sec | ETA 01:41:29
2023-02-05 06:10:45 [INFO]	[TRAIN] epoch: 3029, iter: 239240/250000, loss: 0.1310, lr: 0.000590, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6003 samples/sec | ETA 01:41:30
2023-02-05 06:10:50 [INFO]	[TRAIN] epoch: 3029, iter: 239250/250000, loss: 0.1373, lr: 0.000589, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6139 samples/sec | ETA 01:41:16
2023-02-05 06:10:56 [INFO]	[TRAIN] epoch: 3029, iter: 239260/250000, loss: 0.1442, lr: 0.000589, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6136 samples/sec | ETA 01:41:11
2023-02-05 06:11:02 [INFO]	[TRAIN] epoch: 3029, iter: 239270/250000, loss: 0.1785, lr: 0.000588, batch_cost: 0.5971, reader_cost: 0.03138, ips: 10.0485 samples/sec | ETA 01:46:46
2023-02-05 06:11:07 [INFO]	[TRAIN] epoch: 3029, iter: 239280/250000, loss: 0.1258, lr: 0.000588, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6064 samples/sec | ETA 01:41:04
2023-02-05 06:11:13 [INFO]	[TRAIN] epoch: 3029, iter: 239290/250000, loss: 0.1284, lr: 0.000587, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6116 samples/sec | ETA 01:40:55
2023-02-05 06:11:19 [INFO]	[TRAIN] epoch: 3030, iter: 239300/250000, loss: 0.1235, lr: 0.000587, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6142 samples/sec | ETA 01:40:48
2023-02-05 06:11:24 [INFO]	[TRAIN] epoch: 3030, iter: 239310/250000, loss: 0.1216, lr: 0.000586, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6068 samples/sec | ETA 01:40:47
2023-02-05 06:11:30 [INFO]	[TRAIN] epoch: 3030, iter: 239320/250000, loss: 0.1261, lr: 0.000586, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6075 samples/sec | ETA 01:40:41
2023-02-05 06:11:36 [INFO]	[TRAIN] epoch: 3030, iter: 239330/250000, loss: 0.1263, lr: 0.000585, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6091 samples/sec | ETA 01:40:34
2023-02-05 06:11:41 [INFO]	[TRAIN] epoch: 3030, iter: 239340/250000, loss: 0.1294, lr: 0.000585, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6083 samples/sec | ETA 01:40:29
2023-02-05 06:11:47 [INFO]	[TRAIN] epoch: 3030, iter: 239350/250000, loss: 0.1545, lr: 0.000584, batch_cost: 0.5869, reader_cost: 0.02129, ips: 10.2233 samples/sec | ETA 01:44:10
2023-02-05 06:11:53 [INFO]	[TRAIN] epoch: 3030, iter: 239360/250000, loss: 0.1500, lr: 0.000584, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6191 samples/sec | ETA 01:40:11
2023-02-05 06:11:59 [INFO]	[TRAIN] epoch: 3030, iter: 239370/250000, loss: 0.1161, lr: 0.000583, batch_cost: 0.5656, reader_cost: 0.00011, ips: 10.6091 samples/sec | ETA 01:40:11
2023-02-05 06:12:04 [INFO]	[TRAIN] epoch: 3031, iter: 239380/250000, loss: 0.1226, lr: 0.000583, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6036 samples/sec | ETA 01:40:09
2023-02-05 06:12:10 [INFO]	[TRAIN] epoch: 3031, iter: 239390/250000, loss: 0.1209, lr: 0.000582, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6154 samples/sec | ETA 01:39:56
2023-02-05 06:12:16 [INFO]	[TRAIN] epoch: 3031, iter: 239400/250000, loss: 0.1334, lr: 0.000582, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6070 samples/sec | ETA 01:39:56
2023-02-05 06:12:21 [INFO]	[TRAIN] epoch: 3031, iter: 239410/250000, loss: 0.1164, lr: 0.000581, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6045 samples/sec | ETA 01:39:51
2023-02-05 06:12:27 [INFO]	[TRAIN] epoch: 3031, iter: 239420/250000, loss: 0.1192, lr: 0.000581, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6102 samples/sec | ETA 01:39:42
2023-02-05 06:12:33 [INFO]	[TRAIN] epoch: 3031, iter: 239430/250000, loss: 0.1217, lr: 0.000580, batch_cost: 0.5918, reader_cost: 0.02574, ips: 10.1391 samples/sec | ETA 01:44:15
2023-02-05 06:12:38 [INFO]	[TRAIN] epoch: 3031, iter: 239440/250000, loss: 0.1362, lr: 0.000580, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6048 samples/sec | ETA 01:39:34
2023-02-05 06:12:44 [INFO]	[TRAIN] epoch: 3032, iter: 239450/250000, loss: 0.1325, lr: 0.000579, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6219 samples/sec | ETA 01:39:19
2023-02-05 06:12:50 [INFO]	[TRAIN] epoch: 3032, iter: 239460/250000, loss: 0.1469, lr: 0.000579, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6040 samples/sec | ETA 01:39:23
2023-02-05 06:12:55 [INFO]	[TRAIN] epoch: 3032, iter: 239470/250000, loss: 0.1221, lr: 0.000578, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6055 samples/sec | ETA 01:39:17
2023-02-05 06:13:01 [INFO]	[TRAIN] epoch: 3032, iter: 239480/250000, loss: 0.1316, lr: 0.000578, batch_cost: 0.5651, reader_cost: 0.00008, ips: 10.6171 samples/sec | ETA 01:39:05
2023-02-05 06:13:07 [INFO]	[TRAIN] epoch: 3032, iter: 239490/250000, loss: 0.1280, lr: 0.000577, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6055 samples/sec | ETA 01:39:05
2023-02-05 06:13:12 [INFO]	[TRAIN] epoch: 3032, iter: 239500/250000, loss: 0.1376, lr: 0.000577, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5959 samples/sec | ETA 01:39:05
2023-02-05 06:13:18 [INFO]	[TRAIN] epoch: 3032, iter: 239510/250000, loss: 0.1189, lr: 0.000576, batch_cost: 0.5888, reader_cost: 0.02312, ips: 10.1908 samples/sec | ETA 01:42:56
2023-02-05 06:13:24 [INFO]	[TRAIN] epoch: 3032, iter: 239520/250000, loss: 0.1343, lr: 0.000576, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6069 samples/sec | ETA 01:38:48
2023-02-05 06:13:30 [INFO]	[TRAIN] epoch: 3033, iter: 239530/250000, loss: 0.1116, lr: 0.000575, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6135 samples/sec | ETA 01:38:38
2023-02-05 06:13:35 [INFO]	[TRAIN] epoch: 3033, iter: 239540/250000, loss: 0.1212, lr: 0.000575, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6059 samples/sec | ETA 01:38:37
2023-02-05 06:13:41 [INFO]	[TRAIN] epoch: 3033, iter: 239550/250000, loss: 0.1367, lr: 0.000574, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6091 samples/sec | ETA 01:38:30
2023-02-05 06:13:47 [INFO]	[TRAIN] epoch: 3033, iter: 239560/250000, loss: 0.1396, lr: 0.000574, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6134 samples/sec | ETA 01:38:21
2023-02-05 06:13:52 [INFO]	[TRAIN] epoch: 3033, iter: 239570/250000, loss: 0.1258, lr: 0.000573, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6054 samples/sec | ETA 01:38:20
2023-02-05 06:13:58 [INFO]	[TRAIN] epoch: 3033, iter: 239580/250000, loss: 0.1351, lr: 0.000573, batch_cost: 0.5898, reader_cost: 0.02432, ips: 10.1737 samples/sec | ETA 01:42:25
2023-02-05 06:14:04 [INFO]	[TRAIN] epoch: 3033, iter: 239590/250000, loss: 0.1417, lr: 0.000572, batch_cost: 0.5659, reader_cost: 0.00020, ips: 10.6035 samples/sec | ETA 01:38:10
2023-02-05 06:14:09 [INFO]	[TRAIN] epoch: 3033, iter: 239600/250000, loss: 0.1419, lr: 0.000572, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6125 samples/sec | ETA 01:37:59
2023-02-05 06:14:15 [INFO]	[TRAIN] epoch: 3034, iter: 239610/250000, loss: 0.1497, lr: 0.000571, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6113 samples/sec | ETA 01:37:54
2023-02-05 06:14:21 [INFO]	[TRAIN] epoch: 3034, iter: 239620/250000, loss: 0.1348, lr: 0.000571, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6057 samples/sec | ETA 01:37:52
2023-02-05 06:14:26 [INFO]	[TRAIN] epoch: 3034, iter: 239630/250000, loss: 0.1355, lr: 0.000570, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6182 samples/sec | ETA 01:37:39
2023-02-05 06:14:32 [INFO]	[TRAIN] epoch: 3034, iter: 239640/250000, loss: 0.1158, lr: 0.000570, batch_cost: 0.5653, reader_cost: 0.00011, ips: 10.6146 samples/sec | ETA 01:37:36
2023-02-05 06:14:38 [INFO]	[TRAIN] epoch: 3034, iter: 239650/250000, loss: 0.1207, lr: 0.000569, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6034 samples/sec | ETA 01:37:36
2023-02-05 06:14:44 [INFO]	[TRAIN] epoch: 3034, iter: 239660/250000, loss: 0.1153, lr: 0.000569, batch_cost: 0.5932, reader_cost: 0.02785, ips: 10.1149 samples/sec | ETA 01:42:13
2023-02-05 06:14:49 [INFO]	[TRAIN] epoch: 3034, iter: 239670/250000, loss: 0.1199, lr: 0.000568, batch_cost: 0.5647, reader_cost: 0.00014, ips: 10.6247 samples/sec | ETA 01:37:13
2023-02-05 06:14:55 [INFO]	[TRAIN] epoch: 3034, iter: 239680/250000, loss: 0.1399, lr: 0.000568, batch_cost: 0.5658, reader_cost: 0.00011, ips: 10.6048 samples/sec | ETA 01:37:18
2023-02-05 06:15:01 [INFO]	[TRAIN] epoch: 3035, iter: 239690/250000, loss: 0.1279, lr: 0.000567, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 01:37:13
2023-02-05 06:15:06 [INFO]	[TRAIN] epoch: 3035, iter: 239700/250000, loss: 0.1541, lr: 0.000567, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 01:37:07
2023-02-05 06:15:12 [INFO]	[TRAIN] epoch: 3035, iter: 239710/250000, loss: 0.1531, lr: 0.000566, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6150 samples/sec | ETA 01:36:56
2023-02-05 06:15:18 [INFO]	[TRAIN] epoch: 3035, iter: 239720/250000, loss: 0.1288, lr: 0.000566, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6107 samples/sec | ETA 01:36:53
2023-02-05 06:15:23 [INFO]	[TRAIN] epoch: 3035, iter: 239730/250000, loss: 0.1934, lr: 0.000565, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6116 samples/sec | ETA 01:36:46
2023-02-05 06:15:29 [INFO]	[TRAIN] epoch: 3035, iter: 239740/250000, loss: 0.1253, lr: 0.000565, batch_cost: 0.5982, reader_cost: 0.03270, ips: 10.0304 samples/sec | ETA 01:42:17
2023-02-05 06:15:35 [INFO]	[TRAIN] epoch: 3035, iter: 239750/250000, loss: 0.1202, lr: 0.000564, batch_cost: 0.5641, reader_cost: 0.00017, ips: 10.6360 samples/sec | ETA 01:36:22
2023-02-05 06:15:40 [INFO]	[TRAIN] epoch: 3035, iter: 239760/250000, loss: 0.1308, lr: 0.000564, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6334 samples/sec | ETA 01:36:18
2023-02-05 06:15:46 [INFO]	[TRAIN] epoch: 3036, iter: 239770/250000, loss: 0.1244, lr: 0.000563, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6230 samples/sec | ETA 01:36:18
2023-02-05 06:15:52 [INFO]	[TRAIN] epoch: 3036, iter: 239780/250000, loss: 0.1061, lr: 0.000563, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6308 samples/sec | ETA 01:36:08
2023-02-05 06:15:57 [INFO]	[TRAIN] epoch: 3036, iter: 239790/250000, loss: 0.1178, lr: 0.000562, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6240 samples/sec | ETA 01:36:06
2023-02-05 06:16:03 [INFO]	[TRAIN] epoch: 3036, iter: 239800/250000, loss: 0.1178, lr: 0.000562, batch_cost: 0.5637, reader_cost: 0.00009, ips: 10.6442 samples/sec | ETA 01:35:49
2023-02-05 06:16:09 [INFO]	[TRAIN] epoch: 3036, iter: 239810/250000, loss: 0.1415, lr: 0.000561, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6372 samples/sec | ETA 01:35:47
2023-02-05 06:16:15 [INFO]	[TRAIN] epoch: 3036, iter: 239820/250000, loss: 0.1227, lr: 0.000561, batch_cost: 0.5884, reader_cost: 0.02424, ips: 10.1967 samples/sec | ETA 01:39:50
2023-02-05 06:16:20 [INFO]	[TRAIN] epoch: 3036, iter: 239830/250000, loss: 0.1294, lr: 0.000560, batch_cost: 0.5647, reader_cost: 0.00013, ips: 10.6243 samples/sec | ETA 01:35:43
2023-02-05 06:16:26 [INFO]	[TRAIN] epoch: 3036, iter: 239840/250000, loss: 0.1443, lr: 0.000560, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6256 samples/sec | ETA 01:35:37
2023-02-05 06:16:32 [INFO]	[TRAIN] epoch: 3037, iter: 239850/250000, loss: 0.1407, lr: 0.000559, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6360 samples/sec | ETA 01:35:25
2023-02-05 06:16:37 [INFO]	[TRAIN] epoch: 3037, iter: 239860/250000, loss: 0.1386, lr: 0.000559, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6316 samples/sec | ETA 01:35:22
2023-02-05 06:16:43 [INFO]	[TRAIN] epoch: 3037, iter: 239870/250000, loss: 0.1217, lr: 0.000558, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6293 samples/sec | ETA 01:35:18
2023-02-05 06:16:48 [INFO]	[TRAIN] epoch: 3037, iter: 239880/250000, loss: 0.1400, lr: 0.000558, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6232 samples/sec | ETA 01:35:15
2023-02-05 06:16:54 [INFO]	[TRAIN] epoch: 3037, iter: 239890/250000, loss: 0.1279, lr: 0.000557, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6177 samples/sec | ETA 01:35:13
2023-02-05 06:17:00 [INFO]	[TRAIN] epoch: 3037, iter: 239900/250000, loss: 0.1387, lr: 0.000557, batch_cost: 0.5882, reader_cost: 0.02317, ips: 10.2011 samples/sec | ETA 01:39:00
2023-02-05 06:17:06 [INFO]	[TRAIN] epoch: 3037, iter: 239910/250000, loss: 0.1828, lr: 0.000556, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6249 samples/sec | ETA 01:34:57
2023-02-05 06:17:11 [INFO]	[TRAIN] epoch: 3037, iter: 239920/250000, loss: 0.1525, lr: 0.000556, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6317 samples/sec | ETA 01:34:48
2023-02-05 06:17:17 [INFO]	[TRAIN] epoch: 3038, iter: 239930/250000, loss: 0.1379, lr: 0.000555, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6315 samples/sec | ETA 01:34:43
2023-02-05 06:17:23 [INFO]	[TRAIN] epoch: 3038, iter: 239940/250000, loss: 0.1632, lr: 0.000555, batch_cost: 0.5661, reader_cost: 0.00008, ips: 10.5991 samples/sec | ETA 01:34:54
2023-02-05 06:17:28 [INFO]	[TRAIN] epoch: 3038, iter: 239950/250000, loss: 0.1136, lr: 0.000554, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6026 samples/sec | ETA 01:34:47
2023-02-05 06:17:34 [INFO]	[TRAIN] epoch: 3038, iter: 239960/250000, loss: 0.1772, lr: 0.000554, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6133 samples/sec | ETA 01:34:35
2023-02-05 06:17:40 [INFO]	[TRAIN] epoch: 3038, iter: 239970/250000, loss: 0.1203, lr: 0.000553, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6122 samples/sec | ETA 01:34:30
2023-02-05 06:17:45 [INFO]	[TRAIN] epoch: 3038, iter: 239980/250000, loss: 0.1544, lr: 0.000553, batch_cost: 0.5920, reader_cost: 0.02620, ips: 10.1351 samples/sec | ETA 01:38:51
2023-02-05 06:17:51 [INFO]	[TRAIN] epoch: 3038, iter: 239990/250000, loss: 0.1354, lr: 0.000552, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6336 samples/sec | ETA 01:34:08
2023-02-05 06:17:57 [INFO]	[TRAIN] epoch: 3038, iter: 240000/250000, loss: 0.1268, lr: 0.000552, batch_cost: 0.5646, reader_cost: 0.00022, ips: 10.6271 samples/sec | ETA 01:34:05
2023-02-05 06:17:57 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1283 - reader cost: 0.0302 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1507 - reader cost: 0.0152 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1575 - reader cost: 0.0101 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1582 - reader cost: 0.0076 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1595 - reader cost: 0.0061 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1613 - reader cost: 0.0051 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1615 - reader cost: 0.0044 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1620 - reader cost: 0.0038 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1633 - reader cost: 0.003410/36 [=======>......................] - ETA: 4s - batch_cost: 0.1632 - reader cost: 0.003111/36 [========>.....................] - ETA: 4s - batch_cost: 0.1637 - reader cost: 0.002812/36 [=========>....................] - ETA: 3s - batch_cost: 0.1632 - reader cost: 0.002613/36 [=========>....................] - ETA: 3s - batch_cost: 0.1634 - reader cost: 0.002414/36 [==========>...................] - ETA: 3s - batch_cost: 0.1640 - reader cost: 0.002215/36 [===========>..................] - ETA: 3s - batch_cost: 0.1639 - reader cost: 0.002116/36 [============>.................] - ETA: 3s - batch_cost: 0.1647 - reader cost: 0.002017/36 [=============>................] - ETA: 3s - batch_cost: 0.1650 - reader cost: 0.001918/36 [==============>...............] - ETA: 2s - batch_cost: 0.1651 - reader cost: 0.001819/36 [==============>...............] - ETA: 2s - batch_cost: 0.1649 - reader cost: 0.001720/36 [===============>..............] - ETA: 2s - batch_cost: 0.1648 - reader cost: 0.001621/36 [================>.............] - ETA: 2s - batch_cost: 0.1649 - reader cost: 0.001522/36 [=================>............] - ETA: 2s - batch_cost: 0.1652 - reader cost: 0.001423/36 [==================>...........] - ETA: 2s - batch_cost: 0.1657 - reader cost: 0.001424/36 [===================>..........] - ETA: 1s - batch_cost: 0.1656 - reader cost: 0.001325/36 [===================>..........] - ETA: 1s - batch_cost: 0.1657 - reader cost: 0.001326/36 [====================>.........] - ETA: 1s - batch_cost: 0.1659 - reader cost: 0.001227/36 [=====================>........] - ETA: 1s - batch_cost: 0.1661 - reader cost: 0.001228/36 [======================>.......] - ETA: 1s - batch_cost: 0.1663 - reader cost: 0.001229/36 [=======================>......] - ETA: 1s - batch_cost: 0.1665 - reader cost: 0.001130/36 [========================>.....] - ETA: 0s - batch_cost: 0.1664 - reader cost: 0.001131/36 [========================>.....] - ETA: 0s - batch_cost: 0.1663 - reader cost: 0.001032/36 [=========================>....] - ETA: 0s - batch_cost: 0.1663 - reader cost: 0.001033/36 [==========================>...] - ETA: 0s - batch_cost: 0.1661 - reader cost: 9.8902e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1658 - reader cost: 9.6177e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1657 - reader cost: 9.3616e-0436/36 [==============================] - 6s 166ms/step - batch_cost: 0.1658 - reader cost: 9.1224e-04
2023-02-05 06:18:03 [INFO]	[EVAL] #Images: 36 mIoU: 0.8647 Acc: 0.9864 Kappa: 0.9508 Dice: 0.9237
2023-02-05 06:18:03 [INFO]	[EVAL] Class IoU: 
[0.9858 0.9157 0.8931 0.7015 0.708  0.9728 0.8761]
2023-02-05 06:18:03 [INFO]	[EVAL] Class Precision: 
[0.9927 0.9679 0.9433 0.8221 0.8494 0.9848 0.9121]
2023-02-05 06:18:03 [INFO]	[EVAL] Class Recall: 
[0.993  0.9443 0.9438 0.827  0.8096 0.9876 0.9568]
2023-02-05 06:18:03 [INFO]	[EVAL] The model with the best validation mIoU (0.8682) was saved at iter 222000.
2023-02-05 06:18:09 [INFO]	[TRAIN] epoch: 3039, iter: 240010/250000, loss: 0.1446, lr: 0.000551, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6299 samples/sec | ETA 01:33:58
2023-02-05 06:18:14 [INFO]	[TRAIN] epoch: 3039, iter: 240020/250000, loss: 0.1273, lr: 0.000551, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6312 samples/sec | ETA 01:33:52
2023-02-05 06:18:20 [INFO]	[TRAIN] epoch: 3039, iter: 240030/250000, loss: 0.1423, lr: 0.000550, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6334 samples/sec | ETA 01:33:45
2023-02-05 06:18:26 [INFO]	[TRAIN] epoch: 3039, iter: 240040/250000, loss: 0.1284, lr: 0.000550, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6346 samples/sec | ETA 01:33:39
2023-02-05 06:18:31 [INFO]	[TRAIN] epoch: 3039, iter: 240050/250000, loss: 0.1216, lr: 0.000549, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6208 samples/sec | ETA 01:33:41
2023-02-05 06:18:37 [INFO]	[TRAIN] epoch: 3039, iter: 240060/250000, loss: 0.1124, lr: 0.000549, batch_cost: 0.5883, reader_cost: 0.02445, ips: 10.1984 samples/sec | ETA 01:37:27
2023-02-05 06:18:43 [INFO]	[TRAIN] epoch: 3039, iter: 240070/250000, loss: 0.1913, lr: 0.000548, batch_cost: 0.5640, reader_cost: 0.00010, ips: 10.6381 samples/sec | ETA 01:33:20
2023-02-05 06:18:48 [INFO]	[TRAIN] epoch: 3039, iter: 240080/250000, loss: 0.1204, lr: 0.000548, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6407 samples/sec | ETA 01:33:13
2023-02-05 06:18:54 [INFO]	[TRAIN] epoch: 3040, iter: 240090/250000, loss: 0.1220, lr: 0.000547, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6229 samples/sec | ETA 01:33:17
2023-02-05 06:19:00 [INFO]	[TRAIN] epoch: 3040, iter: 240100/250000, loss: 0.1284, lr: 0.000547, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6238 samples/sec | ETA 01:33:11
2023-02-05 06:19:05 [INFO]	[TRAIN] epoch: 3040, iter: 240110/250000, loss: 0.1194, lr: 0.000546, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6341 samples/sec | ETA 01:33:00
2023-02-05 06:19:11 [INFO]	[TRAIN] epoch: 3040, iter: 240120/250000, loss: 0.2154, lr: 0.000546, batch_cost: 0.5642, reader_cost: 0.00008, ips: 10.6354 samples/sec | ETA 01:32:53
2023-02-05 06:19:17 [INFO]	[TRAIN] epoch: 3040, iter: 240130/250000, loss: 0.1299, lr: 0.000545, batch_cost: 0.5647, reader_cost: 0.00008, ips: 10.6254 samples/sec | ETA 01:32:53
2023-02-05 06:19:23 [INFO]	[TRAIN] epoch: 3040, iter: 240140/250000, loss: 0.1329, lr: 0.000545, batch_cost: 0.5950, reader_cost: 0.03045, ips: 10.0847 samples/sec | ETA 01:37:46
2023-02-05 06:19:28 [INFO]	[TRAIN] epoch: 3040, iter: 240150/250000, loss: 0.1400, lr: 0.000544, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6249 samples/sec | ETA 01:32:42
2023-02-05 06:19:34 [INFO]	[TRAIN] epoch: 3040, iter: 240160/250000, loss: 0.1279, lr: 0.000544, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6249 samples/sec | ETA 01:32:36
2023-02-05 06:19:39 [INFO]	[TRAIN] epoch: 3041, iter: 240170/250000, loss: 0.1471, lr: 0.000543, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6315 samples/sec | ETA 01:32:27
2023-02-05 06:19:45 [INFO]	[TRAIN] epoch: 3041, iter: 240180/250000, loss: 0.1138, lr: 0.000543, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6363 samples/sec | ETA 01:32:19
2023-02-05 06:19:51 [INFO]	[TRAIN] epoch: 3041, iter: 240190/250000, loss: 0.1133, lr: 0.000542, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6353 samples/sec | ETA 01:32:14
2023-02-05 06:19:56 [INFO]	[TRAIN] epoch: 3041, iter: 240200/250000, loss: 0.1373, lr: 0.000542, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5976 samples/sec | ETA 01:32:28
2023-02-05 06:20:02 [INFO]	[TRAIN] epoch: 3041, iter: 240210/250000, loss: 0.1330, lr: 0.000541, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6021 samples/sec | ETA 01:32:20
2023-02-05 06:20:08 [INFO]	[TRAIN] epoch: 3041, iter: 240220/250000, loss: 0.1340, lr: 0.000541, batch_cost: 0.5963, reader_cost: 0.03157, ips: 10.0614 samples/sec | ETA 01:37:12
2023-02-05 06:20:14 [INFO]	[TRAIN] epoch: 3041, iter: 240230/250000, loss: 0.1199, lr: 0.000541, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6346 samples/sec | ETA 01:31:52
2023-02-05 06:20:19 [INFO]	[TRAIN] epoch: 3042, iter: 240240/250000, loss: 0.1366, lr: 0.000540, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6270 samples/sec | ETA 01:31:50
2023-02-05 06:20:25 [INFO]	[TRAIN] epoch: 3042, iter: 240250/250000, loss: 0.1655, lr: 0.000540, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6164 samples/sec | ETA 01:31:50
2023-02-05 06:20:31 [INFO]	[TRAIN] epoch: 3042, iter: 240260/250000, loss: 0.1092, lr: 0.000539, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6090 samples/sec | ETA 01:31:48
2023-02-05 06:20:36 [INFO]	[TRAIN] epoch: 3042, iter: 240270/250000, loss: 0.1557, lr: 0.000539, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6056 samples/sec | ETA 01:31:44
2023-02-05 06:20:42 [INFO]	[TRAIN] epoch: 3042, iter: 240280/250000, loss: 0.1419, lr: 0.000538, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6000 samples/sec | ETA 01:31:41
2023-02-05 06:20:48 [INFO]	[TRAIN] epoch: 3042, iter: 240290/250000, loss: 0.1389, lr: 0.000538, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6092 samples/sec | ETA 01:31:31
2023-02-05 06:20:54 [INFO]	[TRAIN] epoch: 3042, iter: 240300/250000, loss: 0.1199, lr: 0.000537, batch_cost: 0.5942, reader_cost: 0.03008, ips: 10.0969 samples/sec | ETA 01:36:04
2023-02-05 06:20:59 [INFO]	[TRAIN] epoch: 3042, iter: 240310/250000, loss: 0.1375, lr: 0.000537, batch_cost: 0.5648, reader_cost: 0.00008, ips: 10.6225 samples/sec | ETA 01:31:13
2023-02-05 06:21:05 [INFO]	[TRAIN] epoch: 3043, iter: 240320/250000, loss: 0.1491, lr: 0.000536, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6273 samples/sec | ETA 01:31:05
2023-02-05 06:21:11 [INFO]	[TRAIN] epoch: 3043, iter: 240330/250000, loss: 0.1319, lr: 0.000536, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6251 samples/sec | ETA 01:31:00
2023-02-05 06:21:16 [INFO]	[TRAIN] epoch: 3043, iter: 240340/250000, loss: 0.1282, lr: 0.000535, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6283 samples/sec | ETA 01:30:53
2023-02-05 06:21:22 [INFO]	[TRAIN] epoch: 3043, iter: 240350/250000, loss: 0.1037, lr: 0.000535, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6300 samples/sec | ETA 01:30:46
2023-02-05 06:21:27 [INFO]	[TRAIN] epoch: 3043, iter: 240360/250000, loss: 0.1382, lr: 0.000534, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6323 samples/sec | ETA 01:30:40
2023-02-05 06:21:33 [INFO]	[TRAIN] epoch: 3043, iter: 240370/250000, loss: 0.1611, lr: 0.000534, batch_cost: 0.5873, reader_cost: 0.02309, ips: 10.2169 samples/sec | ETA 01:34:15
2023-02-05 06:21:39 [INFO]	[TRAIN] epoch: 3043, iter: 240380/250000, loss: 0.1689, lr: 0.000533, batch_cost: 0.5651, reader_cost: 0.00013, ips: 10.6177 samples/sec | ETA 01:30:36
2023-02-05 06:21:45 [INFO]	[TRAIN] epoch: 3043, iter: 240390/250000, loss: 0.1184, lr: 0.000533, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6360 samples/sec | ETA 01:30:21
2023-02-05 06:21:50 [INFO]	[TRAIN] epoch: 3044, iter: 240400/250000, loss: 0.1111, lr: 0.000532, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6371 samples/sec | ETA 01:30:15
2023-02-05 06:21:56 [INFO]	[TRAIN] epoch: 3044, iter: 240410/250000, loss: 0.1521, lr: 0.000532, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6315 samples/sec | ETA 01:30:12
2023-02-05 06:22:02 [INFO]	[TRAIN] epoch: 3044, iter: 240420/250000, loss: 0.1758, lr: 0.000531, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6223 samples/sec | ETA 01:30:11
2023-02-05 06:22:07 [INFO]	[TRAIN] epoch: 3044, iter: 240430/250000, loss: 0.1414, lr: 0.000531, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6089 samples/sec | ETA 01:30:12
2023-02-05 06:22:13 [INFO]	[TRAIN] epoch: 3044, iter: 240440/250000, loss: 0.1186, lr: 0.000530, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6098 samples/sec | ETA 01:30:06
2023-02-05 06:22:19 [INFO]	[TRAIN] epoch: 3044, iter: 240450/250000, loss: 0.1343, lr: 0.000530, batch_cost: 0.5955, reader_cost: 0.03026, ips: 10.0758 samples/sec | ETA 01:34:46
2023-02-05 06:22:24 [INFO]	[TRAIN] epoch: 3044, iter: 240460/250000, loss: 0.1154, lr: 0.000529, batch_cost: 0.5646, reader_cost: 0.00018, ips: 10.6261 samples/sec | ETA 01:29:46
2023-02-05 06:22:30 [INFO]	[TRAIN] epoch: 3044, iter: 240470/250000, loss: 0.1409, lr: 0.000529, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6311 samples/sec | ETA 01:29:38
2023-02-05 06:22:36 [INFO]	[TRAIN] epoch: 3045, iter: 240480/250000, loss: 0.1332, lr: 0.000528, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6272 samples/sec | ETA 01:29:34
2023-02-05 06:22:41 [INFO]	[TRAIN] epoch: 3045, iter: 240490/250000, loss: 0.1342, lr: 0.000528, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6311 samples/sec | ETA 01:29:27
2023-02-05 06:22:47 [INFO]	[TRAIN] epoch: 3045, iter: 240500/250000, loss: 0.1047, lr: 0.000527, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6361 samples/sec | ETA 01:29:19
2023-02-05 06:22:53 [INFO]	[TRAIN] epoch: 3045, iter: 240510/250000, loss: 0.1151, lr: 0.000527, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6273 samples/sec | ETA 01:29:17
2023-02-05 06:22:58 [INFO]	[TRAIN] epoch: 3045, iter: 240520/250000, loss: 0.1646, lr: 0.000526, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6285 samples/sec | ETA 01:29:11
2023-02-05 06:23:04 [INFO]	[TRAIN] epoch: 3045, iter: 240530/250000, loss: 0.1657, lr: 0.000526, batch_cost: 0.5920, reader_cost: 0.02723, ips: 10.1355 samples/sec | ETA 01:33:26
2023-02-05 06:23:10 [INFO]	[TRAIN] epoch: 3045, iter: 240540/250000, loss: 0.1377, lr: 0.000525, batch_cost: 0.5642, reader_cost: 0.00019, ips: 10.6352 samples/sec | ETA 01:28:56
2023-02-05 06:23:16 [INFO]	[TRAIN] epoch: 3045, iter: 240550/250000, loss: 0.1634, lr: 0.000525, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6220 samples/sec | ETA 01:28:57
2023-02-05 06:23:21 [INFO]	[TRAIN] epoch: 3046, iter: 240560/250000, loss: 0.1967, lr: 0.000524, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6310 samples/sec | ETA 01:28:47
2023-02-05 06:23:27 [INFO]	[TRAIN] epoch: 3046, iter: 240570/250000, loss: 0.1397, lr: 0.000524, batch_cost: 0.5641, reader_cost: 0.00011, ips: 10.6357 samples/sec | ETA 01:28:39
2023-02-05 06:23:32 [INFO]	[TRAIN] epoch: 3046, iter: 240580/250000, loss: 0.1215, lr: 0.000523, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6335 samples/sec | ETA 01:28:35
2023-02-05 06:23:38 [INFO]	[TRAIN] epoch: 3046, iter: 240590/250000, loss: 0.1205, lr: 0.000523, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6304 samples/sec | ETA 01:28:31
2023-02-05 06:23:44 [INFO]	[TRAIN] epoch: 3046, iter: 240600/250000, loss: 0.1410, lr: 0.000522, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6257 samples/sec | ETA 01:28:27
2023-02-05 06:23:50 [INFO]	[TRAIN] epoch: 3046, iter: 240610/250000, loss: 0.1700, lr: 0.000522, batch_cost: 0.5824, reader_cost: 0.01820, ips: 10.3021 samples/sec | ETA 01:31:08
2023-02-05 06:23:55 [INFO]	[TRAIN] epoch: 3046, iter: 240620/250000, loss: 0.1436, lr: 0.000521, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6113 samples/sec | ETA 01:28:23
2023-02-05 06:24:01 [INFO]	[TRAIN] epoch: 3046, iter: 240630/250000, loss: 0.1464, lr: 0.000521, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6326 samples/sec | ETA 01:28:07
2023-02-05 06:24:07 [INFO]	[TRAIN] epoch: 3047, iter: 240640/250000, loss: 0.1367, lr: 0.000520, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6411 samples/sec | ETA 01:27:57
2023-02-05 06:24:12 [INFO]	[TRAIN] epoch: 3047, iter: 240650/250000, loss: 0.1405, lr: 0.000520, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6329 samples/sec | ETA 01:27:56
2023-02-05 06:24:18 [INFO]	[TRAIN] epoch: 3047, iter: 240660/250000, loss: 0.1445, lr: 0.000519, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6250 samples/sec | ETA 01:27:54
2023-02-05 06:24:23 [INFO]	[TRAIN] epoch: 3047, iter: 240670/250000, loss: 0.1314, lr: 0.000519, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6237 samples/sec | ETA 01:27:49
2023-02-05 06:24:29 [INFO]	[TRAIN] epoch: 3047, iter: 240680/250000, loss: 0.1177, lr: 0.000518, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6353 samples/sec | ETA 01:27:37
2023-02-05 06:24:35 [INFO]	[TRAIN] epoch: 3047, iter: 240690/250000, loss: 0.1439, lr: 0.000518, batch_cost: 0.5938, reader_cost: 0.02985, ips: 10.1051 samples/sec | ETA 01:32:07
2023-02-05 06:24:41 [INFO]	[TRAIN] epoch: 3047, iter: 240700/250000, loss: 0.1212, lr: 0.000517, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6297 samples/sec | ETA 01:27:29
2023-02-05 06:24:46 [INFO]	[TRAIN] epoch: 3047, iter: 240710/250000, loss: 0.1451, lr: 0.000517, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6361 samples/sec | ETA 01:27:20
2023-02-05 06:24:52 [INFO]	[TRAIN] epoch: 3048, iter: 240720/250000, loss: 0.1308, lr: 0.000516, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6357 samples/sec | ETA 01:27:15
2023-02-05 06:24:58 [INFO]	[TRAIN] epoch: 3048, iter: 240730/250000, loss: 0.1292, lr: 0.000516, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6252 samples/sec | ETA 01:27:14
2023-02-05 06:25:03 [INFO]	[TRAIN] epoch: 3048, iter: 240740/250000, loss: 0.1293, lr: 0.000515, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6226 samples/sec | ETA 01:27:10
2023-02-05 06:25:09 [INFO]	[TRAIN] epoch: 3048, iter: 240750/250000, loss: 0.1199, lr: 0.000515, batch_cost: 0.5645, reader_cost: 0.00012, ips: 10.6294 samples/sec | ETA 01:27:01
2023-02-05 06:25:15 [INFO]	[TRAIN] epoch: 3048, iter: 240760/250000, loss: 0.1075, lr: 0.000514, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6337 samples/sec | ETA 01:26:53
2023-02-05 06:25:21 [INFO]	[TRAIN] epoch: 3048, iter: 240770/250000, loss: 0.1164, lr: 0.000514, batch_cost: 0.5972, reader_cost: 0.03277, ips: 10.0467 samples/sec | ETA 01:31:52
2023-02-05 06:25:26 [INFO]	[TRAIN] epoch: 3048, iter: 240780/250000, loss: 0.1544, lr: 0.000513, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6276 samples/sec | ETA 01:26:45
2023-02-05 06:25:32 [INFO]	[TRAIN] epoch: 3048, iter: 240790/250000, loss: 0.1283, lr: 0.000513, batch_cost: 0.5646, reader_cost: 0.00008, ips: 10.6273 samples/sec | ETA 01:26:39
2023-02-05 06:25:37 [INFO]	[TRAIN] epoch: 3049, iter: 240800/250000, loss: 0.1049, lr: 0.000512, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6358 samples/sec | ETA 01:26:30
2023-02-05 06:25:43 [INFO]	[TRAIN] epoch: 3049, iter: 240810/250000, loss: 0.1386, lr: 0.000512, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6348 samples/sec | ETA 01:26:24
2023-02-05 06:25:49 [INFO]	[TRAIN] epoch: 3049, iter: 240820/250000, loss: 0.1550, lr: 0.000511, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6354 samples/sec | ETA 01:26:18
2023-02-05 06:25:54 [INFO]	[TRAIN] epoch: 3049, iter: 240830/250000, loss: 0.1504, lr: 0.000511, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6250 samples/sec | ETA 01:26:18
2023-02-05 06:26:00 [INFO]	[TRAIN] epoch: 3049, iter: 240840/250000, loss: 0.1167, lr: 0.000510, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6256 samples/sec | ETA 01:26:12
2023-02-05 06:26:06 [INFO]	[TRAIN] epoch: 3049, iter: 240850/250000, loss: 0.1226, lr: 0.000510, batch_cost: 0.5899, reader_cost: 0.02532, ips: 10.1716 samples/sec | ETA 01:29:57
2023-02-05 06:26:12 [INFO]	[TRAIN] epoch: 3049, iter: 240860/250000, loss: 0.1311, lr: 0.000509, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6259 samples/sec | ETA 01:26:00
2023-02-05 06:26:17 [INFO]	[TRAIN] epoch: 3049, iter: 240870/250000, loss: 0.1253, lr: 0.000509, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6266 samples/sec | ETA 01:25:54
2023-02-05 06:26:23 [INFO]	[TRAIN] epoch: 3050, iter: 240880/250000, loss: 0.2131, lr: 0.000508, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6295 samples/sec | ETA 01:25:47
2023-02-05 06:26:29 [INFO]	[TRAIN] epoch: 3050, iter: 240890/250000, loss: 0.1349, lr: 0.000508, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6357 samples/sec | ETA 01:25:39
2023-02-05 06:26:34 [INFO]	[TRAIN] epoch: 3050, iter: 240900/250000, loss: 0.1645, lr: 0.000507, batch_cost: 0.5645, reader_cost: 0.00019, ips: 10.6297 samples/sec | ETA 01:25:36
2023-02-05 06:26:40 [INFO]	[TRAIN] epoch: 3050, iter: 240910/250000, loss: 0.1306, lr: 0.000507, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 01:25:42
2023-02-05 06:26:45 [INFO]	[TRAIN] epoch: 3050, iter: 240920/250000, loss: 0.1478, lr: 0.000506, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6007 samples/sec | ETA 01:25:39
2023-02-05 06:26:51 [INFO]	[TRAIN] epoch: 3050, iter: 240930/250000, loss: 0.1316, lr: 0.000506, batch_cost: 0.5926, reader_cost: 0.02764, ips: 10.1252 samples/sec | ETA 01:29:34
2023-02-05 06:26:57 [INFO]	[TRAIN] epoch: 3050, iter: 240940/250000, loss: 0.1307, lr: 0.000505, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6231 samples/sec | ETA 01:25:17
2023-02-05 06:27:03 [INFO]	[TRAIN] epoch: 3050, iter: 240950/250000, loss: 0.1183, lr: 0.000505, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6238 samples/sec | ETA 01:25:11
2023-02-05 06:27:08 [INFO]	[TRAIN] epoch: 3051, iter: 240960/250000, loss: 0.1473, lr: 0.000504, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6246 samples/sec | ETA 01:25:05
2023-02-05 06:27:14 [INFO]	[TRAIN] epoch: 3051, iter: 240970/250000, loss: 0.1256, lr: 0.000504, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6278 samples/sec | ETA 01:24:57
2023-02-05 06:27:20 [INFO]	[TRAIN] epoch: 3051, iter: 240980/250000, loss: 0.1221, lr: 0.000503, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6165 samples/sec | ETA 01:24:57
2023-02-05 06:27:25 [INFO]	[TRAIN] epoch: 3051, iter: 240990/250000, loss: 0.1306, lr: 0.000503, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6094 samples/sec | ETA 01:24:55
2023-02-05 06:27:31 [INFO]	[TRAIN] epoch: 3051, iter: 241000/250000, loss: 0.1254, lr: 0.000502, batch_cost: 0.5660, reader_cost: 0.00008, ips: 10.6015 samples/sec | ETA 01:24:53
2023-02-05 06:27:37 [INFO]	[TRAIN] epoch: 3051, iter: 241010/250000, loss: 0.1160, lr: 0.000502, batch_cost: 0.6016, reader_cost: 0.03718, ips: 9.9729 samples/sec | ETA 01:30:08
2023-02-05 06:27:43 [INFO]	[TRAIN] epoch: 3051, iter: 241020/250000, loss: 0.1179, lr: 0.000501, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6347 samples/sec | ETA 01:24:26
2023-02-05 06:27:48 [INFO]	[TRAIN] epoch: 3052, iter: 241030/250000, loss: 0.1458, lr: 0.000501, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6246 samples/sec | ETA 01:24:25
2023-02-05 06:27:54 [INFO]	[TRAIN] epoch: 3052, iter: 241040/250000, loss: 0.1360, lr: 0.000500, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6246 samples/sec | ETA 01:24:19
2023-02-05 06:28:00 [INFO]	[TRAIN] epoch: 3052, iter: 241050/250000, loss: 0.1327, lr: 0.000500, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6098 samples/sec | ETA 01:24:21
2023-02-05 06:28:05 [INFO]	[TRAIN] epoch: 3052, iter: 241060/250000, loss: 0.1330, lr: 0.000499, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6197 samples/sec | ETA 01:24:10
2023-02-05 06:28:11 [INFO]	[TRAIN] epoch: 3052, iter: 241070/250000, loss: 0.1562, lr: 0.000498, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6035 samples/sec | ETA 01:24:13
2023-02-05 06:28:17 [INFO]	[TRAIN] epoch: 3052, iter: 241080/250000, loss: 0.1334, lr: 0.000498, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5953 samples/sec | ETA 01:24:11
2023-02-05 06:28:22 [INFO]	[TRAIN] epoch: 3052, iter: 241090/250000, loss: 0.1181, lr: 0.000497, batch_cost: 0.5949, reader_cost: 0.02983, ips: 10.0849 samples/sec | ETA 01:28:20
2023-02-05 06:28:28 [INFO]	[TRAIN] epoch: 3052, iter: 241100/250000, loss: 0.1510, lr: 0.000497, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6110 samples/sec | ETA 01:23:52
2023-02-05 06:28:34 [INFO]	[TRAIN] epoch: 3053, iter: 241110/250000, loss: 0.1293, lr: 0.000496, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 01:23:48
2023-02-05 06:28:39 [INFO]	[TRAIN] epoch: 3053, iter: 241120/250000, loss: 0.1283, lr: 0.000496, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6096 samples/sec | ETA 01:23:41
2023-02-05 06:28:45 [INFO]	[TRAIN] epoch: 3053, iter: 241130/250000, loss: 0.1196, lr: 0.000495, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6073 samples/sec | ETA 01:23:37
2023-02-05 06:28:51 [INFO]	[TRAIN] epoch: 3053, iter: 241140/250000, loss: 0.1340, lr: 0.000495, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6133 samples/sec | ETA 01:23:28
2023-02-05 06:28:56 [INFO]	[TRAIN] epoch: 3053, iter: 241150/250000, loss: 0.1290, lr: 0.000494, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6094 samples/sec | ETA 01:23:25
2023-02-05 06:29:02 [INFO]	[TRAIN] epoch: 3053, iter: 241160/250000, loss: 0.1274, lr: 0.000494, batch_cost: 0.5909, reader_cost: 0.02540, ips: 10.1537 samples/sec | ETA 01:27:03
2023-02-05 06:29:08 [INFO]	[TRAIN] epoch: 3053, iter: 241170/250000, loss: 0.1167, lr: 0.000493, batch_cost: 0.5667, reader_cost: 0.00018, ips: 10.5881 samples/sec | ETA 01:23:23
2023-02-05 06:29:14 [INFO]	[TRAIN] epoch: 3053, iter: 241180/250000, loss: 0.1078, lr: 0.000493, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6049 samples/sec | ETA 01:23:10
2023-02-05 06:29:19 [INFO]	[TRAIN] epoch: 3054, iter: 241190/250000, loss: 0.1072, lr: 0.000492, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6105 samples/sec | ETA 01:23:01
2023-02-05 06:29:25 [INFO]	[TRAIN] epoch: 3054, iter: 241200/250000, loss: 0.1617, lr: 0.000492, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6020 samples/sec | ETA 01:23:00
2023-02-05 06:29:31 [INFO]	[TRAIN] epoch: 3054, iter: 241210/250000, loss: 0.1148, lr: 0.000491, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6117 samples/sec | ETA 01:22:49
2023-02-05 06:29:36 [INFO]	[TRAIN] epoch: 3054, iter: 241220/250000, loss: 0.1565, lr: 0.000491, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6078 samples/sec | ETA 01:22:46
2023-02-05 06:29:42 [INFO]	[TRAIN] epoch: 3054, iter: 241230/250000, loss: 0.1235, lr: 0.000490, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6014 samples/sec | ETA 01:22:43
2023-02-05 06:29:48 [INFO]	[TRAIN] epoch: 3054, iter: 241240/250000, loss: 0.1212, lr: 0.000490, batch_cost: 0.5982, reader_cost: 0.03207, ips: 10.0294 samples/sec | ETA 01:27:20
2023-02-05 06:29:54 [INFO]	[TRAIN] epoch: 3054, iter: 241250/250000, loss: 0.1290, lr: 0.000489, batch_cost: 0.5646, reader_cost: 0.00015, ips: 10.6272 samples/sec | ETA 01:22:20
2023-02-05 06:29:59 [INFO]	[TRAIN] epoch: 3054, iter: 241260/250000, loss: 0.1255, lr: 0.000489, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6361 samples/sec | ETA 01:22:10
2023-02-05 06:30:05 [INFO]	[TRAIN] epoch: 3055, iter: 241270/250000, loss: 0.1226, lr: 0.000488, batch_cost: 0.5664, reader_cost: 0.00009, ips: 10.5931 samples/sec | ETA 01:22:24
2023-02-05 06:30:11 [INFO]	[TRAIN] epoch: 3055, iter: 241280/250000, loss: 0.1254, lr: 0.000488, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5971 samples/sec | ETA 01:22:17
2023-02-05 06:30:16 [INFO]	[TRAIN] epoch: 3055, iter: 241290/250000, loss: 0.1363, lr: 0.000487, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6124 samples/sec | ETA 01:22:04
2023-02-05 06:30:22 [INFO]	[TRAIN] epoch: 3055, iter: 241300/250000, loss: 0.1261, lr: 0.000487, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6105 samples/sec | ETA 01:21:59
2023-02-05 06:30:28 [INFO]	[TRAIN] epoch: 3055, iter: 241310/250000, loss: 0.1210, lr: 0.000486, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6004 samples/sec | ETA 01:21:58
2023-02-05 06:30:33 [INFO]	[TRAIN] epoch: 3055, iter: 241320/250000, loss: 0.1455, lr: 0.000486, batch_cost: 0.5931, reader_cost: 0.02749, ips: 10.1163 samples/sec | ETA 01:25:48
2023-02-05 06:30:39 [INFO]	[TRAIN] epoch: 3055, iter: 241330/250000, loss: 0.1584, lr: 0.000485, batch_cost: 0.5643, reader_cost: 0.00015, ips: 10.6332 samples/sec | ETA 01:21:32
2023-02-05 06:30:45 [INFO]	[TRAIN] epoch: 3055, iter: 241340/250000, loss: 0.1208, lr: 0.000485, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6316 samples/sec | ETA 01:21:27
2023-02-05 06:30:50 [INFO]	[TRAIN] epoch: 3056, iter: 241350/250000, loss: 0.1237, lr: 0.000484, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6318 samples/sec | ETA 01:21:21
2023-02-05 06:30:56 [INFO]	[TRAIN] epoch: 3056, iter: 241360/250000, loss: 0.1106, lr: 0.000484, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6228 samples/sec | ETA 01:21:20
2023-02-05 06:31:02 [INFO]	[TRAIN] epoch: 3056, iter: 241370/250000, loss: 0.1463, lr: 0.000483, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6109 samples/sec | ETA 01:21:19
2023-02-05 06:31:07 [INFO]	[TRAIN] epoch: 3056, iter: 241380/250000, loss: 0.1240, lr: 0.000483, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5989 samples/sec | ETA 01:21:19
2023-02-05 06:31:13 [INFO]	[TRAIN] epoch: 3056, iter: 241390/250000, loss: 0.1149, lr: 0.000482, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5992 samples/sec | ETA 01:21:13
2023-02-05 06:31:19 [INFO]	[TRAIN] epoch: 3056, iter: 241400/250000, loss: 0.0972, lr: 0.000482, batch_cost: 0.5889, reader_cost: 0.02318, ips: 10.1879 samples/sec | ETA 01:24:24
2023-02-05 06:31:25 [INFO]	[TRAIN] epoch: 3056, iter: 241410/250000, loss: 0.1302, lr: 0.000481, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6221 samples/sec | ETA 01:20:52
2023-02-05 06:31:30 [INFO]	[TRAIN] epoch: 3056, iter: 241420/250000, loss: 0.1122, lr: 0.000481, batch_cost: 0.5647, reader_cost: 0.00008, ips: 10.6248 samples/sec | ETA 01:20:45
2023-02-05 06:31:36 [INFO]	[TRAIN] epoch: 3057, iter: 241430/250000, loss: 0.1339, lr: 0.000480, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6081 samples/sec | ETA 01:20:47
2023-02-05 06:31:42 [INFO]	[TRAIN] epoch: 3057, iter: 241440/250000, loss: 0.1158, lr: 0.000480, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6027 samples/sec | ETA 01:20:44
2023-02-05 06:31:47 [INFO]	[TRAIN] epoch: 3057, iter: 241450/250000, loss: 0.0973, lr: 0.000479, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6083 samples/sec | ETA 01:20:35
2023-02-05 06:31:53 [INFO]	[TRAIN] epoch: 3057, iter: 241460/250000, loss: 0.1145, lr: 0.000479, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6084 samples/sec | ETA 01:20:30
2023-02-05 06:31:58 [INFO]	[TRAIN] epoch: 3057, iter: 241470/250000, loss: 0.1477, lr: 0.000478, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6043 samples/sec | ETA 01:20:26
2023-02-05 06:32:04 [INFO]	[TRAIN] epoch: 3057, iter: 241480/250000, loss: 0.1322, lr: 0.000478, batch_cost: 0.5890, reader_cost: 0.02444, ips: 10.1874 samples/sec | ETA 01:23:37
2023-02-05 06:32:10 [INFO]	[TRAIN] epoch: 3057, iter: 241490/250000, loss: 0.1656, lr: 0.000477, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6250 samples/sec | ETA 01:20:05
2023-02-05 06:32:16 [INFO]	[TRAIN] epoch: 3057, iter: 241500/250000, loss: 0.1155, lr: 0.000477, batch_cost: 0.5648, reader_cost: 0.00008, ips: 10.6225 samples/sec | ETA 01:20:01
2023-02-05 06:32:21 [INFO]	[TRAIN] epoch: 3058, iter: 241510/250000, loss: 0.1630, lr: 0.000476, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6306 samples/sec | ETA 01:19:51
2023-02-05 06:32:27 [INFO]	[TRAIN] epoch: 3058, iter: 241520/250000, loss: 0.1287, lr: 0.000476, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6285 samples/sec | ETA 01:19:47
2023-02-05 06:32:33 [INFO]	[TRAIN] epoch: 3058, iter: 241530/250000, loss: 0.1035, lr: 0.000475, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6056 samples/sec | ETA 01:19:51
2023-02-05 06:32:38 [INFO]	[TRAIN] epoch: 3058, iter: 241540/250000, loss: 0.1210, lr: 0.000475, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6109 samples/sec | ETA 01:19:43
2023-02-05 06:32:44 [INFO]	[TRAIN] epoch: 3058, iter: 241550/250000, loss: 0.1631, lr: 0.000474, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6043 samples/sec | ETA 01:19:41
2023-02-05 06:32:50 [INFO]	[TRAIN] epoch: 3058, iter: 241560/250000, loss: 0.1548, lr: 0.000474, batch_cost: 0.5955, reader_cost: 0.02897, ips: 10.0759 samples/sec | ETA 01:23:45
2023-02-05 06:32:56 [INFO]	[TRAIN] epoch: 3058, iter: 241570/250000, loss: 0.1230, lr: 0.000473, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6266 samples/sec | ETA 01:19:19
2023-02-05 06:33:01 [INFO]	[TRAIN] epoch: 3058, iter: 241580/250000, loss: 0.1402, lr: 0.000473, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6302 samples/sec | ETA 01:19:12
2023-02-05 06:33:07 [INFO]	[TRAIN] epoch: 3059, iter: 241590/250000, loss: 0.1253, lr: 0.000472, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6291 samples/sec | ETA 01:19:07
2023-02-05 06:33:12 [INFO]	[TRAIN] epoch: 3059, iter: 241600/250000, loss: 0.1298, lr: 0.000472, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6287 samples/sec | ETA 01:19:01
2023-02-05 06:33:18 [INFO]	[TRAIN] epoch: 3059, iter: 241610/250000, loss: 0.1256, lr: 0.000471, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6303 samples/sec | ETA 01:18:55
2023-02-05 06:33:24 [INFO]	[TRAIN] epoch: 3059, iter: 241620/250000, loss: 0.1473, lr: 0.000471, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6242 samples/sec | ETA 01:18:52
2023-02-05 06:33:29 [INFO]	[TRAIN] epoch: 3059, iter: 241630/250000, loss: 0.1218, lr: 0.000470, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6014 samples/sec | ETA 01:18:57
2023-02-05 06:33:35 [INFO]	[TRAIN] epoch: 3059, iter: 241640/250000, loss: 0.1358, lr: 0.000470, batch_cost: 0.5961, reader_cost: 0.03061, ips: 10.0654 samples/sec | ETA 01:23:03
2023-02-05 06:33:41 [INFO]	[TRAIN] epoch: 3059, iter: 241650/250000, loss: 0.1254, lr: 0.000469, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6261 samples/sec | ETA 01:18:34
2023-02-05 06:33:47 [INFO]	[TRAIN] epoch: 3059, iter: 241660/250000, loss: 0.1302, lr: 0.000469, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6380 samples/sec | ETA 01:18:23
2023-02-05 06:33:52 [INFO]	[TRAIN] epoch: 3060, iter: 241670/250000, loss: 0.1585, lr: 0.000468, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6271 samples/sec | ETA 01:18:23
2023-02-05 06:33:58 [INFO]	[TRAIN] epoch: 3060, iter: 241680/250000, loss: 0.1151, lr: 0.000468, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6173 samples/sec | ETA 01:18:21
2023-02-05 06:34:04 [INFO]	[TRAIN] epoch: 3060, iter: 241690/250000, loss: 0.1096, lr: 0.000467, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6226 samples/sec | ETA 01:18:13
2023-02-05 06:34:09 [INFO]	[TRAIN] epoch: 3060, iter: 241700/250000, loss: 0.1070, lr: 0.000467, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6269 samples/sec | ETA 01:18:06
2023-02-05 06:34:15 [INFO]	[TRAIN] epoch: 3060, iter: 241710/250000, loss: 0.1341, lr: 0.000466, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6336 samples/sec | ETA 01:17:57
2023-02-05 06:34:21 [INFO]	[TRAIN] epoch: 3060, iter: 241720/250000, loss: 0.1424, lr: 0.000466, batch_cost: 0.5980, reader_cost: 0.03316, ips: 10.0335 samples/sec | ETA 01:22:31
2023-02-05 06:34:27 [INFO]	[TRAIN] epoch: 3060, iter: 241730/250000, loss: 0.1122, lr: 0.000465, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6124 samples/sec | ETA 01:17:55
2023-02-05 06:34:32 [INFO]	[TRAIN] epoch: 3060, iter: 241740/250000, loss: 0.1626, lr: 0.000465, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6063 samples/sec | ETA 01:17:52
2023-02-05 06:34:38 [INFO]	[TRAIN] epoch: 3061, iter: 241750/250000, loss: 0.1277, lr: 0.000464, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6066 samples/sec | ETA 01:17:46
2023-02-05 06:34:44 [INFO]	[TRAIN] epoch: 3061, iter: 241760/250000, loss: 0.2337, lr: 0.000464, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6029 samples/sec | ETA 01:17:42
2023-02-05 06:34:49 [INFO]	[TRAIN] epoch: 3061, iter: 241770/250000, loss: 0.1252, lr: 0.000463, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6081 samples/sec | ETA 01:17:34
2023-02-05 06:34:55 [INFO]	[TRAIN] epoch: 3061, iter: 241780/250000, loss: 0.1623, lr: 0.000463, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6071 samples/sec | ETA 01:17:29
2023-02-05 06:35:00 [INFO]	[TRAIN] epoch: 3061, iter: 241790/250000, loss: 0.1218, lr: 0.000462, batch_cost: 0.5663, reader_cost: 0.00008, ips: 10.5959 samples/sec | ETA 01:17:28
2023-02-05 06:35:06 [INFO]	[TRAIN] epoch: 3061, iter: 241800/250000, loss: 0.1314, lr: 0.000462, batch_cost: 0.5905, reader_cost: 0.02470, ips: 10.1607 samples/sec | ETA 01:20:42
2023-02-05 06:35:12 [INFO]	[TRAIN] epoch: 3061, iter: 241810/250000, loss: 0.1447, lr: 0.000461, batch_cost: 0.5664, reader_cost: 0.00009, ips: 10.5933 samples/sec | ETA 01:17:18
2023-02-05 06:35:18 [INFO]	[TRAIN] epoch: 3062, iter: 241820/250000, loss: 0.1590, lr: 0.000461, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5989 samples/sec | ETA 01:17:10
2023-02-05 06:35:23 [INFO]	[TRAIN] epoch: 3062, iter: 241830/250000, loss: 0.1396, lr: 0.000460, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6147 samples/sec | ETA 01:16:58
2023-02-05 06:35:29 [INFO]	[TRAIN] epoch: 3062, iter: 241840/250000, loss: 0.1413, lr: 0.000460, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6100 samples/sec | ETA 01:16:54
2023-02-05 06:35:35 [INFO]	[TRAIN] epoch: 3062, iter: 241850/250000, loss: 0.1250, lr: 0.000459, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5989 samples/sec | ETA 01:16:53
2023-02-05 06:35:40 [INFO]	[TRAIN] epoch: 3062, iter: 241860/250000, loss: 0.1313, lr: 0.000459, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6139 samples/sec | ETA 01:16:41
2023-02-05 06:35:46 [INFO]	[TRAIN] epoch: 3062, iter: 241870/250000, loss: 0.1120, lr: 0.000458, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6101 samples/sec | ETA 01:16:37
2023-02-05 06:35:52 [INFO]	[TRAIN] epoch: 3062, iter: 241880/250000, loss: 0.1393, lr: 0.000458, batch_cost: 0.5946, reader_cost: 0.02850, ips: 10.0915 samples/sec | ETA 01:20:27
2023-02-05 06:35:58 [INFO]	[TRAIN] epoch: 3062, iter: 241890/250000, loss: 0.1108, lr: 0.000457, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6286 samples/sec | ETA 01:16:18
2023-02-05 06:36:03 [INFO]	[TRAIN] epoch: 3063, iter: 241900/250000, loss: 0.1338, lr: 0.000457, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6310 samples/sec | ETA 01:16:11
2023-02-05 06:36:09 [INFO]	[TRAIN] epoch: 3063, iter: 241910/250000, loss: 0.1307, lr: 0.000456, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6320 samples/sec | ETA 01:16:05
2023-02-05 06:36:15 [INFO]	[TRAIN] epoch: 3063, iter: 241920/250000, loss: 0.1243, lr: 0.000456, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6318 samples/sec | ETA 01:15:59
2023-02-05 06:36:20 [INFO]	[TRAIN] epoch: 3063, iter: 241930/250000, loss: 0.1154, lr: 0.000455, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6359 samples/sec | ETA 01:15:52
2023-02-05 06:36:26 [INFO]	[TRAIN] epoch: 3063, iter: 241940/250000, loss: 0.1177, lr: 0.000455, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6326 samples/sec | ETA 01:15:48
2023-02-05 06:36:32 [INFO]	[TRAIN] epoch: 3063, iter: 241950/250000, loss: 0.1179, lr: 0.000454, batch_cost: 0.6088, reader_cost: 0.04310, ips: 9.8562 samples/sec | ETA 01:21:40
2023-02-05 06:36:38 [INFO]	[TRAIN] epoch: 3063, iter: 241960/250000, loss: 0.1289, lr: 0.000454, batch_cost: 0.5646, reader_cost: 0.00014, ips: 10.6273 samples/sec | ETA 01:15:39
2023-02-05 06:36:43 [INFO]	[TRAIN] epoch: 3063, iter: 241970/250000, loss: 0.1295, lr: 0.000453, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6049 samples/sec | ETA 01:15:43
2023-02-05 06:36:49 [INFO]	[TRAIN] epoch: 3064, iter: 241980/250000, loss: 0.1207, lr: 0.000453, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6136 samples/sec | ETA 01:15:33
2023-02-05 06:36:55 [INFO]	[TRAIN] epoch: 3064, iter: 241990/250000, loss: 0.1212, lr: 0.000452, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6019 samples/sec | ETA 01:15:33
2023-02-05 06:37:00 [INFO]	[TRAIN] epoch: 3064, iter: 242000/250000, loss: 0.1159, lr: 0.000452, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6048 samples/sec | ETA 01:15:26
2023-02-05 06:37:00 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1212 - reader cost: 0.0226 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1479 - reader cost: 0.0113 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1558 - reader cost: 0.0076 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1569 - reader cost: 0.0057 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1588 - reader cost: 0.0046 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1610 - reader cost: 0.0038 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1612 - reader cost: 0.0033 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1612 - reader cost: 0.0029 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1625 - reader cost: 0.002610/36 [=======>......................] - ETA: 4s - batch_cost: 0.1623 - reader cost: 0.002311/36 [========>.....................] - ETA: 4s - batch_cost: 0.1631 - reader cost: 0.002112/36 [=========>....................] - ETA: 3s - batch_cost: 0.1626 - reader cost: 0.001913/36 [=========>....................] - ETA: 3s - batch_cost: 0.1629 - reader cost: 0.001814/36 [==========>...................] - ETA: 3s - batch_cost: 0.1633 - reader cost: 0.001715/36 [===========>..................] - ETA: 3s - batch_cost: 0.1632 - reader cost: 0.001616/36 [============>.................] - ETA: 3s - batch_cost: 0.1643 - reader cost: 0.001517/36 [=============>................] - ETA: 3s - batch_cost: 0.1645 - reader cost: 0.001418/36 [==============>...............] - ETA: 2s - batch_cost: 0.1647 - reader cost: 0.001319/36 [==============>...............] - ETA: 2s - batch_cost: 0.1644 - reader cost: 0.001320/36 [===============>..............] - ETA: 2s - batch_cost: 0.1643 - reader cost: 0.001221/36 [================>.............] - ETA: 2s - batch_cost: 0.1645 - reader cost: 0.001122/36 [=================>............] - ETA: 2s - batch_cost: 0.1647 - reader cost: 0.001123/36 [==================>...........] - ETA: 2s - batch_cost: 0.1654 - reader cost: 0.001124/36 [===================>..........] - ETA: 1s - batch_cost: 0.1653 - reader cost: 0.001025/36 [===================>..........] - ETA: 1s - batch_cost: 0.1655 - reader cost: 9.7380e-0426/36 [====================>.........] - ETA: 1s - batch_cost: 0.1657 - reader cost: 9.3902e-0427/36 [=====================>........] - ETA: 1s - batch_cost: 0.1659 - reader cost: 9.0682e-0428/36 [======================>.......] - ETA: 1s - batch_cost: 0.1663 - reader cost: 8.7692e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1664 - reader cost: 8.4905e-0430/36 [========================>.....] - ETA: 0s - batch_cost: 0.1663 - reader cost: 8.2310e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1664 - reader cost: 7.9934e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1663 - reader cost: 7.7653e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1661 - reader cost: 7.5498e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1659 - reader cost: 7.3539e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1658 - reader cost: 7.1671e-0436/36 [==============================] - 6s 166ms/step - batch_cost: 0.1659 - reader cost: 6.9857e-04
2023-02-05 06:37:06 [INFO]	[EVAL] #Images: 36 mIoU: 0.8666 Acc: 0.9865 Kappa: 0.9510 Dice: 0.9252
2023-02-05 06:37:06 [INFO]	[EVAL] Class IoU: 
[0.9859 0.9185 0.8927 0.7127 0.7194 0.9723 0.8646]
2023-02-05 06:37:06 [INFO]	[EVAL] Class Precision: 
[0.9929 0.9676 0.9434 0.8234 0.8617 0.9826 0.909 ]
2023-02-05 06:37:06 [INFO]	[EVAL] Class Recall: 
[0.9929 0.9477 0.9433 0.8413 0.8133 0.9893 0.9465]
2023-02-05 06:37:06 [INFO]	[EVAL] The model with the best validation mIoU (0.8682) was saved at iter 222000.
2023-02-05 06:37:12 [INFO]	[TRAIN] epoch: 3064, iter: 242010/250000, loss: 0.1183, lr: 0.000451, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6261 samples/sec | ETA 01:15:11
2023-02-05 06:37:18 [INFO]	[TRAIN] epoch: 3064, iter: 242020/250000, loss: 0.1204, lr: 0.000451, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6304 samples/sec | ETA 01:15:04
2023-02-05 06:37:24 [INFO]	[TRAIN] epoch: 3064, iter: 242030/250000, loss: 0.1284, lr: 0.000450, batch_cost: 0.5941, reader_cost: 0.03019, ips: 10.0999 samples/sec | ETA 01:18:54
2023-02-05 06:37:29 [INFO]	[TRAIN] epoch: 3064, iter: 242040/250000, loss: 0.1182, lr: 0.000449, batch_cost: 0.5643, reader_cost: 0.00018, ips: 10.6328 samples/sec | ETA 01:14:51
2023-02-05 06:37:35 [INFO]	[TRAIN] epoch: 3064, iter: 242050/250000, loss: 0.1060, lr: 0.000449, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6256 samples/sec | ETA 01:14:49
2023-02-05 06:37:41 [INFO]	[TRAIN] epoch: 3065, iter: 242060/250000, loss: 0.1220, lr: 0.000448, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6274 samples/sec | ETA 01:14:42
2023-02-05 06:37:46 [INFO]	[TRAIN] epoch: 3065, iter: 242070/250000, loss: 0.1270, lr: 0.000448, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6271 samples/sec | ETA 01:14:37
2023-02-05 06:37:52 [INFO]	[TRAIN] epoch: 3065, iter: 242080/250000, loss: 0.1215, lr: 0.000447, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6292 samples/sec | ETA 01:14:30
2023-02-05 06:37:58 [INFO]	[TRAIN] epoch: 3065, iter: 242090/250000, loss: 0.1453, lr: 0.000447, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6343 samples/sec | ETA 01:14:22
2023-02-05 06:38:03 [INFO]	[TRAIN] epoch: 3065, iter: 242100/250000, loss: 0.1252, lr: 0.000446, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6265 samples/sec | ETA 01:14:20
2023-02-05 06:38:09 [INFO]	[TRAIN] epoch: 3065, iter: 242110/250000, loss: 0.1183, lr: 0.000446, batch_cost: 0.5891, reader_cost: 0.02431, ips: 10.1845 samples/sec | ETA 01:17:28
2023-02-05 06:38:15 [INFO]	[TRAIN] epoch: 3065, iter: 242120/250000, loss: 0.1375, lr: 0.000445, batch_cost: 0.5658, reader_cost: 0.00018, ips: 10.6052 samples/sec | ETA 01:14:18
2023-02-05 06:38:20 [INFO]	[TRAIN] epoch: 3065, iter: 242130/250000, loss: 0.1325, lr: 0.000445, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6236 samples/sec | ETA 01:14:04
2023-02-05 06:38:26 [INFO]	[TRAIN] epoch: 3066, iter: 242140/250000, loss: 0.1183, lr: 0.000444, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6209 samples/sec | ETA 01:14:00
2023-02-05 06:38:32 [INFO]	[TRAIN] epoch: 3066, iter: 242150/250000, loss: 0.1521, lr: 0.000444, batch_cost: 0.5656, reader_cost: 0.00011, ips: 10.6084 samples/sec | ETA 01:13:59
2023-02-05 06:38:37 [INFO]	[TRAIN] epoch: 3066, iter: 242160/250000, loss: 0.1219, lr: 0.000443, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6064 samples/sec | ETA 01:13:55
2023-02-05 06:38:43 [INFO]	[TRAIN] epoch: 3066, iter: 242170/250000, loss: 0.1228, lr: 0.000443, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6066 samples/sec | ETA 01:13:49
2023-02-05 06:38:49 [INFO]	[TRAIN] epoch: 3066, iter: 242180/250000, loss: 0.1248, lr: 0.000442, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6112 samples/sec | ETA 01:13:41
2023-02-05 06:38:55 [INFO]	[TRAIN] epoch: 3066, iter: 242190/250000, loss: 0.1159, lr: 0.000442, batch_cost: 0.5978, reader_cost: 0.03235, ips: 10.0375 samples/sec | ETA 01:17:48
2023-02-05 06:39:00 [INFO]	[TRAIN] epoch: 3066, iter: 242200/250000, loss: 0.1176, lr: 0.000441, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6019 samples/sec | ETA 01:13:34
2023-02-05 06:39:06 [INFO]	[TRAIN] epoch: 3066, iter: 242210/250000, loss: 0.1208, lr: 0.000441, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6031 samples/sec | ETA 01:13:28
2023-02-05 06:39:12 [INFO]	[TRAIN] epoch: 3067, iter: 242220/250000, loss: 0.1274, lr: 0.000440, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6162 samples/sec | ETA 01:13:17
2023-02-05 06:39:17 [INFO]	[TRAIN] epoch: 3067, iter: 242230/250000, loss: 0.1782, lr: 0.000440, batch_cost: 0.5658, reader_cost: 0.00008, ips: 10.6049 samples/sec | ETA 01:13:16
2023-02-05 06:39:23 [INFO]	[TRAIN] epoch: 3067, iter: 242240/250000, loss: 0.1243, lr: 0.000439, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6087 samples/sec | ETA 01:13:08
2023-02-05 06:39:29 [INFO]	[TRAIN] epoch: 3067, iter: 242250/250000, loss: 0.1253, lr: 0.000439, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6075 samples/sec | ETA 01:13:03
2023-02-05 06:39:34 [INFO]	[TRAIN] epoch: 3067, iter: 242260/250000, loss: 0.1215, lr: 0.000438, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6112 samples/sec | ETA 01:12:56
2023-02-05 06:39:40 [INFO]	[TRAIN] epoch: 3067, iter: 242270/250000, loss: 0.1154, lr: 0.000438, batch_cost: 0.5874, reader_cost: 0.02053, ips: 10.2151 samples/sec | ETA 01:15:40
2023-02-05 06:39:46 [INFO]	[TRAIN] epoch: 3067, iter: 242280/250000, loss: 0.1142, lr: 0.000437, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6018 samples/sec | ETA 01:12:49
2023-02-05 06:39:51 [INFO]	[TRAIN] epoch: 3067, iter: 242290/250000, loss: 0.1386, lr: 0.000437, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6130 samples/sec | ETA 01:12:38
2023-02-05 06:39:57 [INFO]	[TRAIN] epoch: 3068, iter: 242300/250000, loss: 0.1385, lr: 0.000436, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6099 samples/sec | ETA 01:12:34
2023-02-05 06:40:03 [INFO]	[TRAIN] epoch: 3068, iter: 242310/250000, loss: 0.1105, lr: 0.000436, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6029 samples/sec | ETA 01:12:31
2023-02-05 06:40:08 [INFO]	[TRAIN] epoch: 3068, iter: 242320/250000, loss: 0.1146, lr: 0.000435, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6115 samples/sec | ETA 01:12:22
2023-02-05 06:40:14 [INFO]	[TRAIN] epoch: 3068, iter: 242330/250000, loss: 0.1225, lr: 0.000435, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6111 samples/sec | ETA 01:12:16
2023-02-05 06:40:20 [INFO]	[TRAIN] epoch: 3068, iter: 242340/250000, loss: 0.1489, lr: 0.000434, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5975 samples/sec | ETA 01:12:16
2023-02-05 06:40:26 [INFO]	[TRAIN] epoch: 3068, iter: 242350/250000, loss: 0.1237, lr: 0.000434, batch_cost: 0.5934, reader_cost: 0.02814, ips: 10.1116 samples/sec | ETA 01:15:39
2023-02-05 06:40:31 [INFO]	[TRAIN] epoch: 3068, iter: 242360/250000, loss: 0.1124, lr: 0.000433, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6260 samples/sec | ETA 01:11:53
2023-02-05 06:40:37 [INFO]	[TRAIN] epoch: 3068, iter: 242370/250000, loss: 0.1217, lr: 0.000433, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6092 samples/sec | ETA 01:11:55
2023-02-05 06:40:43 [INFO]	[TRAIN] epoch: 3069, iter: 242380/250000, loss: 0.1299, lr: 0.000432, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6078 samples/sec | ETA 01:11:50
2023-02-05 06:40:48 [INFO]	[TRAIN] epoch: 3069, iter: 242390/250000, loss: 0.1185, lr: 0.000432, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.5999 samples/sec | ETA 01:11:47
2023-02-05 06:40:54 [INFO]	[TRAIN] epoch: 3069, iter: 242400/250000, loss: 0.1281, lr: 0.000431, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6097 samples/sec | ETA 01:11:37
2023-02-05 06:41:00 [INFO]	[TRAIN] epoch: 3069, iter: 242410/250000, loss: 0.1268, lr: 0.000431, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6124 samples/sec | ETA 01:11:31
2023-02-05 06:41:05 [INFO]	[TRAIN] epoch: 3069, iter: 242420/250000, loss: 0.1433, lr: 0.000430, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5986 samples/sec | ETA 01:11:31
2023-02-05 06:41:11 [INFO]	[TRAIN] epoch: 3069, iter: 242430/250000, loss: 0.1105, lr: 0.000430, batch_cost: 0.5953, reader_cost: 0.03009, ips: 10.0785 samples/sec | ETA 01:15:06
2023-02-05 06:41:17 [INFO]	[TRAIN] epoch: 3069, iter: 242440/250000, loss: 0.1182, lr: 0.000429, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6289 samples/sec | ETA 01:11:07
2023-02-05 06:41:22 [INFO]	[TRAIN] epoch: 3069, iter: 242450/250000, loss: 0.1286, lr: 0.000429, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6253 samples/sec | ETA 01:11:03
2023-02-05 06:41:28 [INFO]	[TRAIN] epoch: 3070, iter: 242460/250000, loss: 0.1147, lr: 0.000428, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6183 samples/sec | ETA 01:11:00
2023-02-05 06:41:34 [INFO]	[TRAIN] epoch: 3070, iter: 242470/250000, loss: 0.1120, lr: 0.000428, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5997 samples/sec | ETA 01:11:02
2023-02-05 06:41:39 [INFO]	[TRAIN] epoch: 3070, iter: 242480/250000, loss: 0.1351, lr: 0.000427, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6044 samples/sec | ETA 01:10:54
2023-02-05 06:41:45 [INFO]	[TRAIN] epoch: 3070, iter: 242490/250000, loss: 0.1499, lr: 0.000427, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6070 samples/sec | ETA 01:10:48
2023-02-05 06:41:51 [INFO]	[TRAIN] epoch: 3070, iter: 242500/250000, loss: 0.1266, lr: 0.000426, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6099 samples/sec | ETA 01:10:41
2023-02-05 06:41:57 [INFO]	[TRAIN] epoch: 3070, iter: 242510/250000, loss: 0.1083, lr: 0.000426, batch_cost: 0.5884, reader_cost: 0.02371, ips: 10.1976 samples/sec | ETA 01:13:26
2023-02-05 06:42:02 [INFO]	[TRAIN] epoch: 3070, iter: 242520/250000, loss: 0.1718, lr: 0.000425, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6310 samples/sec | ETA 01:10:21
2023-02-05 06:42:08 [INFO]	[TRAIN] epoch: 3070, iter: 242530/250000, loss: 0.1349, lr: 0.000425, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6335 samples/sec | ETA 01:10:14
2023-02-05 06:42:14 [INFO]	[TRAIN] epoch: 3071, iter: 242540/250000, loss: 0.1100, lr: 0.000424, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6331 samples/sec | ETA 01:10:09
2023-02-05 06:42:19 [INFO]	[TRAIN] epoch: 3071, iter: 242550/250000, loss: 0.1479, lr: 0.000423, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6262 samples/sec | ETA 01:10:06
2023-02-05 06:42:25 [INFO]	[TRAIN] epoch: 3071, iter: 242560/250000, loss: 0.1765, lr: 0.000423, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6312 samples/sec | ETA 01:09:58
2023-02-05 06:42:30 [INFO]	[TRAIN] epoch: 3071, iter: 242570/250000, loss: 0.1193, lr: 0.000422, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6364 samples/sec | ETA 01:09:51
2023-02-05 06:42:36 [INFO]	[TRAIN] epoch: 3071, iter: 242580/250000, loss: 0.1337, lr: 0.000422, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6349 samples/sec | ETA 01:09:46
2023-02-05 06:42:42 [INFO]	[TRAIN] epoch: 3071, iter: 242590/250000, loss: 0.1177, lr: 0.000421, batch_cost: 0.5954, reader_cost: 0.02925, ips: 10.0775 samples/sec | ETA 01:13:31
2023-02-05 06:42:48 [INFO]	[TRAIN] epoch: 3071, iter: 242600/250000, loss: 0.1194, lr: 0.000421, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6064 samples/sec | ETA 01:09:46
2023-02-05 06:42:53 [INFO]	[TRAIN] epoch: 3072, iter: 242610/250000, loss: 0.1119, lr: 0.000420, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5992 samples/sec | ETA 01:09:43
2023-02-05 06:42:59 [INFO]	[TRAIN] epoch: 3072, iter: 242620/250000, loss: 0.1164, lr: 0.000420, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6093 samples/sec | ETA 01:09:33
2023-02-05 06:43:05 [INFO]	[TRAIN] epoch: 3072, iter: 242630/250000, loss: 0.1566, lr: 0.000419, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6083 samples/sec | ETA 01:09:28
2023-02-05 06:43:10 [INFO]	[TRAIN] epoch: 3072, iter: 242640/250000, loss: 0.1097, lr: 0.000419, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6031 samples/sec | ETA 01:09:24
2023-02-05 06:43:16 [INFO]	[TRAIN] epoch: 3072, iter: 242650/250000, loss: 0.1351, lr: 0.000418, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6056 samples/sec | ETA 01:09:18
2023-02-05 06:43:22 [INFO]	[TRAIN] epoch: 3072, iter: 242660/250000, loss: 0.1283, lr: 0.000418, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6063 samples/sec | ETA 01:09:12
2023-02-05 06:43:28 [INFO]	[TRAIN] epoch: 3072, iter: 242670/250000, loss: 0.1362, lr: 0.000417, batch_cost: 0.5904, reader_cost: 0.02564, ips: 10.1620 samples/sec | ETA 01:12:07
2023-02-05 06:43:33 [INFO]	[TRAIN] epoch: 3072, iter: 242680/250000, loss: 0.1123, lr: 0.000417, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6144 samples/sec | ETA 01:08:57
2023-02-05 06:43:39 [INFO]	[TRAIN] epoch: 3073, iter: 242690/250000, loss: 0.1228, lr: 0.000416, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6003 samples/sec | ETA 01:08:57
2023-02-05 06:43:45 [INFO]	[TRAIN] epoch: 3073, iter: 242700/250000, loss: 0.1084, lr: 0.000416, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6025 samples/sec | ETA 01:08:51
2023-02-05 06:43:50 [INFO]	[TRAIN] epoch: 3073, iter: 242710/250000, loss: 0.1150, lr: 0.000415, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6066 samples/sec | ETA 01:08:43
2023-02-05 06:43:56 [INFO]	[TRAIN] epoch: 3073, iter: 242720/250000, loss: 0.1185, lr: 0.000415, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6090 samples/sec | ETA 01:08:37
2023-02-05 06:44:02 [INFO]	[TRAIN] epoch: 3073, iter: 242730/250000, loss: 0.1260, lr: 0.000414, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6016 samples/sec | ETA 01:08:34
2023-02-05 06:44:07 [INFO]	[TRAIN] epoch: 3073, iter: 242740/250000, loss: 0.1086, lr: 0.000414, batch_cost: 0.5861, reader_cost: 0.02085, ips: 10.2375 samples/sec | ETA 01:10:54
2023-02-05 06:44:13 [INFO]	[TRAIN] epoch: 3073, iter: 242750/250000, loss: 0.1468, lr: 0.000413, batch_cost: 0.5664, reader_cost: 0.00025, ips: 10.5938 samples/sec | ETA 01:08:26
2023-02-05 06:44:19 [INFO]	[TRAIN] epoch: 3073, iter: 242760/250000, loss: 0.1283, lr: 0.000413, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6246 samples/sec | ETA 01:08:08
2023-02-05 06:44:24 [INFO]	[TRAIN] epoch: 3074, iter: 242770/250000, loss: 0.1314, lr: 0.000412, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6275 samples/sec | ETA 01:08:01
2023-02-05 06:44:30 [INFO]	[TRAIN] epoch: 3074, iter: 242780/250000, loss: 0.1197, lr: 0.000412, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6307 samples/sec | ETA 01:07:54
2023-02-05 06:44:36 [INFO]	[TRAIN] epoch: 3074, iter: 242790/250000, loss: 0.1250, lr: 0.000411, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6245 samples/sec | ETA 01:07:51
2023-02-05 06:44:41 [INFO]	[TRAIN] epoch: 3074, iter: 242800/250000, loss: 0.1304, lr: 0.000411, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6066 samples/sec | ETA 01:07:52
2023-02-05 06:44:47 [INFO]	[TRAIN] epoch: 3074, iter: 242810/250000, loss: 0.1171, lr: 0.000410, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6088 samples/sec | ETA 01:07:46
2023-02-05 06:44:53 [INFO]	[TRAIN] epoch: 3074, iter: 242820/250000, loss: 0.1229, lr: 0.000410, batch_cost: 0.5980, reader_cost: 0.03289, ips: 10.0337 samples/sec | ETA 01:11:33
2023-02-05 06:44:59 [INFO]	[TRAIN] epoch: 3074, iter: 242830/250000, loss: 0.1275, lr: 0.000409, batch_cost: 0.5658, reader_cost: 0.00013, ips: 10.6047 samples/sec | ETA 01:07:36
2023-02-05 06:45:04 [INFO]	[TRAIN] epoch: 3074, iter: 242840/250000, loss: 0.1130, lr: 0.000409, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6063 samples/sec | ETA 01:07:30
2023-02-05 06:45:10 [INFO]	[TRAIN] epoch: 3075, iter: 242850/250000, loss: 0.1338, lr: 0.000408, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6133 samples/sec | ETA 01:07:22
2023-02-05 06:45:16 [INFO]	[TRAIN] epoch: 3075, iter: 242860/250000, loss: 0.1095, lr: 0.000408, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6113 samples/sec | ETA 01:07:17
2023-02-05 06:45:21 [INFO]	[TRAIN] epoch: 3075, iter: 242870/250000, loss: 0.1174, lr: 0.000407, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 01:07:14
2023-02-05 06:45:27 [INFO]	[TRAIN] epoch: 3075, iter: 242880/250000, loss: 0.1243, lr: 0.000407, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6143 samples/sec | ETA 01:07:04
2023-02-05 06:45:33 [INFO]	[TRAIN] epoch: 3075, iter: 242890/250000, loss: 0.1098, lr: 0.000406, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6135 samples/sec | ETA 01:06:59
2023-02-05 06:45:38 [INFO]	[TRAIN] epoch: 3075, iter: 242900/250000, loss: 0.1313, lr: 0.000406, batch_cost: 0.5921, reader_cost: 0.02700, ips: 10.1337 samples/sec | ETA 01:10:03
2023-02-05 06:45:44 [INFO]	[TRAIN] epoch: 3075, iter: 242910/250000, loss: 0.1394, lr: 0.000405, batch_cost: 0.5669, reader_cost: 0.00014, ips: 10.5833 samples/sec | ETA 01:06:59
2023-02-05 06:45:50 [INFO]	[TRAIN] epoch: 3075, iter: 242920/250000, loss: 0.1137, lr: 0.000405, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5978 samples/sec | ETA 01:06:48
2023-02-05 06:45:55 [INFO]	[TRAIN] epoch: 3076, iter: 242930/250000, loss: 0.1145, lr: 0.000404, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6026 samples/sec | ETA 01:06:40
2023-02-05 06:46:01 [INFO]	[TRAIN] epoch: 3076, iter: 242940/250000, loss: 0.1277, lr: 0.000403, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6027 samples/sec | ETA 01:06:35
2023-02-05 06:46:07 [INFO]	[TRAIN] epoch: 3076, iter: 242950/250000, loss: 0.1410, lr: 0.000403, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6129 samples/sec | ETA 01:06:25
2023-02-05 06:46:12 [INFO]	[TRAIN] epoch: 3076, iter: 242960/250000, loss: 0.1361, lr: 0.000402, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6081 samples/sec | ETA 01:06:21
2023-02-05 06:46:18 [INFO]	[TRAIN] epoch: 3076, iter: 242970/250000, loss: 0.1121, lr: 0.000402, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 01:06:17
2023-02-05 06:46:24 [INFO]	[TRAIN] epoch: 3076, iter: 242980/250000, loss: 0.1170, lr: 0.000401, batch_cost: 0.5935, reader_cost: 0.02815, ips: 10.1090 samples/sec | ETA 01:09:26
2023-02-05 06:46:30 [INFO]	[TRAIN] epoch: 3076, iter: 242990/250000, loss: 0.1211, lr: 0.000401, batch_cost: 0.5645, reader_cost: 0.00013, ips: 10.6281 samples/sec | ETA 01:05:57
2023-02-05 06:46:35 [INFO]	[TRAIN] epoch: 3076, iter: 243000/250000, loss: 0.1476, lr: 0.000400, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6096 samples/sec | ETA 01:05:58
2023-02-05 06:46:41 [INFO]	[TRAIN] epoch: 3077, iter: 243010/250000, loss: 0.1115, lr: 0.000400, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6043 samples/sec | ETA 01:05:55
2023-02-05 06:46:47 [INFO]	[TRAIN] epoch: 3077, iter: 243020/250000, loss: 0.1301, lr: 0.000399, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6111 samples/sec | ETA 01:05:46
2023-02-05 06:46:52 [INFO]	[TRAIN] epoch: 3077, iter: 243030/250000, loss: 0.1130, lr: 0.000399, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 01:05:42
2023-02-05 06:46:58 [INFO]	[TRAIN] epoch: 3077, iter: 243040/250000, loss: 0.1178, lr: 0.000398, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6053 samples/sec | ETA 01:05:37
2023-02-05 06:47:04 [INFO]	[TRAIN] epoch: 3077, iter: 243050/250000, loss: 0.1032, lr: 0.000398, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6109 samples/sec | ETA 01:05:29
2023-02-05 06:47:09 [INFO]	[TRAIN] epoch: 3077, iter: 243060/250000, loss: 0.1145, lr: 0.000397, batch_cost: 0.5882, reader_cost: 0.02314, ips: 10.2004 samples/sec | ETA 01:08:02
2023-02-05 06:47:15 [INFO]	[TRAIN] epoch: 3077, iter: 243070/250000, loss: 0.1071, lr: 0.000397, batch_cost: 0.5660, reader_cost: 0.00013, ips: 10.6010 samples/sec | ETA 01:05:22
2023-02-05 06:47:21 [INFO]	[TRAIN] epoch: 3077, iter: 243080/250000, loss: 0.1090, lr: 0.000396, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6127 samples/sec | ETA 01:05:12
2023-02-05 06:47:26 [INFO]	[TRAIN] epoch: 3078, iter: 243090/250000, loss: 0.1379, lr: 0.000396, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6099 samples/sec | ETA 01:05:07
2023-02-05 06:47:32 [INFO]	[TRAIN] epoch: 3078, iter: 243100/250000, loss: 0.1233, lr: 0.000395, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5996 samples/sec | ETA 01:05:05
2023-02-05 06:47:38 [INFO]	[TRAIN] epoch: 3078, iter: 243110/250000, loss: 0.1177, lr: 0.000395, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6082 samples/sec | ETA 01:04:56
2023-02-05 06:47:43 [INFO]	[TRAIN] epoch: 3078, iter: 243120/250000, loss: 0.1522, lr: 0.000394, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6141 samples/sec | ETA 01:04:49
2023-02-05 06:47:49 [INFO]	[TRAIN] epoch: 3078, iter: 243130/250000, loss: 0.1073, lr: 0.000394, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5978 samples/sec | ETA 01:04:49
2023-02-05 06:47:55 [INFO]	[TRAIN] epoch: 3078, iter: 243140/250000, loss: 0.1263, lr: 0.000393, batch_cost: 0.6043, reader_cost: 0.03726, ips: 9.9292 samples/sec | ETA 01:09:05
2023-02-05 06:48:01 [INFO]	[TRAIN] epoch: 3078, iter: 243150/250000, loss: 0.1104, lr: 0.000393, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6195 samples/sec | ETA 01:04:30
2023-02-05 06:48:06 [INFO]	[TRAIN] epoch: 3078, iter: 243160/250000, loss: 0.1154, lr: 0.000392, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6336 samples/sec | ETA 01:04:19
2023-02-05 06:48:12 [INFO]	[TRAIN] epoch: 3079, iter: 243170/250000, loss: 0.1426, lr: 0.000392, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6337 samples/sec | ETA 01:04:13
2023-02-05 06:48:18 [INFO]	[TRAIN] epoch: 3079, iter: 243180/250000, loss: 0.1296, lr: 0.000391, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6129 samples/sec | ETA 01:04:15
2023-02-05 06:48:23 [INFO]	[TRAIN] epoch: 3079, iter: 243190/250000, loss: 0.1236, lr: 0.000391, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6059 samples/sec | ETA 01:04:12
2023-02-05 06:48:29 [INFO]	[TRAIN] epoch: 3079, iter: 243200/250000, loss: 0.1326, lr: 0.000390, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6048 samples/sec | ETA 01:04:07
2023-02-05 06:48:35 [INFO]	[TRAIN] epoch: 3079, iter: 243210/250000, loss: 0.1281, lr: 0.000390, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6067 samples/sec | ETA 01:04:00
2023-02-05 06:48:41 [INFO]	[TRAIN] epoch: 3079, iter: 243220/250000, loss: 0.1355, lr: 0.000389, batch_cost: 0.5894, reader_cost: 0.02456, ips: 10.1800 samples/sec | ETA 01:06:36
2023-02-05 06:48:46 [INFO]	[TRAIN] epoch: 3079, iter: 243230/250000, loss: 0.1225, lr: 0.000389, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6197 samples/sec | ETA 01:03:44
2023-02-05 06:48:52 [INFO]	[TRAIN] epoch: 3079, iter: 243240/250000, loss: 0.1047, lr: 0.000388, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6049 samples/sec | ETA 01:03:44
2023-02-05 06:48:58 [INFO]	[TRAIN] epoch: 3080, iter: 243250/250000, loss: 0.2210, lr: 0.000388, batch_cost: 0.5662, reader_cost: 0.00008, ips: 10.5975 samples/sec | ETA 01:03:41
2023-02-05 06:49:03 [INFO]	[TRAIN] epoch: 3080, iter: 243260/250000, loss: 0.1309, lr: 0.000387, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6154 samples/sec | ETA 01:03:29
2023-02-05 06:49:09 [INFO]	[TRAIN] epoch: 3080, iter: 243270/250000, loss: 0.1133, lr: 0.000386, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6100 samples/sec | ETA 01:03:25
2023-02-05 06:49:15 [INFO]	[TRAIN] epoch: 3080, iter: 243280/250000, loss: 0.1249, lr: 0.000386, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5988 samples/sec | ETA 01:03:24
2023-02-05 06:49:20 [INFO]	[TRAIN] epoch: 3080, iter: 243290/250000, loss: 0.1317, lr: 0.000385, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6037 samples/sec | ETA 01:03:16
2023-02-05 06:49:26 [INFO]	[TRAIN] epoch: 3080, iter: 243300/250000, loss: 0.1502, lr: 0.000385, batch_cost: 0.6002, reader_cost: 0.03517, ips: 9.9971 samples/sec | ETA 01:07:01
2023-02-05 06:49:32 [INFO]	[TRAIN] epoch: 3080, iter: 243310/250000, loss: 0.1200, lr: 0.000384, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6265 samples/sec | ETA 01:02:57
2023-02-05 06:49:37 [INFO]	[TRAIN] epoch: 3080, iter: 243320/250000, loss: 0.1411, lr: 0.000384, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6174 samples/sec | ETA 01:02:54
2023-02-05 06:49:43 [INFO]	[TRAIN] epoch: 3081, iter: 243330/250000, loss: 0.1356, lr: 0.000383, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6116 samples/sec | ETA 01:02:51
2023-02-05 06:49:49 [INFO]	[TRAIN] epoch: 3081, iter: 243340/250000, loss: 0.1146, lr: 0.000383, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6022 samples/sec | ETA 01:02:49
2023-02-05 06:49:54 [INFO]	[TRAIN] epoch: 3081, iter: 243350/250000, loss: 0.1121, lr: 0.000382, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6021 samples/sec | ETA 01:02:43
2023-02-05 06:50:00 [INFO]	[TRAIN] epoch: 3081, iter: 243360/250000, loss: 0.1221, lr: 0.000382, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6160 samples/sec | ETA 01:02:32
2023-02-05 06:50:06 [INFO]	[TRAIN] epoch: 3081, iter: 243370/250000, loss: 0.1480, lr: 0.000381, batch_cost: 0.5660, reader_cost: 0.00008, ips: 10.6011 samples/sec | ETA 01:02:32
2023-02-05 06:50:12 [INFO]	[TRAIN] epoch: 3081, iter: 243380/250000, loss: 0.1102, lr: 0.000381, batch_cost: 0.5947, reader_cost: 0.02940, ips: 10.0884 samples/sec | ETA 01:05:37
2023-02-05 06:50:17 [INFO]	[TRAIN] epoch: 3081, iter: 243390/250000, loss: 0.1242, lr: 0.000380, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6010 samples/sec | ETA 01:02:21
2023-02-05 06:50:23 [INFO]	[TRAIN] epoch: 3082, iter: 243400/250000, loss: 0.1167, lr: 0.000380, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6028 samples/sec | ETA 01:02:14
2023-02-05 06:50:29 [INFO]	[TRAIN] epoch: 3082, iter: 243410/250000, loss: 0.1305, lr: 0.000379, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6074 samples/sec | ETA 01:02:07
2023-02-05 06:50:34 [INFO]	[TRAIN] epoch: 3082, iter: 243420/250000, loss: 0.1155, lr: 0.000379, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6089 samples/sec | ETA 01:02:01
2023-02-05 06:50:40 [INFO]	[TRAIN] epoch: 3082, iter: 243430/250000, loss: 0.1164, lr: 0.000378, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6109 samples/sec | ETA 01:01:55
2023-02-05 06:50:46 [INFO]	[TRAIN] epoch: 3082, iter: 243440/250000, loss: 0.1390, lr: 0.000378, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6055 samples/sec | ETA 01:01:51
2023-02-05 06:50:51 [INFO]	[TRAIN] epoch: 3082, iter: 243450/250000, loss: 0.1223, lr: 0.000377, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6114 samples/sec | ETA 01:01:43
2023-02-05 06:50:57 [INFO]	[TRAIN] epoch: 3082, iter: 243460/250000, loss: 0.1223, lr: 0.000377, batch_cost: 0.5909, reader_cost: 0.02693, ips: 10.1540 samples/sec | ETA 01:04:24
2023-02-05 06:51:03 [INFO]	[TRAIN] epoch: 3082, iter: 243470/250000, loss: 0.1350, lr: 0.000376, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6361 samples/sec | ETA 01:01:23
2023-02-05 06:51:09 [INFO]	[TRAIN] epoch: 3083, iter: 243480/250000, loss: 0.1375, lr: 0.000376, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6031 samples/sec | ETA 01:01:29
2023-02-05 06:51:14 [INFO]	[TRAIN] epoch: 3083, iter: 243490/250000, loss: 0.1267, lr: 0.000375, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6011 samples/sec | ETA 01:01:24
2023-02-05 06:51:20 [INFO]	[TRAIN] epoch: 3083, iter: 243500/250000, loss: 0.1109, lr: 0.000375, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6029 samples/sec | ETA 01:01:18
2023-02-05 06:51:25 [INFO]	[TRAIN] epoch: 3083, iter: 243510/250000, loss: 0.1244, lr: 0.000374, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6069 samples/sec | ETA 01:01:11
2023-02-05 06:51:31 [INFO]	[TRAIN] epoch: 3083, iter: 243520/250000, loss: 0.1186, lr: 0.000374, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6119 samples/sec | ETA 01:01:03
2023-02-05 06:51:37 [INFO]	[TRAIN] epoch: 3083, iter: 243530/250000, loss: 0.1239, lr: 0.000373, batch_cost: 0.5871, reader_cost: 0.02180, ips: 10.2198 samples/sec | ETA 01:03:18
2023-02-05 06:51:43 [INFO]	[TRAIN] epoch: 3083, iter: 243540/250000, loss: 0.1207, lr: 0.000372, batch_cost: 0.5652, reader_cost: 0.00019, ips: 10.6156 samples/sec | ETA 01:00:51
2023-02-05 06:51:48 [INFO]	[TRAIN] epoch: 3083, iter: 243550/250000, loss: 0.1207, lr: 0.000372, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6086 samples/sec | ETA 01:00:47
2023-02-05 06:51:54 [INFO]	[TRAIN] epoch: 3084, iter: 243560/250000, loss: 0.1491, lr: 0.000371, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6106 samples/sec | ETA 01:00:41
2023-02-05 06:52:00 [INFO]	[TRAIN] epoch: 3084, iter: 243570/250000, loss: 0.1432, lr: 0.000371, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 01:00:38
2023-02-05 06:52:05 [INFO]	[TRAIN] epoch: 3084, iter: 243580/250000, loss: 0.1231, lr: 0.000370, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6094 samples/sec | ETA 01:00:30
2023-02-05 06:52:11 [INFO]	[TRAIN] epoch: 3084, iter: 243590/250000, loss: 0.1533, lr: 0.000370, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6064 samples/sec | ETA 01:00:26
2023-02-05 06:52:17 [INFO]	[TRAIN] epoch: 3084, iter: 243600/250000, loss: 0.1222, lr: 0.000369, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6041 samples/sec | ETA 01:00:21
2023-02-05 06:52:22 [INFO]	[TRAIN] epoch: 3084, iter: 243610/250000, loss: 0.1338, lr: 0.000369, batch_cost: 0.5897, reader_cost: 0.02217, ips: 10.1751 samples/sec | ETA 01:02:48
2023-02-05 06:52:28 [INFO]	[TRAIN] epoch: 3084, iter: 243620/250000, loss: 0.1263, lr: 0.000368, batch_cost: 0.5647, reader_cost: 0.00014, ips: 10.6247 samples/sec | ETA 01:00:02
2023-02-05 06:52:34 [INFO]	[TRAIN] epoch: 3084, iter: 243630/250000, loss: 0.1155, lr: 0.000368, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6032 samples/sec | ETA 01:00:04
2023-02-05 06:52:39 [INFO]	[TRAIN] epoch: 3085, iter: 243640/250000, loss: 0.1775, lr: 0.000367, batch_cost: 0.5658, reader_cost: 0.00008, ips: 10.6043 samples/sec | ETA 00:59:58
2023-02-05 06:52:45 [INFO]	[TRAIN] epoch: 3085, iter: 243650/250000, loss: 0.1395, lr: 0.000367, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6036 samples/sec | ETA 00:59:53
2023-02-05 06:52:51 [INFO]	[TRAIN] epoch: 3085, iter: 243660/250000, loss: 0.1221, lr: 0.000366, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6017 samples/sec | ETA 00:59:48
2023-02-05 06:52:56 [INFO]	[TRAIN] epoch: 3085, iter: 243670/250000, loss: 0.1668, lr: 0.000366, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6151 samples/sec | ETA 00:59:37
2023-02-05 06:53:02 [INFO]	[TRAIN] epoch: 3085, iter: 243680/250000, loss: 0.1157, lr: 0.000365, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6093 samples/sec | ETA 00:59:34
2023-02-05 06:53:08 [INFO]	[TRAIN] epoch: 3085, iter: 243690/250000, loss: 0.1353, lr: 0.000365, batch_cost: 0.5914, reader_cost: 0.02460, ips: 10.1447 samples/sec | ETA 01:02:12
2023-02-05 06:53:14 [INFO]	[TRAIN] epoch: 3085, iter: 243700/250000, loss: 0.1201, lr: 0.000364, batch_cost: 0.5646, reader_cost: 0.00014, ips: 10.6266 samples/sec | ETA 00:59:17
2023-02-05 06:53:19 [INFO]	[TRAIN] epoch: 3085, iter: 243710/250000, loss: 0.1216, lr: 0.000364, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6225 samples/sec | ETA 00:59:12
2023-02-05 06:53:25 [INFO]	[TRAIN] epoch: 3086, iter: 243720/250000, loss: 0.1163, lr: 0.000363, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6090 samples/sec | ETA 00:59:11
2023-02-05 06:53:31 [INFO]	[TRAIN] epoch: 3086, iter: 243730/250000, loss: 0.1420, lr: 0.000363, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6035 samples/sec | ETA 00:59:07
2023-02-05 06:53:36 [INFO]	[TRAIN] epoch: 3086, iter: 243740/250000, loss: 0.1302, lr: 0.000362, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6123 samples/sec | ETA 00:58:59
2023-02-05 06:53:42 [INFO]	[TRAIN] epoch: 3086, iter: 243750/250000, loss: 0.1005, lr: 0.000362, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6120 samples/sec | ETA 00:58:53
2023-02-05 06:53:48 [INFO]	[TRAIN] epoch: 3086, iter: 243760/250000, loss: 0.1359, lr: 0.000361, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6039 samples/sec | ETA 00:58:50
2023-02-05 06:53:54 [INFO]	[TRAIN] epoch: 3086, iter: 243770/250000, loss: 0.1330, lr: 0.000361, batch_cost: 0.5927, reader_cost: 0.02703, ips: 10.1231 samples/sec | ETA 01:01:32
2023-02-05 06:53:59 [INFO]	[TRAIN] epoch: 3086, iter: 243780/250000, loss: 0.1268, lr: 0.000360, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6235 samples/sec | ETA 00:58:32
2023-02-05 06:54:05 [INFO]	[TRAIN] epoch: 3086, iter: 243790/250000, loss: 0.1198, lr: 0.000360, batch_cost: 0.5654, reader_cost: 0.00011, ips: 10.6111 samples/sec | ETA 00:58:31
2023-02-05 06:54:10 [INFO]	[TRAIN] epoch: 3087, iter: 243800/250000, loss: 0.1317, lr: 0.000359, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 00:58:27
2023-02-05 06:54:16 [INFO]	[TRAIN] epoch: 3087, iter: 243810/250000, loss: 0.1212, lr: 0.000358, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6105 samples/sec | ETA 00:58:20
2023-02-05 06:54:22 [INFO]	[TRAIN] epoch: 3087, iter: 243820/250000, loss: 0.1163, lr: 0.000358, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 00:58:15
2023-02-05 06:54:27 [INFO]	[TRAIN] epoch: 3087, iter: 243830/250000, loss: 0.1326, lr: 0.000357, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6053 samples/sec | ETA 00:58:10
2023-02-05 06:54:33 [INFO]	[TRAIN] epoch: 3087, iter: 243840/250000, loss: 0.1315, lr: 0.000357, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6002 samples/sec | ETA 00:58:06
2023-02-05 06:54:39 [INFO]	[TRAIN] epoch: 3087, iter: 243850/250000, loss: 0.1252, lr: 0.000356, batch_cost: 0.5971, reader_cost: 0.03107, ips: 10.0492 samples/sec | ETA 01:01:11
2023-02-05 06:54:45 [INFO]	[TRAIN] epoch: 3087, iter: 243860/250000, loss: 0.1032, lr: 0.000356, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6017 samples/sec | ETA 00:57:54
2023-02-05 06:54:50 [INFO]	[TRAIN] epoch: 3087, iter: 243870/250000, loss: 0.1609, lr: 0.000355, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6076 samples/sec | ETA 00:57:47
2023-02-05 06:54:56 [INFO]	[TRAIN] epoch: 3088, iter: 243880/250000, loss: 0.1199, lr: 0.000355, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6070 samples/sec | ETA 00:57:41
2023-02-05 06:55:02 [INFO]	[TRAIN] epoch: 3088, iter: 243890/250000, loss: 0.1401, lr: 0.000354, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6058 samples/sec | ETA 00:57:36
2023-02-05 06:55:07 [INFO]	[TRAIN] epoch: 3088, iter: 243900/250000, loss: 0.2439, lr: 0.000354, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6061 samples/sec | ETA 00:57:30
2023-02-05 06:55:13 [INFO]	[TRAIN] epoch: 3088, iter: 243910/250000, loss: 0.1347, lr: 0.000353, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5989 samples/sec | ETA 00:57:27
2023-02-05 06:55:19 [INFO]	[TRAIN] epoch: 3088, iter: 243920/250000, loss: 0.1389, lr: 0.000353, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5988 samples/sec | ETA 00:57:21
2023-02-05 06:55:25 [INFO]	[TRAIN] epoch: 3088, iter: 243930/250000, loss: 0.1585, lr: 0.000352, batch_cost: 0.5938, reader_cost: 0.02749, ips: 10.1041 samples/sec | ETA 01:00:04
2023-02-05 06:55:30 [INFO]	[TRAIN] epoch: 3088, iter: 243940/250000, loss: 0.1177, lr: 0.000352, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6087 samples/sec | ETA 00:57:07
2023-02-05 06:55:36 [INFO]	[TRAIN] epoch: 3088, iter: 243950/250000, loss: 0.1347, lr: 0.000351, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6086 samples/sec | ETA 00:57:01
2023-02-05 06:55:42 [INFO]	[TRAIN] epoch: 3089, iter: 243960/250000, loss: 0.1358, lr: 0.000351, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6102 samples/sec | ETA 00:56:55
2023-02-05 06:55:47 [INFO]	[TRAIN] epoch: 3089, iter: 243970/250000, loss: 0.1309, lr: 0.000350, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6105 samples/sec | ETA 00:56:49
2023-02-05 06:55:53 [INFO]	[TRAIN] epoch: 3089, iter: 243980/250000, loss: 0.1221, lr: 0.000350, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6016 samples/sec | ETA 00:56:47
2023-02-05 06:55:59 [INFO]	[TRAIN] epoch: 3089, iter: 243990/250000, loss: 0.1294, lr: 0.000349, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6056 samples/sec | ETA 00:56:40
2023-02-05 06:56:04 [INFO]	[TRAIN] epoch: 3089, iter: 244000/250000, loss: 0.1043, lr: 0.000349, batch_cost: 0.5651, reader_cost: 0.00008, ips: 10.6171 samples/sec | ETA 00:56:30
2023-02-05 06:56:04 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1259 - reader cost: 0.0258 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1515 - reader cost: 0.0129 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1581 - reader cost: 0.0087 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1588 - reader cost: 0.0065 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1609 - reader cost: 0.0052 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1628 - reader cost: 0.0044 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1625 - reader cost: 0.0038 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1627 - reader cost: 0.0033 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1636 - reader cost: 0.002910/36 [=======>......................] - ETA: 4s - batch_cost: 0.1636 - reader cost: 0.002711/36 [========>.....................] - ETA: 4s - batch_cost: 0.1643 - reader cost: 0.002412/36 [=========>....................] - ETA: 3s - batch_cost: 0.1638 - reader cost: 0.002213/36 [=========>....................] - ETA: 3s - batch_cost: 0.1640 - reader cost: 0.002114/36 [==========>...................] - ETA: 3s - batch_cost: 0.1644 - reader cost: 0.001915/36 [===========>..................] - ETA: 3s - batch_cost: 0.1643 - reader cost: 0.001816/36 [============>.................] - ETA: 3s - batch_cost: 0.1653 - reader cost: 0.001717/36 [=============>................] - ETA: 3s - batch_cost: 0.1655 - reader cost: 0.001618/36 [==============>...............] - ETA: 2s - batch_cost: 0.1656 - reader cost: 0.001519/36 [==============>...............] - ETA: 2s - batch_cost: 0.1653 - reader cost: 0.001420/36 [===============>..............] - ETA: 2s - batch_cost: 0.1652 - reader cost: 0.001421/36 [================>.............] - ETA: 2s - batch_cost: 0.1653 - reader cost: 0.001322/36 [=================>............] - ETA: 2s - batch_cost: 0.1656 - reader cost: 0.001223/36 [==================>...........] - ETA: 2s - batch_cost: 0.1662 - reader cost: 0.001224/36 [===================>..........] - ETA: 1s - batch_cost: 0.1662 - reader cost: 0.001125/36 [===================>..........] - ETA: 1s - batch_cost: 0.1663 - reader cost: 0.001126/36 [====================>.........] - ETA: 1s - batch_cost: 0.1665 - reader cost: 0.001127/36 [=====================>........] - ETA: 1s - batch_cost: 0.1667 - reader cost: 0.001028/36 [======================>.......] - ETA: 1s - batch_cost: 0.1671 - reader cost: 9.9505e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1672 - reader cost: 9.6379e-0430/36 [========================>.....] - ETA: 1s - batch_cost: 0.1671 - reader cost: 9.3412e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1671 - reader cost: 9.0682e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1669 - reader cost: 8.8127e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1668 - reader cost: 8.5676e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1665 - reader cost: 8.3352e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1665 - reader cost: 8.1158e-0436/36 [==============================] - 6s 167ms/step - batch_cost: 0.1666 - reader cost: 7.9119e-04
2023-02-05 06:56:10 [INFO]	[EVAL] #Images: 36 mIoU: 0.8629 Acc: 0.9862 Kappa: 0.9501 Dice: 0.9227
2023-02-05 06:56:10 [INFO]	[EVAL] Class IoU: 
[0.9857 0.9173 0.8932 0.7074 0.7064 0.9722 0.8579]
2023-02-05 06:56:10 [INFO]	[EVAL] Class Precision: 
[0.9922 0.9672 0.9467 0.8323 0.8678 0.9823 0.9137]
2023-02-05 06:56:10 [INFO]	[EVAL] Class Recall: 
[0.9933 0.9467 0.9405 0.825  0.7915 0.9895 0.9336]
2023-02-05 06:56:10 [INFO]	[EVAL] The model with the best validation mIoU (0.8682) was saved at iter 222000.
2023-02-05 06:56:16 [INFO]	[TRAIN] epoch: 3089, iter: 244010/250000, loss: 0.1208, lr: 0.000348, batch_cost: 0.5894, reader_cost: 0.02477, ips: 10.1805 samples/sec | ETA 00:58:50
2023-02-05 06:56:22 [INFO]	[TRAIN] epoch: 3089, iter: 244020/250000, loss: 0.1220, lr: 0.000347, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6331 samples/sec | ETA 00:56:14
2023-02-05 06:56:28 [INFO]	[TRAIN] epoch: 3089, iter: 244030/250000, loss: 0.1243, lr: 0.000347, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6272 samples/sec | ETA 00:56:10
2023-02-05 06:56:33 [INFO]	[TRAIN] epoch: 3090, iter: 244040/250000, loss: 0.1371, lr: 0.000346, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6260 samples/sec | ETA 00:56:05
2023-02-05 06:56:39 [INFO]	[TRAIN] epoch: 3090, iter: 244050/250000, loss: 0.1597, lr: 0.000346, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6270 samples/sec | ETA 00:55:59
2023-02-05 06:56:45 [INFO]	[TRAIN] epoch: 3090, iter: 244060/250000, loss: 0.1130, lr: 0.000345, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6316 samples/sec | ETA 00:55:52
2023-02-05 06:56:50 [INFO]	[TRAIN] epoch: 3090, iter: 244070/250000, loss: 0.1178, lr: 0.000345, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6292 samples/sec | ETA 00:55:47
2023-02-05 06:56:56 [INFO]	[TRAIN] epoch: 3090, iter: 244080/250000, loss: 0.1409, lr: 0.000344, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6285 samples/sec | ETA 00:55:41
2023-02-05 06:57:02 [INFO]	[TRAIN] epoch: 3090, iter: 244090/250000, loss: 0.1137, lr: 0.000344, batch_cost: 0.5909, reader_cost: 0.02591, ips: 10.1543 samples/sec | ETA 00:58:12
2023-02-05 06:57:07 [INFO]	[TRAIN] epoch: 3090, iter: 244100/250000, loss: 0.1352, lr: 0.000343, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6321 samples/sec | ETA 00:55:29
2023-02-05 06:57:13 [INFO]	[TRAIN] epoch: 3090, iter: 244110/250000, loss: 0.1128, lr: 0.000343, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6073 samples/sec | ETA 00:55:31
2023-02-05 06:57:19 [INFO]	[TRAIN] epoch: 3091, iter: 244120/250000, loss: 0.1196, lr: 0.000342, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5965 samples/sec | ETA 00:55:29
2023-02-05 06:57:24 [INFO]	[TRAIN] epoch: 3091, iter: 244130/250000, loss: 0.1291, lr: 0.000342, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6118 samples/sec | ETA 00:55:18
2023-02-05 06:57:30 [INFO]	[TRAIN] epoch: 3091, iter: 244140/250000, loss: 0.1371, lr: 0.000341, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6103 samples/sec | ETA 00:55:13
2023-02-05 06:57:36 [INFO]	[TRAIN] epoch: 3091, iter: 244150/250000, loss: 0.1095, lr: 0.000341, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6018 samples/sec | ETA 00:55:10
2023-02-05 06:57:41 [INFO]	[TRAIN] epoch: 3091, iter: 244160/250000, loss: 0.1874, lr: 0.000340, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 00:55:04
2023-02-05 06:57:47 [INFO]	[TRAIN] epoch: 3091, iter: 244170/250000, loss: 0.1264, lr: 0.000340, batch_cost: 0.5970, reader_cost: 0.03054, ips: 10.0507 samples/sec | ETA 00:58:00
2023-02-05 06:57:53 [INFO]	[TRAIN] epoch: 3091, iter: 244180/250000, loss: 0.1445, lr: 0.000339, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6214 samples/sec | ETA 00:54:47
2023-02-05 06:57:59 [INFO]	[TRAIN] epoch: 3092, iter: 244190/250000, loss: 0.1376, lr: 0.000339, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6213 samples/sec | ETA 00:54:42
2023-02-05 06:58:04 [INFO]	[TRAIN] epoch: 3092, iter: 244200/250000, loss: 0.1414, lr: 0.000338, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6164 samples/sec | ETA 00:54:37
2023-02-05 06:58:10 [INFO]	[TRAIN] epoch: 3092, iter: 244210/250000, loss: 0.1324, lr: 0.000338, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6049 samples/sec | ETA 00:54:35
2023-02-05 06:58:16 [INFO]	[TRAIN] epoch: 3092, iter: 244220/250000, loss: 0.1289, lr: 0.000337, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5972 samples/sec | ETA 00:54:32
2023-02-05 06:58:21 [INFO]	[TRAIN] epoch: 3092, iter: 244230/250000, loss: 0.1244, lr: 0.000336, batch_cost: 0.5650, reader_cost: 0.00010, ips: 10.6187 samples/sec | ETA 00:54:20
2023-02-05 06:58:27 [INFO]	[TRAIN] epoch: 3092, iter: 244240/250000, loss: 0.1181, lr: 0.000336, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6099 samples/sec | ETA 00:54:17
2023-02-05 06:58:33 [INFO]	[TRAIN] epoch: 3092, iter: 244250/250000, loss: 0.1176, lr: 0.000335, batch_cost: 0.6002, reader_cost: 0.03561, ips: 9.9971 samples/sec | ETA 00:57:31
2023-02-05 06:58:39 [INFO]	[TRAIN] epoch: 3092, iter: 244260/250000, loss: 0.1043, lr: 0.000335, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6028 samples/sec | ETA 00:54:08
2023-02-05 06:58:44 [INFO]	[TRAIN] epoch: 3093, iter: 244270/250000, loss: 0.1347, lr: 0.000334, batch_cost: 0.5655, reader_cost: 0.00013, ips: 10.6094 samples/sec | ETA 00:54:00
2023-02-05 06:58:50 [INFO]	[TRAIN] epoch: 3093, iter: 244280/250000, loss: 0.1421, lr: 0.000334, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6085 samples/sec | ETA 00:53:55
2023-02-05 06:58:56 [INFO]	[TRAIN] epoch: 3093, iter: 244290/250000, loss: 0.1135, lr: 0.000333, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6107 samples/sec | ETA 00:53:48
2023-02-05 06:59:01 [INFO]	[TRAIN] epoch: 3093, iter: 244300/250000, loss: 0.1381, lr: 0.000333, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6115 samples/sec | ETA 00:53:42
2023-02-05 06:59:07 [INFO]	[TRAIN] epoch: 3093, iter: 244310/250000, loss: 0.1265, lr: 0.000332, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6070 samples/sec | ETA 00:53:38
2023-02-05 06:59:13 [INFO]	[TRAIN] epoch: 3093, iter: 244320/250000, loss: 0.1309, lr: 0.000332, batch_cost: 0.5951, reader_cost: 0.02963, ips: 10.0822 samples/sec | ETA 00:56:20
2023-02-05 06:59:18 [INFO]	[TRAIN] epoch: 3093, iter: 244330/250000, loss: 0.1305, lr: 0.000331, batch_cost: 0.5669, reader_cost: 0.00014, ips: 10.5844 samples/sec | ETA 00:53:34
2023-02-05 06:59:24 [INFO]	[TRAIN] epoch: 3093, iter: 244340/250000, loss: 0.1193, lr: 0.000331, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6128 samples/sec | ETA 00:53:19
2023-02-05 06:59:30 [INFO]	[TRAIN] epoch: 3094, iter: 244350/250000, loss: 0.1086, lr: 0.000330, batch_cost: 0.5658, reader_cost: 0.00008, ips: 10.6047 samples/sec | ETA 00:53:16
2023-02-05 06:59:35 [INFO]	[TRAIN] epoch: 3094, iter: 244360/250000, loss: 0.1215, lr: 0.000330, batch_cost: 0.5658, reader_cost: 0.00008, ips: 10.6041 samples/sec | ETA 00:53:11
2023-02-05 06:59:41 [INFO]	[TRAIN] epoch: 3094, iter: 244370/250000, loss: 0.1174, lr: 0.000329, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6100 samples/sec | ETA 00:53:03
2023-02-05 06:59:47 [INFO]	[TRAIN] epoch: 3094, iter: 244380/250000, loss: 0.1548, lr: 0.000329, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6113 samples/sec | ETA 00:52:57
2023-02-05 06:59:52 [INFO]	[TRAIN] epoch: 3094, iter: 244390/250000, loss: 0.1099, lr: 0.000328, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5973 samples/sec | ETA 00:52:56
2023-02-05 06:59:58 [INFO]	[TRAIN] epoch: 3094, iter: 244400/250000, loss: 0.1395, lr: 0.000328, batch_cost: 0.5883, reader_cost: 0.02316, ips: 10.1991 samples/sec | ETA 00:54:54
2023-02-05 07:00:04 [INFO]	[TRAIN] epoch: 3094, iter: 244410/250000, loss: 0.1190, lr: 0.000327, batch_cost: 0.5646, reader_cost: 0.00013, ips: 10.6275 samples/sec | ETA 00:52:35
2023-02-05 07:00:10 [INFO]	[TRAIN] epoch: 3094, iter: 244420/250000, loss: 0.1143, lr: 0.000327, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6162 samples/sec | ETA 00:52:33
2023-02-05 07:00:15 [INFO]	[TRAIN] epoch: 3095, iter: 244430/250000, loss: 0.1326, lr: 0.000326, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6080 samples/sec | ETA 00:52:30
2023-02-05 07:00:21 [INFO]	[TRAIN] epoch: 3095, iter: 244440/250000, loss: 0.1299, lr: 0.000325, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6144 samples/sec | ETA 00:52:22
2023-02-05 07:00:27 [INFO]	[TRAIN] epoch: 3095, iter: 244450/250000, loss: 0.1202, lr: 0.000325, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6090 samples/sec | ETA 00:52:18
2023-02-05 07:00:32 [INFO]	[TRAIN] epoch: 3095, iter: 244460/250000, loss: 0.1301, lr: 0.000324, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6011 samples/sec | ETA 00:52:15
2023-02-05 07:00:38 [INFO]	[TRAIN] epoch: 3095, iter: 244470/250000, loss: 0.1213, lr: 0.000324, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6016 samples/sec | ETA 00:52:09
2023-02-05 07:00:44 [INFO]	[TRAIN] epoch: 3095, iter: 244480/250000, loss: 0.1410, lr: 0.000323, batch_cost: 0.5870, reader_cost: 0.02178, ips: 10.2216 samples/sec | ETA 00:54:00
2023-02-05 07:00:49 [INFO]	[TRAIN] epoch: 3095, iter: 244490/250000, loss: 0.1016, lr: 0.000323, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6153 samples/sec | ETA 00:51:54
2023-02-05 07:00:55 [INFO]	[TRAIN] epoch: 3095, iter: 244500/250000, loss: 0.1226, lr: 0.000322, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6245 samples/sec | ETA 00:51:46
2023-02-05 07:01:01 [INFO]	[TRAIN] epoch: 3096, iter: 244510/250000, loss: 0.1329, lr: 0.000322, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6344 samples/sec | ETA 00:51:37
2023-02-05 07:01:06 [INFO]	[TRAIN] epoch: 3096, iter: 244520/250000, loss: 0.1262, lr: 0.000321, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6079 samples/sec | ETA 00:51:39
2023-02-05 07:01:12 [INFO]	[TRAIN] epoch: 3096, iter: 244530/250000, loss: 0.1160, lr: 0.000321, batch_cost: 0.5659, reader_cost: 0.00008, ips: 10.6035 samples/sec | ETA 00:51:35
2023-02-05 07:01:18 [INFO]	[TRAIN] epoch: 3096, iter: 244540/250000, loss: 0.1239, lr: 0.000320, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6048 samples/sec | ETA 00:51:29
2023-02-05 07:01:23 [INFO]	[TRAIN] epoch: 3096, iter: 244550/250000, loss: 0.1112, lr: 0.000320, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6113 samples/sec | ETA 00:51:21
2023-02-05 07:01:29 [INFO]	[TRAIN] epoch: 3096, iter: 244560/250000, loss: 0.1134, lr: 0.000319, batch_cost: 0.5943, reader_cost: 0.02925, ips: 10.0959 samples/sec | ETA 00:53:52
2023-02-05 07:01:35 [INFO]	[TRAIN] epoch: 3096, iter: 244570/250000, loss: 0.1079, lr: 0.000319, batch_cost: 0.5646, reader_cost: 0.00015, ips: 10.6276 samples/sec | ETA 00:51:05
2023-02-05 07:01:41 [INFO]	[TRAIN] epoch: 3096, iter: 244580/250000, loss: 0.1069, lr: 0.000318, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6271 samples/sec | ETA 00:51:00
2023-02-05 07:01:46 [INFO]	[TRAIN] epoch: 3097, iter: 244590/250000, loss: 0.1269, lr: 0.000318, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6364 samples/sec | ETA 00:50:51
2023-02-05 07:01:52 [INFO]	[TRAIN] epoch: 3097, iter: 244600/250000, loss: 0.1407, lr: 0.000317, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6315 samples/sec | ETA 00:50:47
2023-02-05 07:01:57 [INFO]	[TRAIN] epoch: 3097, iter: 244610/250000, loss: 0.1356, lr: 0.000316, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6317 samples/sec | ETA 00:50:41
2023-02-05 07:02:03 [INFO]	[TRAIN] epoch: 3097, iter: 244620/250000, loss: 0.1491, lr: 0.000316, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6249 samples/sec | ETA 00:50:38
2023-02-05 07:02:09 [INFO]	[TRAIN] epoch: 3097, iter: 244630/250000, loss: 0.1100, lr: 0.000315, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6276 samples/sec | ETA 00:50:31
2023-02-05 07:02:15 [INFO]	[TRAIN] epoch: 3097, iter: 244640/250000, loss: 0.1116, lr: 0.000315, batch_cost: 0.5841, reader_cost: 0.01947, ips: 10.2719 samples/sec | ETA 00:52:10
2023-02-05 07:02:20 [INFO]	[TRAIN] epoch: 3097, iter: 244650/250000, loss: 0.1185, lr: 0.000314, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6309 samples/sec | ETA 00:50:19
2023-02-05 07:02:26 [INFO]	[TRAIN] epoch: 3097, iter: 244660/250000, loss: 0.1255, lr: 0.000314, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6361 samples/sec | ETA 00:50:12
2023-02-05 07:02:32 [INFO]	[TRAIN] epoch: 3098, iter: 244670/250000, loss: 0.1359, lr: 0.000313, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6358 samples/sec | ETA 00:50:06
2023-02-05 07:02:37 [INFO]	[TRAIN] epoch: 3098, iter: 244680/250000, loss: 0.1043, lr: 0.000313, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6392 samples/sec | ETA 00:50:00
2023-02-05 07:02:43 [INFO]	[TRAIN] epoch: 3098, iter: 244690/250000, loss: 0.1306, lr: 0.000312, batch_cost: 0.5662, reader_cost: 0.00009, ips: 10.5974 samples/sec | ETA 00:50:06
2023-02-05 07:02:49 [INFO]	[TRAIN] epoch: 3098, iter: 244700/250000, loss: 0.1051, lr: 0.000312, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 00:49:58
2023-02-05 07:02:54 [INFO]	[TRAIN] epoch: 3098, iter: 244710/250000, loss: 0.1072, lr: 0.000311, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6071 samples/sec | ETA 00:49:52
2023-02-05 07:03:00 [INFO]	[TRAIN] epoch: 3098, iter: 244720/250000, loss: 0.1331, lr: 0.000311, batch_cost: 0.5984, reader_cost: 0.03257, ips: 10.0272 samples/sec | ETA 00:52:39
2023-02-05 07:03:06 [INFO]	[TRAIN] epoch: 3098, iter: 244730/250000, loss: 0.1309, lr: 0.000310, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6340 samples/sec | ETA 00:49:33
2023-02-05 07:03:11 [INFO]	[TRAIN] epoch: 3098, iter: 244740/250000, loss: 0.1452, lr: 0.000310, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6110 samples/sec | ETA 00:49:34
2023-02-05 07:03:17 [INFO]	[TRAIN] epoch: 3099, iter: 244750/250000, loss: 0.1320, lr: 0.000309, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6084 samples/sec | ETA 00:49:29
2023-02-05 07:03:23 [INFO]	[TRAIN] epoch: 3099, iter: 244760/250000, loss: 0.1407, lr: 0.000309, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6018 samples/sec | ETA 00:49:25
2023-02-05 07:03:28 [INFO]	[TRAIN] epoch: 3099, iter: 244770/250000, loss: 0.1079, lr: 0.000308, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6182 samples/sec | ETA 00:49:15
2023-02-05 07:03:34 [INFO]	[TRAIN] epoch: 3099, iter: 244780/250000, loss: 0.1431, lr: 0.000307, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6045 samples/sec | ETA 00:49:13
2023-02-05 07:03:40 [INFO]	[TRAIN] epoch: 3099, iter: 244790/250000, loss: 0.1175, lr: 0.000307, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.5998 samples/sec | ETA 00:49:09
2023-02-05 07:03:46 [INFO]	[TRAIN] epoch: 3099, iter: 244800/250000, loss: 0.1245, lr: 0.000306, batch_cost: 0.5875, reader_cost: 0.02280, ips: 10.2123 samples/sec | ETA 00:50:55
2023-02-05 07:03:51 [INFO]	[TRAIN] epoch: 3099, iter: 244810/250000, loss: 0.1203, lr: 0.000306, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6108 samples/sec | ETA 00:48:54
2023-02-05 07:03:57 [INFO]	[TRAIN] epoch: 3099, iter: 244820/250000, loss: 0.1214, lr: 0.000305, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6095 samples/sec | ETA 00:48:49
2023-02-05 07:04:03 [INFO]	[TRAIN] epoch: 3100, iter: 244830/250000, loss: 0.1028, lr: 0.000305, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6073 samples/sec | ETA 00:48:44
2023-02-05 07:04:08 [INFO]	[TRAIN] epoch: 3100, iter: 244840/250000, loss: 0.1381, lr: 0.000304, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6073 samples/sec | ETA 00:48:38
2023-02-05 07:04:14 [INFO]	[TRAIN] epoch: 3100, iter: 244850/250000, loss: 0.1111, lr: 0.000304, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6020 samples/sec | ETA 00:48:34
2023-02-05 07:04:20 [INFO]	[TRAIN] epoch: 3100, iter: 244860/250000, loss: 0.1320, lr: 0.000303, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6099 samples/sec | ETA 00:48:26
2023-02-05 07:04:25 [INFO]	[TRAIN] epoch: 3100, iter: 244870/250000, loss: 0.1442, lr: 0.000303, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6127 samples/sec | ETA 00:48:20
2023-02-05 07:04:31 [INFO]	[TRAIN] epoch: 3100, iter: 244880/250000, loss: 0.0974, lr: 0.000302, batch_cost: 0.5966, reader_cost: 0.03035, ips: 10.0571 samples/sec | ETA 00:50:54
2023-02-05 07:04:37 [INFO]	[TRAIN] epoch: 3100, iter: 244890/250000, loss: 0.1292, lr: 0.000302, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6259 samples/sec | ETA 00:48:05
2023-02-05 07:04:42 [INFO]	[TRAIN] epoch: 3100, iter: 244900/250000, loss: 0.1276, lr: 0.000301, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6281 samples/sec | ETA 00:47:59
2023-02-05 07:04:48 [INFO]	[TRAIN] epoch: 3101, iter: 244910/250000, loss: 0.1147, lr: 0.000301, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6251 samples/sec | ETA 00:47:54
2023-02-05 07:04:54 [INFO]	[TRAIN] epoch: 3101, iter: 244920/250000, loss: 0.1169, lr: 0.000300, batch_cost: 0.5650, reader_cost: 0.00008, ips: 10.6201 samples/sec | ETA 00:47:50
2023-02-05 07:04:59 [INFO]	[TRAIN] epoch: 3101, iter: 244930/250000, loss: 0.1092, lr: 0.000300, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6073 samples/sec | ETA 00:47:47
2023-02-05 07:05:05 [INFO]	[TRAIN] epoch: 3101, iter: 244940/250000, loss: 0.1448, lr: 0.000299, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6091 samples/sec | ETA 00:47:41
2023-02-05 07:05:11 [INFO]	[TRAIN] epoch: 3101, iter: 244950/250000, loss: 0.1243, lr: 0.000298, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6061 samples/sec | ETA 00:47:36
2023-02-05 07:05:17 [INFO]	[TRAIN] epoch: 3101, iter: 244960/250000, loss: 0.1295, lr: 0.000298, batch_cost: 0.5906, reader_cost: 0.02599, ips: 10.1586 samples/sec | ETA 00:49:36
2023-02-05 07:05:22 [INFO]	[TRAIN] epoch: 3101, iter: 244970/250000, loss: 0.1324, lr: 0.000297, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6238 samples/sec | ETA 00:47:20
2023-02-05 07:05:28 [INFO]	[TRAIN] epoch: 3102, iter: 244980/250000, loss: 0.1027, lr: 0.000297, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6281 samples/sec | ETA 00:47:14
2023-02-05 07:05:34 [INFO]	[TRAIN] epoch: 3102, iter: 244990/250000, loss: 0.1311, lr: 0.000296, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6238 samples/sec | ETA 00:47:09
2023-02-05 07:05:39 [INFO]	[TRAIN] epoch: 3102, iter: 245000/250000, loss: 0.1280, lr: 0.000296, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6274 samples/sec | ETA 00:47:02
2023-02-05 07:05:45 [INFO]	[TRAIN] epoch: 3102, iter: 245010/250000, loss: 0.1190, lr: 0.000295, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6268 samples/sec | ETA 00:46:57
2023-02-05 07:05:51 [INFO]	[TRAIN] epoch: 3102, iter: 245020/250000, loss: 0.1340, lr: 0.000295, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6057 samples/sec | ETA 00:46:57
2023-02-05 07:05:56 [INFO]	[TRAIN] epoch: 3102, iter: 245030/250000, loss: 0.1296, lr: 0.000294, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6165 samples/sec | ETA 00:46:48
2023-02-05 07:06:02 [INFO]	[TRAIN] epoch: 3102, iter: 245040/250000, loss: 0.1285, lr: 0.000294, batch_cost: 0.5852, reader_cost: 0.02089, ips: 10.2524 samples/sec | ETA 00:48:22
2023-02-05 07:06:08 [INFO]	[TRAIN] epoch: 3102, iter: 245050/250000, loss: 0.1113, lr: 0.000293, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6070 samples/sec | ETA 00:46:40
2023-02-05 07:06:13 [INFO]	[TRAIN] epoch: 3103, iter: 245060/250000, loss: 0.1374, lr: 0.000293, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6184 samples/sec | ETA 00:46:31
2023-02-05 07:06:19 [INFO]	[TRAIN] epoch: 3103, iter: 245070/250000, loss: 0.1251, lr: 0.000292, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6091 samples/sec | ETA 00:46:28
2023-02-05 07:06:25 [INFO]	[TRAIN] epoch: 3103, iter: 245080/250000, loss: 0.1203, lr: 0.000292, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6084 samples/sec | ETA 00:46:22
2023-02-05 07:06:30 [INFO]	[TRAIN] epoch: 3103, iter: 245090/250000, loss: 0.1420, lr: 0.000291, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6084 samples/sec | ETA 00:46:17
2023-02-05 07:06:36 [INFO]	[TRAIN] epoch: 3103, iter: 245100/250000, loss: 0.1136, lr: 0.000290, batch_cost: 0.5654, reader_cost: 0.00012, ips: 10.6118 samples/sec | ETA 00:46:10
2023-02-05 07:06:42 [INFO]	[TRAIN] epoch: 3103, iter: 245110/250000, loss: 0.1254, lr: 0.000290, batch_cost: 0.5957, reader_cost: 0.03047, ips: 10.0730 samples/sec | ETA 00:48:32
2023-02-05 07:06:48 [INFO]	[TRAIN] epoch: 3103, iter: 245120/250000, loss: 0.1193, lr: 0.000289, batch_cost: 0.5649, reader_cost: 0.00010, ips: 10.6222 samples/sec | ETA 00:45:56
2023-02-05 07:06:53 [INFO]	[TRAIN] epoch: 3103, iter: 245130/250000, loss: 0.1515, lr: 0.000289, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6266 samples/sec | ETA 00:45:49
2023-02-05 07:06:59 [INFO]	[TRAIN] epoch: 3104, iter: 245140/250000, loss: 0.1412, lr: 0.000288, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6246 samples/sec | ETA 00:45:44
2023-02-05 07:07:05 [INFO]	[TRAIN] epoch: 3104, iter: 245150/250000, loss: 0.1285, lr: 0.000288, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6324 samples/sec | ETA 00:45:36
2023-02-05 07:07:10 [INFO]	[TRAIN] epoch: 3104, iter: 245160/250000, loss: 0.1100, lr: 0.000287, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5997 samples/sec | ETA 00:45:39
2023-02-05 07:07:16 [INFO]	[TRAIN] epoch: 3104, iter: 245170/250000, loss: 0.1307, lr: 0.000287, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6058 samples/sec | ETA 00:45:32
2023-02-05 07:07:21 [INFO]	[TRAIN] epoch: 3104, iter: 245180/250000, loss: 0.1131, lr: 0.000286, batch_cost: 0.5651, reader_cost: 0.00008, ips: 10.6171 samples/sec | ETA 00:45:23
2023-02-05 07:07:27 [INFO]	[TRAIN] epoch: 3104, iter: 245190/250000, loss: 0.1113, lr: 0.000286, batch_cost: 0.5929, reader_cost: 0.02754, ips: 10.1196 samples/sec | ETA 00:47:31
2023-02-05 07:07:33 [INFO]	[TRAIN] epoch: 3104, iter: 245200/250000, loss: 0.1369, lr: 0.000285, batch_cost: 0.5656, reader_cost: 0.00016, ips: 10.6087 samples/sec | ETA 00:45:14
2023-02-05 07:07:39 [INFO]	[TRAIN] epoch: 3104, iter: 245210/250000, loss: 0.1174, lr: 0.000285, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6328 samples/sec | ETA 00:45:02
2023-02-05 07:07:44 [INFO]	[TRAIN] epoch: 3105, iter: 245220/250000, loss: 0.1314, lr: 0.000284, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6261 samples/sec | ETA 00:44:59
2023-02-05 07:07:50 [INFO]	[TRAIN] epoch: 3105, iter: 245230/250000, loss: 0.1388, lr: 0.000284, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6228 samples/sec | ETA 00:44:54
2023-02-05 07:07:56 [INFO]	[TRAIN] epoch: 3105, iter: 245240/250000, loss: 0.1363, lr: 0.000283, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6289 samples/sec | ETA 00:44:47
2023-02-05 07:08:01 [INFO]	[TRAIN] epoch: 3105, iter: 245250/250000, loss: 0.1247, lr: 0.000282, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6305 samples/sec | ETA 00:44:40
2023-02-05 07:08:07 [INFO]	[TRAIN] epoch: 3105, iter: 245260/250000, loss: 0.1468, lr: 0.000282, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6257 samples/sec | ETA 00:44:36
2023-02-05 07:08:13 [INFO]	[TRAIN] epoch: 3105, iter: 245270/250000, loss: 0.1063, lr: 0.000281, batch_cost: 0.5935, reader_cost: 0.02852, ips: 10.1101 samples/sec | ETA 00:46:47
2023-02-05 07:08:19 [INFO]	[TRAIN] epoch: 3105, iter: 245280/250000, loss: 0.1090, lr: 0.000281, batch_cost: 0.5642, reader_cost: 0.00011, ips: 10.6336 samples/sec | ETA 00:44:23
2023-02-05 07:08:24 [INFO]	[TRAIN] epoch: 3105, iter: 245290/250000, loss: 0.1053, lr: 0.000280, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6131 samples/sec | ETA 00:44:22
2023-02-05 07:08:30 [INFO]	[TRAIN] epoch: 3106, iter: 245300/250000, loss: 0.1073, lr: 0.000280, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6243 samples/sec | ETA 00:44:14
2023-02-05 07:08:35 [INFO]	[TRAIN] epoch: 3106, iter: 245310/250000, loss: 0.1264, lr: 0.000279, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6301 samples/sec | ETA 00:44:07
2023-02-05 07:08:41 [INFO]	[TRAIN] epoch: 3106, iter: 245320/250000, loss: 0.1245, lr: 0.000279, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6340 samples/sec | ETA 00:44:00
2023-02-05 07:08:47 [INFO]	[TRAIN] epoch: 3106, iter: 245330/250000, loss: 0.1405, lr: 0.000278, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6267 samples/sec | ETA 00:43:56
2023-02-05 07:08:52 [INFO]	[TRAIN] epoch: 3106, iter: 245340/250000, loss: 0.1034, lr: 0.000278, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6054 samples/sec | ETA 00:43:56
2023-02-05 07:08:58 [INFO]	[TRAIN] epoch: 3106, iter: 245350/250000, loss: 0.1227, lr: 0.000277, batch_cost: 0.6004, reader_cost: 0.03514, ips: 9.9934 samples/sec | ETA 00:46:31
2023-02-05 07:09:04 [INFO]	[TRAIN] epoch: 3106, iter: 245360/250000, loss: 0.1131, lr: 0.000277, batch_cost: 0.5658, reader_cost: 0.00013, ips: 10.6045 samples/sec | ETA 00:43:45
2023-02-05 07:09:10 [INFO]	[TRAIN] epoch: 3106, iter: 245370/250000, loss: 0.1340, lr: 0.000276, batch_cost: 0.5648, reader_cost: 0.00008, ips: 10.6235 samples/sec | ETA 00:43:34
2023-02-05 07:09:15 [INFO]	[TRAIN] epoch: 3107, iter: 245380/250000, loss: 0.1102, lr: 0.000275, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6336 samples/sec | ETA 00:43:26
2023-02-05 07:09:21 [INFO]	[TRAIN] epoch: 3107, iter: 245390/250000, loss: 0.1754, lr: 0.000275, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6309 samples/sec | ETA 00:43:21
2023-02-05 07:09:27 [INFO]	[TRAIN] epoch: 3107, iter: 245400/250000, loss: 0.1151, lr: 0.000274, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6309 samples/sec | ETA 00:43:16
2023-02-05 07:09:32 [INFO]	[TRAIN] epoch: 3107, iter: 245410/250000, loss: 0.1348, lr: 0.000274, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6216 samples/sec | ETA 00:43:12
2023-02-05 07:09:38 [INFO]	[TRAIN] epoch: 3107, iter: 245420/250000, loss: 0.1358, lr: 0.000273, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6045 samples/sec | ETA 00:43:11
2023-02-05 07:09:44 [INFO]	[TRAIN] epoch: 3107, iter: 245430/250000, loss: 0.1358, lr: 0.000273, batch_cost: 0.5882, reader_cost: 0.02357, ips: 10.2010 samples/sec | ETA 00:44:47
2023-02-05 07:09:50 [INFO]	[TRAIN] epoch: 3107, iter: 245440/250000, loss: 0.1340, lr: 0.000272, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6109 samples/sec | ETA 00:42:58
2023-02-05 07:09:55 [INFO]	[TRAIN] epoch: 3107, iter: 245450/250000, loss: 0.1454, lr: 0.000272, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6082 samples/sec | ETA 00:42:53
2023-02-05 07:10:01 [INFO]	[TRAIN] epoch: 3108, iter: 245460/250000, loss: 0.1314, lr: 0.000271, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6169 samples/sec | ETA 00:42:45
2023-02-05 07:10:06 [INFO]	[TRAIN] epoch: 3108, iter: 245470/250000, loss: 0.1151, lr: 0.000271, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6131 samples/sec | ETA 00:42:40
2023-02-05 07:10:12 [INFO]	[TRAIN] epoch: 3108, iter: 245480/250000, loss: 0.1113, lr: 0.000270, batch_cost: 0.5661, reader_cost: 0.00017, ips: 10.5983 samples/sec | ETA 00:42:38
2023-02-05 07:10:18 [INFO]	[TRAIN] epoch: 3108, iter: 245490/250000, loss: 0.1152, lr: 0.000270, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6084 samples/sec | ETA 00:42:30
2023-02-05 07:10:23 [INFO]	[TRAIN] epoch: 3108, iter: 245500/250000, loss: 0.1090, lr: 0.000269, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6120 samples/sec | ETA 00:42:24
2023-02-05 07:10:29 [INFO]	[TRAIN] epoch: 3108, iter: 245510/250000, loss: 0.1160, lr: 0.000269, batch_cost: 0.5930, reader_cost: 0.02777, ips: 10.1177 samples/sec | ETA 00:44:22
2023-02-05 07:10:35 [INFO]	[TRAIN] epoch: 3108, iter: 245520/250000, loss: 0.1171, lr: 0.000268, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6269 samples/sec | ETA 00:42:09
2023-02-05 07:10:41 [INFO]	[TRAIN] epoch: 3108, iter: 245530/250000, loss: 0.1052, lr: 0.000267, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6077 samples/sec | ETA 00:42:08
2023-02-05 07:10:46 [INFO]	[TRAIN] epoch: 3109, iter: 245540/250000, loss: 0.1423, lr: 0.000267, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6109 samples/sec | ETA 00:42:01
2023-02-05 07:10:52 [INFO]	[TRAIN] epoch: 3109, iter: 245550/250000, loss: 0.1287, lr: 0.000266, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6126 samples/sec | ETA 00:41:55
2023-02-05 07:10:58 [INFO]	[TRAIN] epoch: 3109, iter: 245560/250000, loss: 0.1127, lr: 0.000266, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6060 samples/sec | ETA 00:41:51
2023-02-05 07:11:03 [INFO]	[TRAIN] epoch: 3109, iter: 245570/250000, loss: 0.1412, lr: 0.000265, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6049 samples/sec | ETA 00:41:46
2023-02-05 07:11:09 [INFO]	[TRAIN] epoch: 3109, iter: 245580/250000, loss: 0.1103, lr: 0.000265, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6131 samples/sec | ETA 00:41:38
2023-02-05 07:11:15 [INFO]	[TRAIN] epoch: 3109, iter: 245590/250000, loss: 0.1446, lr: 0.000264, batch_cost: 0.5970, reader_cost: 0.03229, ips: 10.0496 samples/sec | ETA 00:43:52
2023-02-05 07:11:21 [INFO]	[TRAIN] epoch: 3109, iter: 245600/250000, loss: 0.1204, lr: 0.000264, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6251 samples/sec | ETA 00:41:24
2023-02-05 07:11:26 [INFO]	[TRAIN] epoch: 3109, iter: 245610/250000, loss: 0.1204, lr: 0.000263, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6150 samples/sec | ETA 00:41:21
2023-02-05 07:11:32 [INFO]	[TRAIN] epoch: 3110, iter: 245620/250000, loss: 0.1134, lr: 0.000263, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6368 samples/sec | ETA 00:41:10
2023-02-05 07:11:38 [INFO]	[TRAIN] epoch: 3110, iter: 245630/250000, loss: 0.1300, lr: 0.000262, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6237 samples/sec | ETA 00:41:08
2023-02-05 07:11:43 [INFO]	[TRAIN] epoch: 3110, iter: 245640/250000, loss: 0.1285, lr: 0.000262, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6177 samples/sec | ETA 00:41:03
2023-02-05 07:11:49 [INFO]	[TRAIN] epoch: 3110, iter: 245650/250000, loss: 0.1061, lr: 0.000261, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5982 samples/sec | ETA 00:41:02
2023-02-05 07:11:54 [INFO]	[TRAIN] epoch: 3110, iter: 245660/250000, loss: 0.1381, lr: 0.000260, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6121 samples/sec | ETA 00:40:53
2023-02-05 07:12:00 [INFO]	[TRAIN] epoch: 3110, iter: 245670/250000, loss: 0.1547, lr: 0.000260, batch_cost: 0.5955, reader_cost: 0.03100, ips: 10.0757 samples/sec | ETA 00:42:58
2023-02-05 07:12:06 [INFO]	[TRAIN] epoch: 3110, iter: 245680/250000, loss: 0.1092, lr: 0.000259, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6296 samples/sec | ETA 00:40:38
2023-02-05 07:12:12 [INFO]	[TRAIN] epoch: 3110, iter: 245690/250000, loss: 0.1167, lr: 0.000259, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6328 samples/sec | ETA 00:40:32
2023-02-05 07:12:17 [INFO]	[TRAIN] epoch: 3111, iter: 245700/250000, loss: 0.1225, lr: 0.000258, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6305 samples/sec | ETA 00:40:26
2023-02-05 07:12:23 [INFO]	[TRAIN] epoch: 3111, iter: 245710/250000, loss: 0.1173, lr: 0.000258, batch_cost: 0.5647, reader_cost: 0.00008, ips: 10.6256 samples/sec | ETA 00:40:22
2023-02-05 07:12:29 [INFO]	[TRAIN] epoch: 3111, iter: 245720/250000, loss: 0.1535, lr: 0.000257, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6289 samples/sec | ETA 00:40:16
2023-02-05 07:12:34 [INFO]	[TRAIN] epoch: 3111, iter: 245730/250000, loss: 0.1133, lr: 0.000257, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6285 samples/sec | ETA 00:40:10
2023-02-05 07:12:40 [INFO]	[TRAIN] epoch: 3111, iter: 245740/250000, loss: 0.1066, lr: 0.000256, batch_cost: 0.5648, reader_cost: 0.00008, ips: 10.6228 samples/sec | ETA 00:40:06
2023-02-05 07:12:46 [INFO]	[TRAIN] epoch: 3111, iter: 245750/250000, loss: 0.1185, lr: 0.000256, batch_cost: 0.5948, reader_cost: 0.02877, ips: 10.0879 samples/sec | ETA 00:42:07
2023-02-05 07:12:52 [INFO]	[TRAIN] epoch: 3111, iter: 245760/250000, loss: 0.1195, lr: 0.000255, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5955 samples/sec | ETA 00:40:01
2023-02-05 07:12:57 [INFO]	[TRAIN] epoch: 3112, iter: 245770/250000, loss: 0.1054, lr: 0.000254, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6116 samples/sec | ETA 00:39:51
2023-02-05 07:13:03 [INFO]	[TRAIN] epoch: 3112, iter: 245780/250000, loss: 0.1214, lr: 0.000254, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6161 samples/sec | ETA 00:39:45
2023-02-05 07:13:09 [INFO]	[TRAIN] epoch: 3112, iter: 245790/250000, loss: 0.1350, lr: 0.000253, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6017 samples/sec | ETA 00:39:42
2023-02-05 07:13:14 [INFO]	[TRAIN] epoch: 3112, iter: 245800/250000, loss: 0.1227, lr: 0.000253, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6018 samples/sec | ETA 00:39:36
2023-02-05 07:13:20 [INFO]	[TRAIN] epoch: 3112, iter: 245810/250000, loss: 0.1527, lr: 0.000252, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6114 samples/sec | ETA 00:39:29
2023-02-05 07:13:26 [INFO]	[TRAIN] epoch: 3112, iter: 245820/250000, loss: 0.1188, lr: 0.000252, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6100 samples/sec | ETA 00:39:23
2023-02-05 07:13:31 [INFO]	[TRAIN] epoch: 3112, iter: 245830/250000, loss: 0.1291, lr: 0.000251, batch_cost: 0.5984, reader_cost: 0.03289, ips: 10.0271 samples/sec | ETA 00:41:35
2023-02-05 07:13:37 [INFO]	[TRAIN] epoch: 3112, iter: 245840/250000, loss: 0.1134, lr: 0.000251, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6343 samples/sec | ETA 00:39:07
2023-02-05 07:13:43 [INFO]	[TRAIN] epoch: 3113, iter: 245850/250000, loss: 0.1111, lr: 0.000250, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6312 samples/sec | ETA 00:39:02
2023-02-05 07:13:48 [INFO]	[TRAIN] epoch: 3113, iter: 245860/250000, loss: 0.1166, lr: 0.000250, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6004 samples/sec | ETA 00:39:03
2023-02-05 07:13:54 [INFO]	[TRAIN] epoch: 3113, iter: 245870/250000, loss: 0.1097, lr: 0.000249, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6101 samples/sec | ETA 00:38:55
2023-02-05 07:14:00 [INFO]	[TRAIN] epoch: 3113, iter: 245880/250000, loss: 0.1181, lr: 0.000249, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6098 samples/sec | ETA 00:38:49
2023-02-05 07:14:05 [INFO]	[TRAIN] epoch: 3113, iter: 245890/250000, loss: 0.1345, lr: 0.000248, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6025 samples/sec | ETA 00:38:45
2023-02-05 07:14:11 [INFO]	[TRAIN] epoch: 3113, iter: 245900/250000, loss: 0.1081, lr: 0.000247, batch_cost: 0.5890, reader_cost: 0.02376, ips: 10.1860 samples/sec | ETA 00:40:15
2023-02-05 07:14:17 [INFO]	[TRAIN] epoch: 3113, iter: 245910/250000, loss: 0.1099, lr: 0.000247, batch_cost: 0.5658, reader_cost: 0.00022, ips: 10.6052 samples/sec | ETA 00:38:33
2023-02-05 07:14:23 [INFO]	[TRAIN] epoch: 3113, iter: 245920/250000, loss: 0.1250, lr: 0.000246, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6240 samples/sec | ETA 00:38:24
2023-02-05 07:14:28 [INFO]	[TRAIN] epoch: 3114, iter: 245930/250000, loss: 0.1564, lr: 0.000246, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6243 samples/sec | ETA 00:38:18
2023-02-05 07:14:34 [INFO]	[TRAIN] epoch: 3114, iter: 245940/250000, loss: 0.1279, lr: 0.000245, batch_cost: 0.5641, reader_cost: 0.00008, ips: 10.6357 samples/sec | ETA 00:38:10
2023-02-05 07:14:40 [INFO]	[TRAIN] epoch: 3114, iter: 245950/250000, loss: 0.1323, lr: 0.000245, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6298 samples/sec | ETA 00:38:06
2023-02-05 07:14:45 [INFO]	[TRAIN] epoch: 3114, iter: 245960/250000, loss: 0.1129, lr: 0.000244, batch_cost: 0.5649, reader_cost: 0.00008, ips: 10.6222 samples/sec | ETA 00:38:02
2023-02-05 07:14:51 [INFO]	[TRAIN] epoch: 3114, iter: 245970/250000, loss: 0.1100, lr: 0.000244, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6219 samples/sec | ETA 00:37:56
2023-02-05 07:14:57 [INFO]	[TRAIN] epoch: 3114, iter: 245980/250000, loss: 0.1139, lr: 0.000243, batch_cost: 0.5927, reader_cost: 0.02695, ips: 10.1229 samples/sec | ETA 00:39:42
2023-02-05 07:15:02 [INFO]	[TRAIN] epoch: 3114, iter: 245990/250000, loss: 0.1302, lr: 0.000243, batch_cost: 0.5648, reader_cost: 0.00017, ips: 10.6240 samples/sec | ETA 00:37:44
2023-02-05 07:15:08 [INFO]	[TRAIN] epoch: 3114, iter: 246000/250000, loss: 0.1299, lr: 0.000242, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6372 samples/sec | ETA 00:37:36
2023-02-05 07:15:08 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1252 - reader cost: 0.0228 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1499 - reader cost: 0.0114 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1569 - reader cost: 0.0076 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1571 - reader cost: 0.0058 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1584 - reader cost: 0.0046 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1601 - reader cost: 0.0039 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1601 - reader cost: 0.0033 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1606 - reader cost: 0.0029 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1617 - reader cost: 0.002610/36 [=======>......................] - ETA: 4s - batch_cost: 0.1615 - reader cost: 0.002311/36 [========>.....................] - ETA: 4s - batch_cost: 0.1622 - reader cost: 0.002112/36 [=========>....................] - ETA: 3s - batch_cost: 0.1618 - reader cost: 0.002013/36 [=========>....................] - ETA: 3s - batch_cost: 0.1623 - reader cost: 0.001814/36 [==========>...................] - ETA: 3s - batch_cost: 0.1627 - reader cost: 0.001715/36 [===========>..................] - ETA: 3s - batch_cost: 0.1628 - reader cost: 0.001616/36 [============>.................] - ETA: 3s - batch_cost: 0.1637 - reader cost: 0.001517/36 [=============>................] - ETA: 3s - batch_cost: 0.1641 - reader cost: 0.001418/36 [==============>...............] - ETA: 2s - batch_cost: 0.1641 - reader cost: 0.001319/36 [==============>...............] - ETA: 2s - batch_cost: 0.1640 - reader cost: 0.001320/36 [===============>..............] - ETA: 2s - batch_cost: 0.1639 - reader cost: 0.001221/36 [================>.............] - ETA: 2s - batch_cost: 0.1641 - reader cost: 0.001222/36 [=================>............] - ETA: 2s - batch_cost: 0.1643 - reader cost: 0.001123/36 [==================>...........] - ETA: 2s - batch_cost: 0.1651 - reader cost: 0.001124/36 [===================>..........] - ETA: 1s - batch_cost: 0.1651 - reader cost: 0.001025/36 [===================>..........] - ETA: 1s - batch_cost: 0.1653 - reader cost: 9.8500e-0426/36 [====================>.........] - ETA: 1s - batch_cost: 0.1654 - reader cost: 9.4982e-0427/36 [=====================>........] - ETA: 1s - batch_cost: 0.1656 - reader cost: 9.1725e-0428/36 [======================>.......] - ETA: 1s - batch_cost: 0.1659 - reader cost: 8.8699e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1660 - reader cost: 8.5896e-0430/36 [========================>.....] - ETA: 0s - batch_cost: 0.1660 - reader cost: 8.3268e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1660 - reader cost: 8.0805e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1659 - reader cost: 7.8496e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1656 - reader cost: 7.6342e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1654 - reader cost: 7.4339e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1654 - reader cost: 7.2402e-0436/36 [==============================] - 6s 166ms/step - batch_cost: 0.1655 - reader cost: 7.0568e-04
2023-02-05 07:15:14 [INFO]	[EVAL] #Images: 36 mIoU: 0.8692 Acc: 0.9866 Kappa: 0.9516 Dice: 0.9268
2023-02-05 07:15:14 [INFO]	[EVAL] Class IoU: 
[0.9861 0.9175 0.8935 0.7207 0.722  0.9728 0.8721]
2023-02-05 07:15:14 [INFO]	[EVAL] Class Precision: 
[0.9928 0.9685 0.9449 0.837  0.8683 0.9835 0.9096]
2023-02-05 07:15:14 [INFO]	[EVAL] Class Recall: 
[0.9932 0.9457 0.9426 0.8384 0.8107 0.9889 0.9548]
2023-02-05 07:15:16 [INFO]	[EVAL] The model with the best validation mIoU (0.8692) was saved at iter 246000.
2023-02-05 07:15:22 [INFO]	[TRAIN] epoch: 3115, iter: 246010/250000, loss: 0.1197, lr: 0.000241, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6069 samples/sec | ETA 00:37:37
2023-02-05 07:15:27 [INFO]	[TRAIN] epoch: 3115, iter: 246020/250000, loss: 0.1070, lr: 0.000241, batch_cost: 0.5642, reader_cost: 0.00008, ips: 10.6340 samples/sec | ETA 00:37:25
2023-02-05 07:15:33 [INFO]	[TRAIN] epoch: 3115, iter: 246030/250000, loss: 0.1234, lr: 0.000240, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6304 samples/sec | ETA 00:37:20
2023-02-05 07:15:39 [INFO]	[TRAIN] epoch: 3115, iter: 246040/250000, loss: 0.1126, lr: 0.000240, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6298 samples/sec | ETA 00:37:15
2023-02-05 07:15:44 [INFO]	[TRAIN] epoch: 3115, iter: 246050/250000, loss: 0.0911, lr: 0.000239, batch_cost: 0.5639, reader_cost: 0.00010, ips: 10.6393 samples/sec | ETA 00:37:07
2023-02-05 07:15:50 [INFO]	[TRAIN] epoch: 3115, iter: 246060/250000, loss: 0.1289, lr: 0.000239, batch_cost: 0.6005, reader_cost: 0.03652, ips: 9.9909 samples/sec | ETA 00:39:26
2023-02-05 07:15:56 [INFO]	[TRAIN] epoch: 3115, iter: 246070/250000, loss: 0.1490, lr: 0.000238, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6092 samples/sec | ETA 00:37:02
2023-02-05 07:16:01 [INFO]	[TRAIN] epoch: 3115, iter: 246080/250000, loss: 0.1132, lr: 0.000238, batch_cost: 0.5637, reader_cost: 0.00009, ips: 10.6431 samples/sec | ETA 00:36:49
2023-02-05 07:16:07 [INFO]	[TRAIN] epoch: 3116, iter: 246090/250000, loss: 0.1251, lr: 0.000237, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6405 samples/sec | ETA 00:36:44
2023-02-05 07:16:13 [INFO]	[TRAIN] epoch: 3116, iter: 246100/250000, loss: 0.1173, lr: 0.000237, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6404 samples/sec | ETA 00:36:39
2023-02-05 07:16:18 [INFO]	[TRAIN] epoch: 3116, iter: 246110/250000, loss: 0.1299, lr: 0.000236, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6317 samples/sec | ETA 00:36:35
2023-02-05 07:16:24 [INFO]	[TRAIN] epoch: 3116, iter: 246120/250000, loss: 0.1116, lr: 0.000235, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6267 samples/sec | ETA 00:36:30
2023-02-05 07:16:30 [INFO]	[TRAIN] epoch: 3116, iter: 246130/250000, loss: 0.1250, lr: 0.000235, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6349 samples/sec | ETA 00:36:23
2023-02-05 07:16:36 [INFO]	[TRAIN] epoch: 3116, iter: 246140/250000, loss: 0.1264, lr: 0.000234, batch_cost: 0.5906, reader_cost: 0.02610, ips: 10.1592 samples/sec | ETA 00:37:59
2023-02-05 07:16:41 [INFO]	[TRAIN] epoch: 3116, iter: 246150/250000, loss: 0.1279, lr: 0.000234, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6320 samples/sec | ETA 00:36:12
2023-02-05 07:16:47 [INFO]	[TRAIN] epoch: 3116, iter: 246160/250000, loss: 0.1478, lr: 0.000233, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6327 samples/sec | ETA 00:36:06
2023-02-05 07:16:52 [INFO]	[TRAIN] epoch: 3117, iter: 246170/250000, loss: 0.1152, lr: 0.000233, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6312 samples/sec | ETA 00:36:01
2023-02-05 07:16:58 [INFO]	[TRAIN] epoch: 3117, iter: 246180/250000, loss: 0.1322, lr: 0.000232, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6334 samples/sec | ETA 00:35:55
2023-02-05 07:17:04 [INFO]	[TRAIN] epoch: 3117, iter: 246190/250000, loss: 0.1214, lr: 0.000232, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6322 samples/sec | ETA 00:35:50
2023-02-05 07:17:09 [INFO]	[TRAIN] epoch: 3117, iter: 246200/250000, loss: 0.1374, lr: 0.000231, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6323 samples/sec | ETA 00:35:44
2023-02-05 07:17:15 [INFO]	[TRAIN] epoch: 3117, iter: 246210/250000, loss: 0.1223, lr: 0.000231, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6273 samples/sec | ETA 00:35:39
2023-02-05 07:17:21 [INFO]	[TRAIN] epoch: 3117, iter: 246220/250000, loss: 0.1492, lr: 0.000230, batch_cost: 0.5938, reader_cost: 0.02866, ips: 10.1044 samples/sec | ETA 00:37:24
2023-02-05 07:17:27 [INFO]	[TRAIN] epoch: 3117, iter: 246230/250000, loss: 0.1111, lr: 0.000229, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6229 samples/sec | ETA 00:35:29
2023-02-05 07:17:32 [INFO]	[TRAIN] epoch: 3117, iter: 246240/250000, loss: 0.1244, lr: 0.000229, batch_cost: 0.5644, reader_cost: 0.00011, ips: 10.6313 samples/sec | ETA 00:35:22
2023-02-05 07:17:38 [INFO]	[TRAIN] epoch: 3118, iter: 246250/250000, loss: 0.1055, lr: 0.000228, batch_cost: 0.5642, reader_cost: 0.00011, ips: 10.6338 samples/sec | ETA 00:35:15
2023-02-05 07:17:44 [INFO]	[TRAIN] epoch: 3118, iter: 246260/250000, loss: 0.1116, lr: 0.000228, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6295 samples/sec | ETA 00:35:11
2023-02-05 07:17:49 [INFO]	[TRAIN] epoch: 3118, iter: 246270/250000, loss: 0.1017, lr: 0.000227, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6331 samples/sec | ETA 00:35:04
2023-02-05 07:17:55 [INFO]	[TRAIN] epoch: 3118, iter: 246280/250000, loss: 0.1297, lr: 0.000227, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5951 samples/sec | ETA 00:35:06
2023-02-05 07:18:01 [INFO]	[TRAIN] epoch: 3118, iter: 246290/250000, loss: 0.1212, lr: 0.000226, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6075 samples/sec | ETA 00:34:58
2023-02-05 07:18:06 [INFO]	[TRAIN] epoch: 3118, iter: 246300/250000, loss: 0.1256, lr: 0.000226, batch_cost: 0.5926, reader_cost: 0.02729, ips: 10.1252 samples/sec | ETA 00:36:32
2023-02-05 07:18:12 [INFO]	[TRAIN] epoch: 3118, iter: 246310/250000, loss: 0.1169, lr: 0.000225, batch_cost: 0.5639, reader_cost: 0.00009, ips: 10.6398 samples/sec | ETA 00:34:40
2023-02-05 07:18:18 [INFO]	[TRAIN] epoch: 3118, iter: 246320/250000, loss: 0.1310, lr: 0.000225, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6288 samples/sec | ETA 00:34:37
2023-02-05 07:18:23 [INFO]	[TRAIN] epoch: 3119, iter: 246330/250000, loss: 0.1363, lr: 0.000224, batch_cost: 0.5658, reader_cost: 0.00008, ips: 10.6036 samples/sec | ETA 00:34:36
2023-02-05 07:18:29 [INFO]	[TRAIN] epoch: 3119, iter: 246340/250000, loss: 0.1582, lr: 0.000223, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6094 samples/sec | ETA 00:34:29
2023-02-05 07:18:35 [INFO]	[TRAIN] epoch: 3119, iter: 246350/250000, loss: 0.1479, lr: 0.000223, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6117 samples/sec | ETA 00:34:23
2023-02-05 07:18:40 [INFO]	[TRAIN] epoch: 3119, iter: 246360/250000, loss: 0.1326, lr: 0.000222, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6088 samples/sec | ETA 00:34:18
2023-02-05 07:18:46 [INFO]	[TRAIN] epoch: 3119, iter: 246370/250000, loss: 0.1141, lr: 0.000222, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6016 samples/sec | ETA 00:34:14
2023-02-05 07:18:52 [INFO]	[TRAIN] epoch: 3119, iter: 246380/250000, loss: 0.1152, lr: 0.000221, batch_cost: 0.6000, reader_cost: 0.03523, ips: 10.0002 samples/sec | ETA 00:36:11
2023-02-05 07:18:58 [INFO]	[TRAIN] epoch: 3119, iter: 246390/250000, loss: 0.1346, lr: 0.000221, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6299 samples/sec | ETA 00:33:57
2023-02-05 07:19:03 [INFO]	[TRAIN] epoch: 3119, iter: 246400/250000, loss: 0.1491, lr: 0.000220, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6221 samples/sec | ETA 00:33:53
2023-02-05 07:19:09 [INFO]	[TRAIN] epoch: 3120, iter: 246410/250000, loss: 0.1153, lr: 0.000220, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6258 samples/sec | ETA 00:33:47
2023-02-05 07:19:15 [INFO]	[TRAIN] epoch: 3120, iter: 246420/250000, loss: 0.1149, lr: 0.000219, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6369 samples/sec | ETA 00:33:39
2023-02-05 07:19:20 [INFO]	[TRAIN] epoch: 3120, iter: 246430/250000, loss: 0.1180, lr: 0.000218, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6226 samples/sec | ETA 00:33:36
2023-02-05 07:19:26 [INFO]	[TRAIN] epoch: 3120, iter: 246440/250000, loss: 0.1086, lr: 0.000218, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6139 samples/sec | ETA 00:33:32
2023-02-05 07:19:32 [INFO]	[TRAIN] epoch: 3120, iter: 246450/250000, loss: 0.1299, lr: 0.000217, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6127 samples/sec | ETA 00:33:27
2023-02-05 07:19:38 [INFO]	[TRAIN] epoch: 3120, iter: 246460/250000, loss: 0.1049, lr: 0.000217, batch_cost: 0.6033, reader_cost: 0.03765, ips: 9.9456 samples/sec | ETA 00:35:35
2023-02-05 07:19:43 [INFO]	[TRAIN] epoch: 3120, iter: 246470/250000, loss: 0.1074, lr: 0.000216, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6146 samples/sec | ETA 00:33:15
2023-02-05 07:19:49 [INFO]	[TRAIN] epoch: 3120, iter: 246480/250000, loss: 0.1181, lr: 0.000216, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6090 samples/sec | ETA 00:33:10
2023-02-05 07:19:55 [INFO]	[TRAIN] epoch: 3121, iter: 246490/250000, loss: 0.1174, lr: 0.000215, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6109 samples/sec | ETA 00:33:04
2023-02-05 07:20:00 [INFO]	[TRAIN] epoch: 3121, iter: 246500/250000, loss: 0.1577, lr: 0.000215, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6041 samples/sec | ETA 00:33:00
2023-02-05 07:20:06 [INFO]	[TRAIN] epoch: 3121, iter: 246510/250000, loss: 0.1303, lr: 0.000214, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6176 samples/sec | ETA 00:32:52
2023-02-05 07:20:12 [INFO]	[TRAIN] epoch: 3121, iter: 246520/250000, loss: 0.1242, lr: 0.000213, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6148 samples/sec | ETA 00:32:47
2023-02-05 07:20:17 [INFO]	[TRAIN] epoch: 3121, iter: 246530/250000, loss: 0.1246, lr: 0.000213, batch_cost: 0.5662, reader_cost: 0.00008, ips: 10.5977 samples/sec | ETA 00:32:44
2023-02-05 07:20:23 [INFO]	[TRAIN] epoch: 3121, iter: 246540/250000, loss: 0.1286, lr: 0.000212, batch_cost: 0.5912, reader_cost: 0.02514, ips: 10.1482 samples/sec | ETA 00:34:05
2023-02-05 07:20:29 [INFO]	[TRAIN] epoch: 3121, iter: 246550/250000, loss: 0.1361, lr: 0.000212, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6049 samples/sec | ETA 00:32:31
2023-02-05 07:20:34 [INFO]	[TRAIN] epoch: 3122, iter: 246560/250000, loss: 0.1323, lr: 0.000211, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6065 samples/sec | ETA 00:32:25
2023-02-05 07:20:40 [INFO]	[TRAIN] epoch: 3122, iter: 246570/250000, loss: 0.1223, lr: 0.000211, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6101 samples/sec | ETA 00:32:19
2023-02-05 07:20:46 [INFO]	[TRAIN] epoch: 3122, iter: 246580/250000, loss: 0.1455, lr: 0.000210, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6077 samples/sec | ETA 00:32:14
2023-02-05 07:20:51 [INFO]	[TRAIN] epoch: 3122, iter: 246590/250000, loss: 0.1233, lr: 0.000210, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5982 samples/sec | ETA 00:32:10
2023-02-05 07:20:57 [INFO]	[TRAIN] epoch: 3122, iter: 246600/250000, loss: 0.1105, lr: 0.000209, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6118 samples/sec | ETA 00:32:02
2023-02-05 07:21:03 [INFO]	[TRAIN] epoch: 3122, iter: 246610/250000, loss: 0.1191, lr: 0.000209, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6125 samples/sec | ETA 00:31:56
2023-02-05 07:21:09 [INFO]	[TRAIN] epoch: 3122, iter: 246620/250000, loss: 0.1248, lr: 0.000208, batch_cost: 0.5944, reader_cost: 0.02986, ips: 10.0950 samples/sec | ETA 00:33:28
2023-02-05 07:21:14 [INFO]	[TRAIN] epoch: 3122, iter: 246630/250000, loss: 0.1294, lr: 0.000207, batch_cost: 0.5644, reader_cost: 0.00010, ips: 10.6304 samples/sec | ETA 00:31:42
2023-02-05 07:21:20 [INFO]	[TRAIN] epoch: 3123, iter: 246640/250000, loss: 0.1318, lr: 0.000207, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6257 samples/sec | ETA 00:31:37
2023-02-05 07:21:26 [INFO]	[TRAIN] epoch: 3123, iter: 246650/250000, loss: 0.1330, lr: 0.000206, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6317 samples/sec | ETA 00:31:30
2023-02-05 07:21:31 [INFO]	[TRAIN] epoch: 3123, iter: 246660/250000, loss: 0.1072, lr: 0.000206, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6341 samples/sec | ETA 00:31:24
2023-02-05 07:21:37 [INFO]	[TRAIN] epoch: 3123, iter: 246670/250000, loss: 0.1141, lr: 0.000205, batch_cost: 0.5647, reader_cost: 0.00010, ips: 10.6243 samples/sec | ETA 00:31:20
2023-02-05 07:21:43 [INFO]	[TRAIN] epoch: 3123, iter: 246680/250000, loss: 0.1273, lr: 0.000205, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6337 samples/sec | ETA 00:31:13
2023-02-05 07:21:48 [INFO]	[TRAIN] epoch: 3123, iter: 246690/250000, loss: 0.1076, lr: 0.000204, batch_cost: 0.5957, reader_cost: 0.03051, ips: 10.0725 samples/sec | ETA 00:32:51
2023-02-05 07:21:54 [INFO]	[TRAIN] epoch: 3123, iter: 246700/250000, loss: 0.1429, lr: 0.000204, batch_cost: 0.5663, reader_cost: 0.00017, ips: 10.5960 samples/sec | ETA 00:31:08
2023-02-05 07:22:00 [INFO]	[TRAIN] epoch: 3123, iter: 246710/250000, loss: 0.1152, lr: 0.000203, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6077 samples/sec | ETA 00:31:00
2023-02-05 07:22:05 [INFO]	[TRAIN] epoch: 3124, iter: 246720/250000, loss: 0.1383, lr: 0.000202, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6073 samples/sec | ETA 00:30:55
2023-02-05 07:22:11 [INFO]	[TRAIN] epoch: 3124, iter: 246730/250000, loss: 0.1103, lr: 0.000202, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6112 samples/sec | ETA 00:30:48
2023-02-05 07:22:17 [INFO]	[TRAIN] epoch: 3124, iter: 246740/250000, loss: 0.1490, lr: 0.000201, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6150 samples/sec | ETA 00:30:42
2023-02-05 07:22:22 [INFO]	[TRAIN] epoch: 3124, iter: 246750/250000, loss: 0.1006, lr: 0.000201, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6160 samples/sec | ETA 00:30:36
2023-02-05 07:22:28 [INFO]	[TRAIN] epoch: 3124, iter: 246760/250000, loss: 0.1249, lr: 0.000200, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6016 samples/sec | ETA 00:30:33
2023-02-05 07:22:34 [INFO]	[TRAIN] epoch: 3124, iter: 246770/250000, loss: 0.1481, lr: 0.000200, batch_cost: 0.5945, reader_cost: 0.02873, ips: 10.0922 samples/sec | ETA 00:32:00
2023-02-05 07:22:40 [INFO]	[TRAIN] epoch: 3124, iter: 246780/250000, loss: 0.1173, lr: 0.000199, batch_cost: 0.5646, reader_cost: 0.00014, ips: 10.6264 samples/sec | ETA 00:30:18
2023-02-05 07:22:45 [INFO]	[TRAIN] epoch: 3124, iter: 246790/250000, loss: 0.1285, lr: 0.000199, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6337 samples/sec | ETA 00:30:11
2023-02-05 07:22:51 [INFO]	[TRAIN] epoch: 3125, iter: 246800/250000, loss: 0.1163, lr: 0.000198, batch_cost: 0.5659, reader_cost: 0.00008, ips: 10.6019 samples/sec | ETA 00:30:10
2023-02-05 07:22:57 [INFO]	[TRAIN] epoch: 3125, iter: 246810/250000, loss: 0.0902, lr: 0.000197, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6063 samples/sec | ETA 00:30:04
2023-02-05 07:23:02 [INFO]	[TRAIN] epoch: 3125, iter: 246820/250000, loss: 0.1215, lr: 0.000197, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6176 samples/sec | ETA 00:29:57
2023-02-05 07:23:08 [INFO]	[TRAIN] epoch: 3125, iter: 246830/250000, loss: 0.1141, lr: 0.000196, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6067 samples/sec | ETA 00:29:53
2023-02-05 07:23:14 [INFO]	[TRAIN] epoch: 3125, iter: 246840/250000, loss: 0.1184, lr: 0.000196, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6032 samples/sec | ETA 00:29:48
2023-02-05 07:23:20 [INFO]	[TRAIN] epoch: 3125, iter: 246850/250000, loss: 0.1647, lr: 0.000195, batch_cost: 0.6003, reader_cost: 0.03573, ips: 9.9953 samples/sec | ETA 00:31:30
2023-02-05 07:23:25 [INFO]	[TRAIN] epoch: 3125, iter: 246860/250000, loss: 0.1247, lr: 0.000195, batch_cost: 0.5652, reader_cost: 0.00014, ips: 10.6164 samples/sec | ETA 00:29:34
2023-02-05 07:23:31 [INFO]	[TRAIN] epoch: 3125, iter: 246870/250000, loss: 0.1140, lr: 0.000194, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6019 samples/sec | ETA 00:29:31
2023-02-05 07:23:37 [INFO]	[TRAIN] epoch: 3126, iter: 246880/250000, loss: 0.1040, lr: 0.000194, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6010 samples/sec | ETA 00:29:25
2023-02-05 07:23:42 [INFO]	[TRAIN] epoch: 3126, iter: 246890/250000, loss: 0.1082, lr: 0.000193, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6013 samples/sec | ETA 00:29:20
2023-02-05 07:23:48 [INFO]	[TRAIN] epoch: 3126, iter: 246900/250000, loss: 0.1196, lr: 0.000192, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6070 samples/sec | ETA 00:29:13
2023-02-05 07:23:54 [INFO]	[TRAIN] epoch: 3126, iter: 246910/250000, loss: 0.1324, lr: 0.000192, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6097 samples/sec | ETA 00:29:07
2023-02-05 07:23:59 [INFO]	[TRAIN] epoch: 3126, iter: 246920/250000, loss: 0.1140, lr: 0.000191, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6041 samples/sec | ETA 00:29:02
2023-02-05 07:24:05 [INFO]	[TRAIN] epoch: 3126, iter: 246930/250000, loss: 0.1183, lr: 0.000191, batch_cost: 0.5940, reader_cost: 0.02674, ips: 10.1004 samples/sec | ETA 00:30:23
2023-02-05 07:24:11 [INFO]	[TRAIN] epoch: 3126, iter: 246940/250000, loss: 0.0916, lr: 0.000190, batch_cost: 0.5651, reader_cost: 0.00010, ips: 10.6169 samples/sec | ETA 00:28:49
2023-02-05 07:24:16 [INFO]	[TRAIN] epoch: 3126, iter: 246950/250000, loss: 0.1209, lr: 0.000190, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6225 samples/sec | ETA 00:28:42
2023-02-05 07:24:22 [INFO]	[TRAIN] epoch: 3127, iter: 246960/250000, loss: 0.1047, lr: 0.000189, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6134 samples/sec | ETA 00:28:38
2023-02-05 07:24:28 [INFO]	[TRAIN] epoch: 3127, iter: 246970/250000, loss: 0.1389, lr: 0.000188, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6079 samples/sec | ETA 00:28:33
2023-02-05 07:24:33 [INFO]	[TRAIN] epoch: 3127, iter: 246980/250000, loss: 0.1184, lr: 0.000188, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6117 samples/sec | ETA 00:28:27
2023-02-05 07:24:39 [INFO]	[TRAIN] epoch: 3127, iter: 246990/250000, loss: 0.1231, lr: 0.000187, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6012 samples/sec | ETA 00:28:23
2023-02-05 07:24:45 [INFO]	[TRAIN] epoch: 3127, iter: 247000/250000, loss: 0.1192, lr: 0.000187, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6107 samples/sec | ETA 00:28:16
2023-02-05 07:24:51 [INFO]	[TRAIN] epoch: 3127, iter: 247010/250000, loss: 0.1274, lr: 0.000186, batch_cost: 0.5960, reader_cost: 0.03005, ips: 10.0665 samples/sec | ETA 00:29:42
2023-02-05 07:24:56 [INFO]	[TRAIN] epoch: 3127, iter: 247020/250000, loss: 0.1003, lr: 0.000186, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6290 samples/sec | ETA 00:28:02
2023-02-05 07:25:02 [INFO]	[TRAIN] epoch: 3127, iter: 247030/250000, loss: 0.1188, lr: 0.000185, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6095 samples/sec | ETA 00:27:59
2023-02-05 07:25:08 [INFO]	[TRAIN] epoch: 3128, iter: 247040/250000, loss: 0.1146, lr: 0.000185, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6085 samples/sec | ETA 00:27:54
2023-02-05 07:25:13 [INFO]	[TRAIN] epoch: 3128, iter: 247050/250000, loss: 0.1493, lr: 0.000184, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6016 samples/sec | ETA 00:27:49
2023-02-05 07:25:19 [INFO]	[TRAIN] epoch: 3128, iter: 247060/250000, loss: 0.1294, lr: 0.000183, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6023 samples/sec | ETA 00:27:43
2023-02-05 07:25:25 [INFO]	[TRAIN] epoch: 3128, iter: 247070/250000, loss: 0.1282, lr: 0.000183, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6145 samples/sec | ETA 00:27:36
2023-02-05 07:25:30 [INFO]	[TRAIN] epoch: 3128, iter: 247080/250000, loss: 0.1344, lr: 0.000182, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6025 samples/sec | ETA 00:27:32
2023-02-05 07:25:36 [INFO]	[TRAIN] epoch: 3128, iter: 247090/250000, loss: 0.0997, lr: 0.000182, batch_cost: 0.6014, reader_cost: 0.03557, ips: 9.9764 samples/sec | ETA 00:29:10
2023-02-05 07:25:42 [INFO]	[TRAIN] epoch: 3128, iter: 247100/250000, loss: 0.1293, lr: 0.000181, batch_cost: 0.5642, reader_cost: 0.00010, ips: 10.6338 samples/sec | ETA 00:27:16
2023-02-05 07:25:48 [INFO]	[TRAIN] epoch: 3128, iter: 247110/250000, loss: 0.1315, lr: 0.000181, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6212 samples/sec | ETA 00:27:12
2023-02-05 07:25:53 [INFO]	[TRAIN] epoch: 3129, iter: 247120/250000, loss: 0.1224, lr: 0.000180, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6173 samples/sec | ETA 00:27:07
2023-02-05 07:25:59 [INFO]	[TRAIN] epoch: 3129, iter: 247130/250000, loss: 0.1418, lr: 0.000180, batch_cost: 0.5659, reader_cost: 0.00010, ips: 10.6031 samples/sec | ETA 00:27:04
2023-02-05 07:26:05 [INFO]	[TRAIN] epoch: 3129, iter: 247140/250000, loss: 0.2138, lr: 0.000179, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6070 samples/sec | ETA 00:26:57
2023-02-05 07:26:10 [INFO]	[TRAIN] epoch: 3129, iter: 247150/250000, loss: 0.1323, lr: 0.000178, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6119 samples/sec | ETA 00:26:51
2023-02-05 07:26:16 [INFO]	[TRAIN] epoch: 3129, iter: 247160/250000, loss: 0.1301, lr: 0.000178, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6092 samples/sec | ETA 00:26:46
2023-02-05 07:26:22 [INFO]	[TRAIN] epoch: 3129, iter: 247170/250000, loss: 0.1337, lr: 0.000177, batch_cost: 0.5933, reader_cost: 0.02820, ips: 10.1126 samples/sec | ETA 00:27:59
2023-02-05 07:26:27 [INFO]	[TRAIN] epoch: 3129, iter: 247180/250000, loss: 0.1163, lr: 0.000177, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6203 samples/sec | ETA 00:26:33
2023-02-05 07:26:33 [INFO]	[TRAIN] epoch: 3129, iter: 247190/250000, loss: 0.1465, lr: 0.000176, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6350 samples/sec | ETA 00:26:25
2023-02-05 07:26:39 [INFO]	[TRAIN] epoch: 3130, iter: 247200/250000, loss: 0.1159, lr: 0.000176, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6341 samples/sec | ETA 00:26:19
2023-02-05 07:26:44 [INFO]	[TRAIN] epoch: 3130, iter: 247210/250000, loss: 0.1153, lr: 0.000175, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6346 samples/sec | ETA 00:26:14
2023-02-05 07:26:50 [INFO]	[TRAIN] epoch: 3130, iter: 247220/250000, loss: 0.0978, lr: 0.000174, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6288 samples/sec | ETA 00:26:09
2023-02-05 07:26:56 [INFO]	[TRAIN] epoch: 3130, iter: 247230/250000, loss: 0.1323, lr: 0.000174, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6325 samples/sec | ETA 00:26:03
2023-02-05 07:27:01 [INFO]	[TRAIN] epoch: 3130, iter: 247240/250000, loss: 0.1076, lr: 0.000173, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6347 samples/sec | ETA 00:25:57
2023-02-05 07:27:07 [INFO]	[TRAIN] epoch: 3130, iter: 247250/250000, loss: 0.1462, lr: 0.000173, batch_cost: 0.5917, reader_cost: 0.02716, ips: 10.1401 samples/sec | ETA 00:27:07
2023-02-05 07:27:13 [INFO]	[TRAIN] epoch: 3130, iter: 247260/250000, loss: 0.1610, lr: 0.000172, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6294 samples/sec | ETA 00:25:46
2023-02-05 07:27:19 [INFO]	[TRAIN] epoch: 3130, iter: 247270/250000, loss: 0.1466, lr: 0.000172, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6387 samples/sec | ETA 00:25:39
2023-02-05 07:27:24 [INFO]	[TRAIN] epoch: 3131, iter: 247280/250000, loss: 0.1272, lr: 0.000171, batch_cost: 0.5659, reader_cost: 0.00008, ips: 10.6021 samples/sec | ETA 00:25:39
2023-02-05 07:27:30 [INFO]	[TRAIN] epoch: 3131, iter: 247290/250000, loss: 0.1013, lr: 0.000170, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6064 samples/sec | ETA 00:25:33
2023-02-05 07:27:35 [INFO]	[TRAIN] epoch: 3131, iter: 247300/250000, loss: 0.1146, lr: 0.000170, batch_cost: 0.5652, reader_cost: 0.00010, ips: 10.6159 samples/sec | ETA 00:25:26
2023-02-05 07:27:41 [INFO]	[TRAIN] epoch: 3131, iter: 247310/250000, loss: 0.1164, lr: 0.000169, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6074 samples/sec | ETA 00:25:21
2023-02-05 07:27:47 [INFO]	[TRAIN] epoch: 3131, iter: 247320/250000, loss: 0.1361, lr: 0.000169, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 00:25:16
2023-02-05 07:27:53 [INFO]	[TRAIN] epoch: 3131, iter: 247330/250000, loss: 0.1075, lr: 0.000168, batch_cost: 0.5896, reader_cost: 0.02514, ips: 10.1761 samples/sec | ETA 00:26:14
2023-02-05 07:27:58 [INFO]	[TRAIN] epoch: 3131, iter: 247340/250000, loss: 0.1604, lr: 0.000168, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6280 samples/sec | ETA 00:25:01
2023-02-05 07:28:04 [INFO]	[TRAIN] epoch: 3132, iter: 247350/250000, loss: 0.1321, lr: 0.000167, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5995 samples/sec | ETA 00:25:00
2023-02-05 07:28:10 [INFO]	[TRAIN] epoch: 3132, iter: 247360/250000, loss: 0.1334, lr: 0.000167, batch_cost: 0.5663, reader_cost: 0.00009, ips: 10.5947 samples/sec | ETA 00:24:55
2023-02-05 07:28:15 [INFO]	[TRAIN] epoch: 3132, iter: 247370/250000, loss: 0.1240, lr: 0.000166, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6077 samples/sec | ETA 00:24:47
2023-02-05 07:28:21 [INFO]	[TRAIN] epoch: 3132, iter: 247380/250000, loss: 0.1007, lr: 0.000165, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6096 samples/sec | ETA 00:24:41
2023-02-05 07:28:27 [INFO]	[TRAIN] epoch: 3132, iter: 247390/250000, loss: 0.1170, lr: 0.000165, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6106 samples/sec | ETA 00:24:35
2023-02-05 07:28:32 [INFO]	[TRAIN] epoch: 3132, iter: 247400/250000, loss: 0.1323, lr: 0.000164, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6111 samples/sec | ETA 00:24:30
2023-02-05 07:28:38 [INFO]	[TRAIN] epoch: 3132, iter: 247410/250000, loss: 0.1128, lr: 0.000164, batch_cost: 0.5907, reader_cost: 0.02467, ips: 10.1567 samples/sec | ETA 00:25:30
2023-02-05 07:28:44 [INFO]	[TRAIN] epoch: 3132, iter: 247420/250000, loss: 0.1150, lr: 0.000163, batch_cost: 0.5651, reader_cost: 0.00008, ips: 10.6177 samples/sec | ETA 00:24:17
2023-02-05 07:28:49 [INFO]	[TRAIN] epoch: 3133, iter: 247430/250000, loss: 0.1015, lr: 0.000163, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6081 samples/sec | ETA 00:24:13
2023-02-05 07:28:55 [INFO]	[TRAIN] epoch: 3133, iter: 247440/250000, loss: 0.1282, lr: 0.000162, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6145 samples/sec | ETA 00:24:07
2023-02-05 07:29:01 [INFO]	[TRAIN] epoch: 3133, iter: 247450/250000, loss: 0.1186, lr: 0.000161, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6086 samples/sec | ETA 00:24:02
2023-02-05 07:29:06 [INFO]	[TRAIN] epoch: 3133, iter: 247460/250000, loss: 0.1161, lr: 0.000161, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6050 samples/sec | ETA 00:23:57
2023-02-05 07:29:12 [INFO]	[TRAIN] epoch: 3133, iter: 247470/250000, loss: 0.1076, lr: 0.000160, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6072 samples/sec | ETA 00:23:51
2023-02-05 07:29:18 [INFO]	[TRAIN] epoch: 3133, iter: 247480/250000, loss: 0.1192, lr: 0.000160, batch_cost: 0.5995, reader_cost: 0.03436, ips: 10.0078 samples/sec | ETA 00:25:10
2023-02-05 07:29:24 [INFO]	[TRAIN] epoch: 3133, iter: 247490/250000, loss: 0.1147, lr: 0.000159, batch_cost: 0.5657, reader_cost: 0.00017, ips: 10.6059 samples/sec | ETA 00:23:39
2023-02-05 07:29:29 [INFO]	[TRAIN] epoch: 3133, iter: 247500/250000, loss: 0.1151, lr: 0.000159, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6027 samples/sec | ETA 00:23:34
2023-02-05 07:29:35 [INFO]	[TRAIN] epoch: 3134, iter: 247510/250000, loss: 0.1353, lr: 0.000158, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6055 samples/sec | ETA 00:23:28
2023-02-05 07:29:41 [INFO]	[TRAIN] epoch: 3134, iter: 247520/250000, loss: 0.1264, lr: 0.000157, batch_cost: 0.5650, reader_cost: 0.00008, ips: 10.6190 samples/sec | ETA 00:23:21
2023-02-05 07:29:46 [INFO]	[TRAIN] epoch: 3134, iter: 247530/250000, loss: 0.1179, lr: 0.000157, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6046 samples/sec | ETA 00:23:17
2023-02-05 07:29:52 [INFO]	[TRAIN] epoch: 3134, iter: 247540/250000, loss: 0.1226, lr: 0.000156, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6036 samples/sec | ETA 00:23:11
2023-02-05 07:29:58 [INFO]	[TRAIN] epoch: 3134, iter: 247550/250000, loss: 0.1091, lr: 0.000156, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6234 samples/sec | ETA 00:23:03
2023-02-05 07:30:04 [INFO]	[TRAIN] epoch: 3134, iter: 247560/250000, loss: 0.1161, lr: 0.000155, batch_cost: 0.5979, reader_cost: 0.03211, ips: 10.0354 samples/sec | ETA 00:24:18
2023-02-05 07:30:09 [INFO]	[TRAIN] epoch: 3134, iter: 247570/250000, loss: 0.1081, lr: 0.000155, batch_cost: 0.5648, reader_cost: 0.00014, ips: 10.6235 samples/sec | ETA 00:22:52
2023-02-05 07:30:15 [INFO]	[TRAIN] epoch: 3134, iter: 247580/250000, loss: 0.1363, lr: 0.000154, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6287 samples/sec | ETA 00:22:46
2023-02-05 07:30:21 [INFO]	[TRAIN] epoch: 3135, iter: 247590/250000, loss: 0.1412, lr: 0.000153, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6101 samples/sec | ETA 00:22:42
2023-02-05 07:30:26 [INFO]	[TRAIN] epoch: 3135, iter: 247600/250000, loss: 0.1417, lr: 0.000153, batch_cost: 0.5652, reader_cost: 0.00008, ips: 10.6151 samples/sec | ETA 00:22:36
2023-02-05 07:30:32 [INFO]	[TRAIN] epoch: 3135, iter: 247610/250000, loss: 0.0918, lr: 0.000152, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6089 samples/sec | ETA 00:22:31
2023-02-05 07:30:38 [INFO]	[TRAIN] epoch: 3135, iter: 247620/250000, loss: 0.1144, lr: 0.000152, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6033 samples/sec | ETA 00:22:26
2023-02-05 07:30:43 [INFO]	[TRAIN] epoch: 3135, iter: 247630/250000, loss: 0.1145, lr: 0.000151, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6148 samples/sec | ETA 00:22:19
2023-02-05 07:30:49 [INFO]	[TRAIN] epoch: 3135, iter: 247640/250000, loss: 0.1344, lr: 0.000151, batch_cost: 0.5957, reader_cost: 0.03003, ips: 10.0714 samples/sec | ETA 00:23:25
2023-02-05 07:30:55 [INFO]	[TRAIN] epoch: 3135, iter: 247650/250000, loss: 0.1108, lr: 0.000150, batch_cost: 0.5650, reader_cost: 0.00014, ips: 10.6189 samples/sec | ETA 00:22:07
2023-02-05 07:31:01 [INFO]	[TRAIN] epoch: 3135, iter: 247660/250000, loss: 0.1126, lr: 0.000149, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6070 samples/sec | ETA 00:22:03
2023-02-05 07:31:06 [INFO]	[TRAIN] epoch: 3136, iter: 247670/250000, loss: 0.1075, lr: 0.000149, batch_cost: 0.5656, reader_cost: 0.00011, ips: 10.6091 samples/sec | ETA 00:21:57
2023-02-05 07:31:12 [INFO]	[TRAIN] epoch: 3136, iter: 247680/250000, loss: 0.1127, lr: 0.000148, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6086 samples/sec | ETA 00:21:52
2023-02-05 07:31:17 [INFO]	[TRAIN] epoch: 3136, iter: 247690/250000, loss: 0.1215, lr: 0.000148, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6089 samples/sec | ETA 00:21:46
2023-02-05 07:31:23 [INFO]	[TRAIN] epoch: 3136, iter: 247700/250000, loss: 0.1283, lr: 0.000147, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6072 samples/sec | ETA 00:21:41
2023-02-05 07:31:29 [INFO]	[TRAIN] epoch: 3136, iter: 247710/250000, loss: 0.1252, lr: 0.000147, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 00:21:35
2023-02-05 07:31:35 [INFO]	[TRAIN] epoch: 3136, iter: 247720/250000, loss: 0.1196, lr: 0.000146, batch_cost: 0.5945, reader_cost: 0.02945, ips: 10.0920 samples/sec | ETA 00:22:35
2023-02-05 07:31:40 [INFO]	[TRAIN] epoch: 3136, iter: 247730/250000, loss: 0.1441, lr: 0.000145, batch_cost: 0.5648, reader_cost: 0.00018, ips: 10.6240 samples/sec | ETA 00:21:22
2023-02-05 07:31:46 [INFO]	[TRAIN] epoch: 3136, iter: 247740/250000, loss: 0.1196, lr: 0.000145, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6314 samples/sec | ETA 00:21:15
2023-02-05 07:31:52 [INFO]	[TRAIN] epoch: 3137, iter: 247750/250000, loss: 0.1297, lr: 0.000144, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6071 samples/sec | ETA 00:21:12
2023-02-05 07:31:57 [INFO]	[TRAIN] epoch: 3137, iter: 247760/250000, loss: 0.1234, lr: 0.000144, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6073 samples/sec | ETA 00:21:07
2023-02-05 07:32:03 [INFO]	[TRAIN] epoch: 3137, iter: 247770/250000, loss: 0.1033, lr: 0.000143, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6101 samples/sec | ETA 00:21:01
2023-02-05 07:32:09 [INFO]	[TRAIN] epoch: 3137, iter: 247780/250000, loss: 0.1432, lr: 0.000142, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5986 samples/sec | ETA 00:20:56
2023-02-05 07:32:14 [INFO]	[TRAIN] epoch: 3137, iter: 247790/250000, loss: 0.1146, lr: 0.000142, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6080 samples/sec | ETA 00:20:49
2023-02-05 07:32:20 [INFO]	[TRAIN] epoch: 3137, iter: 247800/250000, loss: 0.1116, lr: 0.000141, batch_cost: 0.5909, reader_cost: 0.02555, ips: 10.1533 samples/sec | ETA 00:21:40
2023-02-05 07:32:26 [INFO]	[TRAIN] epoch: 3137, iter: 247810/250000, loss: 0.1471, lr: 0.000141, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6055 samples/sec | ETA 00:20:38
2023-02-05 07:32:32 [INFO]	[TRAIN] epoch: 3137, iter: 247820/250000, loss: 0.1208, lr: 0.000140, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6138 samples/sec | ETA 00:20:32
2023-02-05 07:32:37 [INFO]	[TRAIN] epoch: 3138, iter: 247830/250000, loss: 0.0925, lr: 0.000140, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6024 samples/sec | ETA 00:20:28
2023-02-05 07:32:43 [INFO]	[TRAIN] epoch: 3138, iter: 247840/250000, loss: 0.1140, lr: 0.000139, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6044 samples/sec | ETA 00:20:22
2023-02-05 07:32:49 [INFO]	[TRAIN] epoch: 3138, iter: 247850/250000, loss: 0.1117, lr: 0.000138, batch_cost: 0.5656, reader_cost: 0.00011, ips: 10.6088 samples/sec | ETA 00:20:15
2023-02-05 07:32:54 [INFO]	[TRAIN] epoch: 3138, iter: 247860/250000, loss: 0.1301, lr: 0.000138, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6099 samples/sec | ETA 00:20:10
2023-02-05 07:33:00 [INFO]	[TRAIN] epoch: 3138, iter: 247870/250000, loss: 0.1158, lr: 0.000137, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6067 samples/sec | ETA 00:20:04
2023-02-05 07:33:06 [INFO]	[TRAIN] epoch: 3138, iter: 247880/250000, loss: 0.1042, lr: 0.000137, batch_cost: 0.5874, reader_cost: 0.02205, ips: 10.2143 samples/sec | ETA 00:20:45
2023-02-05 07:33:11 [INFO]	[TRAIN] epoch: 3138, iter: 247890/250000, loss: 0.1802, lr: 0.000136, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6207 samples/sec | ETA 00:19:52
2023-02-05 07:33:17 [INFO]	[TRAIN] epoch: 3138, iter: 247900/250000, loss: 0.1173, lr: 0.000136, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6144 samples/sec | ETA 00:19:47
2023-02-05 07:33:23 [INFO]	[TRAIN] epoch: 3139, iter: 247910/250000, loss: 0.1122, lr: 0.000135, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6094 samples/sec | ETA 00:19:41
2023-02-05 07:33:28 [INFO]	[TRAIN] epoch: 3139, iter: 247920/250000, loss: 0.1380, lr: 0.000134, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6148 samples/sec | ETA 00:19:35
2023-02-05 07:33:34 [INFO]	[TRAIN] epoch: 3139, iter: 247930/250000, loss: 0.1083, lr: 0.000134, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6054 samples/sec | ETA 00:19:31
2023-02-05 07:33:40 [INFO]	[TRAIN] epoch: 3139, iter: 247940/250000, loss: 0.1177, lr: 0.000133, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6093 samples/sec | ETA 00:19:25
2023-02-05 07:33:45 [INFO]	[TRAIN] epoch: 3139, iter: 247950/250000, loss: 0.1254, lr: 0.000133, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6122 samples/sec | ETA 00:19:19
2023-02-05 07:33:51 [INFO]	[TRAIN] epoch: 3139, iter: 247960/250000, loss: 0.1026, lr: 0.000132, batch_cost: 0.5883, reader_cost: 0.02327, ips: 10.1989 samples/sec | ETA 00:20:00
2023-02-05 07:33:57 [INFO]	[TRAIN] epoch: 3139, iter: 247970/250000, loss: 0.1064, lr: 0.000131, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6015 samples/sec | ETA 00:19:08
2023-02-05 07:34:02 [INFO]	[TRAIN] epoch: 3139, iter: 247980/250000, loss: 0.1618, lr: 0.000131, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6007 samples/sec | ETA 00:19:03
2023-02-05 07:34:08 [INFO]	[TRAIN] epoch: 3140, iter: 247990/250000, loss: 0.1212, lr: 0.000130, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6110 samples/sec | ETA 00:18:56
2023-02-05 07:34:14 [INFO]	[TRAIN] epoch: 3140, iter: 248000/250000, loss: 0.1093, lr: 0.000130, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6073 samples/sec | ETA 00:18:51
2023-02-05 07:34:14 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1271 - reader cost: 0.0241 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1516 - reader cost: 0.0121 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1582 - reader cost: 0.0081 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1586 - reader cost: 0.0061 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1600 - reader cost: 0.0049 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1618 - reader cost: 0.0041 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1614 - reader cost: 0.0035 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1617 - reader cost: 0.0031 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1626 - reader cost: 0.002710/36 [=======>......................] - ETA: 4s - batch_cost: 0.1627 - reader cost: 0.002511/36 [========>.....................] - ETA: 4s - batch_cost: 0.1634 - reader cost: 0.002312/36 [=========>....................] - ETA: 3s - batch_cost: 0.1631 - reader cost: 0.002113/36 [=========>....................] - ETA: 3s - batch_cost: 0.1636 - reader cost: 0.001914/36 [==========>...................] - ETA: 3s - batch_cost: 0.1639 - reader cost: 0.001815/36 [===========>..................] - ETA: 3s - batch_cost: 0.1639 - reader cost: 0.001716/36 [============>.................] - ETA: 3s - batch_cost: 0.1649 - reader cost: 0.001617/36 [=============>................] - ETA: 3s - batch_cost: 0.1653 - reader cost: 0.001518/36 [==============>...............] - ETA: 2s - batch_cost: 0.1652 - reader cost: 0.001419/36 [==============>...............] - ETA: 2s - batch_cost: 0.1650 - reader cost: 0.001320/36 [===============>..............] - ETA: 2s - batch_cost: 0.1649 - reader cost: 0.001321/36 [================>.............] - ETA: 2s - batch_cost: 0.1651 - reader cost: 0.001222/36 [=================>............] - ETA: 2s - batch_cost: 0.1654 - reader cost: 0.001223/36 [==================>...........] - ETA: 2s - batch_cost: 0.1659 - reader cost: 0.001124/36 [===================>..........] - ETA: 1s - batch_cost: 0.1659 - reader cost: 0.001125/36 [===================>..........] - ETA: 1s - batch_cost: 0.1660 - reader cost: 0.001026/36 [====================>.........] - ETA: 1s - batch_cost: 0.1662 - reader cost: 9.9877e-0427/36 [=====================>........] - ETA: 1s - batch_cost: 0.1664 - reader cost: 9.6446e-0428/36 [======================>.......] - ETA: 1s - batch_cost: 0.1667 - reader cost: 9.3254e-0429/36 [=======================>......] - ETA: 1s - batch_cost: 0.1668 - reader cost: 9.0338e-0430/36 [========================>.....] - ETA: 1s - batch_cost: 0.1667 - reader cost: 8.7617e-0431/36 [========================>.....] - ETA: 0s - batch_cost: 0.1667 - reader cost: 8.5018e-0432/36 [=========================>....] - ETA: 0s - batch_cost: 0.1665 - reader cost: 8.2626e-0433/36 [==========================>...] - ETA: 0s - batch_cost: 0.1663 - reader cost: 8.0320e-0434/36 [===========================>..] - ETA: 0s - batch_cost: 0.1662 - reader cost: 7.8149e-0435/36 [============================>.] - ETA: 0s - batch_cost: 0.1661 - reader cost: 7.6108e-0436/36 [==============================] - 6s 166ms/step - batch_cost: 0.1663 - reader cost: 7.4226e-04
2023-02-05 07:34:20 [INFO]	[EVAL] #Images: 36 mIoU: 0.8670 Acc: 0.9865 Kappa: 0.9512 Dice: 0.9254
2023-02-05 07:34:20 [INFO]	[EVAL] Class IoU: 
[0.986  0.9145 0.893  0.7127 0.7159 0.9728 0.8741]
2023-02-05 07:34:20 [INFO]	[EVAL] Class Precision: 
[0.9929 0.9673 0.9416 0.8295 0.8751 0.984  0.909 ]
2023-02-05 07:34:20 [INFO]	[EVAL] Class Recall: 
[0.993  0.9437 0.9454 0.835  0.7974 0.9884 0.958 ]
2023-02-05 07:34:20 [INFO]	[EVAL] The model with the best validation mIoU (0.8692) was saved at iter 246000.
2023-02-05 07:34:26 [INFO]	[TRAIN] epoch: 3140, iter: 248010/250000, loss: 0.1864, lr: 0.000129, batch_cost: 0.5645, reader_cost: 0.00011, ips: 10.6292 samples/sec | ETA 00:18:43
2023-02-05 07:34:31 [INFO]	[TRAIN] epoch: 3140, iter: 248020/250000, loss: 0.1302, lr: 0.000129, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6243 samples/sec | ETA 00:18:38
2023-02-05 07:34:37 [INFO]	[TRAIN] epoch: 3140, iter: 248030/250000, loss: 0.1226, lr: 0.000128, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6325 samples/sec | ETA 00:18:31
2023-02-05 07:34:43 [INFO]	[TRAIN] epoch: 3140, iter: 248040/250000, loss: 0.1054, lr: 0.000127, batch_cost: 0.5938, reader_cost: 0.02892, ips: 10.1039 samples/sec | ETA 00:19:23
2023-02-05 07:34:49 [INFO]	[TRAIN] epoch: 3140, iter: 248050/250000, loss: 0.1076, lr: 0.000127, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6327 samples/sec | ETA 00:18:20
2023-02-05 07:34:54 [INFO]	[TRAIN] epoch: 3140, iter: 248060/250000, loss: 0.1079, lr: 0.000126, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6062 samples/sec | ETA 00:18:17
2023-02-05 07:35:00 [INFO]	[TRAIN] epoch: 3141, iter: 248070/250000, loss: 0.1361, lr: 0.000126, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6095 samples/sec | ETA 00:18:11
2023-02-05 07:35:06 [INFO]	[TRAIN] epoch: 3141, iter: 248080/250000, loss: 0.1312, lr: 0.000125, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6080 samples/sec | ETA 00:18:05
2023-02-05 07:35:11 [INFO]	[TRAIN] epoch: 3141, iter: 248090/250000, loss: 0.1432, lr: 0.000124, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6127 samples/sec | ETA 00:17:59
2023-02-05 07:35:17 [INFO]	[TRAIN] epoch: 3141, iter: 248100/250000, loss: 0.1159, lr: 0.000124, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6047 samples/sec | ETA 00:17:54
2023-02-05 07:35:23 [INFO]	[TRAIN] epoch: 3141, iter: 248110/250000, loss: 0.1221, lr: 0.000123, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6143 samples/sec | ETA 00:17:48
2023-02-05 07:35:28 [INFO]	[TRAIN] epoch: 3141, iter: 248120/250000, loss: 0.1245, lr: 0.000123, batch_cost: 0.5949, reader_cost: 0.03085, ips: 10.0855 samples/sec | ETA 00:18:38
2023-02-05 07:35:34 [INFO]	[TRAIN] epoch: 3141, iter: 248130/250000, loss: 0.1180, lr: 0.000122, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6017 samples/sec | ETA 00:17:38
2023-02-05 07:35:40 [INFO]	[TRAIN] epoch: 3142, iter: 248140/250000, loss: 0.1114, lr: 0.000122, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6138 samples/sec | ETA 00:17:31
2023-02-05 07:35:45 [INFO]	[TRAIN] epoch: 3142, iter: 248150/250000, loss: 0.1142, lr: 0.000121, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6114 samples/sec | ETA 00:17:26
2023-02-05 07:35:51 [INFO]	[TRAIN] epoch: 3142, iter: 248160/250000, loss: 0.1349, lr: 0.000120, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6058 samples/sec | ETA 00:17:20
2023-02-05 07:35:57 [INFO]	[TRAIN] epoch: 3142, iter: 248170/250000, loss: 0.1351, lr: 0.000120, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6099 samples/sec | ETA 00:17:14
2023-02-05 07:36:02 [INFO]	[TRAIN] epoch: 3142, iter: 248180/250000, loss: 0.1370, lr: 0.000119, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6077 samples/sec | ETA 00:17:09
2023-02-05 07:36:08 [INFO]	[TRAIN] epoch: 3142, iter: 248190/250000, loss: 0.1309, lr: 0.000119, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6106 samples/sec | ETA 00:17:03
2023-02-05 07:36:14 [INFO]	[TRAIN] epoch: 3142, iter: 248200/250000, loss: 0.1221, lr: 0.000118, batch_cost: 0.5913, reader_cost: 0.02631, ips: 10.1467 samples/sec | ETA 00:17:44
2023-02-05 07:36:20 [INFO]	[TRAIN] epoch: 3142, iter: 248210/250000, loss: 0.1123, lr: 0.000117, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6299 samples/sec | ETA 00:16:50
2023-02-05 07:36:25 [INFO]	[TRAIN] epoch: 3143, iter: 248220/250000, loss: 0.1039, lr: 0.000117, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6249 samples/sec | ETA 00:16:45
2023-02-05 07:36:31 [INFO]	[TRAIN] epoch: 3143, iter: 248230/250000, loss: 0.1324, lr: 0.000116, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6105 samples/sec | ETA 00:16:40
2023-02-05 07:36:37 [INFO]	[TRAIN] epoch: 3143, iter: 248240/250000, loss: 0.1163, lr: 0.000116, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6152 samples/sec | ETA 00:16:34
2023-02-05 07:36:42 [INFO]	[TRAIN] epoch: 3143, iter: 248250/250000, loss: 0.1277, lr: 0.000115, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6138 samples/sec | ETA 00:16:29
2023-02-05 07:36:48 [INFO]	[TRAIN] epoch: 3143, iter: 248260/250000, loss: 0.1175, lr: 0.000114, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6128 samples/sec | ETA 00:16:23
2023-02-05 07:36:54 [INFO]	[TRAIN] epoch: 3143, iter: 248270/250000, loss: 0.1131, lr: 0.000114, batch_cost: 0.5896, reader_cost: 0.02453, ips: 10.1756 samples/sec | ETA 00:17:00
2023-02-05 07:36:59 [INFO]	[TRAIN] epoch: 3143, iter: 248280/250000, loss: 0.1118, lr: 0.000113, batch_cost: 0.5652, reader_cost: 0.00015, ips: 10.6157 samples/sec | ETA 00:16:12
2023-02-05 07:37:05 [INFO]	[TRAIN] epoch: 3143, iter: 248290/250000, loss: 0.1120, lr: 0.000113, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6082 samples/sec | ETA 00:16:07
2023-02-05 07:37:11 [INFO]	[TRAIN] epoch: 3144, iter: 248300/250000, loss: 0.1236, lr: 0.000112, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6125 samples/sec | ETA 00:16:01
2023-02-05 07:37:16 [INFO]	[TRAIN] epoch: 3144, iter: 248310/250000, loss: 0.1597, lr: 0.000111, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6182 samples/sec | ETA 00:15:54
2023-02-05 07:37:22 [INFO]	[TRAIN] epoch: 3144, iter: 248320/250000, loss: 0.1164, lr: 0.000111, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6068 samples/sec | ETA 00:15:50
2023-02-05 07:37:28 [INFO]	[TRAIN] epoch: 3144, iter: 248330/250000, loss: 0.0948, lr: 0.000110, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6127 samples/sec | ETA 00:15:44
2023-02-05 07:37:33 [INFO]	[TRAIN] epoch: 3144, iter: 248340/250000, loss: 0.1215, lr: 0.000110, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6107 samples/sec | ETA 00:15:38
2023-02-05 07:37:39 [INFO]	[TRAIN] epoch: 3144, iter: 248350/250000, loss: 0.1220, lr: 0.000109, batch_cost: 0.5970, reader_cost: 0.03115, ips: 10.0500 samples/sec | ETA 00:16:25
2023-02-05 07:37:45 [INFO]	[TRAIN] epoch: 3144, iter: 248360/250000, loss: 0.1109, lr: 0.000109, batch_cost: 0.5644, reader_cost: 0.00014, ips: 10.6308 samples/sec | ETA 00:15:25
2023-02-05 07:37:51 [INFO]	[TRAIN] epoch: 3144, iter: 248370/250000, loss: 0.1271, lr: 0.000108, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6211 samples/sec | ETA 00:15:20
2023-02-05 07:37:56 [INFO]	[TRAIN] epoch: 3145, iter: 248380/250000, loss: 0.1470, lr: 0.000107, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6112 samples/sec | ETA 00:15:16
2023-02-05 07:38:02 [INFO]	[TRAIN] epoch: 3145, iter: 248390/250000, loss: 0.1197, lr: 0.000107, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6101 samples/sec | ETA 00:15:10
2023-02-05 07:38:08 [INFO]	[TRAIN] epoch: 3145, iter: 248400/250000, loss: 0.1095, lr: 0.000106, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6052 samples/sec | ETA 00:15:05
2023-02-05 07:38:13 [INFO]	[TRAIN] epoch: 3145, iter: 248410/250000, loss: 0.1141, lr: 0.000106, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6110 samples/sec | ETA 00:14:59
2023-02-05 07:38:19 [INFO]	[TRAIN] epoch: 3145, iter: 248420/250000, loss: 0.1821, lr: 0.000105, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6086 samples/sec | ETA 00:14:53
2023-02-05 07:38:25 [INFO]	[TRAIN] epoch: 3145, iter: 248430/250000, loss: 0.1127, lr: 0.000104, batch_cost: 0.5946, reader_cost: 0.02860, ips: 10.0908 samples/sec | ETA 00:15:33
2023-02-05 07:38:30 [INFO]	[TRAIN] epoch: 3145, iter: 248440/250000, loss: 0.1156, lr: 0.000104, batch_cost: 0.5642, reader_cost: 0.00013, ips: 10.6338 samples/sec | ETA 00:14:40
2023-02-05 07:38:36 [INFO]	[TRAIN] epoch: 3145, iter: 248450/250000, loss: 0.1105, lr: 0.000103, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6333 samples/sec | ETA 00:14:34
2023-02-05 07:38:42 [INFO]	[TRAIN] epoch: 3146, iter: 248460/250000, loss: 0.1182, lr: 0.000103, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6249 samples/sec | ETA 00:14:29
2023-02-05 07:38:47 [INFO]	[TRAIN] epoch: 3146, iter: 248470/250000, loss: 0.1129, lr: 0.000102, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6275 samples/sec | ETA 00:14:23
2023-02-05 07:38:53 [INFO]	[TRAIN] epoch: 3146, iter: 248480/250000, loss: 0.1110, lr: 0.000101, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6389 samples/sec | ETA 00:14:17
2023-02-05 07:38:59 [INFO]	[TRAIN] epoch: 3146, iter: 248490/250000, loss: 0.0944, lr: 0.000101, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6375 samples/sec | ETA 00:14:11
2023-02-05 07:39:04 [INFO]	[TRAIN] epoch: 3146, iter: 248500/250000, loss: 0.1341, lr: 0.000100, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6138 samples/sec | ETA 00:14:07
2023-02-05 07:39:10 [INFO]	[TRAIN] epoch: 3146, iter: 248510/250000, loss: 0.1034, lr: 0.000100, batch_cost: 0.5897, reader_cost: 0.02426, ips: 10.1751 samples/sec | ETA 00:14:38
2023-02-05 07:39:16 [INFO]	[TRAIN] epoch: 3146, iter: 248520/250000, loss: 0.1165, lr: 0.000099, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6367 samples/sec | ETA 00:13:54
2023-02-05 07:39:22 [INFO]	[TRAIN] epoch: 3146, iter: 248530/250000, loss: 0.1303, lr: 0.000098, batch_cost: 0.5644, reader_cost: 0.00009, ips: 10.6315 samples/sec | ETA 00:13:49
2023-02-05 07:39:27 [INFO]	[TRAIN] epoch: 3147, iter: 248540/250000, loss: 0.1031, lr: 0.000098, batch_cost: 0.5666, reader_cost: 0.00009, ips: 10.5890 samples/sec | ETA 00:13:47
2023-02-05 07:39:33 [INFO]	[TRAIN] epoch: 3147, iter: 248550/250000, loss: 0.1300, lr: 0.000097, batch_cost: 0.5659, reader_cost: 0.00014, ips: 10.6030 samples/sec | ETA 00:13:40
2023-02-05 07:39:39 [INFO]	[TRAIN] epoch: 3147, iter: 248560/250000, loss: 0.1052, lr: 0.000097, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6059 samples/sec | ETA 00:13:34
2023-02-05 07:39:44 [INFO]	[TRAIN] epoch: 3147, iter: 248570/250000, loss: 0.1177, lr: 0.000096, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6052 samples/sec | ETA 00:13:29
2023-02-05 07:39:50 [INFO]	[TRAIN] epoch: 3147, iter: 248580/250000, loss: 0.1439, lr: 0.000095, batch_cost: 0.5654, reader_cost: 0.00010, ips: 10.6116 samples/sec | ETA 00:13:22
2023-02-05 07:39:56 [INFO]	[TRAIN] epoch: 3147, iter: 248590/250000, loss: 0.1068, lr: 0.000095, batch_cost: 0.5925, reader_cost: 0.02752, ips: 10.1262 samples/sec | ETA 00:13:55
2023-02-05 07:40:01 [INFO]	[TRAIN] epoch: 3147, iter: 248600/250000, loss: 0.1259, lr: 0.000094, batch_cost: 0.5646, reader_cost: 0.00010, ips: 10.6263 samples/sec | ETA 00:13:10
2023-02-05 07:40:07 [INFO]	[TRAIN] epoch: 3147, iter: 248610/250000, loss: 0.1489, lr: 0.000094, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6085 samples/sec | ETA 00:13:06
2023-02-05 07:40:13 [INFO]	[TRAIN] epoch: 3148, iter: 248620/250000, loss: 0.1129, lr: 0.000093, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6024 samples/sec | ETA 00:13:00
2023-02-05 07:40:18 [INFO]	[TRAIN] epoch: 3148, iter: 248630/250000, loss: 0.1348, lr: 0.000092, batch_cost: 0.5663, reader_cost: 0.00008, ips: 10.5956 samples/sec | ETA 00:12:55
2023-02-05 07:40:24 [INFO]	[TRAIN] epoch: 3148, iter: 248640/250000, loss: 0.1162, lr: 0.000092, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6216 samples/sec | ETA 00:12:48
2023-02-05 07:40:30 [INFO]	[TRAIN] epoch: 3148, iter: 248650/250000, loss: 0.1047, lr: 0.000091, batch_cost: 0.5661, reader_cost: 0.00008, ips: 10.5988 samples/sec | ETA 00:12:44
2023-02-05 07:40:35 [INFO]	[TRAIN] epoch: 3148, iter: 248660/250000, loss: 0.1271, lr: 0.000090, batch_cost: 0.5662, reader_cost: 0.00010, ips: 10.5964 samples/sec | ETA 00:12:38
2023-02-05 07:40:41 [INFO]	[TRAIN] epoch: 3148, iter: 248670/250000, loss: 0.1289, lr: 0.000090, batch_cost: 0.5899, reader_cost: 0.02305, ips: 10.1705 samples/sec | ETA 00:13:04
2023-02-05 07:40:47 [INFO]	[TRAIN] epoch: 3148, iter: 248680/250000, loss: 0.1176, lr: 0.000089, batch_cost: 0.5645, reader_cost: 0.00010, ips: 10.6288 samples/sec | ETA 00:12:25
2023-02-05 07:40:53 [INFO]	[TRAIN] epoch: 3148, iter: 248690/250000, loss: 0.1235, lr: 0.000089, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6323 samples/sec | ETA 00:12:19
2023-02-05 07:40:58 [INFO]	[TRAIN] epoch: 3149, iter: 248700/250000, loss: 0.1428, lr: 0.000088, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6163 samples/sec | ETA 00:12:14
2023-02-05 07:41:04 [INFO]	[TRAIN] epoch: 3149, iter: 248710/250000, loss: 0.1239, lr: 0.000087, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6076 samples/sec | ETA 00:12:09
2023-02-05 07:41:10 [INFO]	[TRAIN] epoch: 3149, iter: 248720/250000, loss: 0.1287, lr: 0.000087, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6006 samples/sec | ETA 00:12:04
2023-02-05 07:41:15 [INFO]	[TRAIN] epoch: 3149, iter: 248730/250000, loss: 0.1298, lr: 0.000086, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6060 samples/sec | ETA 00:11:58
2023-02-05 07:41:21 [INFO]	[TRAIN] epoch: 3149, iter: 248740/250000, loss: 0.1127, lr: 0.000086, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6084 samples/sec | ETA 00:11:52
2023-02-05 07:41:27 [INFO]	[TRAIN] epoch: 3149, iter: 248750/250000, loss: 0.1265, lr: 0.000085, batch_cost: 0.5964, reader_cost: 0.03049, ips: 10.0603 samples/sec | ETA 00:12:25
2023-02-05 07:41:32 [INFO]	[TRAIN] epoch: 3149, iter: 248760/250000, loss: 0.1306, lr: 0.000084, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6067 samples/sec | ETA 00:11:41
2023-02-05 07:41:38 [INFO]	[TRAIN] epoch: 3149, iter: 248770/250000, loss: 0.1133, lr: 0.000084, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6054 samples/sec | ETA 00:11:35
2023-02-05 07:41:44 [INFO]	[TRAIN] epoch: 3150, iter: 248780/250000, loss: 0.1030, lr: 0.000083, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6132 samples/sec | ETA 00:11:29
2023-02-05 07:41:49 [INFO]	[TRAIN] epoch: 3150, iter: 248790/250000, loss: 0.1261, lr: 0.000083, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6091 samples/sec | ETA 00:11:24
2023-02-05 07:41:55 [INFO]	[TRAIN] epoch: 3150, iter: 248800/250000, loss: 0.1364, lr: 0.000082, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5995 samples/sec | ETA 00:11:19
2023-02-05 07:42:01 [INFO]	[TRAIN] epoch: 3150, iter: 248810/250000, loss: 0.1339, lr: 0.000081, batch_cost: 0.5661, reader_cost: 0.00010, ips: 10.5996 samples/sec | ETA 00:11:13
2023-02-05 07:42:06 [INFO]	[TRAIN] epoch: 3150, iter: 248820/250000, loss: 0.0997, lr: 0.000081, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5992 samples/sec | ETA 00:11:07
2023-02-05 07:42:12 [INFO]	[TRAIN] epoch: 3150, iter: 248830/250000, loss: 0.1157, lr: 0.000080, batch_cost: 0.5905, reader_cost: 0.02566, ips: 10.1601 samples/sec | ETA 00:11:30
2023-02-05 07:42:18 [INFO]	[TRAIN] epoch: 3150, iter: 248840/250000, loss: 0.1234, lr: 0.000079, batch_cost: 0.5648, reader_cost: 0.00008, ips: 10.6232 samples/sec | ETA 00:10:55
2023-02-05 07:42:24 [INFO]	[TRAIN] epoch: 3150, iter: 248850/250000, loss: 0.1334, lr: 0.000079, batch_cost: 0.5656, reader_cost: 0.00010, ips: 10.6073 samples/sec | ETA 00:10:50
2023-02-05 07:42:29 [INFO]	[TRAIN] epoch: 3151, iter: 248860/250000, loss: 0.1126, lr: 0.000078, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6176 samples/sec | ETA 00:10:44
2023-02-05 07:42:35 [INFO]	[TRAIN] epoch: 3151, iter: 248870/250000, loss: 0.1141, lr: 0.000078, batch_cost: 0.5655, reader_cost: 0.00008, ips: 10.6100 samples/sec | ETA 00:10:39
2023-02-05 07:42:41 [INFO]	[TRAIN] epoch: 3151, iter: 248880/250000, loss: 0.0976, lr: 0.000077, batch_cost: 0.5654, reader_cost: 0.00008, ips: 10.6112 samples/sec | ETA 00:10:33
2023-02-05 07:42:46 [INFO]	[TRAIN] epoch: 3151, iter: 248890/250000, loss: 0.1263, lr: 0.000076, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6013 samples/sec | ETA 00:10:28
2023-02-05 07:42:52 [INFO]	[TRAIN] epoch: 3151, iter: 248900/250000, loss: 0.1349, lr: 0.000076, batch_cost: 0.5657, reader_cost: 0.00008, ips: 10.6067 samples/sec | ETA 00:10:22
2023-02-05 07:42:58 [INFO]	[TRAIN] epoch: 3151, iter: 248910/250000, loss: 0.1350, lr: 0.000075, batch_cost: 0.5940, reader_cost: 0.02951, ips: 10.1007 samples/sec | ETA 00:10:47
2023-02-05 07:43:03 [INFO]	[TRAIN] epoch: 3151, iter: 248920/250000, loss: 0.1271, lr: 0.000075, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6246 samples/sec | ETA 00:10:09
2023-02-05 07:43:09 [INFO]	[TRAIN] epoch: 3152, iter: 248930/250000, loss: 0.1205, lr: 0.000074, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6214 samples/sec | ETA 00:10:04
2023-02-05 07:43:15 [INFO]	[TRAIN] epoch: 3152, iter: 248940/250000, loss: 0.1247, lr: 0.000073, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6282 samples/sec | ETA 00:09:58
2023-02-05 07:43:20 [INFO]	[TRAIN] epoch: 3152, iter: 248950/250000, loss: 0.1338, lr: 0.000073, batch_cost: 0.5650, reader_cost: 0.00009, ips: 10.6189 samples/sec | ETA 00:09:53
2023-02-05 07:43:26 [INFO]	[TRAIN] epoch: 3152, iter: 248960/250000, loss: 0.1282, lr: 0.000072, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6093 samples/sec | ETA 00:09:48
2023-02-05 07:43:32 [INFO]	[TRAIN] epoch: 3152, iter: 248970/250000, loss: 0.1245, lr: 0.000071, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6067 samples/sec | ETA 00:09:42
2023-02-05 07:43:37 [INFO]	[TRAIN] epoch: 3152, iter: 248980/250000, loss: 0.0953, lr: 0.000071, batch_cost: 0.5650, reader_cost: 0.00008, ips: 10.6190 samples/sec | ETA 00:09:36
2023-02-05 07:43:43 [INFO]	[TRAIN] epoch: 3152, iter: 248990/250000, loss: 0.1093, lr: 0.000070, batch_cost: 0.5851, reader_cost: 0.01999, ips: 10.2539 samples/sec | ETA 00:09:50
2023-02-05 07:43:49 [INFO]	[TRAIN] epoch: 3152, iter: 249000/250000, loss: 0.1459, lr: 0.000070, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6149 samples/sec | ETA 00:09:25
2023-02-05 07:43:55 [INFO]	[TRAIN] epoch: 3153, iter: 249010/250000, loss: 0.1262, lr: 0.000069, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6066 samples/sec | ETA 00:09:20
2023-02-05 07:44:00 [INFO]	[TRAIN] epoch: 3153, iter: 249020/250000, loss: 0.1144, lr: 0.000068, batch_cost: 0.5653, reader_cost: 0.00008, ips: 10.6132 samples/sec | ETA 00:09:14
2023-02-05 07:44:06 [INFO]	[TRAIN] epoch: 3153, iter: 249030/250000, loss: 0.1112, lr: 0.000068, batch_cost: 0.5655, reader_cost: 0.00010, ips: 10.6100 samples/sec | ETA 00:09:08
2023-02-05 07:44:12 [INFO]	[TRAIN] epoch: 3153, iter: 249040/250000, loss: 0.1102, lr: 0.000067, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6031 samples/sec | ETA 00:09:03
2023-02-05 07:44:17 [INFO]	[TRAIN] epoch: 3153, iter: 249050/250000, loss: 0.1569, lr: 0.000066, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6100 samples/sec | ETA 00:08:57
2023-02-05 07:44:23 [INFO]	[TRAIN] epoch: 3153, iter: 249060/250000, loss: 0.1786, lr: 0.000066, batch_cost: 0.5903, reader_cost: 0.02517, ips: 10.1648 samples/sec | ETA 00:09:14
2023-02-05 07:44:29 [INFO]	[TRAIN] epoch: 3153, iter: 249070/250000, loss: 0.1343, lr: 0.000065, batch_cost: 0.5659, reader_cost: 0.00021, ips: 10.6033 samples/sec | ETA 00:08:46
2023-02-05 07:44:34 [INFO]	[TRAIN] epoch: 3153, iter: 249080/250000, loss: 0.1308, lr: 0.000065, batch_cost: 0.5657, reader_cost: 0.00010, ips: 10.6063 samples/sec | ETA 00:08:40
2023-02-05 07:44:40 [INFO]	[TRAIN] epoch: 3154, iter: 249090/250000, loss: 0.1100, lr: 0.000064, batch_cost: 0.5650, reader_cost: 0.00008, ips: 10.6203 samples/sec | ETA 00:08:34
2023-02-05 07:44:46 [INFO]	[TRAIN] epoch: 3154, iter: 249100/250000, loss: 0.1292, lr: 0.000063, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5988 samples/sec | ETA 00:08:29
2023-02-05 07:44:51 [INFO]	[TRAIN] epoch: 3154, iter: 249110/250000, loss: 0.1175, lr: 0.000063, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6089 samples/sec | ETA 00:08:23
2023-02-05 07:44:57 [INFO]	[TRAIN] epoch: 3154, iter: 249120/250000, loss: 0.1132, lr: 0.000062, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6071 samples/sec | ETA 00:08:17
2023-02-05 07:45:03 [INFO]	[TRAIN] epoch: 3154, iter: 249130/250000, loss: 0.1329, lr: 0.000061, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6108 samples/sec | ETA 00:08:11
2023-02-05 07:45:09 [INFO]	[TRAIN] epoch: 3154, iter: 249140/250000, loss: 0.1179, lr: 0.000061, batch_cost: 0.5892, reader_cost: 0.02349, ips: 10.1830 samples/sec | ETA 00:08:26
2023-02-05 07:45:14 [INFO]	[TRAIN] epoch: 3154, iter: 249150/250000, loss: 0.1284, lr: 0.000060, batch_cost: 0.5650, reader_cost: 0.00013, ips: 10.6203 samples/sec | ETA 00:08:00
2023-02-05 07:45:20 [INFO]	[TRAIN] epoch: 3154, iter: 249160/250000, loss: 0.1101, lr: 0.000059, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6242 samples/sec | ETA 00:07:54
2023-02-05 07:45:26 [INFO]	[TRAIN] epoch: 3155, iter: 249170/250000, loss: 0.1215, lr: 0.000059, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6098 samples/sec | ETA 00:07:49
2023-02-05 07:45:31 [INFO]	[TRAIN] epoch: 3155, iter: 249180/250000, loss: 0.1435, lr: 0.000058, batch_cost: 0.5652, reader_cost: 0.00008, ips: 10.6166 samples/sec | ETA 00:07:43
2023-02-05 07:45:37 [INFO]	[TRAIN] epoch: 3155, iter: 249190/250000, loss: 0.1212, lr: 0.000058, batch_cost: 0.5660, reader_cost: 0.00010, ips: 10.6011 samples/sec | ETA 00:07:38
2023-02-05 07:45:42 [INFO]	[TRAIN] epoch: 3155, iter: 249200/250000, loss: 0.1399, lr: 0.000057, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6000 samples/sec | ETA 00:07:32
2023-02-05 07:45:48 [INFO]	[TRAIN] epoch: 3155, iter: 249210/250000, loss: 0.1150, lr: 0.000056, batch_cost: 0.5651, reader_cost: 0.00008, ips: 10.6184 samples/sec | ETA 00:07:26
2023-02-05 07:45:54 [INFO]	[TRAIN] epoch: 3155, iter: 249220/250000, loss: 0.1329, lr: 0.000056, batch_cost: 0.5935, reader_cost: 0.02831, ips: 10.1091 samples/sec | ETA 00:07:42
2023-02-05 07:46:00 [INFO]	[TRAIN] epoch: 3155, iter: 249230/250000, loss: 0.2910, lr: 0.000055, batch_cost: 0.5652, reader_cost: 0.00013, ips: 10.6149 samples/sec | ETA 00:07:15
2023-02-05 07:46:05 [INFO]	[TRAIN] epoch: 3155, iter: 249240/250000, loss: 0.1052, lr: 0.000054, batch_cost: 0.5658, reader_cost: 0.00008, ips: 10.6041 samples/sec | ETA 00:07:10
2023-02-05 07:46:11 [INFO]	[TRAIN] epoch: 3156, iter: 249250/250000, loss: 0.1391, lr: 0.000054, batch_cost: 0.5663, reader_cost: 0.00010, ips: 10.5947 samples/sec | ETA 00:07:04
2023-02-05 07:46:17 [INFO]	[TRAIN] epoch: 3156, iter: 249260/250000, loss: 0.1109, lr: 0.000053, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6091 samples/sec | ETA 00:06:58
2023-02-05 07:46:22 [INFO]	[TRAIN] epoch: 3156, iter: 249270/250000, loss: 0.1416, lr: 0.000052, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6134 samples/sec | ETA 00:06:52
2023-02-05 07:46:28 [INFO]	[TRAIN] epoch: 3156, iter: 249280/250000, loss: 0.1161, lr: 0.000052, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6036 samples/sec | ETA 00:06:47
2023-02-05 07:46:34 [INFO]	[TRAIN] epoch: 3156, iter: 249290/250000, loss: 0.1191, lr: 0.000051, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6029 samples/sec | ETA 00:06:41
2023-02-05 07:46:40 [INFO]	[TRAIN] epoch: 3156, iter: 249300/250000, loss: 0.1050, lr: 0.000050, batch_cost: 0.5889, reader_cost: 0.02372, ips: 10.1885 samples/sec | ETA 00:06:52
2023-02-05 07:46:45 [INFO]	[TRAIN] epoch: 3156, iter: 249310/250000, loss: 0.1329, lr: 0.000050, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6275 samples/sec | ETA 00:06:29
2023-02-05 07:46:51 [INFO]	[TRAIN] epoch: 3156, iter: 249320/250000, loss: 0.1135, lr: 0.000049, batch_cost: 0.5648, reader_cost: 0.00010, ips: 10.6226 samples/sec | ETA 00:06:24
2023-02-05 07:46:57 [INFO]	[TRAIN] epoch: 3157, iter: 249330/250000, loss: 0.1286, lr: 0.000049, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6324 samples/sec | ETA 00:06:18
2023-02-05 07:47:02 [INFO]	[TRAIN] epoch: 3157, iter: 249340/250000, loss: 0.1090, lr: 0.000048, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6345 samples/sec | ETA 00:06:12
2023-02-05 07:47:08 [INFO]	[TRAIN] epoch: 3157, iter: 249350/250000, loss: 0.1144, lr: 0.000047, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6056 samples/sec | ETA 00:06:07
2023-02-05 07:47:13 [INFO]	[TRAIN] epoch: 3157, iter: 249360/250000, loss: 0.1149, lr: 0.000047, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6004 samples/sec | ETA 00:06:02
2023-02-05 07:47:19 [INFO]	[TRAIN] epoch: 3157, iter: 249370/250000, loss: 0.1217, lr: 0.000046, batch_cost: 0.5658, reader_cost: 0.00009, ips: 10.6042 samples/sec | ETA 00:05:56
2023-02-05 07:47:25 [INFO]	[TRAIN] epoch: 3157, iter: 249380/250000, loss: 0.1323, lr: 0.000045, batch_cost: 0.5912, reader_cost: 0.02583, ips: 10.1490 samples/sec | ETA 00:06:06
2023-02-05 07:47:31 [INFO]	[TRAIN] epoch: 3157, iter: 249390/250000, loss: 0.1291, lr: 0.000045, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6275 samples/sec | ETA 00:05:44
2023-02-05 07:47:36 [INFO]	[TRAIN] epoch: 3157, iter: 249400/250000, loss: 0.1219, lr: 0.000044, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6015 samples/sec | ETA 00:05:39
2023-02-05 07:47:42 [INFO]	[TRAIN] epoch: 3158, iter: 249410/250000, loss: 0.1190, lr: 0.000043, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5996 samples/sec | ETA 00:05:33
2023-02-05 07:47:48 [INFO]	[TRAIN] epoch: 3158, iter: 249420/250000, loss: 0.1147, lr: 0.000043, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6073 samples/sec | ETA 00:05:28
2023-02-05 07:47:53 [INFO]	[TRAIN] epoch: 3158, iter: 249430/250000, loss: 0.0925, lr: 0.000042, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6116 samples/sec | ETA 00:05:22
2023-02-05 07:47:59 [INFO]	[TRAIN] epoch: 3158, iter: 249440/250000, loss: 0.1580, lr: 0.000041, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6030 samples/sec | ETA 00:05:16
2023-02-05 07:48:05 [INFO]	[TRAIN] epoch: 3158, iter: 249450/250000, loss: 0.1364, lr: 0.000041, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6065 samples/sec | ETA 00:05:11
2023-02-05 07:48:11 [INFO]	[TRAIN] epoch: 3158, iter: 249460/250000, loss: 0.1129, lr: 0.000040, batch_cost: 0.5914, reader_cost: 0.02574, ips: 10.1446 samples/sec | ETA 00:05:19
2023-02-05 07:48:16 [INFO]	[TRAIN] epoch: 3158, iter: 249470/250000, loss: 0.1131, lr: 0.000039, batch_cost: 0.5647, reader_cost: 0.00011, ips: 10.6258 samples/sec | ETA 00:04:59
2023-02-05 07:48:22 [INFO]	[TRAIN] epoch: 3158, iter: 249480/250000, loss: 0.1167, lr: 0.000039, batch_cost: 0.5646, reader_cost: 0.00008, ips: 10.6261 samples/sec | ETA 00:04:53
2023-02-05 07:48:27 [INFO]	[TRAIN] epoch: 3159, iter: 249490/250000, loss: 0.1372, lr: 0.000038, batch_cost: 0.5650, reader_cost: 0.00008, ips: 10.6204 samples/sec | ETA 00:04:48
2023-02-05 07:48:33 [INFO]	[TRAIN] epoch: 3159, iter: 249500/250000, loss: 0.1114, lr: 0.000037, batch_cost: 0.5645, reader_cost: 0.00009, ips: 10.6289 samples/sec | ETA 00:04:42
2023-02-05 07:48:39 [INFO]	[TRAIN] epoch: 3159, iter: 249510/250000, loss: 0.1245, lr: 0.000037, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6221 samples/sec | ETA 00:04:36
2023-02-05 07:48:44 [INFO]	[TRAIN] epoch: 3159, iter: 249520/250000, loss: 0.1421, lr: 0.000036, batch_cost: 0.5643, reader_cost: 0.00008, ips: 10.6329 samples/sec | ETA 00:04:30
2023-02-05 07:48:50 [INFO]	[TRAIN] epoch: 3159, iter: 249530/250000, loss: 0.1195, lr: 0.000035, batch_cost: 0.5647, reader_cost: 0.00009, ips: 10.6245 samples/sec | ETA 00:04:25
2023-02-05 07:48:56 [INFO]	[TRAIN] epoch: 3159, iter: 249540/250000, loss: 0.1140, lr: 0.000035, batch_cost: 0.5902, reader_cost: 0.02464, ips: 10.1662 samples/sec | ETA 00:04:31
2023-02-05 07:49:02 [INFO]	[TRAIN] epoch: 3159, iter: 249550/250000, loss: 0.1283, lr: 0.000034, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6074 samples/sec | ETA 00:04:14
2023-02-05 07:49:07 [INFO]	[TRAIN] epoch: 3159, iter: 249560/250000, loss: 0.1260, lr: 0.000033, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5979 samples/sec | ETA 00:04:09
2023-02-05 07:49:13 [INFO]	[TRAIN] epoch: 3160, iter: 249570/250000, loss: 0.1154, lr: 0.000033, batch_cost: 0.5658, reader_cost: 0.00010, ips: 10.6042 samples/sec | ETA 00:04:03
2023-02-05 07:49:19 [INFO]	[TRAIN] epoch: 3160, iter: 249580/250000, loss: 0.1258, lr: 0.000032, batch_cost: 0.5651, reader_cost: 0.00008, ips: 10.6167 samples/sec | ETA 00:03:57
2023-02-05 07:49:24 [INFO]	[TRAIN] epoch: 3160, iter: 249590/250000, loss: 0.1095, lr: 0.000031, batch_cost: 0.5658, reader_cost: 0.00016, ips: 10.6045 samples/sec | ETA 00:03:51
2023-02-05 07:49:30 [INFO]	[TRAIN] epoch: 3160, iter: 249600/250000, loss: 0.1194, lr: 0.000031, batch_cost: 0.5661, reader_cost: 0.00009, ips: 10.5984 samples/sec | ETA 00:03:46
2023-02-05 07:49:36 [INFO]	[TRAIN] epoch: 3160, iter: 249610/250000, loss: 0.1354, lr: 0.000030, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6125 samples/sec | ETA 00:03:40
2023-02-05 07:49:41 [INFO]	[TRAIN] epoch: 3160, iter: 249620/250000, loss: 0.1201, lr: 0.000029, batch_cost: 0.5896, reader_cost: 0.02383, ips: 10.1756 samples/sec | ETA 00:03:44
2023-02-05 07:49:47 [INFO]	[TRAIN] epoch: 3160, iter: 249630/250000, loss: 0.1039, lr: 0.000028, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6226 samples/sec | ETA 00:03:28
2023-02-05 07:49:53 [INFO]	[TRAIN] epoch: 3160, iter: 249640/250000, loss: 0.1577, lr: 0.000028, batch_cost: 0.5645, reader_cost: 0.00008, ips: 10.6288 samples/sec | ETA 00:03:23
2023-02-05 07:49:58 [INFO]	[TRAIN] epoch: 3161, iter: 249650/250000, loss: 0.1368, lr: 0.000027, batch_cost: 0.5640, reader_cost: 0.00009, ips: 10.6376 samples/sec | ETA 00:03:17
2023-02-05 07:50:04 [INFO]	[TRAIN] epoch: 3161, iter: 249660/250000, loss: 0.1265, lr: 0.000026, batch_cost: 0.5651, reader_cost: 0.00009, ips: 10.6180 samples/sec | ETA 00:03:12
2023-02-05 07:50:10 [INFO]	[TRAIN] epoch: 3161, iter: 249670/250000, loss: 0.1376, lr: 0.000026, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6084 samples/sec | ETA 00:03:06
2023-02-05 07:50:15 [INFO]	[TRAIN] epoch: 3161, iter: 249680/250000, loss: 0.1128, lr: 0.000025, batch_cost: 0.5654, reader_cost: 0.00009, ips: 10.6112 samples/sec | ETA 00:03:00
2023-02-05 07:50:21 [INFO]	[TRAIN] epoch: 3161, iter: 249690/250000, loss: 0.1066, lr: 0.000024, batch_cost: 0.5655, reader_cost: 0.00009, ips: 10.6098 samples/sec | ETA 00:02:55
2023-02-05 07:50:27 [INFO]	[TRAIN] epoch: 3161, iter: 249700/250000, loss: 0.1150, lr: 0.000024, batch_cost: 0.5927, reader_cost: 0.02816, ips: 10.1236 samples/sec | ETA 00:02:57
2023-02-05 07:50:33 [INFO]	[TRAIN] epoch: 3161, iter: 249710/250000, loss: 0.1057, lr: 0.000023, batch_cost: 0.5652, reader_cost: 0.00009, ips: 10.6165 samples/sec | ETA 00:02:43
2023-02-05 07:50:38 [INFO]	[TRAIN] epoch: 3162, iter: 249720/250000, loss: 0.1395, lr: 0.000022, batch_cost: 0.5660, reader_cost: 0.00009, ips: 10.6010 samples/sec | ETA 00:02:38
2023-02-05 07:50:44 [INFO]	[TRAIN] epoch: 3162, iter: 249730/250000, loss: 0.1095, lr: 0.000021, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6079 samples/sec | ETA 00:02:32
2023-02-05 07:50:50 [INFO]	[TRAIN] epoch: 3162, iter: 249740/250000, loss: 0.1272, lr: 0.000021, batch_cost: 0.5656, reader_cost: 0.00009, ips: 10.6081 samples/sec | ETA 00:02:27
2023-02-05 07:50:55 [INFO]	[TRAIN] epoch: 3162, iter: 249750/250000, loss: 0.1189, lr: 0.000020, batch_cost: 0.5657, reader_cost: 0.00011, ips: 10.6055 samples/sec | ETA 00:02:21
2023-02-05 07:51:01 [INFO]	[TRAIN] epoch: 3162, iter: 249760/250000, loss: 0.1256, lr: 0.000019, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6022 samples/sec | ETA 00:02:15
2023-02-05 07:51:07 [INFO]	[TRAIN] epoch: 3162, iter: 249770/250000, loss: 0.1097, lr: 0.000019, batch_cost: 0.5650, reader_cost: 0.00008, ips: 10.6191 samples/sec | ETA 00:02:09
2023-02-05 07:51:12 [INFO]	[TRAIN] epoch: 3162, iter: 249780/250000, loss: 0.1121, lr: 0.000018, batch_cost: 0.5904, reader_cost: 0.02515, ips: 10.1619 samples/sec | ETA 00:02:09
2023-02-05 07:51:18 [INFO]	[TRAIN] epoch: 3162, iter: 249790/250000, loss: 0.1208, lr: 0.000017, batch_cost: 0.5643, reader_cost: 0.00010, ips: 10.6323 samples/sec | ETA 00:01:58
2023-02-05 07:51:24 [INFO]	[TRAIN] epoch: 3163, iter: 249800/250000, loss: 0.1051, lr: 0.000016, batch_cost: 0.5642, reader_cost: 0.00009, ips: 10.6353 samples/sec | ETA 00:01:52
2023-02-05 07:51:29 [INFO]	[TRAIN] epoch: 3163, iter: 249810/250000, loss: 0.1335, lr: 0.000016, batch_cost: 0.5646, reader_cost: 0.00008, ips: 10.6263 samples/sec | ETA 00:01:47
2023-02-05 07:51:35 [INFO]	[TRAIN] epoch: 3163, iter: 249820/250000, loss: 0.1300, lr: 0.000015, batch_cost: 0.5646, reader_cost: 0.00009, ips: 10.6267 samples/sec | ETA 00:01:41
2023-02-05 07:51:41 [INFO]	[TRAIN] epoch: 3163, iter: 249830/250000, loss: 0.1020, lr: 0.000014, batch_cost: 0.5649, reader_cost: 0.00009, ips: 10.6208 samples/sec | ETA 00:01:36
2023-02-05 07:51:46 [INFO]	[TRAIN] epoch: 3163, iter: 249840/250000, loss: 0.1583, lr: 0.000013, batch_cost: 0.5641, reader_cost: 0.00009, ips: 10.6358 samples/sec | ETA 00:01:30
2023-02-05 07:51:52 [INFO]	[TRAIN] epoch: 3163, iter: 249850/250000, loss: 0.1156, lr: 0.000013, batch_cost: 0.5976, reader_cost: 0.03304, ips: 10.0405 samples/sec | ETA 00:01:29
2023-02-05 07:51:58 [INFO]	[TRAIN] epoch: 3163, iter: 249860/250000, loss: 0.1542, lr: 0.000012, batch_cost: 0.5650, reader_cost: 0.00019, ips: 10.6195 samples/sec | ETA 00:01:19
2023-02-05 07:52:04 [INFO]	[TRAIN] epoch: 3163, iter: 249870/250000, loss: 0.1056, lr: 0.000011, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6305 samples/sec | ETA 00:01:13
2023-02-05 07:52:09 [INFO]	[TRAIN] epoch: 3164, iter: 249880/250000, loss: 0.1131, lr: 0.000010, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6225 samples/sec | ETA 00:01:07
2023-02-05 07:52:15 [INFO]	[TRAIN] epoch: 3164, iter: 249890/250000, loss: 0.1250, lr: 0.000010, batch_cost: 0.5643, reader_cost: 0.00009, ips: 10.6328 samples/sec | ETA 00:01:02
2023-02-05 07:52:21 [INFO]	[TRAIN] epoch: 3164, iter: 249900/250000, loss: 0.1247, lr: 0.000009, batch_cost: 0.5644, reader_cost: 0.00008, ips: 10.6303 samples/sec | ETA 00:00:56
2023-02-05 07:52:26 [INFO]	[TRAIN] epoch: 3164, iter: 249910/250000, loss: 0.1449, lr: 0.000008, batch_cost: 0.5648, reader_cost: 0.00009, ips: 10.6241 samples/sec | ETA 00:00:50
2023-02-05 07:52:32 [INFO]	[TRAIN] epoch: 3164, iter: 249920/250000, loss: 0.1619, lr: 0.000007, batch_cost: 0.5659, reader_cost: 0.00009, ips: 10.6028 samples/sec | ETA 00:00:45
2023-02-05 07:52:38 [INFO]	[TRAIN] epoch: 3164, iter: 249930/250000, loss: 0.1304, lr: 0.000006, batch_cost: 0.5891, reader_cost: 0.02364, ips: 10.1856 samples/sec | ETA 00:00:41
2023-02-05 07:52:43 [INFO]	[TRAIN] epoch: 3164, iter: 249940/250000, loss: 0.1127, lr: 0.000006, batch_cost: 0.5650, reader_cost: 0.00014, ips: 10.6193 samples/sec | ETA 00:00:33
2023-02-05 07:52:49 [INFO]	[TRAIN] epoch: 3164, iter: 249950/250000, loss: 0.1229, lr: 0.000005, batch_cost: 0.5648, reader_cost: 0.00008, ips: 10.6241 samples/sec | ETA 00:00:28
2023-02-05 07:52:55 [INFO]	[TRAIN] epoch: 3165, iter: 249960/250000, loss: 0.1119, lr: 0.000004, batch_cost: 0.5653, reader_cost: 0.00009, ips: 10.6147 samples/sec | ETA 00:00:22
2023-02-05 07:53:00 [INFO]	[TRAIN] epoch: 3165, iter: 249970/250000, loss: 0.1212, lr: 0.000003, batch_cost: 0.5657, reader_cost: 0.00009, ips: 10.6068 samples/sec | ETA 00:00:16
2023-02-05 07:53:06 [INFO]	[TRAIN] epoch: 3165, iter: 249980/250000, loss: 0.1382, lr: 0.000002, batch_cost: 0.5658, reader_cost: 0.00008, ips: 10.6037 samples/sec | ETA 00:00:11
2023-02-05 07:53:12 [INFO]	[TRAIN] epoch: 3165, iter: 249990/250000, loss: 0.1617, lr: 0.000001, batch_cost: 0.5656, reader_cost: 0.00008, ips: 10.6079 samples/sec | ETA 00:00:05
2023-02-05 07:53:17 [INFO]	[TRAIN] epoch: 3165, iter: 250000/250000, loss: 0.1269, lr: 0.000000, batch_cost: 0.5653, reader_cost: 0.00010, ips: 10.6146 samples/sec | ETA 00:00:00
2023-02-05 07:53:17 [INFO]	Start evaluating (total_samples: 36, total_iters: 36)...
 1/36 [..............................] - ETA: 4s - batch_cost: 0.1300 - reader cost: 0.0322 2/36 [>.............................] - ETA: 5s - batch_cost: 0.1537 - reader cost: 0.0161 3/36 [=>............................] - ETA: 5s - batch_cost: 0.1595 - reader cost: 0.0108 4/36 [==>...........................] - ETA: 5s - batch_cost: 0.1595 - reader cost: 0.0081 5/36 [===>..........................] - ETA: 4s - batch_cost: 0.1607 - reader cost: 0.0065 6/36 [====>.........................] - ETA: 4s - batch_cost: 0.1624 - reader cost: 0.0054 7/36 [====>.........................] - ETA: 4s - batch_cost: 0.1622 - reader cost: 0.0047 8/36 [=====>........................] - ETA: 4s - batch_cost: 0.1624 - reader cost: 0.0041 9/36 [======>.......................] - ETA: 4s - batch_cost: 0.1633 - reader cost: 0.003610/36 [=======>......................] - ETA: 4s - batch_cost: 0.1633 - reader cost: 0.003311/36 [========>.....................] - ETA: 4s - batch_cost: 0.1641 - reader cost: 0.003012/36 [=========>....................] - ETA: 3s - batch_cost: 0.1636 - reader cost: 0.002713/36 [=========>....................] - ETA: 3s - batch_cost: 0.1639 - reader cost: 0.002514/36 [==========>...................] - ETA: 3s - batch_cost: 0.1642 - reader cost: 0.002415/36 [===========>..................] - ETA: 3s - batch_cost: 0.1641 - reader cost: 0.002216/36 [============>.................] - ETA: 3s - batch_cost: 0.1651 - reader cost: 0.002117/36 [=============>................] - ETA: 3s - batch_cost: 0.1655 - reader cost: 0.002018/36 [==============>...............] - ETA: 2s - batch_cost: 0.1655 - reader cost: 0.001919/36 [==============>...............] - ETA: 2s - batch_cost: 0.1652 - reader cost: 0.001820/36 [===============>..............] - ETA: 2s - batch_cost: 0.1650 - reader cost: 0.001721/36 [================>.............] - ETA: 2s - batch_cost: 0.1651 - reader cost: 0.001622/36 [=================>............] - ETA: 2s - batch_cost: 0.1655 - reader cost: 0.001523/36 [==================>...........] - ETA: 2s - batch_cost: 0.1661 - reader cost: 0.001524/36 [===================>..........] - ETA: 1s - batch_cost: 0.1660 - reader cost: 0.001425/36 [===================>..........] - ETA: 1s - batch_cost: 0.1662 - reader cost: 0.001426/36 [====================>.........] - ETA: 1s - batch_cost: 0.1663 - reader cost: 0.001327/36 [=====================>........] - ETA: 1s - batch_cost: 0.1665 - reader cost: 0.001328/36 [======================>.......] - ETA: 1s - batch_cost: 0.1667 - reader cost: 0.001229/36 [=======================>......] - ETA: 1s - batch_cost: 0.1668 - reader cost: 0.001230/36 [========================>.....] - ETA: 1s - batch_cost: 0.1666 - reader cost: 0.001131/36 [========================>.....] - ETA: 0s - batch_cost: 0.1666 - reader cost: 0.001132/36 [=========================>....] - ETA: 0s - batch_cost: 0.1664 - reader cost: 0.001133/36 [==========================>...] - ETA: 0s - batch_cost: 0.1662 - reader cost: 0.001034/36 [===========================>..] - ETA: 0s - batch_cost: 0.1661 - reader cost: 0.001035/36 [============================>.] - ETA: 0s - batch_cost: 0.1660 - reader cost: 9.9162e-0436/36 [==============================] - 6s 166ms/step - batch_cost: 0.1661 - reader cost: 9.6625e-04
2023-02-05 07:53:23 [INFO]	[EVAL] #Images: 36 mIoU: 0.8679 Acc: 0.9867 Kappa: 0.9518 Dice: 0.9259
2023-02-05 07:53:23 [INFO]	[EVAL] Class IoU: 
[0.9862 0.9183 0.8938 0.7118 0.7185 0.9728 0.8738]
2023-02-05 07:53:23 [INFO]	[EVAL] Class Precision: 
[0.993  0.9672 0.9447 0.8307 0.8686 0.9829 0.9094]
2023-02-05 07:53:23 [INFO]	[EVAL] Class Recall: 
[0.9931 0.9478 0.9431 0.8326 0.8061 0.9895 0.9571]
2023-02-05 07:53:24 [INFO]	[EVAL] The model with the best validation mIoU (0.8692) was saved at iter 246000.
Traceback (most recent call last):
  File "train.py", line 230, in <module>
    main(args)
  File "train.py", line 206, in main
    train(
  File "/data/zcq/PaddleSeg/paddleseg/core/train.py", line 344, in train
    plt.plot(range(0,len(train_loss)[::500],1), train_loss[::500])
TypeError: 'int' object is not subscriptable
